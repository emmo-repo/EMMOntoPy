{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"EMMOntoPy \u00b6 Python API for the Elemental Multiperspective Material Ontology ( EMMO ). Note : EMMOntoPy is a continuation of the EMMO-python project and the associated emmo Python package. To see the legacy versions go to PyPI . This package is based on Owlready2 and provides an intuitive representation of EMMO in Python. It is available on GitHub and on PyPI under the open source BSD 3-Clause license . The Elemental Multiperspective Material Ontology (EMMO) is an ongoing effort to create an ontology that takes into account fundamental concepts of physics, chemistry and materials science and is designed to pave the road for semantic interoperability. The aim of EMMO is to be generic and provide a common ground for describing materials, models and data that can be adapted by all domains. EMMO is formulated using OWL. EMMOntoPy is a Python API for using EMMO to solving real problems. By using the excellent Python package Owlready2 , EMMOntoPy provides a natural representation of EMMO in Python. On top of that EMMOntoPy provides: Access by label (as well as by names, important since class and property names in EMMO are based on UUIDs). Test suite for EMMO-based ontologies. Generation of graphs. Generation of documentation. Command-line tools: emmocheck : Checks an ontology against EMMO conventions. ontoversion : Prints ontology version number. ontograph : Vertasile tool for visualising (parts of) an ontology. ontodoc : Documents an ontology. ontoconvert : Converts between ontology formats. excel2onto : Generate an EMMO-based ontology from an excel file. Some examples of what you can do with EMMOntoPy includes: Access and query RDF-based ontologies from your application. This includes several different flavors of RDF (OWL, Turtle ( ttl ) , and more). Access and query EMMO-based ontologies from your application. Extend EMMO with new domain or application ontologies. This can be done both statically with easy readable Python code or dynamically within your application. Generate graphs and documentation of your ontologies. EMMOntoPy includes ontodoc : A dedicated command line tool for this. You find it in the tools/ sub directory. Check that an EMMO-based domain or application ontology adhere to the conventions of EMMO. Interactively explore an ontology in any Python interpreter, e.g., IPython . Tab-completion makes exploration easy and fast. Below is an example of an IPython session where we check the relations of Matter in EMMO utilizing the emmopy.get_emmo function: In [1]: from emmopy import get_emmo In [2]: emmo = get_emmo() In [3]: emmo.Matter Out[3]: physicalistic.Matter In [4]: emmo.Matter.is_a Out[4]: [physicalistic.Physicalistic, physical.Physical, mereotopology.hasPart.some(physicalistic.Massive), physical.hasTemporalPart.only(physicalistic.Matter)] Documentation and examples \u00b6 The Owlready2 documentation is a good starting point. The EMMOntoPy package also has its own dedicated documentation . This includes a few examples and demos: demo/vertical shows an example of how EMMO may be used to achieve vertical interoperability. The file define-ontology.py provides a good example for how an EMMO-based application ontology can be defined in Python. demo/horizontal shows an example of how EMMO may be used to achieve horizontal interoperability. This demo also shows how you can use EMMOntoPy to represent your ontology with the low-level metadata framework DLite . In addition to achieve interoperability, as shown in the demo, DLite also allow you to automatically generate C or Fortran code base on your ontology. examples/emmodoc shows how the documentation of EMMO is generated using the ontodoc tool. Installation \u00b6 Install with pip install EMMOntoPy Required Dependencies \u00b6 Python 3.7 or later. Owlready2 v0.23 or later. Optional Dependencies \u00b6 Graphviz : Needed for graph generation. With support for generation pdf, png and svg figures for tests and generation of documentation automatically ( ontodoc ). pandoc : Only used for generated documentation from markdown to nicely formatted html or pdf. Tested with v2.1.2. pdfLaTeX or XeLaTeX and the upgreek LaTeX package (included in texlive-was on RetHat-based distributions and texlive-latex-extra on Ubuntu) for generation of pdf documentation. If your ontology contains exotic unicode characters, we recommend XeLaTeX. Java. Needed for reasoning. Optional Python packages: graphviz : Generation of documentation and graphs. PyYAML : Required for generating documentation with pandoc. blessings : Clean output for emmocheck . Pygments : Coloured output for emmocheck . rdflib : Required for ontoversion -tool. semver : Required for ontoversion -tool. pydot : Used for generating graphs. Will be deprecated. pyparsing : Used for parsing Manchester syntax See docker-instructions.md for how to build a docker image. Known issues \u00b6 Invalid serialising to turtle: Due to rdflib issue #1043 ontoconvert may produce invalid turtle output (if your ontology contains real literals using scientific notation without a dot in the mantissa). This issue was fixed after the release of rdflib 5.0.0. Hence, install the latest rdflib from PyPI ( pip install --upgrade rdflib ) or directly from the source code repository: GitHub if you need to serialise to turtle. Attributions and credits \u00b6 EMMOntoPy is maintained by EMMC-ASBL . It has mainly been developed by SINTEF , specifically: Jesper Friis ( jesper-friis ) Francesca L. Bleken ( francescalb ) Casper W. Andersen ( CasperWA ) Bj\u00f8rn Tore L\u00f8vfall ( lovfall ) Contributing projects \u00b6 EMMC-CSA; Grant Agreement No: 723867 The EMMC-ASBL organization takes on the efforts of continuing and expanding on the efforts of the CSA. - MarketPlace ; Grant Agreement No: 760173 - OntoTrans ; Grant Agreement No: 862136 - BIG-MAP ; Grant Agreement No: 957189 - OpenModel ; Grant Agreement No: 953167","title":"Home"},{"location":"#emmontopy","text":"Python API for the Elemental Multiperspective Material Ontology ( EMMO ). Note : EMMOntoPy is a continuation of the EMMO-python project and the associated emmo Python package. To see the legacy versions go to PyPI . This package is based on Owlready2 and provides an intuitive representation of EMMO in Python. It is available on GitHub and on PyPI under the open source BSD 3-Clause license . The Elemental Multiperspective Material Ontology (EMMO) is an ongoing effort to create an ontology that takes into account fundamental concepts of physics, chemistry and materials science and is designed to pave the road for semantic interoperability. The aim of EMMO is to be generic and provide a common ground for describing materials, models and data that can be adapted by all domains. EMMO is formulated using OWL. EMMOntoPy is a Python API for using EMMO to solving real problems. By using the excellent Python package Owlready2 , EMMOntoPy provides a natural representation of EMMO in Python. On top of that EMMOntoPy provides: Access by label (as well as by names, important since class and property names in EMMO are based on UUIDs). Test suite for EMMO-based ontologies. Generation of graphs. Generation of documentation. Command-line tools: emmocheck : Checks an ontology against EMMO conventions. ontoversion : Prints ontology version number. ontograph : Vertasile tool for visualising (parts of) an ontology. ontodoc : Documents an ontology. ontoconvert : Converts between ontology formats. excel2onto : Generate an EMMO-based ontology from an excel file. Some examples of what you can do with EMMOntoPy includes: Access and query RDF-based ontologies from your application. This includes several different flavors of RDF (OWL, Turtle ( ttl ) , and more). Access and query EMMO-based ontologies from your application. Extend EMMO with new domain or application ontologies. This can be done both statically with easy readable Python code or dynamically within your application. Generate graphs and documentation of your ontologies. EMMOntoPy includes ontodoc : A dedicated command line tool for this. You find it in the tools/ sub directory. Check that an EMMO-based domain or application ontology adhere to the conventions of EMMO. Interactively explore an ontology in any Python interpreter, e.g., IPython . Tab-completion makes exploration easy and fast. Below is an example of an IPython session where we check the relations of Matter in EMMO utilizing the emmopy.get_emmo function: In [1]: from emmopy import get_emmo In [2]: emmo = get_emmo() In [3]: emmo.Matter Out[3]: physicalistic.Matter In [4]: emmo.Matter.is_a Out[4]: [physicalistic.Physicalistic, physical.Physical, mereotopology.hasPart.some(physicalistic.Massive), physical.hasTemporalPart.only(physicalistic.Matter)]","title":"EMMOntoPy"},{"location":"#documentation-and-examples","text":"The Owlready2 documentation is a good starting point. The EMMOntoPy package also has its own dedicated documentation . This includes a few examples and demos: demo/vertical shows an example of how EMMO may be used to achieve vertical interoperability. The file define-ontology.py provides a good example for how an EMMO-based application ontology can be defined in Python. demo/horizontal shows an example of how EMMO may be used to achieve horizontal interoperability. This demo also shows how you can use EMMOntoPy to represent your ontology with the low-level metadata framework DLite . In addition to achieve interoperability, as shown in the demo, DLite also allow you to automatically generate C or Fortran code base on your ontology. examples/emmodoc shows how the documentation of EMMO is generated using the ontodoc tool.","title":"Documentation and examples"},{"location":"#installation","text":"Install with pip install EMMOntoPy","title":"Installation"},{"location":"#required-dependencies","text":"Python 3.7 or later. Owlready2 v0.23 or later.","title":"Required Dependencies"},{"location":"#optional-dependencies","text":"Graphviz : Needed for graph generation. With support for generation pdf, png and svg figures for tests and generation of documentation automatically ( ontodoc ). pandoc : Only used for generated documentation from markdown to nicely formatted html or pdf. Tested with v2.1.2. pdfLaTeX or XeLaTeX and the upgreek LaTeX package (included in texlive-was on RetHat-based distributions and texlive-latex-extra on Ubuntu) for generation of pdf documentation. If your ontology contains exotic unicode characters, we recommend XeLaTeX. Java. Needed for reasoning. Optional Python packages: graphviz : Generation of documentation and graphs. PyYAML : Required for generating documentation with pandoc. blessings : Clean output for emmocheck . Pygments : Coloured output for emmocheck . rdflib : Required for ontoversion -tool. semver : Required for ontoversion -tool. pydot : Used for generating graphs. Will be deprecated. pyparsing : Used for parsing Manchester syntax See docker-instructions.md for how to build a docker image.","title":"Optional Dependencies"},{"location":"#known-issues","text":"Invalid serialising to turtle: Due to rdflib issue #1043 ontoconvert may produce invalid turtle output (if your ontology contains real literals using scientific notation without a dot in the mantissa). This issue was fixed after the release of rdflib 5.0.0. Hence, install the latest rdflib from PyPI ( pip install --upgrade rdflib ) or directly from the source code repository: GitHub if you need to serialise to turtle.","title":"Known issues"},{"location":"#attributions-and-credits","text":"EMMOntoPy is maintained by EMMC-ASBL . It has mainly been developed by SINTEF , specifically: Jesper Friis ( jesper-friis ) Francesca L. Bleken ( francescalb ) Casper W. Andersen ( CasperWA ) Bj\u00f8rn Tore L\u00f8vfall ( lovfall )","title":"Attributions and credits"},{"location":"#contributing-projects","text":"EMMC-CSA; Grant Agreement No: 723867 The EMMC-ASBL organization takes on the efforts of continuing and expanding on the efforts of the CSA. - MarketPlace ; Grant Agreement No: 760173 - OntoTrans ; Grant Agreement No: 862136 - BIG-MAP ; Grant Agreement No: 957189 - OpenModel ; Grant Agreement No: 953167","title":"Contributing projects"},{"location":"CHANGELOG/","text":"Changelog \u00b6 Unreleased (2022-10-11) \u00b6 Full Changelog Closed issues: Drop Python 3.6 support - extend Python >3.7 support #486 Update pypi-release github action #482 Make workflows dispatchable #481 excel2onto: Read catalog file for imported ontology #474 Give option to write_catalog for writing relative paths #473 excel2onto: add choice of prefix for imported ontologies #467 Merged pull requests: Makeover for CI/CD workflows, pre-commit & MkDocs #485 ( CasperWA ) write catalog now writes relative paths per default #483 ( francescalb ) Setting prefix explicitly in excelparser #470 ( francescalb ) v0.4.0 (2022-10-04) \u00b6 Full Changelog Fixed bugs: Update repo files with new repo name #479 Pre-commit hook bandit failing #478 Fix publish/release workflow #476 excel2onto: not all relations are included in the generated ontology #457 Unexpected behaviour of get_unabbreviated_triples() #454 Edge without label crash the graph creation #397 Closed issues: excel2onto: restrictions does not allow for using \"emmo:hasProcessOutput some xx\" #464 EMMO is updated to beta4, and now documentation fails #440 some ObjectProperties from EMMO-beta-4.0 cause errors in OntoGraph #429 Excelparser does not write catalog file correctly #421 Add support for prefix #416 Pre.commit failed with ontology.py #415 visualization of EMMO based ontology #412 Avoid infinite recursion when loading catalog file #369 Excelparser: Automatize emmo-based? #335 What are the applications of EMMO for materials informatics? #325 Provide 'support' for same entities with different namespaces #128 Remove deprecated emmo/ontograph.py that uses pydot #103 Merged pull requests: Update from 'EMMO-python' -> 'EMMOntoPy' #477 ( CasperWA ) Allow for adding prefix in manchester notation. #469 ( francescalb ) Fixed issue with exel2onto: not all relations are included in the generated ontology #458 ( jesper-friis ) Added documentation of excel2onto #456 ( jesper-friis ) factpluspluswrapper README file #453 ( jesper-friis ) Improved get_unabbreviated_triples() #449 ( jesper-friis ) Fix loading in windows, url paths #446 ( francescalb ) Fixed reading web destinations defined in catalog #445 ( francescalb ) SUPPORT EMMO-beta4.0 #441 ( francescalb ) Support for userdefined prefixes #439 ( francescalb ) Flb/issue421 #438 ( francescalb ) Update demo #437 ( jesper-friis ) Silence false negative from pylint on github #436 ( jesper-friis ) Better error messages #435 ( jesper-friis ) Updated logo. #418 ( jesper-friis ) cytoscapegraph fails with missing edge labels #414 ( francescalb ) v0.3.1 (2022-05-08) \u00b6 Full Changelog Merged pull requests: Fixed typo in ontoconvert #409 ( jesper-friis ) v0.3.0 (2022-05-05) \u00b6 Full Changelog Fixed bugs: Documentation is currently not building #407 Pytest is currently failing #384 permission denied when working with temporary file #313 Closed issues: Make get_descendants(levels=1) #403 Add functionality for setting name part of IRI to prefLabel #398 Generate excelsheet from ontology. #394 Return a list of the concepts that are disregarded during when converting from excel with -force argument #393 Demo - Broken ontology URLs #390 Excelparser: how to handle entities that already exist in one of the imported ontologies? #334 Merged pull requests: Updated docs python handler #408 ( CasperWA ) Flb/get descendants #405 ( francescalb ) Corrected expected number of returned arguments #404 ( jesper-friis ) Add functionality for setting name part of IRI to prefLabel #399 ( jesper-friis ) create_from_excel/pandas return as list of concepts that are worngly defined in the excelfile #396 ( francescalb ) Download EMMO from raw.github deirectly as redirection is broken #392 ( francescalb ) Workaround for failing test #385 ( CasperWA ) fix #313 remove handle #315 ( sygout ) v0.2.0 (2022-03-02) \u00b6 Full Changelog Implemented enhancements: spaces before or after word in prefLabel makes excelparser fail #332 Make EMMOntopy PyPi #268 Use pre-commit #243 Standard dunder/magic methods for Ontology #228 Update code styling and linting #223 Fix checking PR body & improve error message in CD #318 ( CasperWA ) Fixed bugs: GH GraphQL type issue for auto-merge workflow #374 Missing warning for excel parser relations and problem with \"nan\" #365 Seting metadata in excelparser fails if there are no imported ontologies. #331 Edge-case fails CD workflow for dependabot #319 Ontodoc failing due to wrong rdflib import #306 Overwriting get_triples() method #280 OpenModel logo not loading in README #278 Disable FOAF test as xmlns.com is down #276 Closed issues: Use TEAM 4.0[bot] for GH Actions jobs #352 _get_triples_spo take argumens s, and p, not subject and predicate #350 Add --force to excelparser #333 Cannot load ontology in Windows. #328 make get_ontology accept 'PosixPath' #326 Make EMMOntoPy baseexception and basewarning #321 get_by_label crash if not str #311 make excel parser that creates and ontology from a filled excel file #302 Check out how to get version of ontology #299 Let ontology.new_entity acccept one or more parents directly #294 Make ManchesterSyntaxParser that returns Owlready2 #293 onto.new_entity should throw Error if label name consists of more than one word #290 ReadTheDocs #288 Add logo to README #287 Write EMMO-python is deprecated and link to EMMOtopy on PyPi #269 Consider MarkDown header styling #231 Merged pull requests: Use ID! type instead of String! #375 ( CasperWA ) Avoided infinite recursion when loading catalog files that recursively #370 ( jesper-friis ) Warning relation excelparser #366 ( sygout ) Close temporary file before reading it #364 ( jesper-friis ) Ignore safety ID 44715 + add numpy dependency #361 ( CasperWA ) Use TEAM 4.0[bot] #353 ( CasperWA ) Changed arguments in _has_obj_triples_spo #351 ( francescalb ) Fix serialised ontology iri #341 ( jesper-friis ) Corrected parsing cardinality restrictions #340 ( jesper-friis ) When visualising restrictions, annotate the edges with the restriction type by default #339 ( jesper-friis ) Flb/update excel parser accroding to thermodynamics example #336 ( francescalb ) Added sconverting Posix to str in get_ontology #327 ( francescalb ) Added package specific base exception and base warning for EMMOntoPy #322 ( francescalb ) Added checking that label is string in get_by_label #312 ( francescalb ) Make excelparser that converts a filled excel sheet to an ontology #309 ( francescalb ) Fix ontoconvert rdflib import #307 ( CasperWA ) Check first versionIRI then versionInfo in ontology.get_version() #301 ( francescalb ) Removed .readthedocs.yml #298 ( jesper-friis ) Added support for evaluating Manchester expression to owlready2 #296 ( jesper-friis ) Added functionality for more than one parent in new_entity #295 ( francescalb ) Added test for label name length in ontology.new_entity #291 ( francescalb ) add logo to Readme and doc #289 ( m-abdollahi ) Improved representation of blank nodes #283 ( jesper-friis ) Update method name to avoid overwriting inherited #281 ( CasperWA ) Fixed link to OpenModel logo #279 ( francescalb ) Skip FOAF test #277 ( CasperWA ) Added Standard methods to Ontology #246 ( francescalb ) Implement pre-commit & various tools #245 ( CasperWA ) v0.1.3 (2021-10-27) \u00b6 Full Changelog v0.1.2 (2021-10-27) \u00b6 Full Changelog v0.1.1 (2021-10-27) \u00b6 Full Changelog v0.1.0 (2021-10-27) \u00b6 Full Changelog Implemented enhancements: \"Warning\" Importing from collections #236 Fixed bugs: Loading ontologies that do not import skos fails #261 Fix documentation build warnings #250 Fix images in documentation #233 Circular reference from Owlready2 #210 Closed issues: Write up transfer from EMMOpython to EMMOntoPy i README.md #267 Add test to emmocheck for upcoming EMMO #257 Add packaging as dependency in requirements #255 Add CI check for building documentation #244 Add OpenModel as contributing project #237 Update public documentation to new framework #234 Automate documentation releases #232 Update name of EMMO to Elemental Multiperspective Material Ontology #230 Tidy up unittests #220 Remove importability of sub- factpluspluswrapper folders #213 Make function that automatically loads emmo #209 Require rdflib>5.0.0? #206 change package name #205 test_catalog fails because seraching for .owl in emmo/master #203 Consider using mike for versioned documentation #197 Add a test that checks that loading of non-EMMO based ontologies work - e.g. do not require skos:prefLabel #196 Setup Materials for MkDocs framework #195 Clean up demo, examples and docs #193 Formalize review process with checklists #190 funksjon ontology.add_class(label, parent) #183 Merged pull requests: Reset version to 0.1.0 #271 ( CasperWA ) Update README with PyPI and deprecation msgs #270 ( CasperWA ) Added option: EMMObased = False in ontology.load() #262 ( francescalb ) Added new test \"test_physical_quantity_dimension\" #258 ( jesper-friis ) Add packaging to list of requirements #256 ( CasperWA ) Fix MkDocs build warnings and CI job #254 ( CasperWA ) Update dependencies #252 ( CasperWA ) Add OpenModel contributing project #247 ( francescalb ) Automate documentation releases #242 ( CasperWA ) Import from collections.abc when possible #240 ( CasperWA ) Ensure all produced files from tests are in a temp dir #239 ( CasperWA ) Changed EMMO to be acronym for Elemental Multiperspective Material Ontology #238 ( francescalb ) Use width in img HTML #235 ( CasperWA ) Added function to load the emmo (the ontology) directly #226 ( francescalb ) Created pull request template #225 ( francescalb ) Setup new documentation framework #222 ( CasperWA ) Remove __init__.py files for FaCT++ wrapper (again) #221 ( CasperWA ) Unskip test as #210 has been resolved #218 ( CasperWA ) Remove sub-fact++ modules importability #217 ( CasperWA ) Update requirements #216 ( CasperWA ) Avoid using Owlready2 v0.34 #211 ( CasperWA ) Update package names #208 ( CasperWA ) Added function new_entitiy to ontology #207 ( francescalb ) ttl standard for emmo #204 ( francescalb ) Added choice for specifying namespace in get_by_label #202 ( francescalb ) v1.0.1b (2021-07-01) \u00b6 Full Changelog Closed issues: Correct updating of catalog in ontology.load #188 Merged pull requests: Update version to 1.0.1 #189 ( francescalb ) v1.0.1 (2021-07-01) \u00b6 Full Changelog Fixed bugs: Windows paths are not handled properly #147 Closed issues: Failing tests when lodaing battinfo #185 Fix dependatbot to 'wider' #182 Change to get_label instead of asstring in ontograph, emmodoc, ontodoc, be careful #158 licence does not work with metadata #157 ontograph with several roots fails #153 fix redudant getlabel, get_preferred_label, get_label #152 add --no-catalog and default as in emmocheck for ontograph #150 make tests for checking upgrade of Owlready2 #137 Add periodic_table to examples #130 Add support for simple property-based ontology annotations like dcterms:license #129 Update documentation of tools re reasoner #123 Ontograph: Include multiple parents/inheritance #86 Merged pull requests: Fixed updating of catalog in load #187 ( francescalb ) Temporarily commented out loading ontologies with error in redirecting link on emmo.info #186 ( francescalb ) Changed dependabot to widen #181 ( francescalb ) Changed requirements to greater than #179 ( francescalb ) Owread2-0.32 not accepted die to error in owlready2 triplelite #178 ( francescalb ) Fixed import of defaultstyle in ontograph-tool #177 ( francescalb ) Updated pygments req to at least 2.7.4 because of high seq alert #168 ( francescalb ) Owlready requirement >0.28 #167 ( francescalb ) WIP: Ipycytoscape #163 ( francescalb ) Made it possible to load other ontologies like foaf #162 ( jesper-friis ) Added get_label instead of asstring #160 ( francescalb ) Added write_catalog() #159 ( jesper-friis ) Periodic table example #156 ( francescalb ) Make one get label #154 ( francescalb ) Issue150 ontograph cannotload emmo inferred directly #151 ( francescalb ) Added Fact++ in tools documentation #149 ( francescalb ) Improved issue reporting in emmocheck #146 ( jesper-friis ) v1.0.0 (2021-03-25) \u00b6 Full Changelog Closed issues: Use rdflib in Ontology.save() to support more file formats #143 Tool for publishing domain ontologies #140 Merged pull requests: Save to turtle and ontology annotations (via the metadata attribute) #144 ( jesper-friis ) Corrected configuration of exceptions for test_class_label test. #142 ( jesper-friis ) v1.0.0-alpha-30 (2021-03-18) \u00b6 Full Changelog Merged pull requests: Load ontology #141 ( jesper-friis ) v1.0.0-alpha-29 (2021-03-16) \u00b6 Full Changelog Implemented enhancements: Add Wu&Palmer measure #134 Closed issues: Convert-imported update in utils #138 Merged pull requests: Fixed reading xml as 'rdfxml' #139 ( francescalb ) Added wu_palmer_measure for semantic similarity #135 ( francescalb ) v1.0.0-alpha-28 (2021-03-09) \u00b6 Full Changelog Closed issues: Also use the catalog file to map web URLs, not only local files. #109 Check Error with Owlready2-0.26 #81 Merged pull requests: Version updated for rel of v0.28 #133 ( francescalb ) Load ontology #131 ( jesper-friis ) Optimised label lookup in ontology and dir listing. It is now much faster #127 ( jesper-friis ) Use catalog by default #126 ( jesper-friis ) v1.0.0-alpha-27 (2021-02-27) \u00b6 Full Changelog Merged pull requests: Ontodoc #125 ( jesper-friis ) v1.0.0-alpha-26 (2021-02-26) \u00b6 Full Changelog Closed issues: Make fact++ reasoner available and default in tools #122 Use PyPI token in publish workflow #118 Update publish workflow #115 do something #108 Merged pull requests: Added functionality to document domain ontologies #124 ( jesper-friis ) Made ontoconvert and ontograph tools executable in linux #120 ( jesper-friis ) Update CI #119 ( CasperWA ) Update publish workflow + add dependabot #116 ( CasperWA ) v1.0.0-alpha-25 (2021-01-17) \u00b6 Full Changelog Closed issues: Update Dockerfile to install correct pandoc #99 Correct turtle serialisation #97 Merged pull requests: Update emmocheck exceptions #113 ( jesper-friis ) Fix recursion in graph #112 ( jesper-friis ) Avoid unnessesary/infinite recursion in get_imported_ontologies() #111 ( jesper-friis ) Break recursion error in get_by_label() #110 ( jesper-friis ) Updated the Ontology.sync_attributes() method. #107 ( jesper-friis ) Updated pandoc req in Dockerfile #106 ( francescalb ) v1.0.0-alpha-24 (2021-01-04) \u00b6 Full Changelog Merged pull requests: Bumped version number up to 1.0.0-alpha-24 #105 ( jesper-friis ) v1.0.0-alpha-23 (2021-01-04) \u00b6 Full Changelog Closed issues: Fix loading imported ttl from web such that emmocheck works for crystallography.ttl #98 Add reasoning with FaCT++ #95 Correctly load ontologies like crystallography that imports both local and online sub-ontologies #91 Fix flake8 errors #88 Remove the .ttl namespace when loading domain-crystallography in EMMO-python #83 Add option of documenting imported ontologies in ontodoc and ontograph #82 Emmocheck fails if Physicaluantities and MeaurementsUnits are not imported from emmo. Make sure that it does not fail if whole of EMMO is not imported. #80 Ontograph: Make default root #79 Ontodoc: PDF is not generated, produces error. #76 AttributeError from ontodoc #70 Import emmo .ttl from emmo-repo.github.io #69 Unable to use the vertical interoperability demo .py files #66 Merged pull requests: Release 1.0.0-alpha-23 #104 ( jesper-friis ) Allow to load turtle ontologies without catalog file. #102 ( jesper-friis ) Updated README file #100 ( jesper-friis ) Changed the sync_reasoner() method to use FaCT++ as the default reasoner #94 ( jesper-friis ) Add reasoning #93 ( jesper-friis ) Improve load ontologies #92 ( jesper-friis ) Remove the '.ttl' in namespace names by monkey patching owlready2.Namespace #90 ( jesper-friis ) Fix flake8 warnings #89 ( jesper-friis ) Ontodoc pdf #87 ( jesper-friis ) Automatically find roots in ontograph #85 ( francescalb ) Automatic import of ttl from GitHub emmo-repo.io #84 ( francescalb ) Fixes needed for access ontologies #77 ( jesper-friis ) v1.0.0-alpha-22 (2020-12-21) \u00b6 Full Changelog Merged pull requests: Loading ttl both locally and importing from iri #75 ( francescalb ) Added sync_python_names() and corrected handling of individuals in sync_attributes() #73 ( jesper-friis ) Add preflabel to individuals declared in python #72 ( jesper-friis ) v1.0.0-alpha-21b (2020-12-13) \u00b6 Full Changelog Merged pull requests: Fix bug introduced in ontoconvert #71 ( jesper-friis ) v1.0.0-alpha-21 (2020-12-11) \u00b6 Full Changelog Merged pull requests: Use rdflib to load non-supported formats. #68 ( jesper-friis ) Added a quick fix for vertical demo. #67 ( jesper-friis ) Updated emmocheck to new 1.0.0-beta. Old version should still work. #65 ( jesper-friis ) Added ontoconvert tool #64 ( jesper-friis ) Improved error messages for classes that doesn't define prefLabel #63 ( jesper-friis ) v1.0.0-alpha-20b (2020-11-04) \u00b6 Full Changelog Merged pull requests: Version1.0.0 alpha20 #62 ( francescalb ) v1.0.0-alpha-20 (2020-11-04) \u00b6 Full Changelog Merged pull requests: Improve support for imported ontologies #61 ( jesper-friis ) v1.0.0-alpha-19 (2020-11-02) \u00b6 Full Changelog Merged pull requests: Added --ignore-namespace to emmocheck #60 ( francescalb ) v1.0.0-alpha-18 (2020-10-29) \u00b6 Full Changelog Merged pull requests: Bumped up version number to 1.0.0-alpha-18 #59 ( jesper-friis ) Added option url_from_catalog to ontology.load() #58 ( jesper-friis ) Added get_preferred_label() method to classes, properties and individuals #57 ( jesper-friis ) Correct default IRI to inferred ontology #56 ( jesper-friis ) v1.0.0-alpha-17 (2020-10-21) \u00b6 Full Changelog Merged pull requests: Added materials.EngineeredMaterial to namespace exception in emmocheck #55 ( francescalb ) v1.0.0-alpha-16 (2020-10-20) \u00b6 Full Changelog Closed issues: Include all annotations in .get_annotations() #50 Merged pull requests: Update to v1.0.0-alpha-16 for new release #54 ( francescalb ) Update dimensionality checks #53 ( jesper-friis ) Updated to say that pypi realese is automatic in docs #52 ( francescalb ) v1.0.0-alpha-15 (2020-09-25) \u00b6 Full Changelog Merged pull requests: Added all labels in get_class_annotations in emmo/patch.py including #51 ( francescalb ) Support use of skos:prefLabel instead of rdfs:label #49 ( jesper-friis ) v1.0.0-alpha-14 #48 ( jesper-friis ) Fix emmocheck to not fail upon use of dcterms and skos #47 ( jesper-friis ) v1.0.0-alpha-13 (2020-09-19) \u00b6 Full Changelog Closed issues: Not immediately installable with pip #45 Merged pull requests: Fix setup #46 ( jesper-friis ) Make emmo package pip installable in fresh env #44 ( CasperWA ) Update emmodoc to latest version of emmo-alpha2 #43 ( jesper-friis ) Ensure that emmocheck exit with non-zero return value if a test is faing #42 ( jesper-friis ) Installed missing dependencies in pythonpublish deployment workflow #41 ( jesper-friis ) v1.0.0-alpha-11 (2020-08-12) \u00b6 Full Changelog Merged pull requests: Add skip option to emmocheck #40 ( jesper-friis ) v1.0.0-alpha-10 (2020-04-27) \u00b6 Full Changelog Merged pull requests: Added exceptions to emmocheck \"test_number_of_labels\" #39 ( jesper-friis ) v1.0.0-alpha-9 (2020-04-13) \u00b6 Full Changelog Closed issues: Enhance ontology.sync_attributes() to also update class names #10 Add support for the FaCT++ reasoner #9 Merged pull requests: Set new release version 1.0.0-alpha-9 #38 ( francescalb ) Added get_version() and set_version() methods to emmo.Ontology. #37 ( jesper-friis ) Updated example in README file to current version of EMMO. #36 ( jesper-friis ) Update tools #35 ( jesper-friis ) Updated simplifed demo_vertical in compliance with EMMO-1.0.0alpha2 as of 202\u2026 #34 ( francescalb ) Fixed PyPI badge in README #33 ( jesper-friis ) Update emmocheck #32 ( jesper-friis ) Sync attributes #31 ( jesper-friis ) Cleanup ci workflow #28 ( jesper-friis ) Added ontoversion tool #27 ( jesper-friis ) Update emmodoc #25 ( jesper-friis ) v1.0.0-alpha-8 (2020-03-22) \u00b6 Full Changelog Merged pull requests: 1.0.0 alpha 8 #30 ( jesper-friis ) Updated requirements such that \"pip install EMMO\" works #24 ( jesper-friis ) v1.0.0-alpha-5 (2020-03-18) \u00b6 Full Changelog Implemented enhancements: Make EMMO-python available on pypi (installable with pip) #7 Merged pull requests: Bumbed up version to 1.0.0-alpha-5 #23 ( jesper-friis ) Emmocheck #22 ( jesper-friis ) Reworked the generation of graphs - using the graphviz Python package #21 ( jesper-friis ) 1.0.0 #19 ( jesper-friis ) v1.0.0-alpha-3 (2020-02-16) \u00b6 Full Changelog v1.0.0-alpha-2 (2020-01-11) \u00b6 Full Changelog v1.0.0-alpha-1 (2020-01-11) \u00b6 Full Changelog Closed issues: Missing https://emmc.info/emmo-inferred #16 setup.py #15 Fix emmodoc #6 v1.0.0-alpha (2020-01-08) \u00b6 Full Changelog Closed issues: Update the user case ontology #3 Merged pull requests: Fixed a typo in the title #14 ( blokhin ) Fixed #5 - homogenised call to reasoner #13 ( francescalb ) v0.9.9 (2019-07-14) \u00b6 Full Changelog Closed issues: Homogenise call to reasoner in emmo.Ontology.sync_reasoner() #5 Merged pull requests: #3 update usercase ontology #12 ( jesper-friis ) Fixed 3 #8 ( jesper-friis ) Dockerdevel #2 ( francescalb ) Fix by lukas #1 ( jesper-friis ) * This Changelog was automatically generated by github_changelog_generator","title":"Changelog"},{"location":"CHANGELOG/#changelog","text":"","title":"Changelog"},{"location":"CHANGELOG/#unreleased-2022-10-11","text":"Full Changelog Closed issues: Drop Python 3.6 support - extend Python >3.7 support #486 Update pypi-release github action #482 Make workflows dispatchable #481 excel2onto: Read catalog file for imported ontology #474 Give option to write_catalog for writing relative paths #473 excel2onto: add choice of prefix for imported ontologies #467 Merged pull requests: Makeover for CI/CD workflows, pre-commit & MkDocs #485 ( CasperWA ) write catalog now writes relative paths per default #483 ( francescalb ) Setting prefix explicitly in excelparser #470 ( francescalb )","title":"Unreleased (2022-10-11)"},{"location":"CHANGELOG/#v040-2022-10-04","text":"Full Changelog Fixed bugs: Update repo files with new repo name #479 Pre-commit hook bandit failing #478 Fix publish/release workflow #476 excel2onto: not all relations are included in the generated ontology #457 Unexpected behaviour of get_unabbreviated_triples() #454 Edge without label crash the graph creation #397 Closed issues: excel2onto: restrictions does not allow for using \"emmo:hasProcessOutput some xx\" #464 EMMO is updated to beta4, and now documentation fails #440 some ObjectProperties from EMMO-beta-4.0 cause errors in OntoGraph #429 Excelparser does not write catalog file correctly #421 Add support for prefix #416 Pre.commit failed with ontology.py #415 visualization of EMMO based ontology #412 Avoid infinite recursion when loading catalog file #369 Excelparser: Automatize emmo-based? #335 What are the applications of EMMO for materials informatics? #325 Provide 'support' for same entities with different namespaces #128 Remove deprecated emmo/ontograph.py that uses pydot #103 Merged pull requests: Update from 'EMMO-python' -> 'EMMOntoPy' #477 ( CasperWA ) Allow for adding prefix in manchester notation. #469 ( francescalb ) Fixed issue with exel2onto: not all relations are included in the generated ontology #458 ( jesper-friis ) Added documentation of excel2onto #456 ( jesper-friis ) factpluspluswrapper README file #453 ( jesper-friis ) Improved get_unabbreviated_triples() #449 ( jesper-friis ) Fix loading in windows, url paths #446 ( francescalb ) Fixed reading web destinations defined in catalog #445 ( francescalb ) SUPPORT EMMO-beta4.0 #441 ( francescalb ) Support for userdefined prefixes #439 ( francescalb ) Flb/issue421 #438 ( francescalb ) Update demo #437 ( jesper-friis ) Silence false negative from pylint on github #436 ( jesper-friis ) Better error messages #435 ( jesper-friis ) Updated logo. #418 ( jesper-friis ) cytoscapegraph fails with missing edge labels #414 ( francescalb )","title":"v0.4.0 (2022-10-04)"},{"location":"CHANGELOG/#v031-2022-05-08","text":"Full Changelog Merged pull requests: Fixed typo in ontoconvert #409 ( jesper-friis )","title":"v0.3.1 (2022-05-08)"},{"location":"CHANGELOG/#v030-2022-05-05","text":"Full Changelog Fixed bugs: Documentation is currently not building #407 Pytest is currently failing #384 permission denied when working with temporary file #313 Closed issues: Make get_descendants(levels=1) #403 Add functionality for setting name part of IRI to prefLabel #398 Generate excelsheet from ontology. #394 Return a list of the concepts that are disregarded during when converting from excel with -force argument #393 Demo - Broken ontology URLs #390 Excelparser: how to handle entities that already exist in one of the imported ontologies? #334 Merged pull requests: Updated docs python handler #408 ( CasperWA ) Flb/get descendants #405 ( francescalb ) Corrected expected number of returned arguments #404 ( jesper-friis ) Add functionality for setting name part of IRI to prefLabel #399 ( jesper-friis ) create_from_excel/pandas return as list of concepts that are worngly defined in the excelfile #396 ( francescalb ) Download EMMO from raw.github deirectly as redirection is broken #392 ( francescalb ) Workaround for failing test #385 ( CasperWA ) fix #313 remove handle #315 ( sygout )","title":"v0.3.0 (2022-05-05)"},{"location":"CHANGELOG/#v020-2022-03-02","text":"Full Changelog Implemented enhancements: spaces before or after word in prefLabel makes excelparser fail #332 Make EMMOntopy PyPi #268 Use pre-commit #243 Standard dunder/magic methods for Ontology #228 Update code styling and linting #223 Fix checking PR body & improve error message in CD #318 ( CasperWA ) Fixed bugs: GH GraphQL type issue for auto-merge workflow #374 Missing warning for excel parser relations and problem with \"nan\" #365 Seting metadata in excelparser fails if there are no imported ontologies. #331 Edge-case fails CD workflow for dependabot #319 Ontodoc failing due to wrong rdflib import #306 Overwriting get_triples() method #280 OpenModel logo not loading in README #278 Disable FOAF test as xmlns.com is down #276 Closed issues: Use TEAM 4.0[bot] for GH Actions jobs #352 _get_triples_spo take argumens s, and p, not subject and predicate #350 Add --force to excelparser #333 Cannot load ontology in Windows. #328 make get_ontology accept 'PosixPath' #326 Make EMMOntoPy baseexception and basewarning #321 get_by_label crash if not str #311 make excel parser that creates and ontology from a filled excel file #302 Check out how to get version of ontology #299 Let ontology.new_entity acccept one or more parents directly #294 Make ManchesterSyntaxParser that returns Owlready2 #293 onto.new_entity should throw Error if label name consists of more than one word #290 ReadTheDocs #288 Add logo to README #287 Write EMMO-python is deprecated and link to EMMOtopy on PyPi #269 Consider MarkDown header styling #231 Merged pull requests: Use ID! type instead of String! #375 ( CasperWA ) Avoided infinite recursion when loading catalog files that recursively #370 ( jesper-friis ) Warning relation excelparser #366 ( sygout ) Close temporary file before reading it #364 ( jesper-friis ) Ignore safety ID 44715 + add numpy dependency #361 ( CasperWA ) Use TEAM 4.0[bot] #353 ( CasperWA ) Changed arguments in _has_obj_triples_spo #351 ( francescalb ) Fix serialised ontology iri #341 ( jesper-friis ) Corrected parsing cardinality restrictions #340 ( jesper-friis ) When visualising restrictions, annotate the edges with the restriction type by default #339 ( jesper-friis ) Flb/update excel parser accroding to thermodynamics example #336 ( francescalb ) Added sconverting Posix to str in get_ontology #327 ( francescalb ) Added package specific base exception and base warning for EMMOntoPy #322 ( francescalb ) Added checking that label is string in get_by_label #312 ( francescalb ) Make excelparser that converts a filled excel sheet to an ontology #309 ( francescalb ) Fix ontoconvert rdflib import #307 ( CasperWA ) Check first versionIRI then versionInfo in ontology.get_version() #301 ( francescalb ) Removed .readthedocs.yml #298 ( jesper-friis ) Added support for evaluating Manchester expression to owlready2 #296 ( jesper-friis ) Added functionality for more than one parent in new_entity #295 ( francescalb ) Added test for label name length in ontology.new_entity #291 ( francescalb ) add logo to Readme and doc #289 ( m-abdollahi ) Improved representation of blank nodes #283 ( jesper-friis ) Update method name to avoid overwriting inherited #281 ( CasperWA ) Fixed link to OpenModel logo #279 ( francescalb ) Skip FOAF test #277 ( CasperWA ) Added Standard methods to Ontology #246 ( francescalb ) Implement pre-commit & various tools #245 ( CasperWA )","title":"v0.2.0 (2022-03-02)"},{"location":"CHANGELOG/#v013-2021-10-27","text":"Full Changelog","title":"v0.1.3 (2021-10-27)"},{"location":"CHANGELOG/#v012-2021-10-27","text":"Full Changelog","title":"v0.1.2 (2021-10-27)"},{"location":"CHANGELOG/#v011-2021-10-27","text":"Full Changelog","title":"v0.1.1 (2021-10-27)"},{"location":"CHANGELOG/#v010-2021-10-27","text":"Full Changelog Implemented enhancements: \"Warning\" Importing from collections #236 Fixed bugs: Loading ontologies that do not import skos fails #261 Fix documentation build warnings #250 Fix images in documentation #233 Circular reference from Owlready2 #210 Closed issues: Write up transfer from EMMOpython to EMMOntoPy i README.md #267 Add test to emmocheck for upcoming EMMO #257 Add packaging as dependency in requirements #255 Add CI check for building documentation #244 Add OpenModel as contributing project #237 Update public documentation to new framework #234 Automate documentation releases #232 Update name of EMMO to Elemental Multiperspective Material Ontology #230 Tidy up unittests #220 Remove importability of sub- factpluspluswrapper folders #213 Make function that automatically loads emmo #209 Require rdflib>5.0.0? #206 change package name #205 test_catalog fails because seraching for .owl in emmo/master #203 Consider using mike for versioned documentation #197 Add a test that checks that loading of non-EMMO based ontologies work - e.g. do not require skos:prefLabel #196 Setup Materials for MkDocs framework #195 Clean up demo, examples and docs #193 Formalize review process with checklists #190 funksjon ontology.add_class(label, parent) #183 Merged pull requests: Reset version to 0.1.0 #271 ( CasperWA ) Update README with PyPI and deprecation msgs #270 ( CasperWA ) Added option: EMMObased = False in ontology.load() #262 ( francescalb ) Added new test \"test_physical_quantity_dimension\" #258 ( jesper-friis ) Add packaging to list of requirements #256 ( CasperWA ) Fix MkDocs build warnings and CI job #254 ( CasperWA ) Update dependencies #252 ( CasperWA ) Add OpenModel contributing project #247 ( francescalb ) Automate documentation releases #242 ( CasperWA ) Import from collections.abc when possible #240 ( CasperWA ) Ensure all produced files from tests are in a temp dir #239 ( CasperWA ) Changed EMMO to be acronym for Elemental Multiperspective Material Ontology #238 ( francescalb ) Use width in img HTML #235 ( CasperWA ) Added function to load the emmo (the ontology) directly #226 ( francescalb ) Created pull request template #225 ( francescalb ) Setup new documentation framework #222 ( CasperWA ) Remove __init__.py files for FaCT++ wrapper (again) #221 ( CasperWA ) Unskip test as #210 has been resolved #218 ( CasperWA ) Remove sub-fact++ modules importability #217 ( CasperWA ) Update requirements #216 ( CasperWA ) Avoid using Owlready2 v0.34 #211 ( CasperWA ) Update package names #208 ( CasperWA ) Added function new_entitiy to ontology #207 ( francescalb ) ttl standard for emmo #204 ( francescalb ) Added choice for specifying namespace in get_by_label #202 ( francescalb )","title":"v0.1.0 (2021-10-27)"},{"location":"CHANGELOG/#v101b-2021-07-01","text":"Full Changelog Closed issues: Correct updating of catalog in ontology.load #188 Merged pull requests: Update version to 1.0.1 #189 ( francescalb )","title":"v1.0.1b (2021-07-01)"},{"location":"CHANGELOG/#v101-2021-07-01","text":"Full Changelog Fixed bugs: Windows paths are not handled properly #147 Closed issues: Failing tests when lodaing battinfo #185 Fix dependatbot to 'wider' #182 Change to get_label instead of asstring in ontograph, emmodoc, ontodoc, be careful #158 licence does not work with metadata #157 ontograph with several roots fails #153 fix redudant getlabel, get_preferred_label, get_label #152 add --no-catalog and default as in emmocheck for ontograph #150 make tests for checking upgrade of Owlready2 #137 Add periodic_table to examples #130 Add support for simple property-based ontology annotations like dcterms:license #129 Update documentation of tools re reasoner #123 Ontograph: Include multiple parents/inheritance #86 Merged pull requests: Fixed updating of catalog in load #187 ( francescalb ) Temporarily commented out loading ontologies with error in redirecting link on emmo.info #186 ( francescalb ) Changed dependabot to widen #181 ( francescalb ) Changed requirements to greater than #179 ( francescalb ) Owread2-0.32 not accepted die to error in owlready2 triplelite #178 ( francescalb ) Fixed import of defaultstyle in ontograph-tool #177 ( francescalb ) Updated pygments req to at least 2.7.4 because of high seq alert #168 ( francescalb ) Owlready requirement >0.28 #167 ( francescalb ) WIP: Ipycytoscape #163 ( francescalb ) Made it possible to load other ontologies like foaf #162 ( jesper-friis ) Added get_label instead of asstring #160 ( francescalb ) Added write_catalog() #159 ( jesper-friis ) Periodic table example #156 ( francescalb ) Make one get label #154 ( francescalb ) Issue150 ontograph cannotload emmo inferred directly #151 ( francescalb ) Added Fact++ in tools documentation #149 ( francescalb ) Improved issue reporting in emmocheck #146 ( jesper-friis )","title":"v1.0.1 (2021-07-01)"},{"location":"CHANGELOG/#v100-2021-03-25","text":"Full Changelog Closed issues: Use rdflib in Ontology.save() to support more file formats #143 Tool for publishing domain ontologies #140 Merged pull requests: Save to turtle and ontology annotations (via the metadata attribute) #144 ( jesper-friis ) Corrected configuration of exceptions for test_class_label test. #142 ( jesper-friis )","title":"v1.0.0 (2021-03-25)"},{"location":"CHANGELOG/#v100-alpha-30-2021-03-18","text":"Full Changelog Merged pull requests: Load ontology #141 ( jesper-friis )","title":"v1.0.0-alpha-30 (2021-03-18)"},{"location":"CHANGELOG/#v100-alpha-29-2021-03-16","text":"Full Changelog Implemented enhancements: Add Wu&Palmer measure #134 Closed issues: Convert-imported update in utils #138 Merged pull requests: Fixed reading xml as 'rdfxml' #139 ( francescalb ) Added wu_palmer_measure for semantic similarity #135 ( francescalb )","title":"v1.0.0-alpha-29 (2021-03-16)"},{"location":"CHANGELOG/#v100-alpha-28-2021-03-09","text":"Full Changelog Closed issues: Also use the catalog file to map web URLs, not only local files. #109 Check Error with Owlready2-0.26 #81 Merged pull requests: Version updated for rel of v0.28 #133 ( francescalb ) Load ontology #131 ( jesper-friis ) Optimised label lookup in ontology and dir listing. It is now much faster #127 ( jesper-friis ) Use catalog by default #126 ( jesper-friis )","title":"v1.0.0-alpha-28 (2021-03-09)"},{"location":"CHANGELOG/#v100-alpha-27-2021-02-27","text":"Full Changelog Merged pull requests: Ontodoc #125 ( jesper-friis )","title":"v1.0.0-alpha-27 (2021-02-27)"},{"location":"CHANGELOG/#v100-alpha-26-2021-02-26","text":"Full Changelog Closed issues: Make fact++ reasoner available and default in tools #122 Use PyPI token in publish workflow #118 Update publish workflow #115 do something #108 Merged pull requests: Added functionality to document domain ontologies #124 ( jesper-friis ) Made ontoconvert and ontograph tools executable in linux #120 ( jesper-friis ) Update CI #119 ( CasperWA ) Update publish workflow + add dependabot #116 ( CasperWA )","title":"v1.0.0-alpha-26 (2021-02-26)"},{"location":"CHANGELOG/#v100-alpha-25-2021-01-17","text":"Full Changelog Closed issues: Update Dockerfile to install correct pandoc #99 Correct turtle serialisation #97 Merged pull requests: Update emmocheck exceptions #113 ( jesper-friis ) Fix recursion in graph #112 ( jesper-friis ) Avoid unnessesary/infinite recursion in get_imported_ontologies() #111 ( jesper-friis ) Break recursion error in get_by_label() #110 ( jesper-friis ) Updated the Ontology.sync_attributes() method. #107 ( jesper-friis ) Updated pandoc req in Dockerfile #106 ( francescalb )","title":"v1.0.0-alpha-25 (2021-01-17)"},{"location":"CHANGELOG/#v100-alpha-24-2021-01-04","text":"Full Changelog Merged pull requests: Bumped version number up to 1.0.0-alpha-24 #105 ( jesper-friis )","title":"v1.0.0-alpha-24 (2021-01-04)"},{"location":"CHANGELOG/#v100-alpha-23-2021-01-04","text":"Full Changelog Closed issues: Fix loading imported ttl from web such that emmocheck works for crystallography.ttl #98 Add reasoning with FaCT++ #95 Correctly load ontologies like crystallography that imports both local and online sub-ontologies #91 Fix flake8 errors #88 Remove the .ttl namespace when loading domain-crystallography in EMMO-python #83 Add option of documenting imported ontologies in ontodoc and ontograph #82 Emmocheck fails if Physicaluantities and MeaurementsUnits are not imported from emmo. Make sure that it does not fail if whole of EMMO is not imported. #80 Ontograph: Make default root #79 Ontodoc: PDF is not generated, produces error. #76 AttributeError from ontodoc #70 Import emmo .ttl from emmo-repo.github.io #69 Unable to use the vertical interoperability demo .py files #66 Merged pull requests: Release 1.0.0-alpha-23 #104 ( jesper-friis ) Allow to load turtle ontologies without catalog file. #102 ( jesper-friis ) Updated README file #100 ( jesper-friis ) Changed the sync_reasoner() method to use FaCT++ as the default reasoner #94 ( jesper-friis ) Add reasoning #93 ( jesper-friis ) Improve load ontologies #92 ( jesper-friis ) Remove the '.ttl' in namespace names by monkey patching owlready2.Namespace #90 ( jesper-friis ) Fix flake8 warnings #89 ( jesper-friis ) Ontodoc pdf #87 ( jesper-friis ) Automatically find roots in ontograph #85 ( francescalb ) Automatic import of ttl from GitHub emmo-repo.io #84 ( francescalb ) Fixes needed for access ontologies #77 ( jesper-friis )","title":"v1.0.0-alpha-23 (2021-01-04)"},{"location":"CHANGELOG/#v100-alpha-22-2020-12-21","text":"Full Changelog Merged pull requests: Loading ttl both locally and importing from iri #75 ( francescalb ) Added sync_python_names() and corrected handling of individuals in sync_attributes() #73 ( jesper-friis ) Add preflabel to individuals declared in python #72 ( jesper-friis )","title":"v1.0.0-alpha-22 (2020-12-21)"},{"location":"CHANGELOG/#v100-alpha-21b-2020-12-13","text":"Full Changelog Merged pull requests: Fix bug introduced in ontoconvert #71 ( jesper-friis )","title":"v1.0.0-alpha-21b (2020-12-13)"},{"location":"CHANGELOG/#v100-alpha-21-2020-12-11","text":"Full Changelog Merged pull requests: Use rdflib to load non-supported formats. #68 ( jesper-friis ) Added a quick fix for vertical demo. #67 ( jesper-friis ) Updated emmocheck to new 1.0.0-beta. Old version should still work. #65 ( jesper-friis ) Added ontoconvert tool #64 ( jesper-friis ) Improved error messages for classes that doesn't define prefLabel #63 ( jesper-friis )","title":"v1.0.0-alpha-21 (2020-12-11)"},{"location":"CHANGELOG/#v100-alpha-20b-2020-11-04","text":"Full Changelog Merged pull requests: Version1.0.0 alpha20 #62 ( francescalb )","title":"v1.0.0-alpha-20b (2020-11-04)"},{"location":"CHANGELOG/#v100-alpha-20-2020-11-04","text":"Full Changelog Merged pull requests: Improve support for imported ontologies #61 ( jesper-friis )","title":"v1.0.0-alpha-20 (2020-11-04)"},{"location":"CHANGELOG/#v100-alpha-19-2020-11-02","text":"Full Changelog Merged pull requests: Added --ignore-namespace to emmocheck #60 ( francescalb )","title":"v1.0.0-alpha-19 (2020-11-02)"},{"location":"CHANGELOG/#v100-alpha-18-2020-10-29","text":"Full Changelog Merged pull requests: Bumped up version number to 1.0.0-alpha-18 #59 ( jesper-friis ) Added option url_from_catalog to ontology.load() #58 ( jesper-friis ) Added get_preferred_label() method to classes, properties and individuals #57 ( jesper-friis ) Correct default IRI to inferred ontology #56 ( jesper-friis )","title":"v1.0.0-alpha-18 (2020-10-29)"},{"location":"CHANGELOG/#v100-alpha-17-2020-10-21","text":"Full Changelog Merged pull requests: Added materials.EngineeredMaterial to namespace exception in emmocheck #55 ( francescalb )","title":"v1.0.0-alpha-17 (2020-10-21)"},{"location":"CHANGELOG/#v100-alpha-16-2020-10-20","text":"Full Changelog Closed issues: Include all annotations in .get_annotations() #50 Merged pull requests: Update to v1.0.0-alpha-16 for new release #54 ( francescalb ) Update dimensionality checks #53 ( jesper-friis ) Updated to say that pypi realese is automatic in docs #52 ( francescalb )","title":"v1.0.0-alpha-16 (2020-10-20)"},{"location":"CHANGELOG/#v100-alpha-15-2020-09-25","text":"Full Changelog Merged pull requests: Added all labels in get_class_annotations in emmo/patch.py including #51 ( francescalb ) Support use of skos:prefLabel instead of rdfs:label #49 ( jesper-friis ) v1.0.0-alpha-14 #48 ( jesper-friis ) Fix emmocheck to not fail upon use of dcterms and skos #47 ( jesper-friis )","title":"v1.0.0-alpha-15 (2020-09-25)"},{"location":"CHANGELOG/#v100-alpha-13-2020-09-19","text":"Full Changelog Closed issues: Not immediately installable with pip #45 Merged pull requests: Fix setup #46 ( jesper-friis ) Make emmo package pip installable in fresh env #44 ( CasperWA ) Update emmodoc to latest version of emmo-alpha2 #43 ( jesper-friis ) Ensure that emmocheck exit with non-zero return value if a test is faing #42 ( jesper-friis ) Installed missing dependencies in pythonpublish deployment workflow #41 ( jesper-friis )","title":"v1.0.0-alpha-13 (2020-09-19)"},{"location":"CHANGELOG/#v100-alpha-11-2020-08-12","text":"Full Changelog Merged pull requests: Add skip option to emmocheck #40 ( jesper-friis )","title":"v1.0.0-alpha-11 (2020-08-12)"},{"location":"CHANGELOG/#v100-alpha-10-2020-04-27","text":"Full Changelog Merged pull requests: Added exceptions to emmocheck \"test_number_of_labels\" #39 ( jesper-friis )","title":"v1.0.0-alpha-10 (2020-04-27)"},{"location":"CHANGELOG/#v100-alpha-9-2020-04-13","text":"Full Changelog Closed issues: Enhance ontology.sync_attributes() to also update class names #10 Add support for the FaCT++ reasoner #9 Merged pull requests: Set new release version 1.0.0-alpha-9 #38 ( francescalb ) Added get_version() and set_version() methods to emmo.Ontology. #37 ( jesper-friis ) Updated example in README file to current version of EMMO. #36 ( jesper-friis ) Update tools #35 ( jesper-friis ) Updated simplifed demo_vertical in compliance with EMMO-1.0.0alpha2 as of 202\u2026 #34 ( francescalb ) Fixed PyPI badge in README #33 ( jesper-friis ) Update emmocheck #32 ( jesper-friis ) Sync attributes #31 ( jesper-friis ) Cleanup ci workflow #28 ( jesper-friis ) Added ontoversion tool #27 ( jesper-friis ) Update emmodoc #25 ( jesper-friis )","title":"v1.0.0-alpha-9 (2020-04-13)"},{"location":"CHANGELOG/#v100-alpha-8-2020-03-22","text":"Full Changelog Merged pull requests: 1.0.0 alpha 8 #30 ( jesper-friis ) Updated requirements such that \"pip install EMMO\" works #24 ( jesper-friis )","title":"v1.0.0-alpha-8 (2020-03-22)"},{"location":"CHANGELOG/#v100-alpha-5-2020-03-18","text":"Full Changelog Implemented enhancements: Make EMMO-python available on pypi (installable with pip) #7 Merged pull requests: Bumbed up version to 1.0.0-alpha-5 #23 ( jesper-friis ) Emmocheck #22 ( jesper-friis ) Reworked the generation of graphs - using the graphviz Python package #21 ( jesper-friis ) 1.0.0 #19 ( jesper-friis )","title":"v1.0.0-alpha-5 (2020-03-18)"},{"location":"CHANGELOG/#v100-alpha-3-2020-02-16","text":"Full Changelog","title":"v1.0.0-alpha-3 (2020-02-16)"},{"location":"CHANGELOG/#v100-alpha-2-2020-01-11","text":"Full Changelog","title":"v1.0.0-alpha-2 (2020-01-11)"},{"location":"CHANGELOG/#v100-alpha-1-2020-01-11","text":"Full Changelog Closed issues: Missing https://emmc.info/emmo-inferred #16 setup.py #15 Fix emmodoc #6","title":"v1.0.0-alpha-1 (2020-01-11)"},{"location":"CHANGELOG/#v100-alpha-2020-01-08","text":"Full Changelog Closed issues: Update the user case ontology #3 Merged pull requests: Fixed a typo in the title #14 ( blokhin ) Fixed #5 - homogenised call to reasoner #13 ( francescalb )","title":"v1.0.0-alpha (2020-01-08)"},{"location":"CHANGELOG/#v099-2019-07-14","text":"Full Changelog Closed issues: Homogenise call to reasoner in emmo.Ontology.sync_reasoner() #5 Merged pull requests: #3 update usercase ontology #12 ( jesper-friis ) Fixed 3 #8 ( jesper-friis ) Dockerdevel #2 ( francescalb ) Fix by lukas #1 ( jesper-friis ) * This Changelog was automatically generated by github_changelog_generator","title":"v0.9.9 (2019-07-14)"},{"location":"LICENSE/","text":"Copyright 2019-2022 SINTEF Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"License"},{"location":"docker-instructions/","text":"EMMOntoPy Docker \u00b6 Clone project \u00b6 git clone git@github.com:emmo-repo/EMMOntoPy.git Build Docker image \u00b6 cd EMMOntoPy docker build -t emmo . Run Docker container \u00b6 docker run -it emmo Notes \u00b6 Your Docker container may run out of memory while executing the HermiT reasoner ( sync_reasoner ). Append --memory=2GB to docker run in order to align the memory limit with the Java runtime environment. It is recommended to instead use the FaCT++ reaonser (now default). Uncomment the last line in the Dockerfile, if you wish to start directly in the Python interpreter. Dockerfile for mounting EMMOntoPy as volume (mount.Dockerfile) \u00b6 Build Docker image (mount.DockerFile) \u00b6 docker build -t emmomount -f mount.Dockerfile . Run Docker container (mount.Dockerfile) \u00b6 In a unix terminal (Linux) docker run --rm -it -v $( pwd ) :/home/user/EMMOntoPy emmomount In PowerShell (Windows 10): docker run - -rm -it -v ${ PWD }:/ home / user / EMMOntoPy emmomount To install EMMOntoPy package inside container: cd EMMOntoPy pip install . Notes on mounting on Windows \u00b6 Allow for mounting of C: in Docker (as administrator). Docker (rightclick in system tray) -> Settings -> Shared Drives -> tick of C -> Apply. Run the following command in PowerShell: Set-NetConnectionProfile -interfacealias \"vEthernet (DockerNAT)\" -NetworkCategory Private If mounting does not succeed Reset Credentials (Docker -> Settings -> Shared Drives) and repeat the steps above.","title":"Docker"},{"location":"docker-instructions/#emmontopy-docker","text":"","title":"EMMOntoPy Docker"},{"location":"docker-instructions/#clone-project","text":"git clone git@github.com:emmo-repo/EMMOntoPy.git","title":"Clone project"},{"location":"docker-instructions/#build-docker-image","text":"cd EMMOntoPy docker build -t emmo .","title":"Build Docker image"},{"location":"docker-instructions/#run-docker-container","text":"docker run -it emmo","title":"Run Docker container"},{"location":"docker-instructions/#notes","text":"Your Docker container may run out of memory while executing the HermiT reasoner ( sync_reasoner ). Append --memory=2GB to docker run in order to align the memory limit with the Java runtime environment. It is recommended to instead use the FaCT++ reaonser (now default). Uncomment the last line in the Dockerfile, if you wish to start directly in the Python interpreter.","title":"Notes"},{"location":"docker-instructions/#dockerfile-for-mounting-emmontopy-as-volume-mountdockerfile","text":"","title":"Dockerfile for mounting EMMOntoPy as volume (mount.Dockerfile)"},{"location":"docker-instructions/#build-docker-image-mountdockerfile","text":"docker build -t emmomount -f mount.Dockerfile .","title":"Build Docker image (mount.DockerFile)"},{"location":"docker-instructions/#run-docker-container-mountdockerfile","text":"In a unix terminal (Linux) docker run --rm -it -v $( pwd ) :/home/user/EMMOntoPy emmomount In PowerShell (Windows 10): docker run - -rm -it -v ${ PWD }:/ home / user / EMMOntoPy emmomount To install EMMOntoPy package inside container: cd EMMOntoPy pip install .","title":"Run Docker container (mount.Dockerfile)"},{"location":"docker-instructions/#notes-on-mounting-on-windows","text":"Allow for mounting of C: in Docker (as administrator). Docker (rightclick in system tray) -> Settings -> Shared Drives -> tick of C -> Apply. Run the following command in PowerShell: Set-NetConnectionProfile -interfacealias \"vEthernet (DockerNAT)\" -NetworkCategory Private If mounting does not succeed Reset Credentials (Docker -> Settings -> Shared Drives) and repeat the steps above.","title":"Notes on mounting on Windows"},{"location":"tools-instructions/","text":"Instructions for tools available in EMMOntoPy \u00b6 Content: emmocheck ontoversion ontograph ontodoc ontoconvert excel2onto emmocheck \u00b6 Tool for checking that ontologies conform to EMMO conventions. Usage \u00b6 emmocheck [options] iri Options \u00b6 positional arguments: iri File name or URI to the ontology to test. optional arguments: -h, --help show this help message and exit --database FILENAME, -d FILENAME Load ontology from Owlready2 sqlite3 database. The `iri` argument should in this case be the IRI of the ontology you want to check. --local, -l Load imported ontologies locally. Their paths are specified in Prot\u00e9g\u00e9 catalog files or via the --path option. The IRI should be a file name. --catalog-file CATALOG_FILE Name of Prot\u00e9g\u00e9 catalog file in the same folder as the ontology. This option is used together with --local and defaults to \"catalog-v001.xml\". --path PATH Paths where imported ontologies can be found. May be provided as a comma-separated string and/or with multiple --path options. --check-imported, -i Whether to check imported ontologies. --verbose, -v Verbosity level. --configfile CONFIGFILE, -c CONFIGFILE A yaml file with additional test configurations. --skip, -s ShellPattern Shell pattern matching tests to skip. This option may be provided multiple times. --url-from-catalog, -u Get url from catalog file. --ignore-namespace, -n Namespace to be ignored. Can be given multiple times Examples \u00b6 emmocheck http://emmo.info/emmo/1.0.0-alpha2 emmocheck --database demo.sqlite3 http://www.emmc.info/emmc-csa/demo# emmocheck -l emmo.owl (in folder to which emmo was downloaded locally) emmocheck --check-imported --ignore-namespace=physicalistic --verbose --url-from-catalog emmo.owl (in folder with downloaded EMMO) emmocheck --check-imported --local --url-from-catalog --skip test_namespace emmo.owl Example configuration file \u00b6 Example of YAML configuration file provided with the --configfile option that will omit myunits.MyUnitCategory1 and myunits.MyUnitCategory1 from the unit dimensions test . test_unit_dimensions: exceptions: - myunits.MyUnitCategory1 - myunits.MyUnitCategory2 ontoversion \u00b6 Prints version of an ontology to standard output. This script uses RDFLib and the versionIRI tag of the ontology to infer the version. Usage \u00b6 ontoversion [options] iri Special dependencies \u00b6 rdflib (Python package) Options \u00b6 positional arguments: IRI IRI/file to OWL source to extract the version from. optional arguments: -h, --help show this help message and exit --format FORMAT, -f FORMAT OWL format. Default is \"xml\". Examples \u00b6 ontoversion http://emmo.info/emmo/1.0.0-alpha Warning Fails if ontology has no versionIRI tag. ontograph \u00b6 Tool for visualizing ontologies. Usage \u00b6 ontograph [options] iri [output] Dependencies \u00b6 Graphviz Options \u00b6 positional arguments: IRI File name or URI of the ontology to visualise. output name of output file. optional arguments: -h, --help show this help message and exit --format FORMAT, -f FORMAT Format of output file. By default it is inferred from the output file extension. --database FILENAME, -d FILENAME Load ontology from Owlready2 sqlite3 database. The `iri` argument should in this case be the IRI of the ontology you want to visualise. --local, -l Load imported ontologies locally. Their paths are specified in Prot\u00e9g\u00e9 catalog files or via the --path option. The IRI should be a file name. --catalog-file CATALOG_FILE Name of Prot\u00e9g\u00e9 catalog file in the same folder as the ontology. This option is used together with --local and defaults to \"catalog-v001.xml\". --path PATH Paths where imported ontologies can be found. May be provided as a comma-separated string and/or with multiple --path options. --reasoner [{FaCT++,HermiT,Pellet}] Run given reasoner on the ontology. Valid reasoners are \"FaCT++\" (default), \"HermiT\" and \"Pellet\". Note: FaCT++ is preferred with EMMO. --root ROOT, -r ROOT Name of root node in the graph. Defaults to all classes. --leafs LEAFS Leafs nodes for plotting sub-graphs. May be provided as a comma-separated string and/or with multiple --leafs options. --exclude EXCLUDE, -E EXCLUDE Nodes, including their subclasses, to exclude from sub-graphs. May be provided as a comma-separated string and/or with multiple --exclude options. --parents N, -p N Adds N levels of parents to graph. --relations RELATIONS, -R RELATIONS Comma-separated string of relations to visualise. Default is \"isA\". \"all\" means include all relations. --edgelabels, -e Whether to add labels to edges. --addnodes, -n Whether to add missing target nodes in relations. --addconstructs, -c Whether to add nodes representing class constructs. --rankdir {BT,TB,RL,LR} Graph direction (from leaves to root). Possible values are: \"BT\" (bottom-top, default), \"TB\" (top-bottom), \"RL\" (right-left) and \"LR\" (left-right). --style-file JSON_FILE, -s JSON_FILE A json file with style definitions. --legend, -L Whether to add a legend to the graph. --generate-style-file JSON_FILE, -S JSON_FILE Write default style file to a json file. --plot-modules, -m Whether to plot module inter-dependencies instead of their content. --display, -D Whether to display graph. Examples \u00b6 The figure below is generated with the following command: ontograph --root=Material --relations=all --legend emmo-inferred material.png ontodoc \u00b6 Tool for documenting ontologies. Usage \u00b6 ontodoc [options] iri outfile Dependencies \u00b6 pandoc pdflatex or xelatex Options \u00b6 positional arguments: IRI File name or URI of the ontology to document. OUTFILE Output file. optional arguments: -h, --help show this help message and exit --database FILENAME, -d FILENAME Load ontology from Owlready2 sqlite3 database. The `iri` argument should in this case be the IRI of the ontology you want to document. --local, -l Load imported ontologies locally. Their paths are specified in Prot\u00e9g\u00e9 catalog files or via the --path option. The IRI should be a file name. --imported, -i Include imported ontologies --no-catalog, -n Do not read url from catalog even if it exists. --catalog-file CATALOG_FILE Name of Prot\u00e9g\u00e9 catalog file in the same folder as the ontology. This option is used together with --local and defaults to \"catalog-v001.xml\". --path PATH Paths where imported ontologies can be found. May be provided as a comma-separated string and/or with multiple --path options. --reasoner [{FaCT++,HermiT,Pellet}] Run given reasoner on the ontology. Valid reasoners are \"FaCT++\" (default), \"HermiT\" and \"Pellet\". Note: FaCT++ is preferred with EMMO. --template FILE, -t FILE ontodoc input template. If not provided, a simple default template will be used. Don't confuse it with the pandoc templates. --format FORMAT, -f FORMAT Output format. May be \"md\", \"simple-html\" or any other format supported by pandoc. By default the format is inferred from --output. --figdir DIR, -D DIR Default directory to store generated figures. If a relative path is given, it is relative to the template (see --template), or the current directory, if --template is not given. Default: \"genfigs\" --figformat FIGFORMAT, -F FIGFORMAT Format for generated figures. The default is inferred from --format.\" --max-figwidth MAX_FIGWIDTH, -w MAX_FIGWIDTH Maximum figure width. The default is inferred from --format. --pandoc-option STRING, -p STRING Additional pandoc long options overriding those read from --pandoc-option-file. It is possible to remove pandoc option --XXX with \"--pandoc-option=no-XXX\". This option may be provided multiple times. --pandoc-option-file FILE, -P FILE YAML file with additional pandoc options. Note, that default pandoc options are read from the files \"pandoc-options.yaml\" and \"pandoc-FORMAT-options.yaml\" (where FORMAT is format specified with --format). This option allows to override the defaults and add additional pandoc options. This option may be provided multiple times. --keep-generated FILE, -k FILE Keep a copy of generated markdown input file for pandoc (for debugging). Examples \u00b6 Basic documentation of an ontology demo.owl can be generated with: ontodoc --format=simple-html --local demo.owl demo.html See examples/emmodoc/README.md for how this tool is used to generate the html and pdf documentation of EMMO itself. ontoconvert \u00b6 Tool for converting between different ontology formats. Usage \u00b6 ontoconvert [options] inputfile outputfile Dependencies \u00b6 rdflib (Python package) Options \u00b6 positional arguments: INPUTFILE Name of inputfile. OUTPUTFILE Name og output file. optional arguments: -h, --help show this help message and exit --input-format, -f INPUT_FORMAT Inputformat. Default is to infer from input. --output-format, -F OUTPUT_FORMAT Default is to infer from output. --no-catalog, -n Do not read catalog even if it exists. --inferred, -i Add additional relations inferred by the FaCT++ reasoner to the converted ontology. Implies --squash. --base-iri BASE_IRI, -b BASE_IRI Base iri of inferred ontology. The default is the base iri of the input ontology with \"-inferred\" appended to it. Used together with --inferred. --recursive, -r The output is written to the directories matching the input. This requires Protege catalog files to be present. --squash, -s Squash imported ontologies into a single output file. Examples \u00b6 ontoconvert --recursive emmo.ttl owl/emmo.owl ontoconvert --inferred emmo.ttl emmo-inferred.owl Note, it is then required to add the argument only_local=True when loading the locally converted ontology in EMMOntoPy, e.g.: from ontopy import get_ontology emmo_ontology = get_ontology ( \"emmo.owl\" ) . load ( only_local = True ) Since the catalog file will be overwritten in the above example writing output to a separate directory is useful. ontoconvert --recursive emmo.ttl owl/emmo.owl Bugs \u00b6 Since parsing the results from the reasoner is currently broken in Owlready2 (v0.37), a workaround has been added to ontoconvert. This workaround only only supports FaCT++. Hence, HermiT and Pellet are currently not available. excel2onto \u00b6 Tool for converting EMMO-based ontologies from Excel to OWL, making it easy for non-ontologists to make EMMO-based domain ontologies. The Excel file must be in the format provided by ontology_template.xlsx. Usage \u00b6 excel2onto [options] excelpath Dependencies \u00b6 pandas (Python package) Options \u00b6 positional arguments: excelpath path to excel book options: -h, --help show this help message and exit --output OUTPUT, -o OUTPUT Name of output ontology, \u00b4ontology.ttl\u00b4 is default --force, -f Whether to force generation of ontology on non-fatal error. Examples \u00b6 Create a new_ontology.ttl turtle file from the Excel file new_ontology.xlsx : excel2onto -o new_ontology.ttl new_ontology.xlsx Bugs \u00b6 equivalentTo is currently not supported.","title":"Tools"},{"location":"tools-instructions/#instructions-for-tools-available-in-emmontopy","text":"Content: emmocheck ontoversion ontograph ontodoc ontoconvert excel2onto","title":"Instructions for tools available in EMMOntoPy"},{"location":"tools-instructions/#emmocheck","text":"Tool for checking that ontologies conform to EMMO conventions.","title":"emmocheck"},{"location":"tools-instructions/#usage","text":"emmocheck [options] iri","title":"Usage"},{"location":"tools-instructions/#options","text":"positional arguments: iri File name or URI to the ontology to test. optional arguments: -h, --help show this help message and exit --database FILENAME, -d FILENAME Load ontology from Owlready2 sqlite3 database. The `iri` argument should in this case be the IRI of the ontology you want to check. --local, -l Load imported ontologies locally. Their paths are specified in Prot\u00e9g\u00e9 catalog files or via the --path option. The IRI should be a file name. --catalog-file CATALOG_FILE Name of Prot\u00e9g\u00e9 catalog file in the same folder as the ontology. This option is used together with --local and defaults to \"catalog-v001.xml\". --path PATH Paths where imported ontologies can be found. May be provided as a comma-separated string and/or with multiple --path options. --check-imported, -i Whether to check imported ontologies. --verbose, -v Verbosity level. --configfile CONFIGFILE, -c CONFIGFILE A yaml file with additional test configurations. --skip, -s ShellPattern Shell pattern matching tests to skip. This option may be provided multiple times. --url-from-catalog, -u Get url from catalog file. --ignore-namespace, -n Namespace to be ignored. Can be given multiple times","title":"Options"},{"location":"tools-instructions/#examples","text":"emmocheck http://emmo.info/emmo/1.0.0-alpha2 emmocheck --database demo.sqlite3 http://www.emmc.info/emmc-csa/demo# emmocheck -l emmo.owl (in folder to which emmo was downloaded locally) emmocheck --check-imported --ignore-namespace=physicalistic --verbose --url-from-catalog emmo.owl (in folder with downloaded EMMO) emmocheck --check-imported --local --url-from-catalog --skip test_namespace emmo.owl","title":"Examples"},{"location":"tools-instructions/#example-configuration-file","text":"Example of YAML configuration file provided with the --configfile option that will omit myunits.MyUnitCategory1 and myunits.MyUnitCategory1 from the unit dimensions test . test_unit_dimensions: exceptions: - myunits.MyUnitCategory1 - myunits.MyUnitCategory2","title":"Example configuration file"},{"location":"tools-instructions/#ontoversion","text":"Prints version of an ontology to standard output. This script uses RDFLib and the versionIRI tag of the ontology to infer the version.","title":"ontoversion"},{"location":"tools-instructions/#usage_1","text":"ontoversion [options] iri","title":"Usage"},{"location":"tools-instructions/#special-dependencies","text":"rdflib (Python package)","title":"Special dependencies"},{"location":"tools-instructions/#options_1","text":"positional arguments: IRI IRI/file to OWL source to extract the version from. optional arguments: -h, --help show this help message and exit --format FORMAT, -f FORMAT OWL format. Default is \"xml\".","title":"Options"},{"location":"tools-instructions/#examples_1","text":"ontoversion http://emmo.info/emmo/1.0.0-alpha Warning Fails if ontology has no versionIRI tag.","title":"Examples"},{"location":"tools-instructions/#ontograph","text":"Tool for visualizing ontologies.","title":"ontograph"},{"location":"tools-instructions/#usage_2","text":"ontograph [options] iri [output]","title":"Usage"},{"location":"tools-instructions/#dependencies","text":"Graphviz","title":"Dependencies"},{"location":"tools-instructions/#options_2","text":"positional arguments: IRI File name or URI of the ontology to visualise. output name of output file. optional arguments: -h, --help show this help message and exit --format FORMAT, -f FORMAT Format of output file. By default it is inferred from the output file extension. --database FILENAME, -d FILENAME Load ontology from Owlready2 sqlite3 database. The `iri` argument should in this case be the IRI of the ontology you want to visualise. --local, -l Load imported ontologies locally. Their paths are specified in Prot\u00e9g\u00e9 catalog files or via the --path option. The IRI should be a file name. --catalog-file CATALOG_FILE Name of Prot\u00e9g\u00e9 catalog file in the same folder as the ontology. This option is used together with --local and defaults to \"catalog-v001.xml\". --path PATH Paths where imported ontologies can be found. May be provided as a comma-separated string and/or with multiple --path options. --reasoner [{FaCT++,HermiT,Pellet}] Run given reasoner on the ontology. Valid reasoners are \"FaCT++\" (default), \"HermiT\" and \"Pellet\". Note: FaCT++ is preferred with EMMO. --root ROOT, -r ROOT Name of root node in the graph. Defaults to all classes. --leafs LEAFS Leafs nodes for plotting sub-graphs. May be provided as a comma-separated string and/or with multiple --leafs options. --exclude EXCLUDE, -E EXCLUDE Nodes, including their subclasses, to exclude from sub-graphs. May be provided as a comma-separated string and/or with multiple --exclude options. --parents N, -p N Adds N levels of parents to graph. --relations RELATIONS, -R RELATIONS Comma-separated string of relations to visualise. Default is \"isA\". \"all\" means include all relations. --edgelabels, -e Whether to add labels to edges. --addnodes, -n Whether to add missing target nodes in relations. --addconstructs, -c Whether to add nodes representing class constructs. --rankdir {BT,TB,RL,LR} Graph direction (from leaves to root). Possible values are: \"BT\" (bottom-top, default), \"TB\" (top-bottom), \"RL\" (right-left) and \"LR\" (left-right). --style-file JSON_FILE, -s JSON_FILE A json file with style definitions. --legend, -L Whether to add a legend to the graph. --generate-style-file JSON_FILE, -S JSON_FILE Write default style file to a json file. --plot-modules, -m Whether to plot module inter-dependencies instead of their content. --display, -D Whether to display graph.","title":"Options"},{"location":"tools-instructions/#examples_2","text":"The figure below is generated with the following command: ontograph --root=Material --relations=all --legend emmo-inferred material.png","title":"Examples"},{"location":"tools-instructions/#ontodoc","text":"Tool for documenting ontologies.","title":"ontodoc"},{"location":"tools-instructions/#usage_3","text":"ontodoc [options] iri outfile","title":"Usage"},{"location":"tools-instructions/#dependencies_1","text":"pandoc pdflatex or xelatex","title":"Dependencies"},{"location":"tools-instructions/#options_3","text":"positional arguments: IRI File name or URI of the ontology to document. OUTFILE Output file. optional arguments: -h, --help show this help message and exit --database FILENAME, -d FILENAME Load ontology from Owlready2 sqlite3 database. The `iri` argument should in this case be the IRI of the ontology you want to document. --local, -l Load imported ontologies locally. Their paths are specified in Prot\u00e9g\u00e9 catalog files or via the --path option. The IRI should be a file name. --imported, -i Include imported ontologies --no-catalog, -n Do not read url from catalog even if it exists. --catalog-file CATALOG_FILE Name of Prot\u00e9g\u00e9 catalog file in the same folder as the ontology. This option is used together with --local and defaults to \"catalog-v001.xml\". --path PATH Paths where imported ontologies can be found. May be provided as a comma-separated string and/or with multiple --path options. --reasoner [{FaCT++,HermiT,Pellet}] Run given reasoner on the ontology. Valid reasoners are \"FaCT++\" (default), \"HermiT\" and \"Pellet\". Note: FaCT++ is preferred with EMMO. --template FILE, -t FILE ontodoc input template. If not provided, a simple default template will be used. Don't confuse it with the pandoc templates. --format FORMAT, -f FORMAT Output format. May be \"md\", \"simple-html\" or any other format supported by pandoc. By default the format is inferred from --output. --figdir DIR, -D DIR Default directory to store generated figures. If a relative path is given, it is relative to the template (see --template), or the current directory, if --template is not given. Default: \"genfigs\" --figformat FIGFORMAT, -F FIGFORMAT Format for generated figures. The default is inferred from --format.\" --max-figwidth MAX_FIGWIDTH, -w MAX_FIGWIDTH Maximum figure width. The default is inferred from --format. --pandoc-option STRING, -p STRING Additional pandoc long options overriding those read from --pandoc-option-file. It is possible to remove pandoc option --XXX with \"--pandoc-option=no-XXX\". This option may be provided multiple times. --pandoc-option-file FILE, -P FILE YAML file with additional pandoc options. Note, that default pandoc options are read from the files \"pandoc-options.yaml\" and \"pandoc-FORMAT-options.yaml\" (where FORMAT is format specified with --format). This option allows to override the defaults and add additional pandoc options. This option may be provided multiple times. --keep-generated FILE, -k FILE Keep a copy of generated markdown input file for pandoc (for debugging).","title":"Options"},{"location":"tools-instructions/#examples_3","text":"Basic documentation of an ontology demo.owl can be generated with: ontodoc --format=simple-html --local demo.owl demo.html See examples/emmodoc/README.md for how this tool is used to generate the html and pdf documentation of EMMO itself.","title":"Examples"},{"location":"tools-instructions/#ontoconvert","text":"Tool for converting between different ontology formats.","title":"ontoconvert"},{"location":"tools-instructions/#usage_4","text":"ontoconvert [options] inputfile outputfile","title":"Usage"},{"location":"tools-instructions/#dependencies_2","text":"rdflib (Python package)","title":"Dependencies"},{"location":"tools-instructions/#options_4","text":"positional arguments: INPUTFILE Name of inputfile. OUTPUTFILE Name og output file. optional arguments: -h, --help show this help message and exit --input-format, -f INPUT_FORMAT Inputformat. Default is to infer from input. --output-format, -F OUTPUT_FORMAT Default is to infer from output. --no-catalog, -n Do not read catalog even if it exists. --inferred, -i Add additional relations inferred by the FaCT++ reasoner to the converted ontology. Implies --squash. --base-iri BASE_IRI, -b BASE_IRI Base iri of inferred ontology. The default is the base iri of the input ontology with \"-inferred\" appended to it. Used together with --inferred. --recursive, -r The output is written to the directories matching the input. This requires Protege catalog files to be present. --squash, -s Squash imported ontologies into a single output file.","title":"Options"},{"location":"tools-instructions/#examples_4","text":"ontoconvert --recursive emmo.ttl owl/emmo.owl ontoconvert --inferred emmo.ttl emmo-inferred.owl Note, it is then required to add the argument only_local=True when loading the locally converted ontology in EMMOntoPy, e.g.: from ontopy import get_ontology emmo_ontology = get_ontology ( \"emmo.owl\" ) . load ( only_local = True ) Since the catalog file will be overwritten in the above example writing output to a separate directory is useful. ontoconvert --recursive emmo.ttl owl/emmo.owl","title":"Examples"},{"location":"tools-instructions/#bugs","text":"Since parsing the results from the reasoner is currently broken in Owlready2 (v0.37), a workaround has been added to ontoconvert. This workaround only only supports FaCT++. Hence, HermiT and Pellet are currently not available.","title":"Bugs"},{"location":"tools-instructions/#excel2onto","text":"Tool for converting EMMO-based ontologies from Excel to OWL, making it easy for non-ontologists to make EMMO-based domain ontologies. The Excel file must be in the format provided by ontology_template.xlsx.","title":"excel2onto"},{"location":"tools-instructions/#usage_5","text":"excel2onto [options] excelpath","title":"Usage"},{"location":"tools-instructions/#dependencies_3","text":"pandas (Python package)","title":"Dependencies"},{"location":"tools-instructions/#options_5","text":"positional arguments: excelpath path to excel book options: -h, --help show this help message and exit --output OUTPUT, -o OUTPUT Name of output ontology, \u00b4ontology.ttl\u00b4 is default --force, -f Whether to force generation of ontology on non-fatal error.","title":"Options"},{"location":"tools-instructions/#examples_5","text":"Create a new_ontology.ttl turtle file from the Excel file new_ontology.xlsx : excel2onto -o new_ontology.ttl new_ontology.xlsx","title":"Examples"},{"location":"tools-instructions/#bugs_1","text":"equivalentTo is currently not supported.","title":"Bugs"},{"location":"api_reference/emmopy/emmocheck/","text":"emmocheck \u00b6 A module for testing an ontology against conventions defined for EMMO. A YAML file can be provided with additional test configurations. Example configuration file: test_unit_dimensions: exceptions: - myunits.MyUnitCategory1 - myunits.MyUnitCategory2 skip: - name_of_test_to_skip enable: - name_of_test_to_enable TestEMMOConventions \u00b6 Base class for testing an ontology against EMMO conventions. Source code in emmopy/emmocheck.py class TestEMMOConventions ( unittest . TestCase ): \"\"\"Base class for testing an ontology against EMMO conventions.\"\"\" config = {} # configurations def get_config ( self , string , default = None ): \"\"\"Returns the configuration specified by `string`. If configuration is not found in the configuration file, `default` is returned. Sub-configurations can be accessed by separating the components with dots, like \"test_namespace.exceptions\". \"\"\" result = self . config try : for token in string . split ( \".\" ): result = result [ token ] except KeyError : return default return result get_config ( self , string , default = None ) \u00b6 Returns the configuration specified by string . If configuration is not found in the configuration file, default is returned. Sub-configurations can be accessed by separating the components with dots, like \"test_namespace.exceptions\". Source code in emmopy/emmocheck.py def get_config ( self , string , default = None ): \"\"\"Returns the configuration specified by `string`. If configuration is not found in the configuration file, `default` is returned. Sub-configurations can be accessed by separating the components with dots, like \"test_namespace.exceptions\". \"\"\" result = self . config try : for token in string . split ( \".\" ): result = result [ token ] except KeyError : return default return result TestFunctionalEMMOConventions \u00b6 Test functional EMMO conventions. Source code in emmopy/emmocheck.py class TestFunctionalEMMOConventions ( TestEMMOConventions ): \"\"\"Test functional EMMO conventions.\"\"\" def test_unit_dimension ( self ): \"\"\"Check that all measurement units have a physical dimension. Configurations: exceptions - full class names of classes to ignore. \"\"\" exceptions = set ( ( \"metrology.MultipleUnit\" , \"metrology.SubMultipleUnit\" , \"metrology.OffSystemUnit\" , \"metrology.PrefixedUnit\" , \"metrology.NonPrefixedUnit\" , \"metrology.SpecialUnit\" , \"metrology.DerivedUnit\" , \"metrology.BaseUnit\" , \"metrology.UnitSymbol\" , \"siunits.SICoherentDerivedUnit\" , \"siunits.SINonCoherentDerivedUnit\" , \"siunits.SISpecialUnit\" , \"siunits.SICoherentUnit\" , \"siunits.SIPrefixedUnit\" , \"siunits.SIBaseUnit\" , \"siunits.SIUnitSymbol\" , \"siunits.SIUnit\" , \"emmo.MultipleUnit\" , \"emmo.SubMultipleUnit\" , \"emmo.OffSystemUnit\" , \"emmo.PrefixedUnit\" , \"emmo.NonPrefixedUnit\" , \"emmo.SpecialUnit\" , \"emmo.DerivedUnit\" , \"emmo.BaseUnit\" , \"emmo.UnitSymbol\" , \"emmo.SICoherentDerivedUnit\" , \"emmo.SINonCoherentDerivedUnit\" , \"emmo.SISpecialUnit\" , \"emmo.SICoherentUnit\" , \"emmo.SIPrefixedUnit\" , \"emmo.SIBaseUnit\" , \"emmo.SIUnitSymbol\" , \"emmo.SIUnit\" , ) ) if not hasattr ( self . onto , \"MeasurementUnit\" ): return exceptions . update ( self . get_config ( \"test_unit_dimension.exceptions\" , ())) regex = re . compile ( r \"^(emmo|metrology).hasPhysicalDimension.some\\(.*\\)$\" ) classes = set ( self . onto . classes ( self . check_imported )) for cls in self . onto . MeasurementUnit . descendants (): if not self . check_imported and cls not in classes : continue # Assume that actual units are not subclassed if not list ( cls . subclasses ()) and repr ( cls ) not in exceptions : with self . subTest ( cls = cls , label = get_label ( cls )): self . assertTrue ( any ( regex . match ( repr ( r )) for r in cls . get_indirect_is_a () ), msg = cls , ) def test_quantity_dimension ( self ): \"\"\"Check that all quantities have a physicalDimension annotation. Note: this test will be deprecated when isq is moved to emmo/domain. Configurations: exceptions - full class names of classes to ignore. \"\"\" exceptions = set ( ( \"properties.ModelledQuantitativeProperty\" , \"properties.MeasuredQuantitativeProperty\" , \"properties.ConventionalQuantitativeProperty\" , \"metrology.QuantitativeProperty\" , \"metrology.Quantity\" , \"metrology.OrdinalQuantity\" , \"metrology.BaseQuantity\" , \"metrology.PhysicalConstant\" , \"metrology.PhysicalQuantity\" , \"metrology.ExactConstant\" , \"metrology.MeasuredConstant\" , \"metrology.DerivedQuantity\" , \"isq.ISQBaseQuantity\" , \"isq.InternationalSystemOfQuantity\" , \"isq.ISQDerivedQuantity\" , \"isq.SIExactConstant\" , \"emmo.ModelledQuantitativeProperty\" , \"emmo.MeasuredQuantitativeProperty\" , \"emmo.ConventionalQuantitativeProperty\" , \"emmo.QuantitativeProperty\" , \"emmo.Quantity\" , \"emmo.OrdinalQuantity\" , \"emmo.BaseQuantity\" , \"emmo.PhysicalConstant\" , \"emmo.PhysicalQuantity\" , \"emmo.ExactConstant\" , \"emmo.MeasuredConstant\" , \"emmo.DerivedQuantity\" , \"emmo.ISQBaseQuantity\" , \"emmo.InternationalSystemOfQuantity\" , \"emmo.ISQDerivedQuantity\" , \"emmo.SIExactConstant\" , \"emmo.NonSIUnits\" , \"emmo.StandardizedPhysicalQuantity\" , \"emmo.CategorizedPhysicalQuantity\" , \"emmo.AtomicAndNuclear\" , \"emmo.Defined\" , \"emmo.Electromagnetic\" , \"emmo.FrequentlyUsed\" , \"emmo.PhysicoChemical\" , \"emmo.ChemicalCompositionQuantity\" , \"emmo.Universal\" , ) ) if not hasattr ( self . onto , \"PhysicalQuantity\" ): return exceptions . update ( self . get_config ( \"test_quantity_dimension.exceptions\" , ()) ) regex = re . compile ( \"^T([+-][1-9]|0) L([+-][1-9]|0) M([+-][1-9]|0) I([+-][1-9]|0) \" \"(H|\u0398)([+-][1-9]|0) N([+-][1-9]|0) J([+-][1-9]|0)$\" ) classes = set ( self . onto . classes ( self . check_imported )) for cls in self . onto . PhysicalQuantity . descendants (): if not self . check_imported and cls not in classes : continue if repr ( cls ) not in exceptions : with self . subTest ( cls = cls , label = get_label ( cls )): anno = cls . get_annotations () self . assertIn ( \"physicalDimension\" , anno , msg = cls ) physdim = anno [ \"physicalDimension\" ] . first () self . assertRegex ( physdim , regex , msg = cls ) def test_physical_quantity_dimension ( self ): \"\"\"Check that all physical quantities have `hasPhysicalDimension`. Note: this test will fail before isq is moved to emmo/domain. Configurations: exceptions - full class names of classes to ignore. \"\"\" exceptions = set ( ( \"emmo.ModelledQuantitativeProperty\" , \"emmo.MeasuredQuantitativeProperty\" , \"emmo.ConventionalQuantitativeProperty\" , \"emmo.QuantitativeProperty\" , \"emmo.BaseQuantity\" , \"emmo.PhysicalConstant\" , \"emmo.PhysicalQuantity\" , \"emmo.ExactConstant\" , \"emmo.MeasuredConstant\" , \"emmo.DerivedQuantity\" , \"emmo.ISQBaseQuantity\" , \"emmo.InternationalSystemOfQuantity\" , \"emmo.ISQDerivedQuantity\" , \"emmo.SIExactConstant\" , \"emmo.NonSIUnits\" , \"emmo.StandardizedPhysicalQuantity\" , \"emmo.CategorizedPhysicalQuantity\" , \"emmo.AtomicAndNuclearPhysicsQuantity\" , \"emmo.ThermodynamicalQuantity\" , \"emmo.LightAndRadiationQuantity\" , \"emmo.SpaceAndTimeQuantity\" , \"emmo.AcousticQuantity\" , \"emmo.PhysioChememicalQuantity\" , \"emmo.ElectromagneticQuantity\" , \"emmo.MechanicalQuantity\" , \"emmo.CondensedMatterPhysicsQuantity\" , \"emmo.ChemicalCompositionQuantity\" , \"emmo.Extensive\" , \"emmo.Intensive\" , ) ) if not hasattr ( self . onto , \"PhysicalQuantity\" ): return exceptions . update ( self . get_config ( \"test_physical_quantity_dimension.exceptions\" , ()) ) classes = set ( self . onto . classes ( self . check_imported )) for cls in self . onto . PhysicalQuantity . descendants (): if not self . check_imported and cls not in classes : continue if repr ( cls ) not in exceptions : with self . subTest ( cls = cls , label = get_label ( cls )): try : class_props = cls . INDIRECT_get_class_properties () except AttributeError : # The INDIRECT_get_class_properties() method # does not support inverse properties. Build # class_props manually... class_props = set () for _ in cls . mro (): if hasattr ( _ , \"is_a\" ): class_props . update ( [ restriction . property for restriction in _ . is_a if isinstance ( restriction , owlready2 . Restriction ) ] ) self . assertIn ( self . onto . hasPhysicalDimension , class_props , msg = cls ) def test_namespace ( self ): \"\"\"Check that all IRIs are namespaced after their (sub)ontology. Configurations: exceptions - full name of entities to ignore. \"\"\" exceptions = set ( ( \"owl.qualifiedCardinality\" , \"owl.minQualifiedCardinality\" , \"terms.creator\" , \"terms.contributor\" , \"terms.publisher\" , \"terms.title\" , \"terms.license\" , \"terms.abstract\" , \"core.prefLabel\" , \"core.altLabel\" , \"core.hiddenLabel\" , \"mereotopology.Item\" , \"manufacturing.EngineeredMaterial\" , ) ) exceptions . update ( self . get_config ( \"test_namespace.exceptions\" , ())) def checker ( onto , ignore_namespace ): if list ( filter ( onto . base_iri . strip ( \"#\" ) . endswith , self . ignore_namespace ) ): print ( f \"Skipping namespace: { onto . base_iri } \" ) return entities = itertools . chain ( onto . classes (), onto . object_properties (), onto . data_properties (), onto . individuals (), onto . annotation_properties (), ) for entity in entities : if entity not in visited and repr ( entity ) not in exceptions : visited . add ( entity ) with self . subTest ( iri = entity . iri , base_iri = onto . base_iri , entity = repr ( entity ), ): self . assertTrue ( entity . iri . endswith ( entity . name ), msg = ( \"the final part of entity IRIs must be their \" \"name\" ), ) self . assertEqual ( entity . iri , onto . base_iri + entity . name , msg = ( f \"IRI { entity . iri !r} does not correspond to \" f \"module namespace: { onto . base_iri !r} \" ), ) if self . check_imported : for imp_onto in onto . imported_ontologies : if imp_onto not in visited_onto : visited_onto . add ( imp_onto ) checker ( imp_onto , ignore_namespace ) visited = set () visited_onto = set () checker ( self . onto , self . ignore_namespace ) test_namespace ( self ) \u00b6 Check that all IRIs are namespaced after their (sub)ontology. Configurations exceptions - full name of entities to ignore. Source code in emmopy/emmocheck.py def test_namespace ( self ): \"\"\"Check that all IRIs are namespaced after their (sub)ontology. Configurations: exceptions - full name of entities to ignore. \"\"\" exceptions = set ( ( \"owl.qualifiedCardinality\" , \"owl.minQualifiedCardinality\" , \"terms.creator\" , \"terms.contributor\" , \"terms.publisher\" , \"terms.title\" , \"terms.license\" , \"terms.abstract\" , \"core.prefLabel\" , \"core.altLabel\" , \"core.hiddenLabel\" , \"mereotopology.Item\" , \"manufacturing.EngineeredMaterial\" , ) ) exceptions . update ( self . get_config ( \"test_namespace.exceptions\" , ())) def checker ( onto , ignore_namespace ): if list ( filter ( onto . base_iri . strip ( \"#\" ) . endswith , self . ignore_namespace ) ): print ( f \"Skipping namespace: { onto . base_iri } \" ) return entities = itertools . chain ( onto . classes (), onto . object_properties (), onto . data_properties (), onto . individuals (), onto . annotation_properties (), ) for entity in entities : if entity not in visited and repr ( entity ) not in exceptions : visited . add ( entity ) with self . subTest ( iri = entity . iri , base_iri = onto . base_iri , entity = repr ( entity ), ): self . assertTrue ( entity . iri . endswith ( entity . name ), msg = ( \"the final part of entity IRIs must be their \" \"name\" ), ) self . assertEqual ( entity . iri , onto . base_iri + entity . name , msg = ( f \"IRI { entity . iri !r} does not correspond to \" f \"module namespace: { onto . base_iri !r} \" ), ) if self . check_imported : for imp_onto in onto . imported_ontologies : if imp_onto not in visited_onto : visited_onto . add ( imp_onto ) checker ( imp_onto , ignore_namespace ) visited = set () visited_onto = set () checker ( self . onto , self . ignore_namespace ) test_physical_quantity_dimension ( self ) \u00b6 Check that all physical quantities have hasPhysicalDimension . Note: this test will fail before isq is moved to emmo/domain. Configurations exceptions - full class names of classes to ignore. Source code in emmopy/emmocheck.py def test_physical_quantity_dimension ( self ): \"\"\"Check that all physical quantities have `hasPhysicalDimension`. Note: this test will fail before isq is moved to emmo/domain. Configurations: exceptions - full class names of classes to ignore. \"\"\" exceptions = set ( ( \"emmo.ModelledQuantitativeProperty\" , \"emmo.MeasuredQuantitativeProperty\" , \"emmo.ConventionalQuantitativeProperty\" , \"emmo.QuantitativeProperty\" , \"emmo.BaseQuantity\" , \"emmo.PhysicalConstant\" , \"emmo.PhysicalQuantity\" , \"emmo.ExactConstant\" , \"emmo.MeasuredConstant\" , \"emmo.DerivedQuantity\" , \"emmo.ISQBaseQuantity\" , \"emmo.InternationalSystemOfQuantity\" , \"emmo.ISQDerivedQuantity\" , \"emmo.SIExactConstant\" , \"emmo.NonSIUnits\" , \"emmo.StandardizedPhysicalQuantity\" , \"emmo.CategorizedPhysicalQuantity\" , \"emmo.AtomicAndNuclearPhysicsQuantity\" , \"emmo.ThermodynamicalQuantity\" , \"emmo.LightAndRadiationQuantity\" , \"emmo.SpaceAndTimeQuantity\" , \"emmo.AcousticQuantity\" , \"emmo.PhysioChememicalQuantity\" , \"emmo.ElectromagneticQuantity\" , \"emmo.MechanicalQuantity\" , \"emmo.CondensedMatterPhysicsQuantity\" , \"emmo.ChemicalCompositionQuantity\" , \"emmo.Extensive\" , \"emmo.Intensive\" , ) ) if not hasattr ( self . onto , \"PhysicalQuantity\" ): return exceptions . update ( self . get_config ( \"test_physical_quantity_dimension.exceptions\" , ()) ) classes = set ( self . onto . classes ( self . check_imported )) for cls in self . onto . PhysicalQuantity . descendants (): if not self . check_imported and cls not in classes : continue if repr ( cls ) not in exceptions : with self . subTest ( cls = cls , label = get_label ( cls )): try : class_props = cls . INDIRECT_get_class_properties () except AttributeError : # The INDIRECT_get_class_properties() method # does not support inverse properties. Build # class_props manually... class_props = set () for _ in cls . mro (): if hasattr ( _ , \"is_a\" ): class_props . update ( [ restriction . property for restriction in _ . is_a if isinstance ( restriction , owlready2 . Restriction ) ] ) self . assertIn ( self . onto . hasPhysicalDimension , class_props , msg = cls ) test_quantity_dimension ( self ) \u00b6 Check that all quantities have a physicalDimension annotation. Note: this test will be deprecated when isq is moved to emmo/domain. Configurations exceptions - full class names of classes to ignore. Source code in emmopy/emmocheck.py def test_quantity_dimension ( self ): \"\"\"Check that all quantities have a physicalDimension annotation. Note: this test will be deprecated when isq is moved to emmo/domain. Configurations: exceptions - full class names of classes to ignore. \"\"\" exceptions = set ( ( \"properties.ModelledQuantitativeProperty\" , \"properties.MeasuredQuantitativeProperty\" , \"properties.ConventionalQuantitativeProperty\" , \"metrology.QuantitativeProperty\" , \"metrology.Quantity\" , \"metrology.OrdinalQuantity\" , \"metrology.BaseQuantity\" , \"metrology.PhysicalConstant\" , \"metrology.PhysicalQuantity\" , \"metrology.ExactConstant\" , \"metrology.MeasuredConstant\" , \"metrology.DerivedQuantity\" , \"isq.ISQBaseQuantity\" , \"isq.InternationalSystemOfQuantity\" , \"isq.ISQDerivedQuantity\" , \"isq.SIExactConstant\" , \"emmo.ModelledQuantitativeProperty\" , \"emmo.MeasuredQuantitativeProperty\" , \"emmo.ConventionalQuantitativeProperty\" , \"emmo.QuantitativeProperty\" , \"emmo.Quantity\" , \"emmo.OrdinalQuantity\" , \"emmo.BaseQuantity\" , \"emmo.PhysicalConstant\" , \"emmo.PhysicalQuantity\" , \"emmo.ExactConstant\" , \"emmo.MeasuredConstant\" , \"emmo.DerivedQuantity\" , \"emmo.ISQBaseQuantity\" , \"emmo.InternationalSystemOfQuantity\" , \"emmo.ISQDerivedQuantity\" , \"emmo.SIExactConstant\" , \"emmo.NonSIUnits\" , \"emmo.StandardizedPhysicalQuantity\" , \"emmo.CategorizedPhysicalQuantity\" , \"emmo.AtomicAndNuclear\" , \"emmo.Defined\" , \"emmo.Electromagnetic\" , \"emmo.FrequentlyUsed\" , \"emmo.PhysicoChemical\" , \"emmo.ChemicalCompositionQuantity\" , \"emmo.Universal\" , ) ) if not hasattr ( self . onto , \"PhysicalQuantity\" ): return exceptions . update ( self . get_config ( \"test_quantity_dimension.exceptions\" , ()) ) regex = re . compile ( \"^T([+-][1-9]|0) L([+-][1-9]|0) M([+-][1-9]|0) I([+-][1-9]|0) \" \"(H|\u0398)([+-][1-9]|0) N([+-][1-9]|0) J([+-][1-9]|0)$\" ) classes = set ( self . onto . classes ( self . check_imported )) for cls in self . onto . PhysicalQuantity . descendants (): if not self . check_imported and cls not in classes : continue if repr ( cls ) not in exceptions : with self . subTest ( cls = cls , label = get_label ( cls )): anno = cls . get_annotations () self . assertIn ( \"physicalDimension\" , anno , msg = cls ) physdim = anno [ \"physicalDimension\" ] . first () self . assertRegex ( physdim , regex , msg = cls ) test_unit_dimension ( self ) \u00b6 Check that all measurement units have a physical dimension. Configurations exceptions - full class names of classes to ignore. Source code in emmopy/emmocheck.py def test_unit_dimension ( self ): \"\"\"Check that all measurement units have a physical dimension. Configurations: exceptions - full class names of classes to ignore. \"\"\" exceptions = set ( ( \"metrology.MultipleUnit\" , \"metrology.SubMultipleUnit\" , \"metrology.OffSystemUnit\" , \"metrology.PrefixedUnit\" , \"metrology.NonPrefixedUnit\" , \"metrology.SpecialUnit\" , \"metrology.DerivedUnit\" , \"metrology.BaseUnit\" , \"metrology.UnitSymbol\" , \"siunits.SICoherentDerivedUnit\" , \"siunits.SINonCoherentDerivedUnit\" , \"siunits.SISpecialUnit\" , \"siunits.SICoherentUnit\" , \"siunits.SIPrefixedUnit\" , \"siunits.SIBaseUnit\" , \"siunits.SIUnitSymbol\" , \"siunits.SIUnit\" , \"emmo.MultipleUnit\" , \"emmo.SubMultipleUnit\" , \"emmo.OffSystemUnit\" , \"emmo.PrefixedUnit\" , \"emmo.NonPrefixedUnit\" , \"emmo.SpecialUnit\" , \"emmo.DerivedUnit\" , \"emmo.BaseUnit\" , \"emmo.UnitSymbol\" , \"emmo.SICoherentDerivedUnit\" , \"emmo.SINonCoherentDerivedUnit\" , \"emmo.SISpecialUnit\" , \"emmo.SICoherentUnit\" , \"emmo.SIPrefixedUnit\" , \"emmo.SIBaseUnit\" , \"emmo.SIUnitSymbol\" , \"emmo.SIUnit\" , ) ) if not hasattr ( self . onto , \"MeasurementUnit\" ): return exceptions . update ( self . get_config ( \"test_unit_dimension.exceptions\" , ())) regex = re . compile ( r \"^(emmo|metrology).hasPhysicalDimension.some\\(.*\\)$\" ) classes = set ( self . onto . classes ( self . check_imported )) for cls in self . onto . MeasurementUnit . descendants (): if not self . check_imported and cls not in classes : continue # Assume that actual units are not subclassed if not list ( cls . subclasses ()) and repr ( cls ) not in exceptions : with self . subTest ( cls = cls , label = get_label ( cls )): self . assertTrue ( any ( regex . match ( repr ( r )) for r in cls . get_indirect_is_a () ), msg = cls , ) TestSyntacticEMMOConventions \u00b6 Test syntactic EMMO conventions. Source code in emmopy/emmocheck.py class TestSyntacticEMMOConventions ( TestEMMOConventions ): \"\"\"Test syntactic EMMO conventions.\"\"\" def test_number_of_labels ( self ): \"\"\"Check that all entities have one and only one prefLabel. Use \"altLabel\" for synonyms. The only allowed exception is entities who's representation starts with \"owl.\". \"\"\" exceptions = set ( ( \"terms.license\" , \"terms.abstract\" , \"terms.contributor\" , \"terms.creator\" , \"terms.publisher\" , \"terms.title\" , \"core.prefLabel\" , \"core.altLabel\" , \"core.hiddenLabel\" , ) ) exceptions . update ( self . get_config ( \"test_number_of_labels.exceptions\" , ()) ) if ( \"prefLabel\" in self . onto . world . _props # pylint: disable=protected-access ): for entity in self . onto . get_entities (): if repr ( entity ) not in exceptions : with self . subTest ( entity = entity , label = get_label ( entity ), prefLabels = entity . prefLabel , ): if not repr ( entity ) . startswith ( \"owl.\" ): self . assertTrue ( hasattr ( entity , \"prefLabel\" )) self . assertEqual ( 1 , len ( entity . prefLabel )) else : self . fail ( \"ontology has no prefLabel\" ) def test_class_label ( self ): \"\"\"Check that class labels are CamelCase and valid identifiers. For CamelCase, we are currently only checking that the labels start with upper case. \"\"\" exceptions = set ( ( \"0-manifold\" , # not needed in 1.0.0-beta \"1-manifold\" , \"2-manifold\" , \"3-manifold\" , \"C++\" , ) ) exceptions . update ( self . get_config ( \"test_class_label.exceptions\" , ())) for cls in self . onto . classes ( self . check_imported ): for label in cls . label + getattr ( cls , \"prefLabel\" , []): if label not in exceptions : with self . subTest ( entity = cls , label = label ): self . assertTrue ( label . isidentifier ()) self . assertTrue ( label [ 0 ] . isupper ()) def test_object_property_label ( self ): \"\"\"Check that object property labels are lowerCamelCase. Allowed exceptions: \"EMMORelation\" If they start with \"has\" or \"is\" they should be followed by a upper case letter. If they start with \"is\" they should also end with \"Of\". \"\"\" exceptions = set (( \"EMMORelation\" ,)) exceptions . update ( self . get_config ( \"test_object_property_label.exceptions\" , ()) ) for obj_prop in self . onto . object_properties (): if repr ( obj_prop ) not in exceptions : for label in obj_prop . label : with self . subTest ( entity = obj_prop , label = label ): self . assertTrue ( label [ 0 ] . islower (), \"label start with lowercase\" ) if label . startswith ( \"has\" ): self . assertTrue ( label [ 3 ] . isupper (), 'what follows \"has\" must be \"uppercase\"' , ) if label . startswith ( \"is\" ): self . assertTrue ( label [ 2 ] . isupper (), 'what follows \"is\" must be \"uppercase\"' , ) self . assertTrue ( label . endswith (( \"Of\" , \"With\" )), 'should end with \"Of\" or \"With\"' , ) test_class_label ( self ) \u00b6 Check that class labels are CamelCase and valid identifiers. For CamelCase, we are currently only checking that the labels start with upper case. Source code in emmopy/emmocheck.py def test_class_label ( self ): \"\"\"Check that class labels are CamelCase and valid identifiers. For CamelCase, we are currently only checking that the labels start with upper case. \"\"\" exceptions = set ( ( \"0-manifold\" , # not needed in 1.0.0-beta \"1-manifold\" , \"2-manifold\" , \"3-manifold\" , \"C++\" , ) ) exceptions . update ( self . get_config ( \"test_class_label.exceptions\" , ())) for cls in self . onto . classes ( self . check_imported ): for label in cls . label + getattr ( cls , \"prefLabel\" , []): if label not in exceptions : with self . subTest ( entity = cls , label = label ): self . assertTrue ( label . isidentifier ()) self . assertTrue ( label [ 0 ] . isupper ()) test_number_of_labels ( self ) \u00b6 Check that all entities have one and only one prefLabel. Use \"altLabel\" for synonyms. The only allowed exception is entities who's representation starts with \"owl.\". Source code in emmopy/emmocheck.py def test_number_of_labels ( self ): \"\"\"Check that all entities have one and only one prefLabel. Use \"altLabel\" for synonyms. The only allowed exception is entities who's representation starts with \"owl.\". \"\"\" exceptions = set ( ( \"terms.license\" , \"terms.abstract\" , \"terms.contributor\" , \"terms.creator\" , \"terms.publisher\" , \"terms.title\" , \"core.prefLabel\" , \"core.altLabel\" , \"core.hiddenLabel\" , ) ) exceptions . update ( self . get_config ( \"test_number_of_labels.exceptions\" , ()) ) if ( \"prefLabel\" in self . onto . world . _props # pylint: disable=protected-access ): for entity in self . onto . get_entities (): if repr ( entity ) not in exceptions : with self . subTest ( entity = entity , label = get_label ( entity ), prefLabels = entity . prefLabel , ): if not repr ( entity ) . startswith ( \"owl.\" ): self . assertTrue ( hasattr ( entity , \"prefLabel\" )) self . assertEqual ( 1 , len ( entity . prefLabel )) else : self . fail ( \"ontology has no prefLabel\" ) test_object_property_label ( self ) \u00b6 Check that object property labels are lowerCamelCase. Allowed exceptions: \"EMMORelation\" If they start with \"has\" or \"is\" they should be followed by a upper case letter. If they start with \"is\" they should also end with \"Of\". Source code in emmopy/emmocheck.py def test_object_property_label ( self ): \"\"\"Check that object property labels are lowerCamelCase. Allowed exceptions: \"EMMORelation\" If they start with \"has\" or \"is\" they should be followed by a upper case letter. If they start with \"is\" they should also end with \"Of\". \"\"\" exceptions = set (( \"EMMORelation\" ,)) exceptions . update ( self . get_config ( \"test_object_property_label.exceptions\" , ()) ) for obj_prop in self . onto . object_properties (): if repr ( obj_prop ) not in exceptions : for label in obj_prop . label : with self . subTest ( entity = obj_prop , label = label ): self . assertTrue ( label [ 0 ] . islower (), \"label start with lowercase\" ) if label . startswith ( \"has\" ): self . assertTrue ( label [ 3 ] . isupper (), 'what follows \"has\" must be \"uppercase\"' , ) if label . startswith ( \"is\" ): self . assertTrue ( label [ 2 ] . isupper (), 'what follows \"is\" must be \"uppercase\"' , ) self . assertTrue ( label . endswith (( \"Of\" , \"With\" )), 'should end with \"Of\" or \"With\"' , ) main ( argv = None ) \u00b6 Run all checks on ontology iri . Default is 'http://emmo.info/emmo'. Parameters: Name Type Description Default argv list List of arguments, similar to sys.argv[1:] . Mainly for testing purposes, since it allows one to invoke the tool manually / through Python. None Source code in emmopy/emmocheck.py def main ( argv : list = None , ): # pylint: disable=too-many-locals,too-many-branches,too-many-statements \"\"\"Run all checks on ontology `iri`. Default is 'http://emmo.info/emmo'. Parameters: argv: List of arguments, similar to `sys.argv[1:]`. Mainly for testing purposes, since it allows one to invoke the tool manually / through Python. \"\"\" parser = argparse . ArgumentParser ( description = __doc__ ) parser . add_argument ( \"iri\" , help = \"File name or URI to the ontology to test.\" ) parser . add_argument ( \"--database\" , \"-d\" , metavar = \"FILENAME\" , default = \":memory:\" , help = ( \"Load ontology from Owlready2 sqlite3 database. The `iri` argument\" \" should in this case be the IRI of the ontology you want to \" \"check.\" ), ) parser . add_argument ( \"--local\" , \"-l\" , action = \"store_true\" , help = ( \"Load imported ontologies locally. Their paths are specified in \" \"Prot\u00e8g\u00e8 catalog files or via the --path option. The IRI should \" \"be a file name.\" ), ) parser . add_argument ( \"--catalog-file\" , default = \"catalog-v001.xml\" , help = ( \"Name of Prot\u00e8g\u00e8 catalog file in the same folder as the ontology. \" \"This option is used together with --local and defaults to \" '\"catalog-v001.xml\".' ), ) parser . add_argument ( \"--path\" , action = \"append\" , default = [], help = ( \"Paths where imported ontologies can be found. May be provided as \" \"a comma-separated string and/or with multiple --path options.\" ), ) parser . add_argument ( \"--check-imported\" , \"-i\" , action = \"store_true\" , help = \"Whether to check imported ontologies.\" , ) parser . add_argument ( \"--verbose\" , \"-v\" , action = \"store_true\" , help = \"Verbosity level.\" ) parser . add_argument ( \"--configfile\" , \"-c\" , help = \"A yaml file with additional test configurations.\" , ) parser . add_argument ( \"--skip\" , \"-s\" , action = \"append\" , default = [], help = ( \"Shell pattern matching tests to skip. This option may be \" \"provided multiple times.\" ), ) parser . add_argument ( \"--enable\" , \"-e\" , action = \"append\" , default = [], help = ( \"Shell pattern matching tests to enable that have been skipped by \" \"default or in the config file. This option may be provided \" \"multiple times.\" ), ) parser . add_argument ( # deprecated, replaced by --no-catalog \"--url-from-catalog\" , \"-u\" , default = None , action = \"store_true\" , help = \"Get url from catalog file\" , ) parser . add_argument ( \"--no-catalog\" , action = \"store_false\" , dest = \"url_from_catalog\" , default = None , help = \"Whether to not read catalog file even if it exists.\" , ) parser . add_argument ( \"--ignore-namespace\" , \"-n\" , action = \"append\" , default = [], help = \"Namespace to be ignored. Can be given multiple times\" , ) # Options to pass forward to unittest parser . add_argument ( \"--buffer\" , \"-b\" , dest = \"unittest\" , action = \"append_const\" , const = \"-b\" , help = ( \"The standard output and standard error streams are buffered \" \"during the test run. Output during a passing test is discarded. \" \"Output is echoed normally on test fail or error and is added to \" \"the failure messages.\" ), ) parser . add_argument ( \"--catch\" , dest = \"unittest\" , action = \"append_const\" , const = \"-c\" , help = ( \"Control-C during the test run waits for the current test to end \" \"and then reports all the results so far. A second control-C \" \"raises the normal KeyboardInterrupt exception\" ), ) parser . add_argument ( \"--failfast\" , \"-f\" , dest = \"unittest\" , action = \"append_const\" , const = \"-f\" , help = \"Stop the test run on the first error or failure.\" , ) try : args = parser . parse_args ( args = argv ) sys . argv [ 1 :] = args . unittest if args . unittest else [] if args . verbose : sys . argv . append ( \"-v\" ) except SystemExit as exc : sys . exit ( exc . code ) # Exit without traceback on invalid arguments # Append to onto_path for paths in args . path : for path in paths . split ( \",\" ): if path not in onto_path : onto_path . append ( path ) # Load ontology world = World ( filename = args . database ) if args . database != \":memory:\" and args . iri not in world . ontologies : parser . error ( \"The IRI argument should be one of the ontologies in \" \"the database: \\n \" + \" \\n \" . join ( world . ontologies . keys ()) ) onto = world . get_ontology ( args . iri ) onto . load ( only_local = args . local , url_from_catalog = args . url_from_catalog , catalog_file = args . catalog_file , ) # Store settings TestEMMOConventions TestEMMOConventions . onto = onto TestEMMOConventions . check_imported = args . check_imported TestEMMOConventions . ignore_namespace = args . ignore_namespace # Configure tests verbosity = 2 if args . verbose else 1 if args . configfile : import yaml # pylint: disable=import-outside-toplevel with open ( args . configfile , \"rt\" ) as handle : TestEMMOConventions . config . update ( yaml . load ( handle , Loader = yaml . SafeLoader ) ) # Run all subclasses of TestEMMOConventions as test suites status = 0 for cls in TestEMMOConventions . __subclasses__ (): # pylint: disable=cell-var-from-loop,undefined-loop-variable suite = unittest . TestLoader () . loadTestsFromTestCase ( cls ) # Mark tests to be skipped for test in suite : name = test . id () . split ( \".\" )[ - 1 ] skipped = set ( # skipped by default [ \"test_namespace\" , \"test_physical_quantity_dimension\" , ] ) msg = { name : \"skipped by default\" for name in skipped } # enable/skip tests from config file for pattern in test . get_config ( \"enable\" , ()): if fnmatch . fnmatchcase ( name , pattern ): skipped . remove ( name ) for pattern in test . get_config ( \"skip\" , ()): if fnmatch . fnmatchcase ( name , pattern ): skipped . add ( name ) msg [ name ] = \"skipped from config file\" # enable/skip from command line for pattern in args . enable : if fnmatch . fnmatchcase ( name , pattern ): skipped . remove ( name ) for pattern in args . skip : if fnmatch . fnmatchcase ( name , pattern ): skipped . add ( name ) msg [ name ] = \"skipped from command line\" if name in skipped : setattr ( test , \"setUp\" , lambda : test . skipTest ( msg . get ( name , \"\" ))) runner = TextTestRunner ( verbosity = verbosity ) runner . resultclass . checkmode = True result = runner . run ( suite ) if result . failures : status = 1 return status","title":"emmocheck"},{"location":"api_reference/emmopy/emmocheck/#emmocheck","text":"A module for testing an ontology against conventions defined for EMMO. A YAML file can be provided with additional test configurations. Example configuration file: test_unit_dimensions: exceptions: - myunits.MyUnitCategory1 - myunits.MyUnitCategory2 skip: - name_of_test_to_skip enable: - name_of_test_to_enable","title":"emmocheck"},{"location":"api_reference/emmopy/emmocheck/#emmopy.emmocheck.TestEMMOConventions","text":"Base class for testing an ontology against EMMO conventions. Source code in emmopy/emmocheck.py class TestEMMOConventions ( unittest . TestCase ): \"\"\"Base class for testing an ontology against EMMO conventions.\"\"\" config = {} # configurations def get_config ( self , string , default = None ): \"\"\"Returns the configuration specified by `string`. If configuration is not found in the configuration file, `default` is returned. Sub-configurations can be accessed by separating the components with dots, like \"test_namespace.exceptions\". \"\"\" result = self . config try : for token in string . split ( \".\" ): result = result [ token ] except KeyError : return default return result","title":"TestEMMOConventions"},{"location":"api_reference/emmopy/emmocheck/#emmopy.emmocheck.TestEMMOConventions.get_config","text":"Returns the configuration specified by string . If configuration is not found in the configuration file, default is returned. Sub-configurations can be accessed by separating the components with dots, like \"test_namespace.exceptions\". Source code in emmopy/emmocheck.py def get_config ( self , string , default = None ): \"\"\"Returns the configuration specified by `string`. If configuration is not found in the configuration file, `default` is returned. Sub-configurations can be accessed by separating the components with dots, like \"test_namespace.exceptions\". \"\"\" result = self . config try : for token in string . split ( \".\" ): result = result [ token ] except KeyError : return default return result","title":"get_config()"},{"location":"api_reference/emmopy/emmocheck/#emmopy.emmocheck.TestFunctionalEMMOConventions","text":"Test functional EMMO conventions. Source code in emmopy/emmocheck.py class TestFunctionalEMMOConventions ( TestEMMOConventions ): \"\"\"Test functional EMMO conventions.\"\"\" def test_unit_dimension ( self ): \"\"\"Check that all measurement units have a physical dimension. Configurations: exceptions - full class names of classes to ignore. \"\"\" exceptions = set ( ( \"metrology.MultipleUnit\" , \"metrology.SubMultipleUnit\" , \"metrology.OffSystemUnit\" , \"metrology.PrefixedUnit\" , \"metrology.NonPrefixedUnit\" , \"metrology.SpecialUnit\" , \"metrology.DerivedUnit\" , \"metrology.BaseUnit\" , \"metrology.UnitSymbol\" , \"siunits.SICoherentDerivedUnit\" , \"siunits.SINonCoherentDerivedUnit\" , \"siunits.SISpecialUnit\" , \"siunits.SICoherentUnit\" , \"siunits.SIPrefixedUnit\" , \"siunits.SIBaseUnit\" , \"siunits.SIUnitSymbol\" , \"siunits.SIUnit\" , \"emmo.MultipleUnit\" , \"emmo.SubMultipleUnit\" , \"emmo.OffSystemUnit\" , \"emmo.PrefixedUnit\" , \"emmo.NonPrefixedUnit\" , \"emmo.SpecialUnit\" , \"emmo.DerivedUnit\" , \"emmo.BaseUnit\" , \"emmo.UnitSymbol\" , \"emmo.SICoherentDerivedUnit\" , \"emmo.SINonCoherentDerivedUnit\" , \"emmo.SISpecialUnit\" , \"emmo.SICoherentUnit\" , \"emmo.SIPrefixedUnit\" , \"emmo.SIBaseUnit\" , \"emmo.SIUnitSymbol\" , \"emmo.SIUnit\" , ) ) if not hasattr ( self . onto , \"MeasurementUnit\" ): return exceptions . update ( self . get_config ( \"test_unit_dimension.exceptions\" , ())) regex = re . compile ( r \"^(emmo|metrology).hasPhysicalDimension.some\\(.*\\)$\" ) classes = set ( self . onto . classes ( self . check_imported )) for cls in self . onto . MeasurementUnit . descendants (): if not self . check_imported and cls not in classes : continue # Assume that actual units are not subclassed if not list ( cls . subclasses ()) and repr ( cls ) not in exceptions : with self . subTest ( cls = cls , label = get_label ( cls )): self . assertTrue ( any ( regex . match ( repr ( r )) for r in cls . get_indirect_is_a () ), msg = cls , ) def test_quantity_dimension ( self ): \"\"\"Check that all quantities have a physicalDimension annotation. Note: this test will be deprecated when isq is moved to emmo/domain. Configurations: exceptions - full class names of classes to ignore. \"\"\" exceptions = set ( ( \"properties.ModelledQuantitativeProperty\" , \"properties.MeasuredQuantitativeProperty\" , \"properties.ConventionalQuantitativeProperty\" , \"metrology.QuantitativeProperty\" , \"metrology.Quantity\" , \"metrology.OrdinalQuantity\" , \"metrology.BaseQuantity\" , \"metrology.PhysicalConstant\" , \"metrology.PhysicalQuantity\" , \"metrology.ExactConstant\" , \"metrology.MeasuredConstant\" , \"metrology.DerivedQuantity\" , \"isq.ISQBaseQuantity\" , \"isq.InternationalSystemOfQuantity\" , \"isq.ISQDerivedQuantity\" , \"isq.SIExactConstant\" , \"emmo.ModelledQuantitativeProperty\" , \"emmo.MeasuredQuantitativeProperty\" , \"emmo.ConventionalQuantitativeProperty\" , \"emmo.QuantitativeProperty\" , \"emmo.Quantity\" , \"emmo.OrdinalQuantity\" , \"emmo.BaseQuantity\" , \"emmo.PhysicalConstant\" , \"emmo.PhysicalQuantity\" , \"emmo.ExactConstant\" , \"emmo.MeasuredConstant\" , \"emmo.DerivedQuantity\" , \"emmo.ISQBaseQuantity\" , \"emmo.InternationalSystemOfQuantity\" , \"emmo.ISQDerivedQuantity\" , \"emmo.SIExactConstant\" , \"emmo.NonSIUnits\" , \"emmo.StandardizedPhysicalQuantity\" , \"emmo.CategorizedPhysicalQuantity\" , \"emmo.AtomicAndNuclear\" , \"emmo.Defined\" , \"emmo.Electromagnetic\" , \"emmo.FrequentlyUsed\" , \"emmo.PhysicoChemical\" , \"emmo.ChemicalCompositionQuantity\" , \"emmo.Universal\" , ) ) if not hasattr ( self . onto , \"PhysicalQuantity\" ): return exceptions . update ( self . get_config ( \"test_quantity_dimension.exceptions\" , ()) ) regex = re . compile ( \"^T([+-][1-9]|0) L([+-][1-9]|0) M([+-][1-9]|0) I([+-][1-9]|0) \" \"(H|\u0398)([+-][1-9]|0) N([+-][1-9]|0) J([+-][1-9]|0)$\" ) classes = set ( self . onto . classes ( self . check_imported )) for cls in self . onto . PhysicalQuantity . descendants (): if not self . check_imported and cls not in classes : continue if repr ( cls ) not in exceptions : with self . subTest ( cls = cls , label = get_label ( cls )): anno = cls . get_annotations () self . assertIn ( \"physicalDimension\" , anno , msg = cls ) physdim = anno [ \"physicalDimension\" ] . first () self . assertRegex ( physdim , regex , msg = cls ) def test_physical_quantity_dimension ( self ): \"\"\"Check that all physical quantities have `hasPhysicalDimension`. Note: this test will fail before isq is moved to emmo/domain. Configurations: exceptions - full class names of classes to ignore. \"\"\" exceptions = set ( ( \"emmo.ModelledQuantitativeProperty\" , \"emmo.MeasuredQuantitativeProperty\" , \"emmo.ConventionalQuantitativeProperty\" , \"emmo.QuantitativeProperty\" , \"emmo.BaseQuantity\" , \"emmo.PhysicalConstant\" , \"emmo.PhysicalQuantity\" , \"emmo.ExactConstant\" , \"emmo.MeasuredConstant\" , \"emmo.DerivedQuantity\" , \"emmo.ISQBaseQuantity\" , \"emmo.InternationalSystemOfQuantity\" , \"emmo.ISQDerivedQuantity\" , \"emmo.SIExactConstant\" , \"emmo.NonSIUnits\" , \"emmo.StandardizedPhysicalQuantity\" , \"emmo.CategorizedPhysicalQuantity\" , \"emmo.AtomicAndNuclearPhysicsQuantity\" , \"emmo.ThermodynamicalQuantity\" , \"emmo.LightAndRadiationQuantity\" , \"emmo.SpaceAndTimeQuantity\" , \"emmo.AcousticQuantity\" , \"emmo.PhysioChememicalQuantity\" , \"emmo.ElectromagneticQuantity\" , \"emmo.MechanicalQuantity\" , \"emmo.CondensedMatterPhysicsQuantity\" , \"emmo.ChemicalCompositionQuantity\" , \"emmo.Extensive\" , \"emmo.Intensive\" , ) ) if not hasattr ( self . onto , \"PhysicalQuantity\" ): return exceptions . update ( self . get_config ( \"test_physical_quantity_dimension.exceptions\" , ()) ) classes = set ( self . onto . classes ( self . check_imported )) for cls in self . onto . PhysicalQuantity . descendants (): if not self . check_imported and cls not in classes : continue if repr ( cls ) not in exceptions : with self . subTest ( cls = cls , label = get_label ( cls )): try : class_props = cls . INDIRECT_get_class_properties () except AttributeError : # The INDIRECT_get_class_properties() method # does not support inverse properties. Build # class_props manually... class_props = set () for _ in cls . mro (): if hasattr ( _ , \"is_a\" ): class_props . update ( [ restriction . property for restriction in _ . is_a if isinstance ( restriction , owlready2 . Restriction ) ] ) self . assertIn ( self . onto . hasPhysicalDimension , class_props , msg = cls ) def test_namespace ( self ): \"\"\"Check that all IRIs are namespaced after their (sub)ontology. Configurations: exceptions - full name of entities to ignore. \"\"\" exceptions = set ( ( \"owl.qualifiedCardinality\" , \"owl.minQualifiedCardinality\" , \"terms.creator\" , \"terms.contributor\" , \"terms.publisher\" , \"terms.title\" , \"terms.license\" , \"terms.abstract\" , \"core.prefLabel\" , \"core.altLabel\" , \"core.hiddenLabel\" , \"mereotopology.Item\" , \"manufacturing.EngineeredMaterial\" , ) ) exceptions . update ( self . get_config ( \"test_namespace.exceptions\" , ())) def checker ( onto , ignore_namespace ): if list ( filter ( onto . base_iri . strip ( \"#\" ) . endswith , self . ignore_namespace ) ): print ( f \"Skipping namespace: { onto . base_iri } \" ) return entities = itertools . chain ( onto . classes (), onto . object_properties (), onto . data_properties (), onto . individuals (), onto . annotation_properties (), ) for entity in entities : if entity not in visited and repr ( entity ) not in exceptions : visited . add ( entity ) with self . subTest ( iri = entity . iri , base_iri = onto . base_iri , entity = repr ( entity ), ): self . assertTrue ( entity . iri . endswith ( entity . name ), msg = ( \"the final part of entity IRIs must be their \" \"name\" ), ) self . assertEqual ( entity . iri , onto . base_iri + entity . name , msg = ( f \"IRI { entity . iri !r} does not correspond to \" f \"module namespace: { onto . base_iri !r} \" ), ) if self . check_imported : for imp_onto in onto . imported_ontologies : if imp_onto not in visited_onto : visited_onto . add ( imp_onto ) checker ( imp_onto , ignore_namespace ) visited = set () visited_onto = set () checker ( self . onto , self . ignore_namespace )","title":"TestFunctionalEMMOConventions"},{"location":"api_reference/emmopy/emmocheck/#emmopy.emmocheck.TestFunctionalEMMOConventions.test_namespace","text":"Check that all IRIs are namespaced after their (sub)ontology. Configurations exceptions - full name of entities to ignore. Source code in emmopy/emmocheck.py def test_namespace ( self ): \"\"\"Check that all IRIs are namespaced after their (sub)ontology. Configurations: exceptions - full name of entities to ignore. \"\"\" exceptions = set ( ( \"owl.qualifiedCardinality\" , \"owl.minQualifiedCardinality\" , \"terms.creator\" , \"terms.contributor\" , \"terms.publisher\" , \"terms.title\" , \"terms.license\" , \"terms.abstract\" , \"core.prefLabel\" , \"core.altLabel\" , \"core.hiddenLabel\" , \"mereotopology.Item\" , \"manufacturing.EngineeredMaterial\" , ) ) exceptions . update ( self . get_config ( \"test_namespace.exceptions\" , ())) def checker ( onto , ignore_namespace ): if list ( filter ( onto . base_iri . strip ( \"#\" ) . endswith , self . ignore_namespace ) ): print ( f \"Skipping namespace: { onto . base_iri } \" ) return entities = itertools . chain ( onto . classes (), onto . object_properties (), onto . data_properties (), onto . individuals (), onto . annotation_properties (), ) for entity in entities : if entity not in visited and repr ( entity ) not in exceptions : visited . add ( entity ) with self . subTest ( iri = entity . iri , base_iri = onto . base_iri , entity = repr ( entity ), ): self . assertTrue ( entity . iri . endswith ( entity . name ), msg = ( \"the final part of entity IRIs must be their \" \"name\" ), ) self . assertEqual ( entity . iri , onto . base_iri + entity . name , msg = ( f \"IRI { entity . iri !r} does not correspond to \" f \"module namespace: { onto . base_iri !r} \" ), ) if self . check_imported : for imp_onto in onto . imported_ontologies : if imp_onto not in visited_onto : visited_onto . add ( imp_onto ) checker ( imp_onto , ignore_namespace ) visited = set () visited_onto = set () checker ( self . onto , self . ignore_namespace )","title":"test_namespace()"},{"location":"api_reference/emmopy/emmocheck/#emmopy.emmocheck.TestFunctionalEMMOConventions.test_physical_quantity_dimension","text":"Check that all physical quantities have hasPhysicalDimension . Note: this test will fail before isq is moved to emmo/domain. Configurations exceptions - full class names of classes to ignore. Source code in emmopy/emmocheck.py def test_physical_quantity_dimension ( self ): \"\"\"Check that all physical quantities have `hasPhysicalDimension`. Note: this test will fail before isq is moved to emmo/domain. Configurations: exceptions - full class names of classes to ignore. \"\"\" exceptions = set ( ( \"emmo.ModelledQuantitativeProperty\" , \"emmo.MeasuredQuantitativeProperty\" , \"emmo.ConventionalQuantitativeProperty\" , \"emmo.QuantitativeProperty\" , \"emmo.BaseQuantity\" , \"emmo.PhysicalConstant\" , \"emmo.PhysicalQuantity\" , \"emmo.ExactConstant\" , \"emmo.MeasuredConstant\" , \"emmo.DerivedQuantity\" , \"emmo.ISQBaseQuantity\" , \"emmo.InternationalSystemOfQuantity\" , \"emmo.ISQDerivedQuantity\" , \"emmo.SIExactConstant\" , \"emmo.NonSIUnits\" , \"emmo.StandardizedPhysicalQuantity\" , \"emmo.CategorizedPhysicalQuantity\" , \"emmo.AtomicAndNuclearPhysicsQuantity\" , \"emmo.ThermodynamicalQuantity\" , \"emmo.LightAndRadiationQuantity\" , \"emmo.SpaceAndTimeQuantity\" , \"emmo.AcousticQuantity\" , \"emmo.PhysioChememicalQuantity\" , \"emmo.ElectromagneticQuantity\" , \"emmo.MechanicalQuantity\" , \"emmo.CondensedMatterPhysicsQuantity\" , \"emmo.ChemicalCompositionQuantity\" , \"emmo.Extensive\" , \"emmo.Intensive\" , ) ) if not hasattr ( self . onto , \"PhysicalQuantity\" ): return exceptions . update ( self . get_config ( \"test_physical_quantity_dimension.exceptions\" , ()) ) classes = set ( self . onto . classes ( self . check_imported )) for cls in self . onto . PhysicalQuantity . descendants (): if not self . check_imported and cls not in classes : continue if repr ( cls ) not in exceptions : with self . subTest ( cls = cls , label = get_label ( cls )): try : class_props = cls . INDIRECT_get_class_properties () except AttributeError : # The INDIRECT_get_class_properties() method # does not support inverse properties. Build # class_props manually... class_props = set () for _ in cls . mro (): if hasattr ( _ , \"is_a\" ): class_props . update ( [ restriction . property for restriction in _ . is_a if isinstance ( restriction , owlready2 . Restriction ) ] ) self . assertIn ( self . onto . hasPhysicalDimension , class_props , msg = cls )","title":"test_physical_quantity_dimension()"},{"location":"api_reference/emmopy/emmocheck/#emmopy.emmocheck.TestFunctionalEMMOConventions.test_quantity_dimension","text":"Check that all quantities have a physicalDimension annotation. Note: this test will be deprecated when isq is moved to emmo/domain. Configurations exceptions - full class names of classes to ignore. Source code in emmopy/emmocheck.py def test_quantity_dimension ( self ): \"\"\"Check that all quantities have a physicalDimension annotation. Note: this test will be deprecated when isq is moved to emmo/domain. Configurations: exceptions - full class names of classes to ignore. \"\"\" exceptions = set ( ( \"properties.ModelledQuantitativeProperty\" , \"properties.MeasuredQuantitativeProperty\" , \"properties.ConventionalQuantitativeProperty\" , \"metrology.QuantitativeProperty\" , \"metrology.Quantity\" , \"metrology.OrdinalQuantity\" , \"metrology.BaseQuantity\" , \"metrology.PhysicalConstant\" , \"metrology.PhysicalQuantity\" , \"metrology.ExactConstant\" , \"metrology.MeasuredConstant\" , \"metrology.DerivedQuantity\" , \"isq.ISQBaseQuantity\" , \"isq.InternationalSystemOfQuantity\" , \"isq.ISQDerivedQuantity\" , \"isq.SIExactConstant\" , \"emmo.ModelledQuantitativeProperty\" , \"emmo.MeasuredQuantitativeProperty\" , \"emmo.ConventionalQuantitativeProperty\" , \"emmo.QuantitativeProperty\" , \"emmo.Quantity\" , \"emmo.OrdinalQuantity\" , \"emmo.BaseQuantity\" , \"emmo.PhysicalConstant\" , \"emmo.PhysicalQuantity\" , \"emmo.ExactConstant\" , \"emmo.MeasuredConstant\" , \"emmo.DerivedQuantity\" , \"emmo.ISQBaseQuantity\" , \"emmo.InternationalSystemOfQuantity\" , \"emmo.ISQDerivedQuantity\" , \"emmo.SIExactConstant\" , \"emmo.NonSIUnits\" , \"emmo.StandardizedPhysicalQuantity\" , \"emmo.CategorizedPhysicalQuantity\" , \"emmo.AtomicAndNuclear\" , \"emmo.Defined\" , \"emmo.Electromagnetic\" , \"emmo.FrequentlyUsed\" , \"emmo.PhysicoChemical\" , \"emmo.ChemicalCompositionQuantity\" , \"emmo.Universal\" , ) ) if not hasattr ( self . onto , \"PhysicalQuantity\" ): return exceptions . update ( self . get_config ( \"test_quantity_dimension.exceptions\" , ()) ) regex = re . compile ( \"^T([+-][1-9]|0) L([+-][1-9]|0) M([+-][1-9]|0) I([+-][1-9]|0) \" \"(H|\u0398)([+-][1-9]|0) N([+-][1-9]|0) J([+-][1-9]|0)$\" ) classes = set ( self . onto . classes ( self . check_imported )) for cls in self . onto . PhysicalQuantity . descendants (): if not self . check_imported and cls not in classes : continue if repr ( cls ) not in exceptions : with self . subTest ( cls = cls , label = get_label ( cls )): anno = cls . get_annotations () self . assertIn ( \"physicalDimension\" , anno , msg = cls ) physdim = anno [ \"physicalDimension\" ] . first () self . assertRegex ( physdim , regex , msg = cls )","title":"test_quantity_dimension()"},{"location":"api_reference/emmopy/emmocheck/#emmopy.emmocheck.TestFunctionalEMMOConventions.test_unit_dimension","text":"Check that all measurement units have a physical dimension. Configurations exceptions - full class names of classes to ignore. Source code in emmopy/emmocheck.py def test_unit_dimension ( self ): \"\"\"Check that all measurement units have a physical dimension. Configurations: exceptions - full class names of classes to ignore. \"\"\" exceptions = set ( ( \"metrology.MultipleUnit\" , \"metrology.SubMultipleUnit\" , \"metrology.OffSystemUnit\" , \"metrology.PrefixedUnit\" , \"metrology.NonPrefixedUnit\" , \"metrology.SpecialUnit\" , \"metrology.DerivedUnit\" , \"metrology.BaseUnit\" , \"metrology.UnitSymbol\" , \"siunits.SICoherentDerivedUnit\" , \"siunits.SINonCoherentDerivedUnit\" , \"siunits.SISpecialUnit\" , \"siunits.SICoherentUnit\" , \"siunits.SIPrefixedUnit\" , \"siunits.SIBaseUnit\" , \"siunits.SIUnitSymbol\" , \"siunits.SIUnit\" , \"emmo.MultipleUnit\" , \"emmo.SubMultipleUnit\" , \"emmo.OffSystemUnit\" , \"emmo.PrefixedUnit\" , \"emmo.NonPrefixedUnit\" , \"emmo.SpecialUnit\" , \"emmo.DerivedUnit\" , \"emmo.BaseUnit\" , \"emmo.UnitSymbol\" , \"emmo.SICoherentDerivedUnit\" , \"emmo.SINonCoherentDerivedUnit\" , \"emmo.SISpecialUnit\" , \"emmo.SICoherentUnit\" , \"emmo.SIPrefixedUnit\" , \"emmo.SIBaseUnit\" , \"emmo.SIUnitSymbol\" , \"emmo.SIUnit\" , ) ) if not hasattr ( self . onto , \"MeasurementUnit\" ): return exceptions . update ( self . get_config ( \"test_unit_dimension.exceptions\" , ())) regex = re . compile ( r \"^(emmo|metrology).hasPhysicalDimension.some\\(.*\\)$\" ) classes = set ( self . onto . classes ( self . check_imported )) for cls in self . onto . MeasurementUnit . descendants (): if not self . check_imported and cls not in classes : continue # Assume that actual units are not subclassed if not list ( cls . subclasses ()) and repr ( cls ) not in exceptions : with self . subTest ( cls = cls , label = get_label ( cls )): self . assertTrue ( any ( regex . match ( repr ( r )) for r in cls . get_indirect_is_a () ), msg = cls , )","title":"test_unit_dimension()"},{"location":"api_reference/emmopy/emmocheck/#emmopy.emmocheck.TestSyntacticEMMOConventions","text":"Test syntactic EMMO conventions. Source code in emmopy/emmocheck.py class TestSyntacticEMMOConventions ( TestEMMOConventions ): \"\"\"Test syntactic EMMO conventions.\"\"\" def test_number_of_labels ( self ): \"\"\"Check that all entities have one and only one prefLabel. Use \"altLabel\" for synonyms. The only allowed exception is entities who's representation starts with \"owl.\". \"\"\" exceptions = set ( ( \"terms.license\" , \"terms.abstract\" , \"terms.contributor\" , \"terms.creator\" , \"terms.publisher\" , \"terms.title\" , \"core.prefLabel\" , \"core.altLabel\" , \"core.hiddenLabel\" , ) ) exceptions . update ( self . get_config ( \"test_number_of_labels.exceptions\" , ()) ) if ( \"prefLabel\" in self . onto . world . _props # pylint: disable=protected-access ): for entity in self . onto . get_entities (): if repr ( entity ) not in exceptions : with self . subTest ( entity = entity , label = get_label ( entity ), prefLabels = entity . prefLabel , ): if not repr ( entity ) . startswith ( \"owl.\" ): self . assertTrue ( hasattr ( entity , \"prefLabel\" )) self . assertEqual ( 1 , len ( entity . prefLabel )) else : self . fail ( \"ontology has no prefLabel\" ) def test_class_label ( self ): \"\"\"Check that class labels are CamelCase and valid identifiers. For CamelCase, we are currently only checking that the labels start with upper case. \"\"\" exceptions = set ( ( \"0-manifold\" , # not needed in 1.0.0-beta \"1-manifold\" , \"2-manifold\" , \"3-manifold\" , \"C++\" , ) ) exceptions . update ( self . get_config ( \"test_class_label.exceptions\" , ())) for cls in self . onto . classes ( self . check_imported ): for label in cls . label + getattr ( cls , \"prefLabel\" , []): if label not in exceptions : with self . subTest ( entity = cls , label = label ): self . assertTrue ( label . isidentifier ()) self . assertTrue ( label [ 0 ] . isupper ()) def test_object_property_label ( self ): \"\"\"Check that object property labels are lowerCamelCase. Allowed exceptions: \"EMMORelation\" If they start with \"has\" or \"is\" they should be followed by a upper case letter. If they start with \"is\" they should also end with \"Of\". \"\"\" exceptions = set (( \"EMMORelation\" ,)) exceptions . update ( self . get_config ( \"test_object_property_label.exceptions\" , ()) ) for obj_prop in self . onto . object_properties (): if repr ( obj_prop ) not in exceptions : for label in obj_prop . label : with self . subTest ( entity = obj_prop , label = label ): self . assertTrue ( label [ 0 ] . islower (), \"label start with lowercase\" ) if label . startswith ( \"has\" ): self . assertTrue ( label [ 3 ] . isupper (), 'what follows \"has\" must be \"uppercase\"' , ) if label . startswith ( \"is\" ): self . assertTrue ( label [ 2 ] . isupper (), 'what follows \"is\" must be \"uppercase\"' , ) self . assertTrue ( label . endswith (( \"Of\" , \"With\" )), 'should end with \"Of\" or \"With\"' , )","title":"TestSyntacticEMMOConventions"},{"location":"api_reference/emmopy/emmocheck/#emmopy.emmocheck.TestSyntacticEMMOConventions.test_class_label","text":"Check that class labels are CamelCase and valid identifiers. For CamelCase, we are currently only checking that the labels start with upper case. Source code in emmopy/emmocheck.py def test_class_label ( self ): \"\"\"Check that class labels are CamelCase and valid identifiers. For CamelCase, we are currently only checking that the labels start with upper case. \"\"\" exceptions = set ( ( \"0-manifold\" , # not needed in 1.0.0-beta \"1-manifold\" , \"2-manifold\" , \"3-manifold\" , \"C++\" , ) ) exceptions . update ( self . get_config ( \"test_class_label.exceptions\" , ())) for cls in self . onto . classes ( self . check_imported ): for label in cls . label + getattr ( cls , \"prefLabel\" , []): if label not in exceptions : with self . subTest ( entity = cls , label = label ): self . assertTrue ( label . isidentifier ()) self . assertTrue ( label [ 0 ] . isupper ())","title":"test_class_label()"},{"location":"api_reference/emmopy/emmocheck/#emmopy.emmocheck.TestSyntacticEMMOConventions.test_number_of_labels","text":"Check that all entities have one and only one prefLabel. Use \"altLabel\" for synonyms. The only allowed exception is entities who's representation starts with \"owl.\". Source code in emmopy/emmocheck.py def test_number_of_labels ( self ): \"\"\"Check that all entities have one and only one prefLabel. Use \"altLabel\" for synonyms. The only allowed exception is entities who's representation starts with \"owl.\". \"\"\" exceptions = set ( ( \"terms.license\" , \"terms.abstract\" , \"terms.contributor\" , \"terms.creator\" , \"terms.publisher\" , \"terms.title\" , \"core.prefLabel\" , \"core.altLabel\" , \"core.hiddenLabel\" , ) ) exceptions . update ( self . get_config ( \"test_number_of_labels.exceptions\" , ()) ) if ( \"prefLabel\" in self . onto . world . _props # pylint: disable=protected-access ): for entity in self . onto . get_entities (): if repr ( entity ) not in exceptions : with self . subTest ( entity = entity , label = get_label ( entity ), prefLabels = entity . prefLabel , ): if not repr ( entity ) . startswith ( \"owl.\" ): self . assertTrue ( hasattr ( entity , \"prefLabel\" )) self . assertEqual ( 1 , len ( entity . prefLabel )) else : self . fail ( \"ontology has no prefLabel\" )","title":"test_number_of_labels()"},{"location":"api_reference/emmopy/emmocheck/#emmopy.emmocheck.TestSyntacticEMMOConventions.test_object_property_label","text":"Check that object property labels are lowerCamelCase. Allowed exceptions: \"EMMORelation\" If they start with \"has\" or \"is\" they should be followed by a upper case letter. If they start with \"is\" they should also end with \"Of\". Source code in emmopy/emmocheck.py def test_object_property_label ( self ): \"\"\"Check that object property labels are lowerCamelCase. Allowed exceptions: \"EMMORelation\" If they start with \"has\" or \"is\" they should be followed by a upper case letter. If they start with \"is\" they should also end with \"Of\". \"\"\" exceptions = set (( \"EMMORelation\" ,)) exceptions . update ( self . get_config ( \"test_object_property_label.exceptions\" , ()) ) for obj_prop in self . onto . object_properties (): if repr ( obj_prop ) not in exceptions : for label in obj_prop . label : with self . subTest ( entity = obj_prop , label = label ): self . assertTrue ( label [ 0 ] . islower (), \"label start with lowercase\" ) if label . startswith ( \"has\" ): self . assertTrue ( label [ 3 ] . isupper (), 'what follows \"has\" must be \"uppercase\"' , ) if label . startswith ( \"is\" ): self . assertTrue ( label [ 2 ] . isupper (), 'what follows \"is\" must be \"uppercase\"' , ) self . assertTrue ( label . endswith (( \"Of\" , \"With\" )), 'should end with \"Of\" or \"With\"' , )","title":"test_object_property_label()"},{"location":"api_reference/emmopy/emmocheck/#emmopy.emmocheck.main","text":"Run all checks on ontology iri . Default is 'http://emmo.info/emmo'. Parameters: Name Type Description Default argv list List of arguments, similar to sys.argv[1:] . Mainly for testing purposes, since it allows one to invoke the tool manually / through Python. None Source code in emmopy/emmocheck.py def main ( argv : list = None , ): # pylint: disable=too-many-locals,too-many-branches,too-many-statements \"\"\"Run all checks on ontology `iri`. Default is 'http://emmo.info/emmo'. Parameters: argv: List of arguments, similar to `sys.argv[1:]`. Mainly for testing purposes, since it allows one to invoke the tool manually / through Python. \"\"\" parser = argparse . ArgumentParser ( description = __doc__ ) parser . add_argument ( \"iri\" , help = \"File name or URI to the ontology to test.\" ) parser . add_argument ( \"--database\" , \"-d\" , metavar = \"FILENAME\" , default = \":memory:\" , help = ( \"Load ontology from Owlready2 sqlite3 database. The `iri` argument\" \" should in this case be the IRI of the ontology you want to \" \"check.\" ), ) parser . add_argument ( \"--local\" , \"-l\" , action = \"store_true\" , help = ( \"Load imported ontologies locally. Their paths are specified in \" \"Prot\u00e8g\u00e8 catalog files or via the --path option. The IRI should \" \"be a file name.\" ), ) parser . add_argument ( \"--catalog-file\" , default = \"catalog-v001.xml\" , help = ( \"Name of Prot\u00e8g\u00e8 catalog file in the same folder as the ontology. \" \"This option is used together with --local and defaults to \" '\"catalog-v001.xml\".' ), ) parser . add_argument ( \"--path\" , action = \"append\" , default = [], help = ( \"Paths where imported ontologies can be found. May be provided as \" \"a comma-separated string and/or with multiple --path options.\" ), ) parser . add_argument ( \"--check-imported\" , \"-i\" , action = \"store_true\" , help = \"Whether to check imported ontologies.\" , ) parser . add_argument ( \"--verbose\" , \"-v\" , action = \"store_true\" , help = \"Verbosity level.\" ) parser . add_argument ( \"--configfile\" , \"-c\" , help = \"A yaml file with additional test configurations.\" , ) parser . add_argument ( \"--skip\" , \"-s\" , action = \"append\" , default = [], help = ( \"Shell pattern matching tests to skip. This option may be \" \"provided multiple times.\" ), ) parser . add_argument ( \"--enable\" , \"-e\" , action = \"append\" , default = [], help = ( \"Shell pattern matching tests to enable that have been skipped by \" \"default or in the config file. This option may be provided \" \"multiple times.\" ), ) parser . add_argument ( # deprecated, replaced by --no-catalog \"--url-from-catalog\" , \"-u\" , default = None , action = \"store_true\" , help = \"Get url from catalog file\" , ) parser . add_argument ( \"--no-catalog\" , action = \"store_false\" , dest = \"url_from_catalog\" , default = None , help = \"Whether to not read catalog file even if it exists.\" , ) parser . add_argument ( \"--ignore-namespace\" , \"-n\" , action = \"append\" , default = [], help = \"Namespace to be ignored. Can be given multiple times\" , ) # Options to pass forward to unittest parser . add_argument ( \"--buffer\" , \"-b\" , dest = \"unittest\" , action = \"append_const\" , const = \"-b\" , help = ( \"The standard output and standard error streams are buffered \" \"during the test run. Output during a passing test is discarded. \" \"Output is echoed normally on test fail or error and is added to \" \"the failure messages.\" ), ) parser . add_argument ( \"--catch\" , dest = \"unittest\" , action = \"append_const\" , const = \"-c\" , help = ( \"Control-C during the test run waits for the current test to end \" \"and then reports all the results so far. A second control-C \" \"raises the normal KeyboardInterrupt exception\" ), ) parser . add_argument ( \"--failfast\" , \"-f\" , dest = \"unittest\" , action = \"append_const\" , const = \"-f\" , help = \"Stop the test run on the first error or failure.\" , ) try : args = parser . parse_args ( args = argv ) sys . argv [ 1 :] = args . unittest if args . unittest else [] if args . verbose : sys . argv . append ( \"-v\" ) except SystemExit as exc : sys . exit ( exc . code ) # Exit without traceback on invalid arguments # Append to onto_path for paths in args . path : for path in paths . split ( \",\" ): if path not in onto_path : onto_path . append ( path ) # Load ontology world = World ( filename = args . database ) if args . database != \":memory:\" and args . iri not in world . ontologies : parser . error ( \"The IRI argument should be one of the ontologies in \" \"the database: \\n \" + \" \\n \" . join ( world . ontologies . keys ()) ) onto = world . get_ontology ( args . iri ) onto . load ( only_local = args . local , url_from_catalog = args . url_from_catalog , catalog_file = args . catalog_file , ) # Store settings TestEMMOConventions TestEMMOConventions . onto = onto TestEMMOConventions . check_imported = args . check_imported TestEMMOConventions . ignore_namespace = args . ignore_namespace # Configure tests verbosity = 2 if args . verbose else 1 if args . configfile : import yaml # pylint: disable=import-outside-toplevel with open ( args . configfile , \"rt\" ) as handle : TestEMMOConventions . config . update ( yaml . load ( handle , Loader = yaml . SafeLoader ) ) # Run all subclasses of TestEMMOConventions as test suites status = 0 for cls in TestEMMOConventions . __subclasses__ (): # pylint: disable=cell-var-from-loop,undefined-loop-variable suite = unittest . TestLoader () . loadTestsFromTestCase ( cls ) # Mark tests to be skipped for test in suite : name = test . id () . split ( \".\" )[ - 1 ] skipped = set ( # skipped by default [ \"test_namespace\" , \"test_physical_quantity_dimension\" , ] ) msg = { name : \"skipped by default\" for name in skipped } # enable/skip tests from config file for pattern in test . get_config ( \"enable\" , ()): if fnmatch . fnmatchcase ( name , pattern ): skipped . remove ( name ) for pattern in test . get_config ( \"skip\" , ()): if fnmatch . fnmatchcase ( name , pattern ): skipped . add ( name ) msg [ name ] = \"skipped from config file\" # enable/skip from command line for pattern in args . enable : if fnmatch . fnmatchcase ( name , pattern ): skipped . remove ( name ) for pattern in args . skip : if fnmatch . fnmatchcase ( name , pattern ): skipped . add ( name ) msg [ name ] = \"skipped from command line\" if name in skipped : setattr ( test , \"setUp\" , lambda : test . skipTest ( msg . get ( name , \"\" ))) runner = TextTestRunner ( verbosity = verbosity ) runner . resultclass . checkmode = True result = runner . run ( suite ) if result . failures : status = 1 return status","title":"main()"},{"location":"api_reference/emmopy/emmopy/","text":"emmopy \u00b6 emmopy.emmopy \u00b6 Automagically retrieve the EMMO utilizing ontopy.get_ontology . get_emmo ( inferred = True ) \u00b6 Returns the current version of emmo. Parameters: Name Type Description Default inferred Optional[bool] Whether to import the inferred version of emmo or not. Default is True. True Returns: Type Description Ontology The loaded emmo ontology. Source code in emmopy/emmopy.py def get_emmo ( inferred : Optional [ bool ] = True ) -> \"Ontology\" : \"\"\"Returns the current version of emmo. Args: inferred: Whether to import the inferred version of emmo or not. Default is True. Returns: The loaded emmo ontology. \"\"\" name = \"emmo-inferred\" if inferred in [ True , None ] else \"emmo\" return get_ontology ( name ) . load ( prefix_emmo = True )","title":"emmopy"},{"location":"api_reference/emmopy/emmopy/#emmopy","text":"","title":"emmopy"},{"location":"api_reference/emmopy/emmopy/#emmopy.emmopy--emmopyemmopy","text":"Automagically retrieve the EMMO utilizing ontopy.get_ontology .","title":"\n\n  \n\n\n    \n\n      emmopy.emmopy&para;\nAutomagically retrieve the EMMO utilizing\nontopy.get_ontology.\n\n\n\n  \n\n\n\n\n\n\n\n\n  \n\n\n\n\nget_emmo(inferred=True)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Returns the current version of emmo.\n\nParameters:\n\n  \n    \n      Name\n      Type\n      Description\n      Default\n    \n  \n  \n      \n        inferred\n        Optional[bool]\n        Whether to import the inferred version of emmo or not.\nDefault is True.\n        True\n      \n  \n\nReturns:\n\n  \n    \n      Type\n      Description\n    \n  \n  \n    \n      Ontology\n      The loaded emmo ontology.\n    \n  \n\n        \n          Source code in emmopy/emmopy.py\n          def get_emmo(inferred: Optional[bool] = True) -&gt; &quot;Ontology&quot;:\n    &quot;&quot;&quot;Returns the current version of emmo.\n\n    Args:\n        inferred: Whether to import the inferred version of emmo or not.\n            Default is True.\n\n    Returns:\n        The loaded emmo ontology.\n\n    &quot;&quot;&quot;\n    name = &quot;emmo-inferred&quot; if inferred in [True, None] else &quot;emmo&quot;\n    return get_ontology(name).load(prefix_emmo=True)\n\n        \n    \n\n  \n\n\n\n\n\n\n  \n\n    \n\n  \n\n"},{"location":"api_reference/emmopy/emmopy/#emmopy.emmopy.get_emmo","text":"Returns the current version of emmo. Parameters: Name Type Description Default inferred Optional[bool] Whether to import the inferred version of emmo or not. Default is True. True Returns: Type Description Ontology The loaded emmo ontology. Source code in emmopy/emmopy.py def get_emmo ( inferred : Optional [ bool ] = True ) -> \"Ontology\" : \"\"\"Returns the current version of emmo. Args: inferred: Whether to import the inferred version of emmo or not. Default is True. Returns: The loaded emmo ontology. \"\"\" name = \"emmo-inferred\" if inferred in [ True , None ] else \"emmo\" return get_ontology ( name ) . load ( prefix_emmo = True )","title":"get_emmo()"},{"location":"api_reference/ontopy/colortest/","text":"colortest \u00b6 ontopy.colortest \u00b6 Print tests in colors. Adapted from https://github.com/meshy/colour-runner by Charlie Denton License: MIT ColourTextTestResult ( TestResult ) \u00b6 A test result class that prints colour formatted text results to a stream. Based on https://github.com/python/cpython/blob/3.3/Lib/unittest/runner.py Source code in ontopy/colortest.py class ColourTextTestResult ( TestResult ): \"\"\" A test result class that prints colour formatted text results to a stream. Based on https://github.com/python/cpython/blob/3.3/Lib/unittest/runner.py \"\"\" formatter = formatters . Terminal256Formatter () # pylint: disable=no-member lexer = Lexer () separator1 = \"=\" * 70 separator2 = \"-\" * 70 indent = \" \" * 4 # if `checkmode` is true, simplified output will be generated with # no traceback checkmode = False _terminal = Terminal () colours = { None : str , \"error\" : _terminal . bold_red , \"expected\" : _terminal . blue , # \"fail\": _terminal.bold_yellow, \"fail\" : _terminal . bold_magenta , \"skip\" : str , \"success\" : _terminal . green , \"title\" : _terminal . blue , \"unexpected\" : _terminal . bold_red , } _test_class = None def __init__ ( self , stream , descriptions , verbosity ): super () . __init__ ( stream , descriptions , verbosity ) self . stream = stream self . show_all = verbosity > 1 self . dots = verbosity == 1 self . descriptions = descriptions def getShortDescription ( self , test ): doc_first_line = test . shortDescription () if self . descriptions and doc_first_line : return self . indent + doc_first_line return self . indent + test . _testMethodName def getLongDescription ( self , test ): doc_first_line = test . shortDescription () if self . descriptions and doc_first_line : return \" \\n \" . join (( str ( test ), doc_first_line )) return str ( test ) def getClassDescription ( self , test ): test_class = test . __class__ doc = test_class . __doc__ if self . descriptions and doc : return doc . split ( \" \\n \" )[ 0 ] . strip () return strclass ( test_class ) def startTest ( self , test ): super () . startTest ( test ) pos = 0 if self . show_all : if self . _test_class != test . __class__ : self . _test_class = test . __class__ title = self . getClassDescription ( test ) self . stream . writeln ( self . colours [ \"title\" ]( title )) descr = self . getShortDescription ( test ) self . stream . write ( descr ) pos += len ( descr ) self . stream . write ( \" \" * ( 70 - pos )) # self.stream.write(' ' * (self._terminal.width - 10 - pos)) # self.stream.write(' ... ') self . stream . flush () def printResult ( self , short , extended , colour_key = None ): colour = self . colours [ colour_key ] if self . show_all : self . stream . writeln ( colour ( extended )) elif self . dots : self . stream . write ( colour ( short )) self . stream . flush () def addSuccess ( self , test ): super () . addSuccess ( test ) self . printResult ( \".\" , \"ok\" , \"success\" ) def addError ( self , test , err ): super () . addError ( test , err ) self . printResult ( \"E\" , \"ERROR\" , \"error\" ) def addFailure ( self , test , err ): super () . addFailure ( test , err ) self . printResult ( \"F\" , \"FAIL\" , \"fail\" ) def addSkip ( self , test , reason ): super () . addSkip ( test , reason ) if self . checkmode : self . printResult ( \"s\" , \"skipped\" , \"skip\" ) else : self . printResult ( \"s\" , f \"skipped { reason !r} \" , \"skip\" ) def addExpectedFailure ( self , test , err ): super () . addExpectedFailure ( test , err ) self . printResult ( \"x\" , \"expected failure\" , \"expected\" ) def addUnexpectedSuccess ( self , test ): super () . addUnexpectedSuccess ( test ) self . printResult ( \"u\" , \"unexpected success\" , \"unexpected\" ) def printErrors ( self ): if self . dots or self . show_all : self . stream . writeln () self . printErrorList ( \"ERROR\" , self . errors ) self . printErrorList ( \"FAIL\" , self . failures ) def printErrorList ( self , flavour , errors ): colour = self . colours [ flavour . lower ()] for test , err in errors : if self . checkmode and flavour == \"FAIL\" : self . stream . writeln ( self . separator1 ) title = f \" { flavour } : { test . shortDescription () } \" self . stream . writeln ( colour ( title )) self . stream . writeln ( str ( test )) if self . show_all : self . stream . writeln ( self . separator2 ) lines = str ( err ) . split ( \" \\n \" ) i = 1 for line in lines [ 1 :]: if line . startswith ( \" \" ): i += 1 else : break self . stream . writeln ( highlight ( \" \\n \" . join ( lines [ i :]), self . lexer , self . formatter ) ) else : self . stream . writeln ( self . separator1 ) title = f \" { flavour } : { self . getLongDescription ( test ) } \" self . stream . writeln ( colour ( title )) self . stream . writeln ( self . separator2 ) self . stream . writeln ( highlight ( err , self . lexer , self . formatter )) addError ( self , test , err ) \u00b6 Called when an error has occurred. 'err' is a tuple of values as returned by sys.exc_info(). Source code in ontopy/colortest.py def addError ( self , test , err ): super () . addError ( test , err ) self . printResult ( \"E\" , \"ERROR\" , \"error\" ) addExpectedFailure ( self , test , err ) \u00b6 Called when an expected failure/error occurred. Source code in ontopy/colortest.py def addExpectedFailure ( self , test , err ): super () . addExpectedFailure ( test , err ) self . printResult ( \"x\" , \"expected failure\" , \"expected\" ) addFailure ( self , test , err ) \u00b6 Called when an error has occurred. 'err' is a tuple of values as returned by sys.exc_info(). Source code in ontopy/colortest.py def addFailure ( self , test , err ): super () . addFailure ( test , err ) self . printResult ( \"F\" , \"FAIL\" , \"fail\" ) addSkip ( self , test , reason ) \u00b6 Called when a test is skipped. Source code in ontopy/colortest.py def addSkip ( self , test , reason ): super () . addSkip ( test , reason ) if self . checkmode : self . printResult ( \"s\" , \"skipped\" , \"skip\" ) else : self . printResult ( \"s\" , f \"skipped { reason !r} \" , \"skip\" ) addSuccess ( self , test ) \u00b6 Called when a test has completed successfully Source code in ontopy/colortest.py def addSuccess ( self , test ): super () . addSuccess ( test ) self . printResult ( \".\" , \"ok\" , \"success\" ) addUnexpectedSuccess ( self , test ) \u00b6 Called when a test was expected to fail, but succeed. Source code in ontopy/colortest.py def addUnexpectedSuccess ( self , test ): super () . addUnexpectedSuccess ( test ) self . printResult ( \"u\" , \"unexpected success\" , \"unexpected\" ) printErrors ( self ) \u00b6 Called by TestRunner after test run Source code in ontopy/colortest.py def printErrors ( self ): if self . dots or self . show_all : self . stream . writeln () self . printErrorList ( \"ERROR\" , self . errors ) self . printErrorList ( \"FAIL\" , self . failures ) startTest ( self , test ) \u00b6 Called when the given test is about to be run Source code in ontopy/colortest.py def startTest ( self , test ): super () . startTest ( test ) pos = 0 if self . show_all : if self . _test_class != test . __class__ : self . _test_class = test . __class__ title = self . getClassDescription ( test ) self . stream . writeln ( self . colours [ \"title\" ]( title )) descr = self . getShortDescription ( test ) self . stream . write ( descr ) pos += len ( descr ) self . stream . write ( \" \" * ( 70 - pos )) # self.stream.write(' ' * (self._terminal.width - 10 - pos)) # self.stream.write(' ... ') self . stream . flush () ColourTextTestRunner ( TextTestRunner ) \u00b6 A test runner that uses colour in its output. Source code in ontopy/colortest.py class ColourTextTestRunner ( TextTestRunner ): # pylint: disable=too-few-public-methods \"\"\"A test runner that uses colour in its output.\"\"\" resultclass = ColourTextTestResult resultclass ( TestResult ) \u00b6 A test result class that prints colour formatted text results to a stream. Based on https://github.com/python/cpython/blob/3.3/Lib/unittest/runner.py Source code in ontopy/colortest.py class ColourTextTestResult ( TestResult ): \"\"\" A test result class that prints colour formatted text results to a stream. Based on https://github.com/python/cpython/blob/3.3/Lib/unittest/runner.py \"\"\" formatter = formatters . Terminal256Formatter () # pylint: disable=no-member lexer = Lexer () separator1 = \"=\" * 70 separator2 = \"-\" * 70 indent = \" \" * 4 # if `checkmode` is true, simplified output will be generated with # no traceback checkmode = False _terminal = Terminal () colours = { None : str , \"error\" : _terminal . bold_red , \"expected\" : _terminal . blue , # \"fail\": _terminal.bold_yellow, \"fail\" : _terminal . bold_magenta , \"skip\" : str , \"success\" : _terminal . green , \"title\" : _terminal . blue , \"unexpected\" : _terminal . bold_red , } _test_class = None def __init__ ( self , stream , descriptions , verbosity ): super () . __init__ ( stream , descriptions , verbosity ) self . stream = stream self . show_all = verbosity > 1 self . dots = verbosity == 1 self . descriptions = descriptions def getShortDescription ( self , test ): doc_first_line = test . shortDescription () if self . descriptions and doc_first_line : return self . indent + doc_first_line return self . indent + test . _testMethodName def getLongDescription ( self , test ): doc_first_line = test . shortDescription () if self . descriptions and doc_first_line : return \" \\n \" . join (( str ( test ), doc_first_line )) return str ( test ) def getClassDescription ( self , test ): test_class = test . __class__ doc = test_class . __doc__ if self . descriptions and doc : return doc . split ( \" \\n \" )[ 0 ] . strip () return strclass ( test_class ) def startTest ( self , test ): super () . startTest ( test ) pos = 0 if self . show_all : if self . _test_class != test . __class__ : self . _test_class = test . __class__ title = self . getClassDescription ( test ) self . stream . writeln ( self . colours [ \"title\" ]( title )) descr = self . getShortDescription ( test ) self . stream . write ( descr ) pos += len ( descr ) self . stream . write ( \" \" * ( 70 - pos )) # self.stream.write(' ' * (self._terminal.width - 10 - pos)) # self.stream.write(' ... ') self . stream . flush () def printResult ( self , short , extended , colour_key = None ): colour = self . colours [ colour_key ] if self . show_all : self . stream . writeln ( colour ( extended )) elif self . dots : self . stream . write ( colour ( short )) self . stream . flush () def addSuccess ( self , test ): super () . addSuccess ( test ) self . printResult ( \".\" , \"ok\" , \"success\" ) def addError ( self , test , err ): super () . addError ( test , err ) self . printResult ( \"E\" , \"ERROR\" , \"error\" ) def addFailure ( self , test , err ): super () . addFailure ( test , err ) self . printResult ( \"F\" , \"FAIL\" , \"fail\" ) def addSkip ( self , test , reason ): super () . addSkip ( test , reason ) if self . checkmode : self . printResult ( \"s\" , \"skipped\" , \"skip\" ) else : self . printResult ( \"s\" , f \"skipped { reason !r} \" , \"skip\" ) def addExpectedFailure ( self , test , err ): super () . addExpectedFailure ( test , err ) self . printResult ( \"x\" , \"expected failure\" , \"expected\" ) def addUnexpectedSuccess ( self , test ): super () . addUnexpectedSuccess ( test ) self . printResult ( \"u\" , \"unexpected success\" , \"unexpected\" ) def printErrors ( self ): if self . dots or self . show_all : self . stream . writeln () self . printErrorList ( \"ERROR\" , self . errors ) self . printErrorList ( \"FAIL\" , self . failures ) def printErrorList ( self , flavour , errors ): colour = self . colours [ flavour . lower ()] for test , err in errors : if self . checkmode and flavour == \"FAIL\" : self . stream . writeln ( self . separator1 ) title = f \" { flavour } : { test . shortDescription () } \" self . stream . writeln ( colour ( title )) self . stream . writeln ( str ( test )) if self . show_all : self . stream . writeln ( self . separator2 ) lines = str ( err ) . split ( \" \\n \" ) i = 1 for line in lines [ 1 :]: if line . startswith ( \" \" ): i += 1 else : break self . stream . writeln ( highlight ( \" \\n \" . join ( lines [ i :]), self . lexer , self . formatter ) ) else : self . stream . writeln ( self . separator1 ) title = f \" { flavour } : { self . getLongDescription ( test ) } \" self . stream . writeln ( colour ( title )) self . stream . writeln ( self . separator2 ) self . stream . writeln ( highlight ( err , self . lexer , self . formatter )) addError ( self , test , err ) \u00b6 Called when an error has occurred. 'err' is a tuple of values as returned by sys.exc_info(). Source code in ontopy/colortest.py def addError ( self , test , err ): super () . addError ( test , err ) self . printResult ( \"E\" , \"ERROR\" , \"error\" ) addExpectedFailure ( self , test , err ) \u00b6 Called when an expected failure/error occurred. Source code in ontopy/colortest.py def addExpectedFailure ( self , test , err ): super () . addExpectedFailure ( test , err ) self . printResult ( \"x\" , \"expected failure\" , \"expected\" ) addFailure ( self , test , err ) \u00b6 Called when an error has occurred. 'err' is a tuple of values as returned by sys.exc_info(). Source code in ontopy/colortest.py def addFailure ( self , test , err ): super () . addFailure ( test , err ) self . printResult ( \"F\" , \"FAIL\" , \"fail\" ) addSkip ( self , test , reason ) \u00b6 Called when a test is skipped. Source code in ontopy/colortest.py def addSkip ( self , test , reason ): super () . addSkip ( test , reason ) if self . checkmode : self . printResult ( \"s\" , \"skipped\" , \"skip\" ) else : self . printResult ( \"s\" , f \"skipped { reason !r} \" , \"skip\" ) addSuccess ( self , test ) \u00b6 Called when a test has completed successfully Source code in ontopy/colortest.py def addSuccess ( self , test ): super () . addSuccess ( test ) self . printResult ( \".\" , \"ok\" , \"success\" ) addUnexpectedSuccess ( self , test ) \u00b6 Called when a test was expected to fail, but succeed. Source code in ontopy/colortest.py def addUnexpectedSuccess ( self , test ): super () . addUnexpectedSuccess ( test ) self . printResult ( \"u\" , \"unexpected success\" , \"unexpected\" ) printErrors ( self ) \u00b6 Called by TestRunner after test run Source code in ontopy/colortest.py def printErrors ( self ): if self . dots or self . show_all : self . stream . writeln () self . printErrorList ( \"ERROR\" , self . errors ) self . printErrorList ( \"FAIL\" , self . failures ) startTest ( self , test ) \u00b6 Called when the given test is about to be run Source code in ontopy/colortest.py def startTest ( self , test ): super () . startTest ( test ) pos = 0 if self . show_all : if self . _test_class != test . __class__ : self . _test_class = test . __class__ title = self . getClassDescription ( test ) self . stream . writeln ( self . colours [ \"title\" ]( title )) descr = self . getShortDescription ( test ) self . stream . write ( descr ) pos += len ( descr ) self . stream . write ( \" \" * ( 70 - pos )) # self.stream.write(' ' * (self._terminal.width - 10 - pos)) # self.stream.write(' ... ') self . stream . flush ()","title":"colortest"},{"location":"api_reference/ontopy/colortest/#colortest","text":"","title":"colortest"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest--ontopycolortest","text":"Print tests in colors. Adapted from https://github.com/meshy/colour-runner by Charlie Denton License: MIT","title":"\n\n  \n\n\n    \n\n      ontopy.colortest&para;\nPrint tests in colors.\nAdapted from https://github.com/meshy/colour-runner by Charlie Denton\nLicense: MIT\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n        \nColourTextTestResult            (TestResult)\n        \n\n\n\n\u0002amp\u0003para;\n\n    \n\n      A test result class that prints colour formatted text results to a stream.\nBased on https://github.com/python/cpython/blob/3.3/Lib/unittest/runner.py\n\n        \n          Source code in ontopy/colortest.py\n          class ColourTextTestResult(TestResult):\n    &quot;&quot;&quot;\n    A test result class that prints colour formatted text results to a stream.\n\n    Based on https://github.com/python/cpython/blob/3.3/Lib/unittest/runner.py\n    &quot;&quot;&quot;\n\n    formatter = formatters.Terminal256Formatter()  # pylint: disable=no-member\n    lexer = Lexer()\n    separator1 = &quot;=&quot; * 70\n    separator2 = &quot;-&quot; * 70\n    indent = &quot; &quot; * 4\n    # if `checkmode` is true, simplified output will be generated with\n    # no traceback\n    checkmode = False\n    _terminal = Terminal()\n    colours = {\n        None: str,\n        &quot;error&quot;: _terminal.bold_red,\n        &quot;expected&quot;: _terminal.blue,\n        # &quot;fail&quot;: _terminal.bold_yellow,\n        &quot;fail&quot;: _terminal.bold_magenta,\n        &quot;skip&quot;: str,\n        &quot;success&quot;: _terminal.green,\n        &quot;title&quot;: _terminal.blue,\n        &quot;unexpected&quot;: _terminal.bold_red,\n    }\n\n    _test_class = None\n\n    def __init__(self, stream, descriptions, verbosity):\n        super().__init__(stream, descriptions, verbosity)\n        self.stream = stream\n        self.show_all = verbosity &gt; 1\n        self.dots = verbosity == 1\n        self.descriptions = descriptions\n\n    def getShortDescription(self, test):\n        doc_first_line = test.shortDescription()\n        if self.descriptions and doc_first_line:\n            return self.indent + doc_first_line\n        return self.indent + test._testMethodName\n\n    def getLongDescription(self, test):\n        doc_first_line = test.shortDescription()\n        if self.descriptions and doc_first_line:\n            return &quot;\\n&quot;.join((str(test), doc_first_line))\n        return str(test)\n\n    def getClassDescription(self, test):\n        test_class = test.__class__\n        doc = test_class.__doc__\n        if self.descriptions and doc:\n            return doc.split(&quot;\\n&quot;)[0].strip()\n        return strclass(test_class)\n\n    def startTest(self, test):\n        super().startTest(test)\n        pos = 0\n        if self.show_all:\n            if self._test_class != test.__class__:\n                self._test_class = test.__class__\n                title = self.getClassDescription(test)\n                self.stream.writeln(self.colours[&quot;title&quot;](title))\n            descr = self.getShortDescription(test)\n            self.stream.write(descr)\n            pos += len(descr)\n            self.stream.write(&quot; &quot; * (70 - pos))\n            # self.stream.write(&#39; &#39; * (self._terminal.width - 10 - pos))\n            # self.stream.write(&#39; ... &#39;)\n            self.stream.flush()\n\n    def printResult(self, short, extended, colour_key=None):\n        colour = self.colours[colour_key]\n        if self.show_all:\n            self.stream.writeln(colour(extended))\n        elif self.dots:\n            self.stream.write(colour(short))\n            self.stream.flush()\n\n    def addSuccess(self, test):\n        super().addSuccess(test)\n        self.printResult(&quot;.&quot;, &quot;ok&quot;, &quot;success&quot;)\n\n    def addError(self, test, err):\n        super().addError(test, err)\n        self.printResult(&quot;E&quot;, &quot;ERROR&quot;, &quot;error&quot;)\n\n    def addFailure(self, test, err):\n        super().addFailure(test, err)\n        self.printResult(&quot;F&quot;, &quot;FAIL&quot;, &quot;fail&quot;)\n\n    def addSkip(self, test, reason):\n        super().addSkip(test, reason)\n        if self.checkmode:\n            self.printResult(&quot;s&quot;, &quot;skipped&quot;, &quot;skip&quot;)\n        else:\n            self.printResult(&quot;s&quot;, f&quot;skipped {reason!r}&quot;, &quot;skip&quot;)\n\n    def addExpectedFailure(self, test, err):\n        super().addExpectedFailure(test, err)\n        self.printResult(&quot;x&quot;, &quot;expected failure&quot;, &quot;expected&quot;)\n\n    def addUnexpectedSuccess(self, test):\n        super().addUnexpectedSuccess(test)\n        self.printResult(&quot;u&quot;, &quot;unexpected success&quot;, &quot;unexpected&quot;)\n\n    def printErrors(self):\n        if self.dots or self.show_all:\n            self.stream.writeln()\n        self.printErrorList(&quot;ERROR&quot;, self.errors)\n        self.printErrorList(&quot;FAIL&quot;, self.failures)\n\n    def printErrorList(self, flavour, errors):\n        colour = self.colours[flavour.lower()]\n\n        for test, err in errors:\n            if self.checkmode and flavour == &quot;FAIL&quot;:\n                self.stream.writeln(self.separator1)\n                title = f&quot;{flavour}: {test.shortDescription()}&quot;\n                self.stream.writeln(colour(title))\n                self.stream.writeln(str(test))\n                if self.show_all:\n                    self.stream.writeln(self.separator2)\n                    lines = str(err).split(&quot;\\n&quot;)\n                    i = 1\n                    for line in lines[1:]:\n                        if line.startswith(&quot; &quot;):\n                            i += 1\n                        else:\n                            break\n                    self.stream.writeln(\n                        highlight(\n                            &quot;\\n&quot;.join(lines[i:]), self.lexer, self.formatter\n                        )\n                    )\n            else:\n                self.stream.writeln(self.separator1)\n                title = f&quot;{flavour}: {self.getLongDescription(test)}&quot;\n                self.stream.writeln(colour(title))\n                self.stream.writeln(self.separator2)\n                self.stream.writeln(highlight(err, self.lexer, self.formatter))\n\n        \n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\naddError(self, test, err)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called when an error has occurred. 'err' is a tuple of values as\nreturned by sys.exc_info().\n\n        \n          Source code in ontopy/colortest.py\n          def addError(self, test, err):\n    super().addError(test, err)\n    self.printResult(&quot;E&quot;, &quot;ERROR&quot;, &quot;error&quot;)\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\naddExpectedFailure(self, test, err)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called when an expected failure/error occurred.\n\n        \n          Source code in ontopy/colortest.py\n          def addExpectedFailure(self, test, err):\n    super().addExpectedFailure(test, err)\n    self.printResult(&quot;x&quot;, &quot;expected failure&quot;, &quot;expected&quot;)\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\naddFailure(self, test, err)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called when an error has occurred. 'err' is a tuple of values as\nreturned by sys.exc_info().\n\n        \n          Source code in ontopy/colortest.py\n          def addFailure(self, test, err):\n    super().addFailure(test, err)\n    self.printResult(&quot;F&quot;, &quot;FAIL&quot;, &quot;fail&quot;)\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\naddSkip(self, test, reason)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called when a test is skipped.\n\n        \n          Source code in ontopy/colortest.py\n          def addSkip(self, test, reason):\n    super().addSkip(test, reason)\n    if self.checkmode:\n        self.printResult(&quot;s&quot;, &quot;skipped&quot;, &quot;skip&quot;)\n    else:\n        self.printResult(&quot;s&quot;, f&quot;skipped {reason!r}&quot;, &quot;skip&quot;)\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\naddSuccess(self, test)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called when a test has completed successfully\n\n        \n          Source code in ontopy/colortest.py\n          def addSuccess(self, test):\n    super().addSuccess(test)\n    self.printResult(&quot;.&quot;, &quot;ok&quot;, &quot;success&quot;)\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\naddUnexpectedSuccess(self, test)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called when a test was expected to fail, but succeed.\n\n        \n          Source code in ontopy/colortest.py\n          def addUnexpectedSuccess(self, test):\n    super().addUnexpectedSuccess(test)\n    self.printResult(&quot;u&quot;, &quot;unexpected success&quot;, &quot;unexpected&quot;)\n\n        \n    \n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\nprintErrors(self)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called by TestRunner after test run\n\n        \n          Source code in ontopy/colortest.py\n          def printErrors(self):\n    if self.dots or self.show_all:\n        self.stream.writeln()\n    self.printErrorList(&quot;ERROR&quot;, self.errors)\n    self.printErrorList(&quot;FAIL&quot;, self.failures)\n\n        \n    \n\n  \n\n\n\n\n  \n\n\n\n\nstartTest(self, test)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called when the given test is about to be run\n\n        \n          Source code in ontopy/colortest.py\n          def startTest(self, test):\n    super().startTest(test)\n    pos = 0\n    if self.show_all:\n        if self._test_class != test.__class__:\n            self._test_class = test.__class__\n            title = self.getClassDescription(test)\n            self.stream.writeln(self.colours[&quot;title&quot;](title))\n        descr = self.getShortDescription(test)\n        self.stream.write(descr)\n        pos += len(descr)\n        self.stream.write(&quot; &quot; * (70 - pos))\n        # self.stream.write(&#39; &#39; * (self._terminal.width - 10 - pos))\n        # self.stream.write(&#39; ... &#39;)\n        self.stream.flush()\n\n        \n    \n\n  \n\n\n\n\n\n  \n\n    \n\n  \n\n\n\n  \n\n\n\n\n        \nColourTextTestRunner            (TextTestRunner)\n        \n\n\n\n\u0002amp\u0003para;\n\n    \n\n      A test runner that uses colour in its output.\n\n        \n          Source code in ontopy/colortest.py\n          class ColourTextTestRunner(\n    TextTestRunner\n):  # pylint: disable=too-few-public-methods\n    &quot;&quot;&quot;A test runner that uses colour in its output.&quot;&quot;&quot;\n\n    resultclass = ColourTextTestResult\n\n        \n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n        \nresultclass            (TestResult)\n        \n\n\n\n\u0002amp\u0003para;\n\n    \n\n      A test result class that prints colour formatted text results to a stream.\nBased on https://github.com/python/cpython/blob/3.3/Lib/unittest/runner.py\n\n        \n          Source code in ontopy/colortest.py\n          class ColourTextTestResult(TestResult):\n    &quot;&quot;&quot;\n    A test result class that prints colour formatted text results to a stream.\n\n    Based on https://github.com/python/cpython/blob/3.3/Lib/unittest/runner.py\n    &quot;&quot;&quot;\n\n    formatter = formatters.Terminal256Formatter()  # pylint: disable=no-member\n    lexer = Lexer()\n    separator1 = &quot;=&quot; * 70\n    separator2 = &quot;-&quot; * 70\n    indent = &quot; &quot; * 4\n    # if `checkmode` is true, simplified output will be generated with\n    # no traceback\n    checkmode = False\n    _terminal = Terminal()\n    colours = {\n        None: str,\n        &quot;error&quot;: _terminal.bold_red,\n        &quot;expected&quot;: _terminal.blue,\n        # &quot;fail&quot;: _terminal.bold_yellow,\n        &quot;fail&quot;: _terminal.bold_magenta,\n        &quot;skip&quot;: str,\n        &quot;success&quot;: _terminal.green,\n        &quot;title&quot;: _terminal.blue,\n        &quot;unexpected&quot;: _terminal.bold_red,\n    }\n\n    _test_class = None\n\n    def __init__(self, stream, descriptions, verbosity):\n        super().__init__(stream, descriptions, verbosity)\n        self.stream = stream\n        self.show_all = verbosity &gt; 1\n        self.dots = verbosity == 1\n        self.descriptions = descriptions\n\n    def getShortDescription(self, test):\n        doc_first_line = test.shortDescription()\n        if self.descriptions and doc_first_line:\n            return self.indent + doc_first_line\n        return self.indent + test._testMethodName\n\n    def getLongDescription(self, test):\n        doc_first_line = test.shortDescription()\n        if self.descriptions and doc_first_line:\n            return &quot;\\n&quot;.join((str(test), doc_first_line))\n        return str(test)\n\n    def getClassDescription(self, test):\n        test_class = test.__class__\n        doc = test_class.__doc__\n        if self.descriptions and doc:\n            return doc.split(&quot;\\n&quot;)[0].strip()\n        return strclass(test_class)\n\n    def startTest(self, test):\n        super().startTest(test)\n        pos = 0\n        if self.show_all:\n            if self._test_class != test.__class__:\n                self._test_class = test.__class__\n                title = self.getClassDescription(test)\n                self.stream.writeln(self.colours[&quot;title&quot;](title))\n            descr = self.getShortDescription(test)\n            self.stream.write(descr)\n            pos += len(descr)\n            self.stream.write(&quot; &quot; * (70 - pos))\n            # self.stream.write(&#39; &#39; * (self._terminal.width - 10 - pos))\n            # self.stream.write(&#39; ... &#39;)\n            self.stream.flush()\n\n    def printResult(self, short, extended, colour_key=None):\n        colour = self.colours[colour_key]\n        if self.show_all:\n            self.stream.writeln(colour(extended))\n        elif self.dots:\n            self.stream.write(colour(short))\n            self.stream.flush()\n\n    def addSuccess(self, test):\n        super().addSuccess(test)\n        self.printResult(&quot;.&quot;, &quot;ok&quot;, &quot;success&quot;)\n\n    def addError(self, test, err):\n        super().addError(test, err)\n        self.printResult(&quot;E&quot;, &quot;ERROR&quot;, &quot;error&quot;)\n\n    def addFailure(self, test, err):\n        super().addFailure(test, err)\n        self.printResult(&quot;F&quot;, &quot;FAIL&quot;, &quot;fail&quot;)\n\n    def addSkip(self, test, reason):\n        super().addSkip(test, reason)\n        if self.checkmode:\n            self.printResult(&quot;s&quot;, &quot;skipped&quot;, &quot;skip&quot;)\n        else:\n            self.printResult(&quot;s&quot;, f&quot;skipped {reason!r}&quot;, &quot;skip&quot;)\n\n    def addExpectedFailure(self, test, err):\n        super().addExpectedFailure(test, err)\n        self.printResult(&quot;x&quot;, &quot;expected failure&quot;, &quot;expected&quot;)\n\n    def addUnexpectedSuccess(self, test):\n        super().addUnexpectedSuccess(test)\n        self.printResult(&quot;u&quot;, &quot;unexpected success&quot;, &quot;unexpected&quot;)\n\n    def printErrors(self):\n        if self.dots or self.show_all:\n            self.stream.writeln()\n        self.printErrorList(&quot;ERROR&quot;, self.errors)\n        self.printErrorList(&quot;FAIL&quot;, self.failures)\n\n    def printErrorList(self, flavour, errors):\n        colour = self.colours[flavour.lower()]\n\n        for test, err in errors:\n            if self.checkmode and flavour == &quot;FAIL&quot;:\n                self.stream.writeln(self.separator1)\n                title = f&quot;{flavour}: {test.shortDescription()}&quot;\n                self.stream.writeln(colour(title))\n                self.stream.writeln(str(test))\n                if self.show_all:\n                    self.stream.writeln(self.separator2)\n                    lines = str(err).split(&quot;\\n&quot;)\n                    i = 1\n                    for line in lines[1:]:\n                        if line.startswith(&quot; &quot;):\n                            i += 1\n                        else:\n                            break\n                    self.stream.writeln(\n                        highlight(\n                            &quot;\\n&quot;.join(lines[i:]), self.lexer, self.formatter\n                        )\n                    )\n            else:\n                self.stream.writeln(self.separator1)\n                title = f&quot;{flavour}: {self.getLongDescription(test)}&quot;\n                self.stream.writeln(colour(title))\n                self.stream.writeln(self.separator2)\n                self.stream.writeln(highlight(err, self.lexer, self.formatter))\n\n        \n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\naddError(self, test, err)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called when an error has occurred. 'err' is a tuple of values as\nreturned by sys.exc_info().\n\n        \n          Source code in ontopy/colortest.py\n          def addError(self, test, err):\n    super().addError(test, err)\n    self.printResult(&quot;E&quot;, &quot;ERROR&quot;, &quot;error&quot;)\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\naddExpectedFailure(self, test, err)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called when an expected failure/error occurred.\n\n        \n          Source code in ontopy/colortest.py\n          def addExpectedFailure(self, test, err):\n    super().addExpectedFailure(test, err)\n    self.printResult(&quot;x&quot;, &quot;expected failure&quot;, &quot;expected&quot;)\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\naddFailure(self, test, err)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called when an error has occurred. 'err' is a tuple of values as\nreturned by sys.exc_info().\n\n        \n          Source code in ontopy/colortest.py\n          def addFailure(self, test, err):\n    super().addFailure(test, err)\n    self.printResult(&quot;F&quot;, &quot;FAIL&quot;, &quot;fail&quot;)\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\naddSkip(self, test, reason)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called when a test is skipped.\n\n        \n          Source code in ontopy/colortest.py\n          def addSkip(self, test, reason):\n    super().addSkip(test, reason)\n    if self.checkmode:\n        self.printResult(&quot;s&quot;, &quot;skipped&quot;, &quot;skip&quot;)\n    else:\n        self.printResult(&quot;s&quot;, f&quot;skipped {reason!r}&quot;, &quot;skip&quot;)\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\naddSuccess(self, test)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called when a test has completed successfully\n\n        \n          Source code in ontopy/colortest.py\n          def addSuccess(self, test):\n    super().addSuccess(test)\n    self.printResult(&quot;.&quot;, &quot;ok&quot;, &quot;success&quot;)\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\naddUnexpectedSuccess(self, test)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called when a test was expected to fail, but succeed.\n\n        \n          Source code in ontopy/colortest.py\n          def addUnexpectedSuccess(self, test):\n    super().addUnexpectedSuccess(test)\n    self.printResult(&quot;u&quot;, &quot;unexpected success&quot;, &quot;unexpected&quot;)\n\n        \n    \n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\nprintErrors(self)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called by TestRunner after test run\n\n        \n          Source code in ontopy/colortest.py\n          def printErrors(self):\n    if self.dots or self.show_all:\n        self.stream.writeln()\n    self.printErrorList(&quot;ERROR&quot;, self.errors)\n    self.printErrorList(&quot;FAIL&quot;, self.failures)\n\n        \n    \n\n  \n\n\n\n\n  \n\n\n\n\nstartTest(self, test)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Called when the given test is about to be run\n\n        \n          Source code in ontopy/colortest.py\n          def startTest(self, test):\n    super().startTest(test)\n    pos = 0\n    if self.show_all:\n        if self._test_class != test.__class__:\n            self._test_class = test.__class__\n            title = self.getClassDescription(test)\n            self.stream.writeln(self.colours[&quot;title&quot;](title))\n        descr = self.getShortDescription(test)\n        self.stream.write(descr)\n        pos += len(descr)\n        self.stream.write(&quot; &quot; * (70 - pos))\n        # self.stream.write(&#39; &#39; * (self._terminal.width - 10 - pos))\n        # self.stream.write(&#39; ... &#39;)\n        self.stream.flush()\n\n        \n    \n\n  \n\n\n\n\n\n  \n\n    \n\n  \n\n\n\n\n\n\n\n  \n\n    \n\n  \n\n\n\n\n\n\n\n  \n\n    \n\n  \n\n"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestResult","text":"A test result class that prints colour formatted text results to a stream. Based on https://github.com/python/cpython/blob/3.3/Lib/unittest/runner.py Source code in ontopy/colortest.py class ColourTextTestResult ( TestResult ): \"\"\" A test result class that prints colour formatted text results to a stream. Based on https://github.com/python/cpython/blob/3.3/Lib/unittest/runner.py \"\"\" formatter = formatters . Terminal256Formatter () # pylint: disable=no-member lexer = Lexer () separator1 = \"=\" * 70 separator2 = \"-\" * 70 indent = \" \" * 4 # if `checkmode` is true, simplified output will be generated with # no traceback checkmode = False _terminal = Terminal () colours = { None : str , \"error\" : _terminal . bold_red , \"expected\" : _terminal . blue , # \"fail\": _terminal.bold_yellow, \"fail\" : _terminal . bold_magenta , \"skip\" : str , \"success\" : _terminal . green , \"title\" : _terminal . blue , \"unexpected\" : _terminal . bold_red , } _test_class = None def __init__ ( self , stream , descriptions , verbosity ): super () . __init__ ( stream , descriptions , verbosity ) self . stream = stream self . show_all = verbosity > 1 self . dots = verbosity == 1 self . descriptions = descriptions def getShortDescription ( self , test ): doc_first_line = test . shortDescription () if self . descriptions and doc_first_line : return self . indent + doc_first_line return self . indent + test . _testMethodName def getLongDescription ( self , test ): doc_first_line = test . shortDescription () if self . descriptions and doc_first_line : return \" \\n \" . join (( str ( test ), doc_first_line )) return str ( test ) def getClassDescription ( self , test ): test_class = test . __class__ doc = test_class . __doc__ if self . descriptions and doc : return doc . split ( \" \\n \" )[ 0 ] . strip () return strclass ( test_class ) def startTest ( self , test ): super () . startTest ( test ) pos = 0 if self . show_all : if self . _test_class != test . __class__ : self . _test_class = test . __class__ title = self . getClassDescription ( test ) self . stream . writeln ( self . colours [ \"title\" ]( title )) descr = self . getShortDescription ( test ) self . stream . write ( descr ) pos += len ( descr ) self . stream . write ( \" \" * ( 70 - pos )) # self.stream.write(' ' * (self._terminal.width - 10 - pos)) # self.stream.write(' ... ') self . stream . flush () def printResult ( self , short , extended , colour_key = None ): colour = self . colours [ colour_key ] if self . show_all : self . stream . writeln ( colour ( extended )) elif self . dots : self . stream . write ( colour ( short )) self . stream . flush () def addSuccess ( self , test ): super () . addSuccess ( test ) self . printResult ( \".\" , \"ok\" , \"success\" ) def addError ( self , test , err ): super () . addError ( test , err ) self . printResult ( \"E\" , \"ERROR\" , \"error\" ) def addFailure ( self , test , err ): super () . addFailure ( test , err ) self . printResult ( \"F\" , \"FAIL\" , \"fail\" ) def addSkip ( self , test , reason ): super () . addSkip ( test , reason ) if self . checkmode : self . printResult ( \"s\" , \"skipped\" , \"skip\" ) else : self . printResult ( \"s\" , f \"skipped { reason !r} \" , \"skip\" ) def addExpectedFailure ( self , test , err ): super () . addExpectedFailure ( test , err ) self . printResult ( \"x\" , \"expected failure\" , \"expected\" ) def addUnexpectedSuccess ( self , test ): super () . addUnexpectedSuccess ( test ) self . printResult ( \"u\" , \"unexpected success\" , \"unexpected\" ) def printErrors ( self ): if self . dots or self . show_all : self . stream . writeln () self . printErrorList ( \"ERROR\" , self . errors ) self . printErrorList ( \"FAIL\" , self . failures ) def printErrorList ( self , flavour , errors ): colour = self . colours [ flavour . lower ()] for test , err in errors : if self . checkmode and flavour == \"FAIL\" : self . stream . writeln ( self . separator1 ) title = f \" { flavour } : { test . shortDescription () } \" self . stream . writeln ( colour ( title )) self . stream . writeln ( str ( test )) if self . show_all : self . stream . writeln ( self . separator2 ) lines = str ( err ) . split ( \" \\n \" ) i = 1 for line in lines [ 1 :]: if line . startswith ( \" \" ): i += 1 else : break self . stream . writeln ( highlight ( \" \\n \" . join ( lines [ i :]), self . lexer , self . formatter ) ) else : self . stream . writeln ( self . separator1 ) title = f \" { flavour } : { self . getLongDescription ( test ) } \" self . stream . writeln ( colour ( title )) self . stream . writeln ( self . separator2 ) self . stream . writeln ( highlight ( err , self . lexer , self . formatter ))","title":"ColourTextTestResult"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestResult.addError","text":"Called when an error has occurred. 'err' is a tuple of values as returned by sys.exc_info(). Source code in ontopy/colortest.py def addError ( self , test , err ): super () . addError ( test , err ) self . printResult ( \"E\" , \"ERROR\" , \"error\" )","title":"addError()"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestResult.addExpectedFailure","text":"Called when an expected failure/error occurred. Source code in ontopy/colortest.py def addExpectedFailure ( self , test , err ): super () . addExpectedFailure ( test , err ) self . printResult ( \"x\" , \"expected failure\" , \"expected\" )","title":"addExpectedFailure()"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestResult.addFailure","text":"Called when an error has occurred. 'err' is a tuple of values as returned by sys.exc_info(). Source code in ontopy/colortest.py def addFailure ( self , test , err ): super () . addFailure ( test , err ) self . printResult ( \"F\" , \"FAIL\" , \"fail\" )","title":"addFailure()"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestResult.addSkip","text":"Called when a test is skipped. Source code in ontopy/colortest.py def addSkip ( self , test , reason ): super () . addSkip ( test , reason ) if self . checkmode : self . printResult ( \"s\" , \"skipped\" , \"skip\" ) else : self . printResult ( \"s\" , f \"skipped { reason !r} \" , \"skip\" )","title":"addSkip()"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestResult.addSuccess","text":"Called when a test has completed successfully Source code in ontopy/colortest.py def addSuccess ( self , test ): super () . addSuccess ( test ) self . printResult ( \".\" , \"ok\" , \"success\" )","title":"addSuccess()"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestResult.addUnexpectedSuccess","text":"Called when a test was expected to fail, but succeed. Source code in ontopy/colortest.py def addUnexpectedSuccess ( self , test ): super () . addUnexpectedSuccess ( test ) self . printResult ( \"u\" , \"unexpected success\" , \"unexpected\" )","title":"addUnexpectedSuccess()"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestResult.printErrors","text":"Called by TestRunner after test run Source code in ontopy/colortest.py def printErrors ( self ): if self . dots or self . show_all : self . stream . writeln () self . printErrorList ( \"ERROR\" , self . errors ) self . printErrorList ( \"FAIL\" , self . failures )","title":"printErrors()"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestResult.startTest","text":"Called when the given test is about to be run Source code in ontopy/colortest.py def startTest ( self , test ): super () . startTest ( test ) pos = 0 if self . show_all : if self . _test_class != test . __class__ : self . _test_class = test . __class__ title = self . getClassDescription ( test ) self . stream . writeln ( self . colours [ \"title\" ]( title )) descr = self . getShortDescription ( test ) self . stream . write ( descr ) pos += len ( descr ) self . stream . write ( \" \" * ( 70 - pos )) # self.stream.write(' ' * (self._terminal.width - 10 - pos)) # self.stream.write(' ... ') self . stream . flush ()","title":"startTest()"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestRunner","text":"A test runner that uses colour in its output. Source code in ontopy/colortest.py class ColourTextTestRunner ( TextTestRunner ): # pylint: disable=too-few-public-methods \"\"\"A test runner that uses colour in its output.\"\"\" resultclass = ColourTextTestResult","title":"ColourTextTestRunner"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestRunner.resultclass","text":"A test result class that prints colour formatted text results to a stream. Based on https://github.com/python/cpython/blob/3.3/Lib/unittest/runner.py Source code in ontopy/colortest.py class ColourTextTestResult ( TestResult ): \"\"\" A test result class that prints colour formatted text results to a stream. Based on https://github.com/python/cpython/blob/3.3/Lib/unittest/runner.py \"\"\" formatter = formatters . Terminal256Formatter () # pylint: disable=no-member lexer = Lexer () separator1 = \"=\" * 70 separator2 = \"-\" * 70 indent = \" \" * 4 # if `checkmode` is true, simplified output will be generated with # no traceback checkmode = False _terminal = Terminal () colours = { None : str , \"error\" : _terminal . bold_red , \"expected\" : _terminal . blue , # \"fail\": _terminal.bold_yellow, \"fail\" : _terminal . bold_magenta , \"skip\" : str , \"success\" : _terminal . green , \"title\" : _terminal . blue , \"unexpected\" : _terminal . bold_red , } _test_class = None def __init__ ( self , stream , descriptions , verbosity ): super () . __init__ ( stream , descriptions , verbosity ) self . stream = stream self . show_all = verbosity > 1 self . dots = verbosity == 1 self . descriptions = descriptions def getShortDescription ( self , test ): doc_first_line = test . shortDescription () if self . descriptions and doc_first_line : return self . indent + doc_first_line return self . indent + test . _testMethodName def getLongDescription ( self , test ): doc_first_line = test . shortDescription () if self . descriptions and doc_first_line : return \" \\n \" . join (( str ( test ), doc_first_line )) return str ( test ) def getClassDescription ( self , test ): test_class = test . __class__ doc = test_class . __doc__ if self . descriptions and doc : return doc . split ( \" \\n \" )[ 0 ] . strip () return strclass ( test_class ) def startTest ( self , test ): super () . startTest ( test ) pos = 0 if self . show_all : if self . _test_class != test . __class__ : self . _test_class = test . __class__ title = self . getClassDescription ( test ) self . stream . writeln ( self . colours [ \"title\" ]( title )) descr = self . getShortDescription ( test ) self . stream . write ( descr ) pos += len ( descr ) self . stream . write ( \" \" * ( 70 - pos )) # self.stream.write(' ' * (self._terminal.width - 10 - pos)) # self.stream.write(' ... ') self . stream . flush () def printResult ( self , short , extended , colour_key = None ): colour = self . colours [ colour_key ] if self . show_all : self . stream . writeln ( colour ( extended )) elif self . dots : self . stream . write ( colour ( short )) self . stream . flush () def addSuccess ( self , test ): super () . addSuccess ( test ) self . printResult ( \".\" , \"ok\" , \"success\" ) def addError ( self , test , err ): super () . addError ( test , err ) self . printResult ( \"E\" , \"ERROR\" , \"error\" ) def addFailure ( self , test , err ): super () . addFailure ( test , err ) self . printResult ( \"F\" , \"FAIL\" , \"fail\" ) def addSkip ( self , test , reason ): super () . addSkip ( test , reason ) if self . checkmode : self . printResult ( \"s\" , \"skipped\" , \"skip\" ) else : self . printResult ( \"s\" , f \"skipped { reason !r} \" , \"skip\" ) def addExpectedFailure ( self , test , err ): super () . addExpectedFailure ( test , err ) self . printResult ( \"x\" , \"expected failure\" , \"expected\" ) def addUnexpectedSuccess ( self , test ): super () . addUnexpectedSuccess ( test ) self . printResult ( \"u\" , \"unexpected success\" , \"unexpected\" ) def printErrors ( self ): if self . dots or self . show_all : self . stream . writeln () self . printErrorList ( \"ERROR\" , self . errors ) self . printErrorList ( \"FAIL\" , self . failures ) def printErrorList ( self , flavour , errors ): colour = self . colours [ flavour . lower ()] for test , err in errors : if self . checkmode and flavour == \"FAIL\" : self . stream . writeln ( self . separator1 ) title = f \" { flavour } : { test . shortDescription () } \" self . stream . writeln ( colour ( title )) self . stream . writeln ( str ( test )) if self . show_all : self . stream . writeln ( self . separator2 ) lines = str ( err ) . split ( \" \\n \" ) i = 1 for line in lines [ 1 :]: if line . startswith ( \" \" ): i += 1 else : break self . stream . writeln ( highlight ( \" \\n \" . join ( lines [ i :]), self . lexer , self . formatter ) ) else : self . stream . writeln ( self . separator1 ) title = f \" { flavour } : { self . getLongDescription ( test ) } \" self . stream . writeln ( colour ( title )) self . stream . writeln ( self . separator2 ) self . stream . writeln ( highlight ( err , self . lexer , self . formatter ))","title":"resultclass"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestRunner.resultclass.addError","text":"Called when an error has occurred. 'err' is a tuple of values as returned by sys.exc_info(). Source code in ontopy/colortest.py def addError ( self , test , err ): super () . addError ( test , err ) self . printResult ( \"E\" , \"ERROR\" , \"error\" )","title":"addError()"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestRunner.resultclass.addExpectedFailure","text":"Called when an expected failure/error occurred. Source code in ontopy/colortest.py def addExpectedFailure ( self , test , err ): super () . addExpectedFailure ( test , err ) self . printResult ( \"x\" , \"expected failure\" , \"expected\" )","title":"addExpectedFailure()"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestRunner.resultclass.addFailure","text":"Called when an error has occurred. 'err' is a tuple of values as returned by sys.exc_info(). Source code in ontopy/colortest.py def addFailure ( self , test , err ): super () . addFailure ( test , err ) self . printResult ( \"F\" , \"FAIL\" , \"fail\" )","title":"addFailure()"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestRunner.resultclass.addSkip","text":"Called when a test is skipped. Source code in ontopy/colortest.py def addSkip ( self , test , reason ): super () . addSkip ( test , reason ) if self . checkmode : self . printResult ( \"s\" , \"skipped\" , \"skip\" ) else : self . printResult ( \"s\" , f \"skipped { reason !r} \" , \"skip\" )","title":"addSkip()"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestRunner.resultclass.addSuccess","text":"Called when a test has completed successfully Source code in ontopy/colortest.py def addSuccess ( self , test ): super () . addSuccess ( test ) self . printResult ( \".\" , \"ok\" , \"success\" )","title":"addSuccess()"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestRunner.resultclass.addUnexpectedSuccess","text":"Called when a test was expected to fail, but succeed. Source code in ontopy/colortest.py def addUnexpectedSuccess ( self , test ): super () . addUnexpectedSuccess ( test ) self . printResult ( \"u\" , \"unexpected success\" , \"unexpected\" )","title":"addUnexpectedSuccess()"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestRunner.resultclass.printErrors","text":"Called by TestRunner after test run Source code in ontopy/colortest.py def printErrors ( self ): if self . dots or self . show_all : self . stream . writeln () self . printErrorList ( \"ERROR\" , self . errors ) self . printErrorList ( \"FAIL\" , self . failures )","title":"printErrors()"},{"location":"api_reference/ontopy/colortest/#ontopy.colortest.ColourTextTestRunner.resultclass.startTest","text":"Called when the given test is about to be run Source code in ontopy/colortest.py def startTest ( self , test ): super () . startTest ( test ) pos = 0 if self . show_all : if self . _test_class != test . __class__ : self . _test_class = test . __class__ title = self . getClassDescription ( test ) self . stream . writeln ( self . colours [ \"title\" ]( title )) descr = self . getShortDescription ( test ) self . stream . write ( descr ) pos += len ( descr ) self . stream . write ( \" \" * ( 70 - pos )) # self.stream.write(' ' * (self._terminal.width - 10 - pos)) # self.stream.write(' ... ') self . stream . flush ()","title":"startTest()"},{"location":"api_reference/ontopy/excelparser/","text":"excelparser \u00b6 Module from parsing an excelfile and creating an ontology from it. The excelfile is read by pandas and the pandas dataframe should have column names: prefLabel, altLabel, Elucidation, Comments, Examples, subClassOf, Relations. Note that correct case is mandatory. ExcelError ( EMMOntoPyException ) \u00b6 Raised on errors in Excel file. Source code in ontopy/excelparser.py class ExcelError ( EMMOntoPyException ): \"\"\"Raised on errors in Excel file.\"\"\" create_ontology_from_excel ( excelpath , concept_sheet_name = 'Concepts' , metadata_sheet_name = 'Metadata' , imports_sheet_name = 'ImportedOntologies' , base_iri = 'http://emmo.info/emmo/domain/onto#' , base_iri_from_metadata = True , imports = None , catalog = None , force = False ) \u00b6 Creates an ontology from an Excel-file. Parameters: Name Type Description Default excelpath str Path to Excel workbook. required concept_sheet_name str Name of sheet where concepts are defined. The second row of this sheet should contain column names that are supported. Currently these are 'prefLabel','altLabel', 'Elucidation', 'Comments', 'Examples', 'subClassOf', 'Relations'. Multiple entries are separated with ';'. 'Concepts' metadata_sheet_name str Name of sheet where metadata are defined. The first row contains column names 'Metadata name' and 'Value' Supported 'Metadata names' are: 'Ontology IRI', 'Ontology vesion IRI', 'Ontology version Info', 'Title', 'Abstract', 'License', 'Comment', 'Author', 'Contributor'. Multiple entries are separated with a semi-colon ( ; ). 'Metadata' imports_sheet_name str Name of sheet where imported ontologies are defined. Column name is 'Imported ontologies'. Fully resolvable URL or path to imported ontologies provided one per row. 'ImportedOntologies' base_iri str Base IRI of the new ontology. 'http://emmo.info/emmo/domain/onto#' base_iri_from_metadata bool Whether to use base IRI defined from metadata. True imports list List of imported ontologies. None catalog dict Imported ontologies with (name, full path) key/value-pairs. None force bool Forcibly make an ontology by skipping concepts that are erroneously defined or other errors in the excel sheet. False Returns: Type Description A tuple with the created ontology associated catalog of ontology names and resolvable path as dict a dictionary with lists of concepts that raise errors, with the following keys: \"already_defined\": These are concepts that are already in the ontology, either because they were already added in a previous line of the excelfile/pandas dataframe, or because it is already defined in the imported ontologies. \"in_imported_ontologies\": Concepts that are defined in the excel, but already exist in the imported ontologies. This is a subset of the 'already_defined'. \"wrongly_defined\": Concepts that are given an invalid prefLabel (e.g. with a space in the name). \"missing_parents\": Concepts that are missing parents. These concepts are added directly under owl:Thing. \"invalid_parents\": Concepts with invalidly defined parents. These concepts are added directly under owl:Thing. \"nonadded_concepts\": List of all concepts that are not added, either because the prefLabel is invalid, or because the concept has already been added once or already exists in an imported ontology. Source code in ontopy/excelparser.py def create_ontology_from_excel ( # pylint: disable=too-many-arguments excelpath : str , concept_sheet_name : str = \"Concepts\" , metadata_sheet_name : str = \"Metadata\" , imports_sheet_name : str = \"ImportedOntologies\" , base_iri : str = \"http://emmo.info/emmo/domain/onto#\" , base_iri_from_metadata : bool = True , imports : list = None , catalog : dict = None , force : bool = False , ) -> Tuple [ ontopy . ontology . Ontology , dict , dict ]: \"\"\" Creates an ontology from an Excel-file. Arguments: excelpath: Path to Excel workbook. concept_sheet_name: Name of sheet where concepts are defined. The second row of this sheet should contain column names that are supported. Currently these are 'prefLabel','altLabel', 'Elucidation', 'Comments', 'Examples', 'subClassOf', 'Relations'. Multiple entries are separated with ';'. metadata_sheet_name: Name of sheet where metadata are defined. The first row contains column names 'Metadata name' and 'Value' Supported 'Metadata names' are: 'Ontology IRI', 'Ontology vesion IRI', 'Ontology version Info', 'Title', 'Abstract', 'License', 'Comment', 'Author', 'Contributor'. Multiple entries are separated with a semi-colon (`;`). imports_sheet_name: Name of sheet where imported ontologies are defined. Column name is 'Imported ontologies'. Fully resolvable URL or path to imported ontologies provided one per row. base_iri: Base IRI of the new ontology. base_iri_from_metadata: Whether to use base IRI defined from metadata. imports: List of imported ontologies. catalog: Imported ontologies with (name, full path) key/value-pairs. force: Forcibly make an ontology by skipping concepts that are erroneously defined or other errors in the excel sheet. Returns: A tuple with the: * created ontology * associated catalog of ontology names and resolvable path as dict * a dictionary with lists of concepts that raise errors, with the following keys: - \"already_defined\": These are concepts that are already in the ontology, either because they were already added in a previous line of the excelfile/pandas dataframe, or because it is already defined in the imported ontologies. - \"in_imported_ontologies\": Concepts that are defined in the excel, but already exist in the imported ontologies. This is a subset of the 'already_defined'. - \"wrongly_defined\": Concepts that are given an invalid prefLabel (e.g. with a space in the name). - \"missing_parents\": Concepts that are missing parents. These concepts are added directly under owl:Thing. - \"invalid_parents\": Concepts with invalidly defined parents. These concepts are added directly under owl:Thing. - \"nonadded_concepts\": List of all concepts that are not added, either because the prefLabel is invalid, or because the concept has already been added once or already exists in an imported ontology. \"\"\" web_protocol = \"http://\" , \"https://\" , \"ftp://\" def _relative_to_absolute_paths ( path ): if isinstance ( path , str ): if not path . startswith ( web_protocol ): path = os . path . dirname ( excelpath ) + \"/\" + str ( path ) return path try : imports = pd . read_excel ( excelpath , sheet_name = imports_sheet_name , skiprows = [ 1 ] ) except ValueError : imports = pd . DataFrame () else : # Strip leading and trailing white spaces in paths imports . replace ( r \"^\\s+\" , \"\" , regex = True ) . replace ( r \"\\s+$\" , \"\" , regex = True ) # Set empty strings to nan imports = imports . replace ( r \"^\\s*$\" , np . nan , regex = True ) if \"Imported ontologies\" in imports . columns : imports [ \"Imported ontologies\" ] = imports [ \"Imported ontologies\" ] . apply ( _relative_to_absolute_paths ) # Read datafile TODO: Some magic to identify the header row conceptdata = pd . read_excel ( excelpath , sheet_name = concept_sheet_name , skiprows = [ 0 , 2 ] ) metadata = pd . read_excel ( excelpath , sheet_name = metadata_sheet_name ) return create_ontology_from_pandas ( data = conceptdata , metadata = metadata , imports = imports , base_iri = base_iri , base_iri_from_metadata = base_iri_from_metadata , catalog = catalog , force = force , ) create_ontology_from_pandas ( data , metadata , imports , base_iri = 'http://emmo.info/emmo/domain/onto#' , base_iri_from_metadata = True , catalog = None , force = False ) \u00b6 Create an ontology from a pandas DataFrame. Check 'create_ontology_from_excel' for complete documentation. Source code in ontopy/excelparser.py def create_ontology_from_pandas ( # pylint:disable=too-many-locals,too-many-branches,too-many-statements,too-many-arguments data : pd . DataFrame , metadata : pd . DataFrame , imports : pd . DataFrame , base_iri : str = \"http://emmo.info/emmo/domain/onto#\" , base_iri_from_metadata : bool = True , catalog : dict = None , force : bool = False , ) -> Tuple [ ontopy . ontology . Ontology , dict ]: \"\"\" Create an ontology from a pandas DataFrame. Check 'create_ontology_from_excel' for complete documentation. \"\"\" # Remove lines with empty prefLabel data = data [ data [ \"prefLabel\" ] . notna ()] # Convert all data to string, remove spaces, and finally remove # additional rows with empty prefLabel. data = data . astype ( str ) data [ \"prefLabel\" ] = data [ \"prefLabel\" ] . str . strip () data = data [ data [ \"prefLabel\" ] . str . len () > 0 ] data . reset_index ( drop = True , inplace = True ) # Make new ontology onto , catalog = get_metadata_from_dataframe ( metadata , base_iri , imports = imports ) # Get a set of imported concepts imported_concepts = { concept . prefLabel . first () for concept in onto . get_entities () } # Set given or default base_iri if base_iri_from_metadata is False. if not base_iri_from_metadata : onto . base_iri = base_iri labels = set ( data [ \"prefLabel\" ]) for altlabel in data [ \"altLabel\" ] . str . strip (): if not altlabel == \"nan\" : labels . update ( altlabel . split ( \";\" )) # Dictionary with lists of concepts that raise errors concepts_with_errors = { \"already_defined\" : [], \"in_imported_ontologies\" : [], \"wrongly_defined\" : [], \"missing_parents\" : [], \"invalid_parents\" : [], \"nonadded_concepts\" : [], \"errors_in_properties\" : [], } onto . sync_python_names () with onto : remaining_rows = set ( range ( len ( data ))) all_added_rows = [] while remaining_rows : added_rows = set () for index in remaining_rows : row = data . loc [ index ] name = row [ \"prefLabel\" ] try : onto . get_by_label ( name ) if not force : raise ExcelError ( f 'Concept \" { name } \" already in ontology' ) warnings . warn ( f 'Ignoring concept \" { name } \" since it is already in ' \"the ontology.\" ) concepts_with_errors [ \"already_defined\" ] . append ( name ) # What to do if we want to add info to this concept? # Should that be not allowed? # If it should be allowed the index has to be added to # added_rows continue except ( ValueError , TypeError ) as err : warnings . warn ( f 'Ignoring concept \" { name } \". ' f 'The following error was raised: \" { err } \"' ) concepts_with_errors [ \"wrongly_defined\" ] . append ( name ) continue except NoSuchLabelError : pass if row [ \"subClassOf\" ] == \"nan\" : if not force : raise ExcelError ( f \" { row [ 0 ] } has no subClassOf\" ) parent_names = [] # Should be \"owl:Thing\" concepts_with_errors [ \"missing_parents\" ] . append ( name ) else : parent_names = str ( row [ \"subClassOf\" ]) . split ( \";\" ) parents = [] invalid_parent = False for parent_name in parent_names : try : parent = onto . get_by_label ( parent_name . strip ()) except ( NoSuchLabelError , ValueError ) as exc : if parent_name not in labels : if force : warnings . warn ( f 'Invalid parents for \" { name } \": ' f '\" { parent_name } \".' ) concepts_with_errors [ \"invalid_parents\" ] . append ( name ) break raise ExcelError ( f 'Invalid parents for \" { name } \": { exc } \\n ' \"Have you forgotten an imported ontology?\" ) from exc invalid_parent = True break else : parents . append ( parent ) if invalid_parent : continue if not parents : parents = [ owlready2 . Thing ] concept = onto . new_entity ( name , parents ) added_rows . add ( index ) # Add elucidation try : _add_literal ( row , concept . elucidation , \"Elucidation\" , only_one = True , ) except AttributeError as err : if force : _add_literal ( row , concept . comment , \"Elucidation\" , only_one = True , ) warnings . warn ( \"Elucidation added as comment.\" ) else : raise ExcelError ( f \"Not able to add elucidations. { err } .\" ) from err # Add examples try : _add_literal ( row , concept . example , \"Examples\" , expected = False ) except AttributeError : if force : warnings . warn ( \"Not able to add examples. \" \"Did you forget to import an ontology?.\" ) # Add comments _add_literal ( row , concept . comment , \"Comments\" , expected = False ) # Add altLabels try : _add_literal ( row , concept . altLabel , \"altLabel\" , expected = False ) except AttributeError as err : if force is True : _add_literal ( row , concept . label , \"altLabel\" , expected = False , ) warnings . warn ( \"altLabel added as rdfs.label.\" ) else : raise ExcelError ( f \"Not able to add altLabels. \" f \" { err } .\" ) from err remaining_rows . difference_update ( added_rows ) # Detect infinite loop... if not added_rows and remaining_rows : unadded = [ data . loc [ i ] . prefLabel for i in remaining_rows ] if force is True : warnings . warn ( f \"Not able to add the following concepts: { unadded } .\" \" Will continue without these.\" ) remaining_rows = False concepts_with_errors [ \"nonadded_concepts\" ] = unadded else : raise ExcelError ( f \"Not able to add the following concepts: { unadded } .\" ) all_added_rows . extend ( added_rows ) # Add properties in a second loop for index in all_added_rows : row = data . loc [ index ] properties = row [ \"Relations\" ] if properties == \"nan\" : properties = None if isinstance ( properties , str ): try : concept = onto . get_by_label ( row [ \"prefLabel\" ] . strip ()) except NoSuchLabelError : pass props = properties . split ( \";\" ) for prop in props : try : concept . is_a . append ( evaluate ( onto , prop . strip ())) except pyparsing . ParseException as exc : warnings . warn ( f \"Error in Property assignment for: ' { concept } '. \" f \"Property to be Evaluated: ' { prop } '. \" f \" { exc } \" ) concepts_with_errors [ \"errors_in_properties\" ] . append ( name ) except NoSuchLabelError as exc : msg = ( f \"Error in Property assignment for: { concept } . \" f \"Property to be Evaluated: { prop } . \" f \" { exc } \" ) if force is True : warnings . warn ( msg ) concepts_with_errors [ \"errors_in_properties\" ] . append ( name ) else : raise ExcelError ( msg ) from exc # Synchronise Python attributes to ontology onto . sync_attributes ( name_policy = \"uuid\" , name_prefix = \"EMMO_\" , class_docstring = \"elucidation\" ) onto . dir_label = False concepts_with_errors = { key : set ( value ) for key , value in concepts_with_errors . items () } concepts_with_errors [ \"in_imported_ontologies\" ] = concepts_with_errors [ \"already_defined\" ] . intersection ( imported_concepts ) return onto , catalog , concepts_with_errors english ( string ) \u00b6 Returns string as an English location string. Source code in ontopy/excelparser.py def english ( string ): \"\"\"Returns `string` as an English location string.\"\"\" return owlready2 . locstr ( string , lang = \"en\" ) get_metadata_from_dataframe ( metadata , base_iri , base_iri_from_metadata = True , imports = None , catalog = None ) \u00b6 Create ontology with metadata from pd.DataFrame Source code in ontopy/excelparser.py def get_metadata_from_dataframe ( # pylint: disable=too-many-locals,too-many-branches,too-many-statements metadata : pd . DataFrame , base_iri : str , base_iri_from_metadata : bool = True , imports : pd . DataFrame = None , catalog : dict = None , ) -> Tuple [ ontopy . ontology . Ontology , dict ]: \"\"\"Create ontology with metadata from pd.DataFrame\"\"\" # base_iri from metadata if it exists and base_iri_from_metadata if base_iri_from_metadata : try : base_iris = _parse_literal ( metadata , \"Ontology IRI\" , metadata = True ) if len ( base_iris ) > 1 : warnings . warn ( \"More than one Ontology IRI given. The first was chosen.\" ) base_iri = base_iris [ 0 ] + \"#\" except ( TypeError , ValueError , AttributeError , IndexError ): pass # Create new ontology onto = get_ontology ( base_iri ) # Add imported ontologies catalog = {} if catalog is None else catalog locations = set () for _ , row in imports . iterrows (): # for location in imports: location = row [ \"Imported ontologies\" ] if not pd . isna ( location ) and location not in locations : imported = onto . world . get_ontology ( location ) . load () onto . imported_ontologies . append ( imported ) catalog [ imported . base_iri . rstrip ( \"#/\" )] = location try : cat = read_catalog ( location . rsplit ( \"/\" , 1 )[ 0 ]) catalog . update ( cat ) except ReadCatalogError : warnings . warn ( f \"Catalog for { imported } not found.\" ) locations . add ( location ) # set defined prefix if not pd . isna ( row [ \"prefix\" ]): # set prefix for all ontologies with same 'base_iri_root' if not pd . isna ( row [ \"base_iri_root\" ]): onto . set_common_prefix ( iri_base = row [ \"base_iri_root\" ], prefix = row [ \"prefix\" ] ) # If base_root not given, set prefix only to top ontology else : imported . prefix = row [ \"prefix\" ] with onto : # Add title try : _add_literal ( metadata , onto . metadata . title , \"Title\" , metadata = True , only_one = True , ) except AttributeError : pass # Add license try : _add_literal ( metadata , onto . metadata . license , \"License\" , metadata = True ) except AttributeError : pass # Add authors/creators try : _add_literal ( metadata , onto . metadata . creator , \"Author\" , metadata = True ) except AttributeError : pass # Add contributors try : _add_literal ( metadata , onto . metadata . contributor , \"Contributor\" , metadata = True , ) except AttributeError : pass # Add versionInfo try : _add_literal ( metadata , onto . metadata . versionInfo , \"Ontology version Info\" , metadata = True , only_one = True , ) except AttributeError : pass return onto , catalog","title":"excelparser"},{"location":"api_reference/ontopy/excelparser/#excelparser","text":"Module from parsing an excelfile and creating an ontology from it. The excelfile is read by pandas and the pandas dataframe should have column names: prefLabel, altLabel, Elucidation, Comments, Examples, subClassOf, Relations. Note that correct case is mandatory.","title":"excelparser"},{"location":"api_reference/ontopy/excelparser/#ontopy.excelparser.ExcelError","text":"Raised on errors in Excel file. Source code in ontopy/excelparser.py class ExcelError ( EMMOntoPyException ): \"\"\"Raised on errors in Excel file.\"\"\"","title":"ExcelError"},{"location":"api_reference/ontopy/excelparser/#ontopy.excelparser.create_ontology_from_excel","text":"Creates an ontology from an Excel-file. Parameters: Name Type Description Default excelpath str Path to Excel workbook. required concept_sheet_name str Name of sheet where concepts are defined. The second row of this sheet should contain column names that are supported. Currently these are 'prefLabel','altLabel', 'Elucidation', 'Comments', 'Examples', 'subClassOf', 'Relations'. Multiple entries are separated with ';'. 'Concepts' metadata_sheet_name str Name of sheet where metadata are defined. The first row contains column names 'Metadata name' and 'Value' Supported 'Metadata names' are: 'Ontology IRI', 'Ontology vesion IRI', 'Ontology version Info', 'Title', 'Abstract', 'License', 'Comment', 'Author', 'Contributor'. Multiple entries are separated with a semi-colon ( ; ). 'Metadata' imports_sheet_name str Name of sheet where imported ontologies are defined. Column name is 'Imported ontologies'. Fully resolvable URL or path to imported ontologies provided one per row. 'ImportedOntologies' base_iri str Base IRI of the new ontology. 'http://emmo.info/emmo/domain/onto#' base_iri_from_metadata bool Whether to use base IRI defined from metadata. True imports list List of imported ontologies. None catalog dict Imported ontologies with (name, full path) key/value-pairs. None force bool Forcibly make an ontology by skipping concepts that are erroneously defined or other errors in the excel sheet. False Returns: Type Description A tuple with the created ontology associated catalog of ontology names and resolvable path as dict a dictionary with lists of concepts that raise errors, with the following keys: \"already_defined\": These are concepts that are already in the ontology, either because they were already added in a previous line of the excelfile/pandas dataframe, or because it is already defined in the imported ontologies. \"in_imported_ontologies\": Concepts that are defined in the excel, but already exist in the imported ontologies. This is a subset of the 'already_defined'. \"wrongly_defined\": Concepts that are given an invalid prefLabel (e.g. with a space in the name). \"missing_parents\": Concepts that are missing parents. These concepts are added directly under owl:Thing. \"invalid_parents\": Concepts with invalidly defined parents. These concepts are added directly under owl:Thing. \"nonadded_concepts\": List of all concepts that are not added, either because the prefLabel is invalid, or because the concept has already been added once or already exists in an imported ontology. Source code in ontopy/excelparser.py def create_ontology_from_excel ( # pylint: disable=too-many-arguments excelpath : str , concept_sheet_name : str = \"Concepts\" , metadata_sheet_name : str = \"Metadata\" , imports_sheet_name : str = \"ImportedOntologies\" , base_iri : str = \"http://emmo.info/emmo/domain/onto#\" , base_iri_from_metadata : bool = True , imports : list = None , catalog : dict = None , force : bool = False , ) -> Tuple [ ontopy . ontology . Ontology , dict , dict ]: \"\"\" Creates an ontology from an Excel-file. Arguments: excelpath: Path to Excel workbook. concept_sheet_name: Name of sheet where concepts are defined. The second row of this sheet should contain column names that are supported. Currently these are 'prefLabel','altLabel', 'Elucidation', 'Comments', 'Examples', 'subClassOf', 'Relations'. Multiple entries are separated with ';'. metadata_sheet_name: Name of sheet where metadata are defined. The first row contains column names 'Metadata name' and 'Value' Supported 'Metadata names' are: 'Ontology IRI', 'Ontology vesion IRI', 'Ontology version Info', 'Title', 'Abstract', 'License', 'Comment', 'Author', 'Contributor'. Multiple entries are separated with a semi-colon (`;`). imports_sheet_name: Name of sheet where imported ontologies are defined. Column name is 'Imported ontologies'. Fully resolvable URL or path to imported ontologies provided one per row. base_iri: Base IRI of the new ontology. base_iri_from_metadata: Whether to use base IRI defined from metadata. imports: List of imported ontologies. catalog: Imported ontologies with (name, full path) key/value-pairs. force: Forcibly make an ontology by skipping concepts that are erroneously defined or other errors in the excel sheet. Returns: A tuple with the: * created ontology * associated catalog of ontology names and resolvable path as dict * a dictionary with lists of concepts that raise errors, with the following keys: - \"already_defined\": These are concepts that are already in the ontology, either because they were already added in a previous line of the excelfile/pandas dataframe, or because it is already defined in the imported ontologies. - \"in_imported_ontologies\": Concepts that are defined in the excel, but already exist in the imported ontologies. This is a subset of the 'already_defined'. - \"wrongly_defined\": Concepts that are given an invalid prefLabel (e.g. with a space in the name). - \"missing_parents\": Concepts that are missing parents. These concepts are added directly under owl:Thing. - \"invalid_parents\": Concepts with invalidly defined parents. These concepts are added directly under owl:Thing. - \"nonadded_concepts\": List of all concepts that are not added, either because the prefLabel is invalid, or because the concept has already been added once or already exists in an imported ontology. \"\"\" web_protocol = \"http://\" , \"https://\" , \"ftp://\" def _relative_to_absolute_paths ( path ): if isinstance ( path , str ): if not path . startswith ( web_protocol ): path = os . path . dirname ( excelpath ) + \"/\" + str ( path ) return path try : imports = pd . read_excel ( excelpath , sheet_name = imports_sheet_name , skiprows = [ 1 ] ) except ValueError : imports = pd . DataFrame () else : # Strip leading and trailing white spaces in paths imports . replace ( r \"^\\s+\" , \"\" , regex = True ) . replace ( r \"\\s+$\" , \"\" , regex = True ) # Set empty strings to nan imports = imports . replace ( r \"^\\s*$\" , np . nan , regex = True ) if \"Imported ontologies\" in imports . columns : imports [ \"Imported ontologies\" ] = imports [ \"Imported ontologies\" ] . apply ( _relative_to_absolute_paths ) # Read datafile TODO: Some magic to identify the header row conceptdata = pd . read_excel ( excelpath , sheet_name = concept_sheet_name , skiprows = [ 0 , 2 ] ) metadata = pd . read_excel ( excelpath , sheet_name = metadata_sheet_name ) return create_ontology_from_pandas ( data = conceptdata , metadata = metadata , imports = imports , base_iri = base_iri , base_iri_from_metadata = base_iri_from_metadata , catalog = catalog , force = force , )","title":"create_ontology_from_excel()"},{"location":"api_reference/ontopy/excelparser/#ontopy.excelparser.create_ontology_from_pandas","text":"Create an ontology from a pandas DataFrame. Check 'create_ontology_from_excel' for complete documentation. Source code in ontopy/excelparser.py def create_ontology_from_pandas ( # pylint:disable=too-many-locals,too-many-branches,too-many-statements,too-many-arguments data : pd . DataFrame , metadata : pd . DataFrame , imports : pd . DataFrame , base_iri : str = \"http://emmo.info/emmo/domain/onto#\" , base_iri_from_metadata : bool = True , catalog : dict = None , force : bool = False , ) -> Tuple [ ontopy . ontology . Ontology , dict ]: \"\"\" Create an ontology from a pandas DataFrame. Check 'create_ontology_from_excel' for complete documentation. \"\"\" # Remove lines with empty prefLabel data = data [ data [ \"prefLabel\" ] . notna ()] # Convert all data to string, remove spaces, and finally remove # additional rows with empty prefLabel. data = data . astype ( str ) data [ \"prefLabel\" ] = data [ \"prefLabel\" ] . str . strip () data = data [ data [ \"prefLabel\" ] . str . len () > 0 ] data . reset_index ( drop = True , inplace = True ) # Make new ontology onto , catalog = get_metadata_from_dataframe ( metadata , base_iri , imports = imports ) # Get a set of imported concepts imported_concepts = { concept . prefLabel . first () for concept in onto . get_entities () } # Set given or default base_iri if base_iri_from_metadata is False. if not base_iri_from_metadata : onto . base_iri = base_iri labels = set ( data [ \"prefLabel\" ]) for altlabel in data [ \"altLabel\" ] . str . strip (): if not altlabel == \"nan\" : labels . update ( altlabel . split ( \";\" )) # Dictionary with lists of concepts that raise errors concepts_with_errors = { \"already_defined\" : [], \"in_imported_ontologies\" : [], \"wrongly_defined\" : [], \"missing_parents\" : [], \"invalid_parents\" : [], \"nonadded_concepts\" : [], \"errors_in_properties\" : [], } onto . sync_python_names () with onto : remaining_rows = set ( range ( len ( data ))) all_added_rows = [] while remaining_rows : added_rows = set () for index in remaining_rows : row = data . loc [ index ] name = row [ \"prefLabel\" ] try : onto . get_by_label ( name ) if not force : raise ExcelError ( f 'Concept \" { name } \" already in ontology' ) warnings . warn ( f 'Ignoring concept \" { name } \" since it is already in ' \"the ontology.\" ) concepts_with_errors [ \"already_defined\" ] . append ( name ) # What to do if we want to add info to this concept? # Should that be not allowed? # If it should be allowed the index has to be added to # added_rows continue except ( ValueError , TypeError ) as err : warnings . warn ( f 'Ignoring concept \" { name } \". ' f 'The following error was raised: \" { err } \"' ) concepts_with_errors [ \"wrongly_defined\" ] . append ( name ) continue except NoSuchLabelError : pass if row [ \"subClassOf\" ] == \"nan\" : if not force : raise ExcelError ( f \" { row [ 0 ] } has no subClassOf\" ) parent_names = [] # Should be \"owl:Thing\" concepts_with_errors [ \"missing_parents\" ] . append ( name ) else : parent_names = str ( row [ \"subClassOf\" ]) . split ( \";\" ) parents = [] invalid_parent = False for parent_name in parent_names : try : parent = onto . get_by_label ( parent_name . strip ()) except ( NoSuchLabelError , ValueError ) as exc : if parent_name not in labels : if force : warnings . warn ( f 'Invalid parents for \" { name } \": ' f '\" { parent_name } \".' ) concepts_with_errors [ \"invalid_parents\" ] . append ( name ) break raise ExcelError ( f 'Invalid parents for \" { name } \": { exc } \\n ' \"Have you forgotten an imported ontology?\" ) from exc invalid_parent = True break else : parents . append ( parent ) if invalid_parent : continue if not parents : parents = [ owlready2 . Thing ] concept = onto . new_entity ( name , parents ) added_rows . add ( index ) # Add elucidation try : _add_literal ( row , concept . elucidation , \"Elucidation\" , only_one = True , ) except AttributeError as err : if force : _add_literal ( row , concept . comment , \"Elucidation\" , only_one = True , ) warnings . warn ( \"Elucidation added as comment.\" ) else : raise ExcelError ( f \"Not able to add elucidations. { err } .\" ) from err # Add examples try : _add_literal ( row , concept . example , \"Examples\" , expected = False ) except AttributeError : if force : warnings . warn ( \"Not able to add examples. \" \"Did you forget to import an ontology?.\" ) # Add comments _add_literal ( row , concept . comment , \"Comments\" , expected = False ) # Add altLabels try : _add_literal ( row , concept . altLabel , \"altLabel\" , expected = False ) except AttributeError as err : if force is True : _add_literal ( row , concept . label , \"altLabel\" , expected = False , ) warnings . warn ( \"altLabel added as rdfs.label.\" ) else : raise ExcelError ( f \"Not able to add altLabels. \" f \" { err } .\" ) from err remaining_rows . difference_update ( added_rows ) # Detect infinite loop... if not added_rows and remaining_rows : unadded = [ data . loc [ i ] . prefLabel for i in remaining_rows ] if force is True : warnings . warn ( f \"Not able to add the following concepts: { unadded } .\" \" Will continue without these.\" ) remaining_rows = False concepts_with_errors [ \"nonadded_concepts\" ] = unadded else : raise ExcelError ( f \"Not able to add the following concepts: { unadded } .\" ) all_added_rows . extend ( added_rows ) # Add properties in a second loop for index in all_added_rows : row = data . loc [ index ] properties = row [ \"Relations\" ] if properties == \"nan\" : properties = None if isinstance ( properties , str ): try : concept = onto . get_by_label ( row [ \"prefLabel\" ] . strip ()) except NoSuchLabelError : pass props = properties . split ( \";\" ) for prop in props : try : concept . is_a . append ( evaluate ( onto , prop . strip ())) except pyparsing . ParseException as exc : warnings . warn ( f \"Error in Property assignment for: ' { concept } '. \" f \"Property to be Evaluated: ' { prop } '. \" f \" { exc } \" ) concepts_with_errors [ \"errors_in_properties\" ] . append ( name ) except NoSuchLabelError as exc : msg = ( f \"Error in Property assignment for: { concept } . \" f \"Property to be Evaluated: { prop } . \" f \" { exc } \" ) if force is True : warnings . warn ( msg ) concepts_with_errors [ \"errors_in_properties\" ] . append ( name ) else : raise ExcelError ( msg ) from exc # Synchronise Python attributes to ontology onto . sync_attributes ( name_policy = \"uuid\" , name_prefix = \"EMMO_\" , class_docstring = \"elucidation\" ) onto . dir_label = False concepts_with_errors = { key : set ( value ) for key , value in concepts_with_errors . items () } concepts_with_errors [ \"in_imported_ontologies\" ] = concepts_with_errors [ \"already_defined\" ] . intersection ( imported_concepts ) return onto , catalog , concepts_with_errors","title":"create_ontology_from_pandas()"},{"location":"api_reference/ontopy/excelparser/#ontopy.excelparser.english","text":"Returns string as an English location string. Source code in ontopy/excelparser.py def english ( string ): \"\"\"Returns `string` as an English location string.\"\"\" return owlready2 . locstr ( string , lang = \"en\" )","title":"english()"},{"location":"api_reference/ontopy/excelparser/#ontopy.excelparser.get_metadata_from_dataframe","text":"Create ontology with metadata from pd.DataFrame Source code in ontopy/excelparser.py def get_metadata_from_dataframe ( # pylint: disable=too-many-locals,too-many-branches,too-many-statements metadata : pd . DataFrame , base_iri : str , base_iri_from_metadata : bool = True , imports : pd . DataFrame = None , catalog : dict = None , ) -> Tuple [ ontopy . ontology . Ontology , dict ]: \"\"\"Create ontology with metadata from pd.DataFrame\"\"\" # base_iri from metadata if it exists and base_iri_from_metadata if base_iri_from_metadata : try : base_iris = _parse_literal ( metadata , \"Ontology IRI\" , metadata = True ) if len ( base_iris ) > 1 : warnings . warn ( \"More than one Ontology IRI given. The first was chosen.\" ) base_iri = base_iris [ 0 ] + \"#\" except ( TypeError , ValueError , AttributeError , IndexError ): pass # Create new ontology onto = get_ontology ( base_iri ) # Add imported ontologies catalog = {} if catalog is None else catalog locations = set () for _ , row in imports . iterrows (): # for location in imports: location = row [ \"Imported ontologies\" ] if not pd . isna ( location ) and location not in locations : imported = onto . world . get_ontology ( location ) . load () onto . imported_ontologies . append ( imported ) catalog [ imported . base_iri . rstrip ( \"#/\" )] = location try : cat = read_catalog ( location . rsplit ( \"/\" , 1 )[ 0 ]) catalog . update ( cat ) except ReadCatalogError : warnings . warn ( f \"Catalog for { imported } not found.\" ) locations . add ( location ) # set defined prefix if not pd . isna ( row [ \"prefix\" ]): # set prefix for all ontologies with same 'base_iri_root' if not pd . isna ( row [ \"base_iri_root\" ]): onto . set_common_prefix ( iri_base = row [ \"base_iri_root\" ], prefix = row [ \"prefix\" ] ) # If base_root not given, set prefix only to top ontology else : imported . prefix = row [ \"prefix\" ] with onto : # Add title try : _add_literal ( metadata , onto . metadata . title , \"Title\" , metadata = True , only_one = True , ) except AttributeError : pass # Add license try : _add_literal ( metadata , onto . metadata . license , \"License\" , metadata = True ) except AttributeError : pass # Add authors/creators try : _add_literal ( metadata , onto . metadata . creator , \"Author\" , metadata = True ) except AttributeError : pass # Add contributors try : _add_literal ( metadata , onto . metadata . contributor , \"Contributor\" , metadata = True , ) except AttributeError : pass # Add versionInfo try : _add_literal ( metadata , onto . metadata . versionInfo , \"Ontology version Info\" , metadata = True , only_one = True , ) except AttributeError : pass return onto , catalog","title":"get_metadata_from_dataframe()"},{"location":"api_reference/ontopy/graph/","text":"graph \u00b6 A module for visualising ontologies using graphviz. OntoGraph \u00b6 Class for visualising an ontology. Parameters \u00b6 ontology : ontopy.Ontology instance Ontology to visualize. root : None | graph.ALL | string | owlready2.ThingClass instance Name or owlready2 entity of root node to plot subgraph below. If root is graph.ALL , all classes will be included in the subgraph. leafs : None | sequence A sequence of leaf node names for generating sub-graphs. entities : None | sequence A sequence of entities to add to the graph. relations : \"all\" | str | None | sequence Sequence of relations to visualise. If \"all\", means to include all relations. style : None | dict | \"default\" A dict mapping the name of the different graphical elements to dicts of dot graph attributes. Supported graphical elements include: - graphtype : \"Digraph\" | \"Graph\" - graph : graph attributes (G) - class : nodes for classes (N) - root : additional attributes for root nodes (N) - leaf : additional attributes for leaf nodes (N) - defined_class : nodes for defined classes (N) - class_construct : nodes for class constructs (N) - individual : nodes for invididuals (N) - object_property : nodes for object properties (N) - data_property : nodes for data properties (N) - annotation_property : nodes for annotation properties (N) - added_node : nodes added because addnodes is true (N) - isA : edges for isA relations (E) - not : edges for not class constructs (E) - equivalent_to : edges for equivalent_to relations (E) - disjoint_with : edges for disjoint_with relations (E) - inverse_of : edges for inverse_of relations (E) - default_relation : default edges relations and restrictions (E) - relations : dict of styles for different relations (E) - inverse : default edges for inverse relations (E) - default_dataprop : default edges for data properties (E) - nodes : attribute for individual nodes (N) - edges : attribute for individual edges (E) If style is None or \"default\", the default style is used. See https://www.graphviz.org/doc/info/attrs.html edgelabels : None | bool | dict Whether to add labels to the edges of the generated graph. It is also possible to provide a dict mapping the full labels (with cardinality stripped off for restrictions) to some abbriviations. addnodes : bool Whether to add missing target nodes in relations. addconstructs : bool Whether to add nodes representing class constructs. included_namespaces : sequence In combination with root , only include classes with one of the listed namespaces. If empty (the default), nothing is excluded. included_ontologies : sequence In combination with root , only include classes defined in one of the listed ontologies. If empty (default), nothing is excluded. parents : int Include parents levels of parents. excluded_nodes : None | sequence Sequence of labels of nodes to exclude. graph : None | pydot.Dot instance Graphviz Digraph object to plot into. If None, a new graph object is created using the keyword arguments. imported : bool Whether to include imported classes if entities is None. kwargs : Passed to graphviz.Digraph. Source code in ontopy/graph.py class OntoGraph : # pylint: disable=too-many-instance-attributes \"\"\"Class for visualising an ontology. Parameters ---------- ontology : ontopy.Ontology instance Ontology to visualize. root : None | graph.ALL | string | owlready2.ThingClass instance Name or owlready2 entity of root node to plot subgraph below. If `root` is `graph.ALL`, all classes will be included in the subgraph. leafs : None | sequence A sequence of leaf node names for generating sub-graphs. entities : None | sequence A sequence of entities to add to the graph. relations : \"all\" | str | None | sequence Sequence of relations to visualise. If \"all\", means to include all relations. style : None | dict | \"default\" A dict mapping the name of the different graphical elements to dicts of dot graph attributes. Supported graphical elements include: - graphtype : \"Digraph\" | \"Graph\" - graph : graph attributes (G) - class : nodes for classes (N) - root : additional attributes for root nodes (N) - leaf : additional attributes for leaf nodes (N) - defined_class : nodes for defined classes (N) - class_construct : nodes for class constructs (N) - individual : nodes for invididuals (N) - object_property : nodes for object properties (N) - data_property : nodes for data properties (N) - annotation_property : nodes for annotation properties (N) - added_node : nodes added because `addnodes` is true (N) - isA : edges for isA relations (E) - not : edges for not class constructs (E) - equivalent_to : edges for equivalent_to relations (E) - disjoint_with : edges for disjoint_with relations (E) - inverse_of : edges for inverse_of relations (E) - default_relation : default edges relations and restrictions (E) - relations : dict of styles for different relations (E) - inverse : default edges for inverse relations (E) - default_dataprop : default edges for data properties (E) - nodes : attribute for individual nodes (N) - edges : attribute for individual edges (E) If style is None or \"default\", the default style is used. See https://www.graphviz.org/doc/info/attrs.html edgelabels : None | bool | dict Whether to add labels to the edges of the generated graph. It is also possible to provide a dict mapping the full labels (with cardinality stripped off for restrictions) to some abbriviations. addnodes : bool Whether to add missing target nodes in relations. addconstructs : bool Whether to add nodes representing class constructs. included_namespaces : sequence In combination with `root`, only include classes with one of the listed namespaces. If empty (the default), nothing is excluded. included_ontologies : sequence In combination with `root`, only include classes defined in one of the listed ontologies. If empty (default), nothing is excluded. parents : int Include `parents` levels of parents. excluded_nodes : None | sequence Sequence of labels of nodes to exclude. graph : None | pydot.Dot instance Graphviz Digraph object to plot into. If None, a new graph object is created using the keyword arguments. imported : bool Whether to include imported classes if `entities` is None. kwargs : Passed to graphviz.Digraph. \"\"\" def __init__ ( # pylint: disable=too-many-arguments,too-many-locals self , ontology , root = None , leafs = None , entities = None , relations = \"isA\" , style = None , edgelabels = None , addnodes = False , addconstructs = False , included_namespaces = (), included_ontologies = (), parents = 0 , excluded_nodes = None , graph = None , imported = False , ** kwargs , ): if style is None or style == \"default\" : style = _default_style if graph is None : graphtype = style . get ( \"graphtype\" , \"Digraph\" ) dotcls = getattr ( graphviz , graphtype ) graph_attr = kwargs . pop ( \"graph_attr\" , {}) for key , value in style . get ( \"graph\" , {}) . items (): graph_attr . setdefault ( key , value ) self . dot = dotcls ( graph_attr = graph_attr , ** kwargs ) self . nodes = set () self . edges = set () else : if ontology != graph . ontology : ValueError ( \"the same ontology must be used when extending a graph\" ) self . dot = graph . dot . copy () self . nodes = graph . nodes . copy () self . edges = graph . edges . copy () self . ontology = ontology self . relations = set ( [ relations ] if isinstance ( relations , str ) else relations ) self . style = style self . edgelabels = edgelabels self . addnodes = addnodes self . addconstructs = addconstructs self . excluded_nodes = set ( excluded_nodes ) if excluded_nodes else set () self . imported = imported if root == ALL : self . add_entities ( relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ) elif root : self . add_branch ( root , leafs , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) if parents : self . add_parents ( root , levels = parents , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ) if entities : self . add_entities ( entities = entities , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ) def add_entities ( # pylint: disable=too-many-arguments self , entities = None , relations = \"isA\" , edgelabels = None , addnodes = False , addconstructs = False , nodeattrs = None , ** attrs , ): \"\"\"Adds a sequence of entities to the graph. If `entities` is None, all classes are added to the graph. `nodeattrs` is a dict mapping node names to are attributes for dedicated nodes. \"\"\" if entities is None : entities = self . ontology . classes ( imported = self . imported ) self . add_nodes ( entities , nodeattrs = nodeattrs , ** attrs ) self . add_edges ( relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ** attrs , ) def add_branch ( # pylint: disable=too-many-arguments,too-many-locals self , root , leafs = None , include_leafs = True , strict_leafs = False , exclude = None , relations = \"isA\" , edgelabels = None , addnodes = False , addconstructs = False , included_namespaces = (), included_ontologies = (), include_parents = \"closest\" , ** attrs , ): \"\"\"Adds branch under `root` ending at any entiry included in the sequence `leafs`. If `include_leafs` is true, leafs classes are also included.\"\"\" if leafs is None : leafs = () classes = self . ontology . get_branch ( root = root , leafs = leafs , include_leafs = include_leafs , strict_leafs = strict_leafs , exclude = exclude , ) classes = filter_classes ( classes , included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) nodeattrs = {} nodeattrs [ get_label ( root )] = self . style . get ( \"root\" , {}) for leaf in leafs : nodeattrs [ get_label ( leaf )] = self . style . get ( \"leaf\" , {}) self . add_entities ( entities = classes , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , nodeattrs = nodeattrs , ** attrs , ) parents = self . ontology . get_ancestors ( classes , include = include_parents , strict = True ) if parents : for parent in parents : nodeattrs [ get_label ( parent )] = self . style . get ( \"parent_node\" , {}) self . add_entities ( entities = parents , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , nodeattrs = nodeattrs , ** attrs , ) def add_parents ( # pylint: disable=too-many-arguments self , name , levels = 1 , relations = \"isA\" , edgelabels = None , addnodes = False , addconstructs = False , ** attrs , ): \"\"\"Add `levels` levels of strict parents of entity `name`.\"\"\" def addparents ( entity , nodes , parents ): if nodes > 0 : for parent in entity . get_parents ( strict = True ): parents . add ( parent ) addparents ( parent , nodes - 1 , parents ) entity = self . ontology [ name ] if isinstance ( name , str ) else name parents = set () addparents ( entity , levels , parents ) self . add_entities ( entities = parents , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ** attrs , ) def add_node ( self , name , nodeattrs = None , ** attrs ): \"\"\"Add node with given name. `attrs` are graphviz node attributes.\"\"\" entity = self . ontology [ name ] if isinstance ( name , str ) else name label = get_label ( entity ) if label not in self . nodes . union ( self . excluded_nodes ): kwargs = self . get_node_attrs ( entity , nodeattrs = nodeattrs , attrs = attrs ) if hasattr ( entity , \"iri\" ): kwargs . setdefault ( \"URL\" , entity . iri ) self . dot . node ( label , label = label , ** kwargs ) self . nodes . add ( label ) def add_nodes ( self , names , nodeattrs , ** attrs ): \"\"\"Add nodes with given names. `attrs` are graphviz node attributes.\"\"\" for name in names : self . add_node ( name , nodeattrs = nodeattrs , ** attrs ) def add_edge ( self , subject , predicate , obj , edgelabel = None , ** attrs ): \"\"\"Add edge corresponding for ``(subject, predicate, object)`` triplet.\"\"\" subject = subject if isinstance ( subject , str ) else get_label ( subject ) predicate = ( predicate if isinstance ( predicate , str ) else get_label ( predicate ) ) obj = obj if isinstance ( obj , str ) else get_label ( obj ) if subject in self . excluded_nodes or obj in self . excluded_nodes : return if not isinstance ( subject , str ) or not isinstance ( obj , str ): raise TypeError ( \"`subject` and `object` must be strings\" ) if subject not in self . nodes : raise RuntimeError ( f '`subject` \" { subject } \" must have been added' ) if obj not in self . nodes : raise RuntimeError ( f '`object` \" { obj } \" must have been added' ) key = ( subject , predicate , obj ) if key not in self . edges : if edgelabel is None : edgelabel = self . edgelabels label = None if edgelabel is None : tokens = predicate . split () if len ( tokens ) == 2 and tokens [ 1 ] in ( \"some\" , \"only\" ): label = tokens [ 1 ] elif len ( tokens ) == 3 and tokens [ 1 ] in ( \"exactly\" , \"min\" , \"max\" , ): label = f \" { tokens [ 1 ] } { tokens [ 2 ] } \" elif isinstance ( edgelabel , str ): label = edgelabel elif isinstance ( edgelabel , dict ): label = edgelabel . get ( predicate , predicate ) elif edgelabel : label = predicate kwargs = self . get_edge_attrs ( predicate , attrs = attrs ) self . dot . edge ( subject , obj , label = label , ** kwargs ) self . edges . add ( key ) def add_source_edges ( # pylint: disable=too-many-arguments,too-many-branches self , source , relations = None , edgelabels = None , addnodes = None , addconstructs = None , ** attrs , ): \"\"\"Adds all relations originating from entity `source` who's type are listed in `relations`.\"\"\" if relations is None : relations = self . relations elif isinstance ( relations , str ): relations = set ([ relations ]) else : relations = set ( relations ) edgelabels = self . edgelabels if edgelabels is None else edgelabels addconstructs = ( self . addconstructs if addconstructs is None else addconstructs ) entity = self . ontology [ source ] if isinstance ( source , str ) else source label = get_label ( entity ) for relation in entity . is_a : # isA if isinstance ( relation , ( owlready2 . ThingClass , owlready2 . ObjectPropertyClass ) ): if \"all\" in relations or \"isA\" in relations : rlabel = get_label ( relation ) # FIXME - we actually want to include individuals... if isinstance ( entity , owlready2 . Thing ): continue if relation not in entity . get_parents ( strict = True ): continue if not self . add_missing_node ( relation , addnodes = addnodes ): continue self . add_edge ( subject = label , predicate = \"isA\" , obj = rlabel , edgelabel = edgelabels , ** attrs , ) # restriction elif isinstance ( relation , owlready2 . Restriction ): rname = get_label ( relation . property ) if \"all\" in relations or rname in relations : rlabel = f \" { rname } { typenames [ relation . type ] } \" if isinstance ( relation . value , owlready2 . ThingClass ): obj = get_label ( relation . value ) if not self . add_missing_node ( relation . value , addnodes ): continue elif ( isinstance ( relation . value , owlready2 . ClassConstruct ) and self . addconstructs ): obj = self . add_class_construct ( relation . value ) else : continue pred = asstring ( relation , exclude_object = True ) self . add_edge ( label , pred , obj , edgelabel = edgelabels , ** attrs ) # inverse if isinstance ( relation , owlready2 . Inverse ): if \"all\" in relations or \"inverse\" in relations : rlabel = get_label ( relation ) if not self . add_missing_node ( relation , addnodes = addnodes ): continue if relation not in entity . get_parents ( strict = True ): continue self . add_edge ( subject = label , predicate = \"inverse\" , obj = rlabel , edgelabel = edgelabels , ** attrs , ) def add_edges ( # pylint: disable=too-many-arguments self , sources = None , relations = None , edgelabels = None , addnodes = None , addconstructs = None , ** attrs , ): \"\"\"Adds all relations originating from entities `sources` who's type are listed in `relations`. If `sources` is None, edges are added between all current nodes.\"\"\" if sources is None : sources = self . nodes for source in sources . copy (): self . add_source_edges ( source , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ** attrs , ) def add_missing_node ( self , name , addnodes = None ): \"\"\"Checks if `name` corresponds to a missing node and add it if `addnodes` is true. Returns true if the node exists or is added, false otherwise.\"\"\" addnodes = self . addnodes if addnodes is None else addnodes entity = self . ontology [ name ] if isinstance ( name , str ) else name label = get_label ( entity ) if label not in self . nodes : if addnodes : self . add_node ( entity , ** self . style . get ( \"added_node\" , {})) else : return False return True def add_class_construct ( self , construct ): \"\"\"Adds class construct and return its label.\"\"\" self . add_node ( construct , ** self . style . get ( \"class_construct\" , {})) label = get_label ( construct ) if isinstance ( construct , owlready2 . Or ): for cls in construct . Classes : clslabel = get_label ( cls ) if clslabel not in self . nodes and self . addnodes : self . add_node ( cls ) if clslabel in self . nodes : self . add_edge ( get_label ( cls ), \"isA\" , label ) elif isinstance ( construct , owlready2 . And ): for cls in construct . Classes : clslabel = get_label ( cls ) if clslabel not in self . nodes and self . addnodes : self . add_node ( cls ) if clslabel in self . nodes : self . add_edge ( label , \"isA\" , get_label ( cls )) elif isinstance ( construct , owlready2 . Not ): clslabel = get_label ( construct . Class ) if clslabel not in self . nodes and self . addnodes : self . add_node ( construct . Class ) if clslabel in self . nodes : self . add_edge ( clslabel , \"not\" , label ) # Neither and nor inverse constructs are return label def get_node_attrs ( self , name , nodeattrs , attrs ): \"\"\"Returns attributes for node or edge `name`. `attrs` overrides the default style.\"\"\" entity = self . ontology [ name ] if isinstance ( name , str ) else name label = get_label ( entity ) # class if isinstance ( entity , owlready2 . ThingClass ): if self . ontology . is_defined ( entity ): kwargs = self . style . get ( \"defined_class\" , {}) else : kwargs = self . style . get ( \"class\" , {}) # class construct elif isinstance ( entity , owlready2 . ClassConstruct ): kwargs = self . style . get ( \"class_construct\" , {}) # individual elif isinstance ( entity , owlready2 . Thing ): kwargs = self . style . get ( \"individual\" , {}) # object property elif isinstance ( entity , owlready2 . ObjectPropertyClass ): kwargs = self . style . get ( \"object_property\" , {}) # data property elif isinstance ( entity , owlready2 . DataPropertyClass ): kwargs = self . style . get ( \"data_property\" , {}) # annotation property elif isinstance ( entity , owlready2 . AnnotationPropertyClass ): kwargs = self . style . get ( \"annotation_property\" , {}) else : raise TypeError ( f \"Unknown entity type: { entity !r} \" ) kwargs = kwargs . copy () kwargs . update ( self . style . get ( \"nodes\" , {}) . get ( label , {})) if nodeattrs : kwargs . update ( nodeattrs . get ( label , {})) kwargs . update ( attrs ) return kwargs def get_edge_attrs ( self , predicate , attrs ): \"\"\"Returns attributes for node or edge `name`. `attrs` overrides the default style.\"\"\" # given type types = ( \"isA\" , \"equivalent_to\" , \"disjoint_with\" , \"inverse_of\" ) if predicate in types : kwargs = self . style . get ( predicate , {}) . copy () else : kwargs = {} name = predicate . split ( None , 1 )[ 0 ] match = re . match ( r \"Inverse\\((.*)\\)\" , name ) if match : ( name ,) = match . groups () attrs = attrs . copy () for key , value in self . style . get ( \"inverse\" , {}) . items (): attrs . setdefault ( key , value ) if not isinstance ( name , str ) or name in self . ontology : entity = self . ontology [ name ] if isinstance ( name , str ) else name relations = self . style . get ( \"relations\" , {}) rels = set ( self . ontology [ _ ] for _ in relations if _ in self . ontology ) for relation in entity . mro (): if relation in rels : rattrs = ( relations [ get_label ( relation )] if relation in rels else {} ) break else : warnings . warn ( f \"Style not defined for relation { name } . \" \"Resorting to default style.\" ) rattrs = self . style . get ( \"default_relation\" , {}) # object property if isinstance ( entity , ( owlready2 . ObjectPropertyClass , owlready2 . ObjectProperty ), ): kwargs = self . style . get ( \"default_relation\" , {}) . copy () kwargs . update ( rattrs ) # data property elif isinstance ( entity , ( owlready2 . DataPropertyClass , owlready2 . DataProperty ), ): kwargs = self . style . get ( \"default_dataprop\" , {}) . copy () kwargs . update ( rattrs ) else : raise TypeError ( f \"Unknown entity type: { entity !r} \" ) kwargs . update ( self . style . get ( \"edges\" , {}) . get ( predicate , {})) kwargs . update ( attrs ) return kwargs def add_legend ( self , relations = None ): \"\"\"Adds legend for specified relations to the graph. If `relations` is \"all\", the legend will contain all relations that are defined in the style. By default the legend will only contain relations that are currently included in the graph. Hence, you usually want to call add_legend() as the last method before saving or displaying. \"\"\" rels = self . style . get ( \"relations\" , {}) if relations is None : relations = self . get_relations ( sort = True ) elif relations == \"all\" : relations = [ \"isA\" ] + list ( rels . keys ()) + [ \"inverse\" ] elif isinstance ( relations , str ): relations = relations . split ( \",\" ) nrelations = len ( relations ) if nrelations == 0 : return table = ( '<<table border=\"0\" cellpadding=\"2\" cellspacing=\"0\" cellborder=\"0\">' ) label1 = [ table ] label2 = [ table ] for index , relation in enumerate ( relations ): label1 . append ( f '<tr><td align=\"right\" port=\"i { index } \"> { relation } </td></tr>' ) label2 . append ( f '<tr><td port=\"i { index } \">&nbsp;</td></tr>' ) label1 . append ( \"</table>>\" ) label2 . append ( \"</table>>\" ) self . dot . node ( \"key1\" , label = \" \\n \" . join ( label1 ), shape = \"plaintext\" ) self . dot . node ( \"key2\" , label = \" \\n \" . join ( label2 ), shape = \"plaintext\" ) rankdir = self . dot . graph_attr . get ( \"rankdir\" , \"TB\" ) constraint = \"false\" if rankdir in ( \"TB\" , \"BT\" ) else \"true\" inv = rankdir in ( \"BT\" ,) for index in range ( nrelations ): relation = ( relations [ nrelations - 1 - index ] if inv else relations [ index ] ) if relation == \"inverse\" : kwargs = self . style . get ( \"inverse\" , {}) . copy () else : kwargs = self . get_edge_attrs ( relation , {}) . copy () kwargs [ \"constraint\" ] = constraint with self . dot . subgraph ( name = f \"sub { index } \" ) as subgraph : subgraph . attr ( rank = \"same\" ) if rankdir in ( \"BT\" , \"LR\" ): self . dot . edge ( f \"key1:i { index } :e\" , f \"key2:i { index } :w\" , ** kwargs ) else : self . dot . edge ( f \"key2:i { index } :w\" , f \"key1:i { index } :e\" , ** kwargs ) def get_relations ( self , sort = True ): \"\"\"Returns a set of relations in current graph. If `sort` is true, a sorted list is returned.\"\"\" relations = set () for _ , predicate , _ in self . edges : if predicate . startswith ( \"Inverse\" ): relations . add ( \"inverse\" ) match = re . match ( r \"Inverse\\((.+)\\)\" , predicate ) if match is None : raise ValueError ( \"Could unexpectedly not find the inverse relation \" f \"just added in: { predicate } \" ) relations . add ( match . groups ()[ 0 ]) else : relations . add ( predicate . split ( None , 1 )[ 0 ]) # Sort, but place 'isA' first and 'inverse' last if sort : start , end = [], [] if \"isA\" in relations : relations . remove ( \"isA\" ) start . append ( \"isA\" ) if \"inverse\" in relations : relations . remove ( \"inverse\" ) end . append ( \"inverse\" ) relations = start + sorted ( relations ) + end return relations def save ( self , filename , fmt = None , ** kwargs ): \"\"\"Saves graph to `filename`. If format is not given, it is inferred from `filename`.\"\"\" base , ext = os . path . splitext ( filename ) if fmt is None : fmt = ext . lstrip ( \".\" ) kwargs . setdefault ( \"cleanup\" , True ) if fmt in ( \"graphviz\" , \"gv\" ): if \"dictionary\" in kwargs : self . dot . save ( filename , dictionary = kwargs [ \"dictionary\" ]) else : self . dot . save ( filename ) else : fmt = kwargs . pop ( \"format\" , fmt ) self . dot . render ( base , format = fmt , ** kwargs ) def view ( self ): \"\"\"Shows the graph in a viewer.\"\"\" self . dot . view ( cleanup = True ) def get_figsize ( self ): \"\"\"Returns the default figure size (width, height) in points.\"\"\" with tempfile . TemporaryDirectory () as tmpdir : tmpfile = os . path . join ( tmpdir , \"graph.svg\" ) self . save ( tmpfile ) xml = ET . parse ( tmpfile ) svg = xml . getroot () width = svg . attrib [ \"width\" ] height = svg . attrib [ \"height\" ] if not width . endswith ( \"pt\" ): # ensure that units are in points raise ValueError ( \"The width attribute should always be given in 'pt', \" f \"but it is: { width } \" ) def asfloat ( string ): return float ( re . match ( r \"^[\\d.]+\" , string ) . group ()) return asfloat ( width ), asfloat ( height ) add_branch ( self , root , leafs = None , include_leafs = True , strict_leafs = False , exclude = None , relations = 'isA' , edgelabels = None , addnodes = False , addconstructs = False , included_namespaces = (), included_ontologies = (), include_parents = 'closest' , ** attrs ) \u00b6 Adds branch under root ending at any entiry included in the sequence leafs . If include_leafs is true, leafs classes are also included. Source code in ontopy/graph.py def add_branch ( # pylint: disable=too-many-arguments,too-many-locals self , root , leafs = None , include_leafs = True , strict_leafs = False , exclude = None , relations = \"isA\" , edgelabels = None , addnodes = False , addconstructs = False , included_namespaces = (), included_ontologies = (), include_parents = \"closest\" , ** attrs , ): \"\"\"Adds branch under `root` ending at any entiry included in the sequence `leafs`. If `include_leafs` is true, leafs classes are also included.\"\"\" if leafs is None : leafs = () classes = self . ontology . get_branch ( root = root , leafs = leafs , include_leafs = include_leafs , strict_leafs = strict_leafs , exclude = exclude , ) classes = filter_classes ( classes , included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) nodeattrs = {} nodeattrs [ get_label ( root )] = self . style . get ( \"root\" , {}) for leaf in leafs : nodeattrs [ get_label ( leaf )] = self . style . get ( \"leaf\" , {}) self . add_entities ( entities = classes , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , nodeattrs = nodeattrs , ** attrs , ) parents = self . ontology . get_ancestors ( classes , include = include_parents , strict = True ) if parents : for parent in parents : nodeattrs [ get_label ( parent )] = self . style . get ( \"parent_node\" , {}) self . add_entities ( entities = parents , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , nodeattrs = nodeattrs , ** attrs , ) add_class_construct ( self , construct ) \u00b6 Adds class construct and return its label. Source code in ontopy/graph.py def add_class_construct ( self , construct ): \"\"\"Adds class construct and return its label.\"\"\" self . add_node ( construct , ** self . style . get ( \"class_construct\" , {})) label = get_label ( construct ) if isinstance ( construct , owlready2 . Or ): for cls in construct . Classes : clslabel = get_label ( cls ) if clslabel not in self . nodes and self . addnodes : self . add_node ( cls ) if clslabel in self . nodes : self . add_edge ( get_label ( cls ), \"isA\" , label ) elif isinstance ( construct , owlready2 . And ): for cls in construct . Classes : clslabel = get_label ( cls ) if clslabel not in self . nodes and self . addnodes : self . add_node ( cls ) if clslabel in self . nodes : self . add_edge ( label , \"isA\" , get_label ( cls )) elif isinstance ( construct , owlready2 . Not ): clslabel = get_label ( construct . Class ) if clslabel not in self . nodes and self . addnodes : self . add_node ( construct . Class ) if clslabel in self . nodes : self . add_edge ( clslabel , \"not\" , label ) # Neither and nor inverse constructs are return label add_edge ( self , subject , predicate , obj , edgelabel = None , ** attrs ) \u00b6 Add edge corresponding for (subject, predicate, object) triplet. Source code in ontopy/graph.py def add_edge ( self , subject , predicate , obj , edgelabel = None , ** attrs ): \"\"\"Add edge corresponding for ``(subject, predicate, object)`` triplet.\"\"\" subject = subject if isinstance ( subject , str ) else get_label ( subject ) predicate = ( predicate if isinstance ( predicate , str ) else get_label ( predicate ) ) obj = obj if isinstance ( obj , str ) else get_label ( obj ) if subject in self . excluded_nodes or obj in self . excluded_nodes : return if not isinstance ( subject , str ) or not isinstance ( obj , str ): raise TypeError ( \"`subject` and `object` must be strings\" ) if subject not in self . nodes : raise RuntimeError ( f '`subject` \" { subject } \" must have been added' ) if obj not in self . nodes : raise RuntimeError ( f '`object` \" { obj } \" must have been added' ) key = ( subject , predicate , obj ) if key not in self . edges : if edgelabel is None : edgelabel = self . edgelabels label = None if edgelabel is None : tokens = predicate . split () if len ( tokens ) == 2 and tokens [ 1 ] in ( \"some\" , \"only\" ): label = tokens [ 1 ] elif len ( tokens ) == 3 and tokens [ 1 ] in ( \"exactly\" , \"min\" , \"max\" , ): label = f \" { tokens [ 1 ] } { tokens [ 2 ] } \" elif isinstance ( edgelabel , str ): label = edgelabel elif isinstance ( edgelabel , dict ): label = edgelabel . get ( predicate , predicate ) elif edgelabel : label = predicate kwargs = self . get_edge_attrs ( predicate , attrs = attrs ) self . dot . edge ( subject , obj , label = label , ** kwargs ) self . edges . add ( key ) add_edges ( self , sources = None , relations = None , edgelabels = None , addnodes = None , addconstructs = None , ** attrs ) \u00b6 Adds all relations originating from entities sources who's type are listed in relations . If sources is None, edges are added between all current nodes. Source code in ontopy/graph.py def add_edges ( # pylint: disable=too-many-arguments self , sources = None , relations = None , edgelabels = None , addnodes = None , addconstructs = None , ** attrs , ): \"\"\"Adds all relations originating from entities `sources` who's type are listed in `relations`. If `sources` is None, edges are added between all current nodes.\"\"\" if sources is None : sources = self . nodes for source in sources . copy (): self . add_source_edges ( source , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ** attrs , ) add_entities ( self , entities = None , relations = 'isA' , edgelabels = None , addnodes = False , addconstructs = False , nodeattrs = None , ** attrs ) \u00b6 Adds a sequence of entities to the graph. If entities is None, all classes are added to the graph. nodeattrs is a dict mapping node names to are attributes for dedicated nodes. Source code in ontopy/graph.py def add_entities ( # pylint: disable=too-many-arguments self , entities = None , relations = \"isA\" , edgelabels = None , addnodes = False , addconstructs = False , nodeattrs = None , ** attrs , ): \"\"\"Adds a sequence of entities to the graph. If `entities` is None, all classes are added to the graph. `nodeattrs` is a dict mapping node names to are attributes for dedicated nodes. \"\"\" if entities is None : entities = self . ontology . classes ( imported = self . imported ) self . add_nodes ( entities , nodeattrs = nodeattrs , ** attrs ) self . add_edges ( relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ** attrs , ) add_legend ( self , relations = None ) \u00b6 Adds legend for specified relations to the graph. If relations is \"all\", the legend will contain all relations that are defined in the style. By default the legend will only contain relations that are currently included in the graph. Hence, you usually want to call add_legend() as the last method before saving or displaying. Source code in ontopy/graph.py def add_legend ( self , relations = None ): \"\"\"Adds legend for specified relations to the graph. If `relations` is \"all\", the legend will contain all relations that are defined in the style. By default the legend will only contain relations that are currently included in the graph. Hence, you usually want to call add_legend() as the last method before saving or displaying. \"\"\" rels = self . style . get ( \"relations\" , {}) if relations is None : relations = self . get_relations ( sort = True ) elif relations == \"all\" : relations = [ \"isA\" ] + list ( rels . keys ()) + [ \"inverse\" ] elif isinstance ( relations , str ): relations = relations . split ( \",\" ) nrelations = len ( relations ) if nrelations == 0 : return table = ( '<<table border=\"0\" cellpadding=\"2\" cellspacing=\"0\" cellborder=\"0\">' ) label1 = [ table ] label2 = [ table ] for index , relation in enumerate ( relations ): label1 . append ( f '<tr><td align=\"right\" port=\"i { index } \"> { relation } </td></tr>' ) label2 . append ( f '<tr><td port=\"i { index } \">&nbsp;</td></tr>' ) label1 . append ( \"</table>>\" ) label2 . append ( \"</table>>\" ) self . dot . node ( \"key1\" , label = \" \\n \" . join ( label1 ), shape = \"plaintext\" ) self . dot . node ( \"key2\" , label = \" \\n \" . join ( label2 ), shape = \"plaintext\" ) rankdir = self . dot . graph_attr . get ( \"rankdir\" , \"TB\" ) constraint = \"false\" if rankdir in ( \"TB\" , \"BT\" ) else \"true\" inv = rankdir in ( \"BT\" ,) for index in range ( nrelations ): relation = ( relations [ nrelations - 1 - index ] if inv else relations [ index ] ) if relation == \"inverse\" : kwargs = self . style . get ( \"inverse\" , {}) . copy () else : kwargs = self . get_edge_attrs ( relation , {}) . copy () kwargs [ \"constraint\" ] = constraint with self . dot . subgraph ( name = f \"sub { index } \" ) as subgraph : subgraph . attr ( rank = \"same\" ) if rankdir in ( \"BT\" , \"LR\" ): self . dot . edge ( f \"key1:i { index } :e\" , f \"key2:i { index } :w\" , ** kwargs ) else : self . dot . edge ( f \"key2:i { index } :w\" , f \"key1:i { index } :e\" , ** kwargs ) add_missing_node ( self , name , addnodes = None ) \u00b6 Checks if name corresponds to a missing node and add it if addnodes is true. Returns true if the node exists or is added, false otherwise. Source code in ontopy/graph.py def add_missing_node ( self , name , addnodes = None ): \"\"\"Checks if `name` corresponds to a missing node and add it if `addnodes` is true. Returns true if the node exists or is added, false otherwise.\"\"\" addnodes = self . addnodes if addnodes is None else addnodes entity = self . ontology [ name ] if isinstance ( name , str ) else name label = get_label ( entity ) if label not in self . nodes : if addnodes : self . add_node ( entity , ** self . style . get ( \"added_node\" , {})) else : return False return True add_node ( self , name , nodeattrs = None , ** attrs ) \u00b6 Add node with given name. attrs are graphviz node attributes. Source code in ontopy/graph.py def add_node ( self , name , nodeattrs = None , ** attrs ): \"\"\"Add node with given name. `attrs` are graphviz node attributes.\"\"\" entity = self . ontology [ name ] if isinstance ( name , str ) else name label = get_label ( entity ) if label not in self . nodes . union ( self . excluded_nodes ): kwargs = self . get_node_attrs ( entity , nodeattrs = nodeattrs , attrs = attrs ) if hasattr ( entity , \"iri\" ): kwargs . setdefault ( \"URL\" , entity . iri ) self . dot . node ( label , label = label , ** kwargs ) self . nodes . add ( label ) add_nodes ( self , names , nodeattrs , ** attrs ) \u00b6 Add nodes with given names. attrs are graphviz node attributes. Source code in ontopy/graph.py def add_nodes ( self , names , nodeattrs , ** attrs ): \"\"\"Add nodes with given names. `attrs` are graphviz node attributes.\"\"\" for name in names : self . add_node ( name , nodeattrs = nodeattrs , ** attrs ) add_parents ( self , name , levels = 1 , relations = 'isA' , edgelabels = None , addnodes = False , addconstructs = False , ** attrs ) \u00b6 Add levels levels of strict parents of entity name . Source code in ontopy/graph.py def add_parents ( # pylint: disable=too-many-arguments self , name , levels = 1 , relations = \"isA\" , edgelabels = None , addnodes = False , addconstructs = False , ** attrs , ): \"\"\"Add `levels` levels of strict parents of entity `name`.\"\"\" def addparents ( entity , nodes , parents ): if nodes > 0 : for parent in entity . get_parents ( strict = True ): parents . add ( parent ) addparents ( parent , nodes - 1 , parents ) entity = self . ontology [ name ] if isinstance ( name , str ) else name parents = set () addparents ( entity , levels , parents ) self . add_entities ( entities = parents , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ** attrs , ) add_source_edges ( self , source , relations = None , edgelabels = None , addnodes = None , addconstructs = None , ** attrs ) \u00b6 Adds all relations originating from entity source who's type are listed in relations . Source code in ontopy/graph.py def add_source_edges ( # pylint: disable=too-many-arguments,too-many-branches self , source , relations = None , edgelabels = None , addnodes = None , addconstructs = None , ** attrs , ): \"\"\"Adds all relations originating from entity `source` who's type are listed in `relations`.\"\"\" if relations is None : relations = self . relations elif isinstance ( relations , str ): relations = set ([ relations ]) else : relations = set ( relations ) edgelabels = self . edgelabels if edgelabels is None else edgelabels addconstructs = ( self . addconstructs if addconstructs is None else addconstructs ) entity = self . ontology [ source ] if isinstance ( source , str ) else source label = get_label ( entity ) for relation in entity . is_a : # isA if isinstance ( relation , ( owlready2 . ThingClass , owlready2 . ObjectPropertyClass ) ): if \"all\" in relations or \"isA\" in relations : rlabel = get_label ( relation ) # FIXME - we actually want to include individuals... if isinstance ( entity , owlready2 . Thing ): continue if relation not in entity . get_parents ( strict = True ): continue if not self . add_missing_node ( relation , addnodes = addnodes ): continue self . add_edge ( subject = label , predicate = \"isA\" , obj = rlabel , edgelabel = edgelabels , ** attrs , ) # restriction elif isinstance ( relation , owlready2 . Restriction ): rname = get_label ( relation . property ) if \"all\" in relations or rname in relations : rlabel = f \" { rname } { typenames [ relation . type ] } \" if isinstance ( relation . value , owlready2 . ThingClass ): obj = get_label ( relation . value ) if not self . add_missing_node ( relation . value , addnodes ): continue elif ( isinstance ( relation . value , owlready2 . ClassConstruct ) and self . addconstructs ): obj = self . add_class_construct ( relation . value ) else : continue pred = asstring ( relation , exclude_object = True ) self . add_edge ( label , pred , obj , edgelabel = edgelabels , ** attrs ) # inverse if isinstance ( relation , owlready2 . Inverse ): if \"all\" in relations or \"inverse\" in relations : rlabel = get_label ( relation ) if not self . add_missing_node ( relation , addnodes = addnodes ): continue if relation not in entity . get_parents ( strict = True ): continue self . add_edge ( subject = label , predicate = \"inverse\" , obj = rlabel , edgelabel = edgelabels , ** attrs , ) get_edge_attrs ( self , predicate , attrs ) \u00b6 Returns attributes for node or edge name . attrs overrides the default style. Source code in ontopy/graph.py def get_edge_attrs ( self , predicate , attrs ): \"\"\"Returns attributes for node or edge `name`. `attrs` overrides the default style.\"\"\" # given type types = ( \"isA\" , \"equivalent_to\" , \"disjoint_with\" , \"inverse_of\" ) if predicate in types : kwargs = self . style . get ( predicate , {}) . copy () else : kwargs = {} name = predicate . split ( None , 1 )[ 0 ] match = re . match ( r \"Inverse\\((.*)\\)\" , name ) if match : ( name ,) = match . groups () attrs = attrs . copy () for key , value in self . style . get ( \"inverse\" , {}) . items (): attrs . setdefault ( key , value ) if not isinstance ( name , str ) or name in self . ontology : entity = self . ontology [ name ] if isinstance ( name , str ) else name relations = self . style . get ( \"relations\" , {}) rels = set ( self . ontology [ _ ] for _ in relations if _ in self . ontology ) for relation in entity . mro (): if relation in rels : rattrs = ( relations [ get_label ( relation )] if relation in rels else {} ) break else : warnings . warn ( f \"Style not defined for relation { name } . \" \"Resorting to default style.\" ) rattrs = self . style . get ( \"default_relation\" , {}) # object property if isinstance ( entity , ( owlready2 . ObjectPropertyClass , owlready2 . ObjectProperty ), ): kwargs = self . style . get ( \"default_relation\" , {}) . copy () kwargs . update ( rattrs ) # data property elif isinstance ( entity , ( owlready2 . DataPropertyClass , owlready2 . DataProperty ), ): kwargs = self . style . get ( \"default_dataprop\" , {}) . copy () kwargs . update ( rattrs ) else : raise TypeError ( f \"Unknown entity type: { entity !r} \" ) kwargs . update ( self . style . get ( \"edges\" , {}) . get ( predicate , {})) kwargs . update ( attrs ) return kwargs get_figsize ( self ) \u00b6 Returns the default figure size (width, height) in points. Source code in ontopy/graph.py def get_figsize ( self ): \"\"\"Returns the default figure size (width, height) in points.\"\"\" with tempfile . TemporaryDirectory () as tmpdir : tmpfile = os . path . join ( tmpdir , \"graph.svg\" ) self . save ( tmpfile ) xml = ET . parse ( tmpfile ) svg = xml . getroot () width = svg . attrib [ \"width\" ] height = svg . attrib [ \"height\" ] if not width . endswith ( \"pt\" ): # ensure that units are in points raise ValueError ( \"The width attribute should always be given in 'pt', \" f \"but it is: { width } \" ) def asfloat ( string ): return float ( re . match ( r \"^[\\d.]+\" , string ) . group ()) return asfloat ( width ), asfloat ( height ) get_node_attrs ( self , name , nodeattrs , attrs ) \u00b6 Returns attributes for node or edge name . attrs overrides the default style. Source code in ontopy/graph.py def get_node_attrs ( self , name , nodeattrs , attrs ): \"\"\"Returns attributes for node or edge `name`. `attrs` overrides the default style.\"\"\" entity = self . ontology [ name ] if isinstance ( name , str ) else name label = get_label ( entity ) # class if isinstance ( entity , owlready2 . ThingClass ): if self . ontology . is_defined ( entity ): kwargs = self . style . get ( \"defined_class\" , {}) else : kwargs = self . style . get ( \"class\" , {}) # class construct elif isinstance ( entity , owlready2 . ClassConstruct ): kwargs = self . style . get ( \"class_construct\" , {}) # individual elif isinstance ( entity , owlready2 . Thing ): kwargs = self . style . get ( \"individual\" , {}) # object property elif isinstance ( entity , owlready2 . ObjectPropertyClass ): kwargs = self . style . get ( \"object_property\" , {}) # data property elif isinstance ( entity , owlready2 . DataPropertyClass ): kwargs = self . style . get ( \"data_property\" , {}) # annotation property elif isinstance ( entity , owlready2 . AnnotationPropertyClass ): kwargs = self . style . get ( \"annotation_property\" , {}) else : raise TypeError ( f \"Unknown entity type: { entity !r} \" ) kwargs = kwargs . copy () kwargs . update ( self . style . get ( \"nodes\" , {}) . get ( label , {})) if nodeattrs : kwargs . update ( nodeattrs . get ( label , {})) kwargs . update ( attrs ) return kwargs get_relations ( self , sort = True ) \u00b6 Returns a set of relations in current graph. If sort is true, a sorted list is returned. Source code in ontopy/graph.py def get_relations ( self , sort = True ): \"\"\"Returns a set of relations in current graph. If `sort` is true, a sorted list is returned.\"\"\" relations = set () for _ , predicate , _ in self . edges : if predicate . startswith ( \"Inverse\" ): relations . add ( \"inverse\" ) match = re . match ( r \"Inverse\\((.+)\\)\" , predicate ) if match is None : raise ValueError ( \"Could unexpectedly not find the inverse relation \" f \"just added in: { predicate } \" ) relations . add ( match . groups ()[ 0 ]) else : relations . add ( predicate . split ( None , 1 )[ 0 ]) # Sort, but place 'isA' first and 'inverse' last if sort : start , end = [], [] if \"isA\" in relations : relations . remove ( \"isA\" ) start . append ( \"isA\" ) if \"inverse\" in relations : relations . remove ( \"inverse\" ) end . append ( \"inverse\" ) relations = start + sorted ( relations ) + end return relations save ( self , filename , fmt = None , ** kwargs ) \u00b6 Saves graph to filename . If format is not given, it is inferred from filename . Source code in ontopy/graph.py def save ( self , filename , fmt = None , ** kwargs ): \"\"\"Saves graph to `filename`. If format is not given, it is inferred from `filename`.\"\"\" base , ext = os . path . splitext ( filename ) if fmt is None : fmt = ext . lstrip ( \".\" ) kwargs . setdefault ( \"cleanup\" , True ) if fmt in ( \"graphviz\" , \"gv\" ): if \"dictionary\" in kwargs : self . dot . save ( filename , dictionary = kwargs [ \"dictionary\" ]) else : self . dot . save ( filename ) else : fmt = kwargs . pop ( \"format\" , fmt ) self . dot . render ( base , format = fmt , ** kwargs ) view ( self ) \u00b6 Shows the graph in a viewer. Source code in ontopy/graph.py def view ( self ): \"\"\"Shows the graph in a viewer.\"\"\" self . dot . view ( cleanup = True ) check_module_dependencies ( modules , verbose = True ) \u00b6 Check module dependencies and return a copy of modules with redundant dependencies removed. If verbose is true, warnings are printed for each module that If modules is given, it should be a dict returned by get_module_dependencies(). Source code in ontopy/graph.py def check_module_dependencies ( modules , verbose = True ): \"\"\"Check module dependencies and return a copy of modules with redundant dependencies removed. If `verbose` is true, warnings are printed for each module that If `modules` is given, it should be a dict returned by get_module_dependencies(). \"\"\" visited = set () def get_deps ( iri , excl = None ): \"\"\"Returns a set with all dependencies of `iri`, excluding `excl` and its dependencies.\"\"\" if iri in visited : return set () visited . add ( iri ) deps = set () for dependency in modules [ iri ]: if dependency != excl : deps . add ( dependency ) deps . update ( get_deps ( dependency )) return deps mods = {} redundant = [] for iri , deps in modules . items (): if not deps : mods [ iri ] = set () for dep in deps : if dep in get_deps ( iri , dep ): redundant . append (( iri , dep )) elif iri in mods : mods [ iri ] . add ( dep ) else : mods [ iri ] = set ([ dep ]) if redundant and verbose : print ( \"** Warning: Redundant module dependency:\" ) for iri , dep in redundant : print ( f \" { iri } -> { dep } \" ) return mods cytoscape_style ( style = None ) \u00b6 Get list of color, style and fills. Source code in ontopy/graph.py def cytoscape_style ( style = None ): # pylint: disable=too-many-branches \"\"\"Get list of color, style and fills.\"\"\" if not style : style = _default_style colours = {} styles = {} fill = {} for key , value in style . items (): if isinstance ( value , dict ): if \"color\" in value : colours [ key ] = value [ \"color\" ] else : colours [ key ] = \"black\" if \"style\" in value : styles [ key ] = value [ \"style\" ] else : styles [ key ] = \"solid\" if \"arrowhead\" in value : if value [ \"arrowhead\" ] == \"empty\" : fill [ key ] = \"hollow\" else : fill [ key ] = \"filled\" for key , value in style . get ( \"relations\" , {}) . items (): if isinstance ( value , dict ): if \"color\" in value : colours [ key ] = value [ \"color\" ] else : colours [ key ] = \"black\" if \"style\" in value : styles [ key ] = value [ \"style\" ] else : styles [ key ] = \"solid\" if \"arrowhead\" in value : if value [ \"arrowhead\" ] == \"empty\" : fill [ key ] = \"hollow\" else : fill [ key ] = \"filled\" return [ colours , styles , fill ] cytoscapegraph ( graph , onto = None , infobox = None , force = False ) \u00b6 Returns and instance of icytoscape-figure for an instance Graph of OntoGraph, the accompanying ontology is required for mouse actions. Parameters: Name Type Description Default graph OntoGraph graph generated with OntoGraph with edgelabels=True. required onto Optional[ontopy.ontology.Ontology] ontology to be used for mouse actions. None infobox str \"left\" or \"right\". Placement of infbox with respect to graph. None force bool force generate graph withour correct edgelabels. False Returns: Type Description GridspecLayout cytoscapewidget with graph and infobox to be visualized in jupyter lab. Source code in ontopy/graph.py def cytoscapegraph ( graph : OntoGraph , onto : Optional [ Ontology ] = None , infobox : str = None , force : bool = False , ) -> \"GridspecLayout\" : # pylint: disable=too-many-locals,too-many-statements \"\"\"Returns and instance of icytoscape-figure for an instance Graph of OntoGraph, the accompanying ontology is required for mouse actions. Args: graph: graph generated with OntoGraph with edgelabels=True. onto: ontology to be used for mouse actions. infobox: \"left\" or \"right\". Placement of infbox with respect to graph. force: force generate graph withour correct edgelabels. Returns: cytoscapewidget with graph and infobox to be visualized in jupyter lab. \"\"\" # pylint: disable=import-error,import-outside-toplevel from ipywidgets import Output , VBox , GridspecLayout from IPython.display import display , Image from pathlib import Path import networkx as nx import pydotplus import ipycytoscape from networkx.readwrite.json_graph import cytoscape_data # Define the styles, this has to be aligned with the graphviz values dotplus = pydotplus . graph_from_dot_data ( graph . dot . source ) # if graph doesn't have multiedges, use dotplus.set_strict(true) pydot_graph = nx . nx_pydot . from_pydot ( dotplus ) colours , styles , fill = cytoscape_style () data = cytoscape_data ( pydot_graph )[ \"elements\" ] for datum in data [ \"edges\" ]: try : datum [ \"data\" ][ \"label\" ] = ( datum [ \"data\" ][ \"label\" ] . rsplit ( \" \" , 1 )[ 0 ] . lstrip ( '\"' ) ) except KeyError as err : if not force : raise EMMOntoPyException ( \"Edge label is not defined. Are you sure that the OntoGraph\" \"instance you provided was generated with \" \"\u00b4edgelabels=True\u00b4?\" ) from err warnings . warn ( \"ARROWS WILL NOT BE DISPLAYED CORRECTLY. \" \"Edge label is not defined. Are you sure that the OntoGraph \" \"instance you provided was generated with \u00b4edgelabels=True\u00b4?\" ) datum [ \"data\" ][ \"label\" ] = \"\" lab = datum [ \"data\" ][ \"label\" ] . replace ( \"Inverse(\" , \"\" ) . rstrip ( \")\" ) try : datum [ \"data\" ][ \"colour\" ] = colours [ lab ] except KeyError : datum [ \"data\" ][ \"colour\" ] = \"black\" try : datum [ \"data\" ][ \"style\" ] = styles [ lab ] except KeyError : datum [ \"data\" ][ \"style\" ] = \"solid\" if datum [ \"data\" ][ \"label\" ] . startswith ( \"Inverse(\" ): datum [ \"data\" ][ \"targetarrow\" ] = \"diamond\" datum [ \"data\" ][ \"sourcearrow\" ] = \"none\" else : datum [ \"data\" ][ \"targetarrow\" ] = \"triangle\" datum [ \"data\" ][ \"sourcearrow\" ] = \"none\" try : datum [ \"data\" ][ \"fill\" ] = fill [ lab ] except KeyError : datum [ \"data\" ][ \"fill\" ] = \"filled\" cytofig = ipycytoscape . CytoscapeWidget () cytofig . graph . add_graph_from_json ( data , directed = True ) cytofig . set_style ( [ { \"selector\" : \"node\" , \"css\" : { \"content\" : \"data(label)\" , # \"text-valign\": \"center\", # \"color\": \"white\", # \"text-outline-width\": 2, # \"text-outline-color\": \"red\", \"background-color\" : \"blue\" , }, }, { \"selector\" : \"node:parent\" , \"css\" : { \"background-opacity\" : 0.333 }}, { \"selector\" : \"edge\" , \"style\" : { \"width\" : 2 , \"line-color\" : \"data(colour)\" , # \"content\": \"data(label)\"\", \"line-style\" : \"data(style)\" , }, }, { \"selector\" : \"edge.directed\" , \"style\" : { \"curve-style\" : \"bezier\" , \"target-arrow-shape\" : \"data(targetarrow)\" , \"target-arrow-color\" : \"data(colour)\" , \"target-arrow-fill\" : \"data(fill)\" , \"mid-source-arrow-shape\" : \"data(sourcearrow)\" , \"mid-source-arrow-color\" : \"data(colour)\" , }, }, { \"selector\" : \"edge.multiple_edges\" , \"style\" : { \"curve-style\" : \"bezier\" }, }, { \"selector\" : \":selected\" , \"css\" : { \"background-color\" : \"black\" , \"line-color\" : \"black\" , \"target-arrow-color\" : \"black\" , \"source-arrow-color\" : \"black\" , \"text-outline-color\" : \"black\" , }, }, ] ) if onto is not None : out = Output ( layout = { \"border\" : \"1px solid black\" }) def log_clicks ( node ): with out : print (( onto . get_by_label ( node [ \"data\" ][ \"label\" ]))) parent = onto . get_by_label ( node [ \"data\" ][ \"label\" ]) . get_parents () print ( f \"parents: { parent } \" ) try : elucidation = onto . get_by_label ( node [ \"data\" ][ \"label\" ] ) . elucidation print ( f \"elucidation: { elucidation [ 0 ] } \" ) except ( AttributeError , IndexError ): pass try : annotations = onto . get_by_label ( node [ \"data\" ][ \"label\" ] ) . annotations for _ in annotations : print ( f \"annotation: { _ } \" ) except AttributeError : pass # Try does not work... try : iri = onto . get_by_label ( node [ \"data\" ][ \"label\" ]) . iri print ( f \"iri: { iri } \" ) except ( AttributeError , IndexError ): pass try : fig = node [ \"data\" ][ \"label\" ] if os . path . exists ( Path ( fig + \".png\" )): display ( Image ( fig + \".png\" , width = 100 )) elif os . path . exists ( Path ( fig + \".jpg\" )): display ( Image ( fig + \".jpg\" , width = 100 )) except ( AttributeError , IndexError ): pass out . clear_output ( wait = True ) def log_mouseovers ( node ): with out : print ( onto . get_by_label ( node [ \"data\" ][ \"label\" ])) # print(f'mouseover: {pformat(node)}') out . clear_output ( wait = True ) cytofig . on ( \"node\" , \"click\" , log_clicks ) cytofig . on ( \"node\" , \"mouseover\" , log_mouseovers ) # , remove=True) cytofig . on ( \"node\" , \"mouseout\" , out . clear_output ( wait = True )) grid = GridspecLayout ( 1 , 3 , height = \"400px\" ) if infobox == \"left\" : grid [ 0 , 0 ] = out grid [ 0 , 1 :] = cytofig elif infobox == \"right\" : grid [ 0 , 0 : - 1 ] = cytofig grid [ 0 , 2 ] = out else : return VBox ([ cytofig , out ]) return grid return cytofig filter_classes ( classes , included_namespaces = (), included_ontologies = ()) \u00b6 Filter out classes whos namespace is not in included_namespaces or whos ontology name is not in one of the ontologies in included_ontologies . classes should be a sequence of classes. Source code in ontopy/graph.py def filter_classes ( classes , included_namespaces = (), included_ontologies = ()): \"\"\"Filter out classes whos namespace is not in `included_namespaces` or whos ontology name is not in one of the ontologies in `included_ontologies`. `classes` should be a sequence of classes. \"\"\" filtered = set ( classes ) if included_namespaces : filtered = set ( c for c in filtered if c . namespace . name in included_namespaces ) if included_ontologies : filtered = set ( c for c in filtered if c . namespace . ontology . name in included_ontologies ) return filtered get_module_dependencies ( iri_or_onto , strip_base = None ) \u00b6 Reads iri_or_onto and returns a dict mapping ontology names to a list of ontologies that they depends on. If strip_base is true, the base IRI is stripped from ontology names. If it is a string, it lstrip'ped from the base iri. Source code in ontopy/graph.py def get_module_dependencies ( iri_or_onto , strip_base = None ): \"\"\"Reads `iri_or_onto` and returns a dict mapping ontology names to a list of ontologies that they depends on. If `strip_base` is true, the base IRI is stripped from ontology names. If it is a string, it lstrip'ped from the base iri. \"\"\" from ontopy.ontology import ( # pylint: disable=import-outside-toplevel get_ontology , ) if isinstance ( iri_or_onto , str ): onto = get_ontology ( iri_or_onto ) onto . load () else : onto = iri_or_onto modules = { onto . base_iri : set ()} def strip ( base_iri ): if isinstance ( strip_base , str ): return base_iri . lstrip ( strip_base ) if strip_base : return base_iri . strip ( onto . base_iri ) return base_iri visited = set () def setmodules ( onto ): for imported_onto in onto . imported_ontologies : if onto . base_iri in modules : modules [ strip ( onto . base_iri )] . add ( strip ( imported_onto . base_iri )) else : modules [ strip ( onto . base_iri )] = set ( [ strip ( imported_onto . base_iri )] ) if imported_onto . base_iri not in modules : modules [ strip ( imported_onto . base_iri )] = set () if imported_onto not in visited : visited . add ( imported_onto ) setmodules ( imported_onto ) setmodules ( onto ) return modules plot_modules ( src , filename = None , fmt = None , show = False , strip_base = None , ignore_redundant = True ) \u00b6 Plot module dependency graph for src and return a graph object. Here src may be an IRI, a path the the ontology or a dict returned by get_module_dependencies(). If filename is given, write the graph to this file. If fmt is None, the output format is inferred from filename . If show is true, the graph is displayed. strip_base is passed on to get_module_dependencies() if src is not a dict. If ignore_redundant is true, redundant dependencies are not plotted. Source code in ontopy/graph.py def plot_modules ( # pylint: disable=too-many-arguments src , filename = None , fmt = None , show = False , strip_base = None , ignore_redundant = True , ): \"\"\"Plot module dependency graph for `src` and return a graph object. Here `src` may be an IRI, a path the the ontology or a dict returned by get_module_dependencies(). If `filename` is given, write the graph to this file. If `fmt` is None, the output format is inferred from `filename`. If `show` is true, the graph is displayed. `strip_base` is passed on to get_module_dependencies() if `src` is not a dict. If `ignore_redundant` is true, redundant dependencies are not plotted. \"\"\" if isinstance ( src , dict ): modules = src else : modules = get_module_dependencies ( src , strip_base = strip_base ) if ignore_redundant : modules = check_module_dependencies ( modules , verbose = False ) dot = graphviz . Digraph ( comment = \"Module dependencies\" ) dot . attr ( rankdir = \"TB\" ) dot . node_attr . update ( style = \"filled\" , fillcolor = \"lightblue\" , shape = \"box\" , edgecolor = \"blue\" ) dot . edge_attr . update ( arrowtail = \"open\" , dir = \"back\" ) for iri in modules . keys (): iriname = iri . split ( \":\" , 1 )[ 1 ] dot . node ( iriname , label = iri , URL = iri ) for iri , deps in modules . items (): for dep in deps : iriname = iri . split ( \":\" , 1 )[ 1 ] depname = dep . split ( \":\" , 1 )[ 1 ] dot . edge ( depname , iriname ) if filename : base , ext = os . path . splitext ( filename ) if fmt is None : fmt = ext . lstrip ( \".\" ) dot . render ( base , format = fmt , view = False , cleanup = True ) if show : dot . view ( cleanup = True ) return dot","title":"graph"},{"location":"api_reference/ontopy/graph/#graph","text":"A module for visualising ontologies using graphviz.","title":"graph"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph","text":"Class for visualising an ontology.","title":"OntoGraph"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph--parameters","text":"ontology : ontopy.Ontology instance Ontology to visualize. root : None | graph.ALL | string | owlready2.ThingClass instance Name or owlready2 entity of root node to plot subgraph below. If root is graph.ALL , all classes will be included in the subgraph. leafs : None | sequence A sequence of leaf node names for generating sub-graphs. entities : None | sequence A sequence of entities to add to the graph. relations : \"all\" | str | None | sequence Sequence of relations to visualise. If \"all\", means to include all relations. style : None | dict | \"default\" A dict mapping the name of the different graphical elements to dicts of dot graph attributes. Supported graphical elements include: - graphtype : \"Digraph\" | \"Graph\" - graph : graph attributes (G) - class : nodes for classes (N) - root : additional attributes for root nodes (N) - leaf : additional attributes for leaf nodes (N) - defined_class : nodes for defined classes (N) - class_construct : nodes for class constructs (N) - individual : nodes for invididuals (N) - object_property : nodes for object properties (N) - data_property : nodes for data properties (N) - annotation_property : nodes for annotation properties (N) - added_node : nodes added because addnodes is true (N) - isA : edges for isA relations (E) - not : edges for not class constructs (E) - equivalent_to : edges for equivalent_to relations (E) - disjoint_with : edges for disjoint_with relations (E) - inverse_of : edges for inverse_of relations (E) - default_relation : default edges relations and restrictions (E) - relations : dict of styles for different relations (E) - inverse : default edges for inverse relations (E) - default_dataprop : default edges for data properties (E) - nodes : attribute for individual nodes (N) - edges : attribute for individual edges (E) If style is None or \"default\", the default style is used. See https://www.graphviz.org/doc/info/attrs.html edgelabels : None | bool | dict Whether to add labels to the edges of the generated graph. It is also possible to provide a dict mapping the full labels (with cardinality stripped off for restrictions) to some abbriviations. addnodes : bool Whether to add missing target nodes in relations. addconstructs : bool Whether to add nodes representing class constructs. included_namespaces : sequence In combination with root , only include classes with one of the listed namespaces. If empty (the default), nothing is excluded. included_ontologies : sequence In combination with root , only include classes defined in one of the listed ontologies. If empty (default), nothing is excluded. parents : int Include parents levels of parents. excluded_nodes : None | sequence Sequence of labels of nodes to exclude. graph : None | pydot.Dot instance Graphviz Digraph object to plot into. If None, a new graph object is created using the keyword arguments. imported : bool Whether to include imported classes if entities is None. kwargs : Passed to graphviz.Digraph. Source code in ontopy/graph.py class OntoGraph : # pylint: disable=too-many-instance-attributes \"\"\"Class for visualising an ontology. Parameters ---------- ontology : ontopy.Ontology instance Ontology to visualize. root : None | graph.ALL | string | owlready2.ThingClass instance Name or owlready2 entity of root node to plot subgraph below. If `root` is `graph.ALL`, all classes will be included in the subgraph. leafs : None | sequence A sequence of leaf node names for generating sub-graphs. entities : None | sequence A sequence of entities to add to the graph. relations : \"all\" | str | None | sequence Sequence of relations to visualise. If \"all\", means to include all relations. style : None | dict | \"default\" A dict mapping the name of the different graphical elements to dicts of dot graph attributes. Supported graphical elements include: - graphtype : \"Digraph\" | \"Graph\" - graph : graph attributes (G) - class : nodes for classes (N) - root : additional attributes for root nodes (N) - leaf : additional attributes for leaf nodes (N) - defined_class : nodes for defined classes (N) - class_construct : nodes for class constructs (N) - individual : nodes for invididuals (N) - object_property : nodes for object properties (N) - data_property : nodes for data properties (N) - annotation_property : nodes for annotation properties (N) - added_node : nodes added because `addnodes` is true (N) - isA : edges for isA relations (E) - not : edges for not class constructs (E) - equivalent_to : edges for equivalent_to relations (E) - disjoint_with : edges for disjoint_with relations (E) - inverse_of : edges for inverse_of relations (E) - default_relation : default edges relations and restrictions (E) - relations : dict of styles for different relations (E) - inverse : default edges for inverse relations (E) - default_dataprop : default edges for data properties (E) - nodes : attribute for individual nodes (N) - edges : attribute for individual edges (E) If style is None or \"default\", the default style is used. See https://www.graphviz.org/doc/info/attrs.html edgelabels : None | bool | dict Whether to add labels to the edges of the generated graph. It is also possible to provide a dict mapping the full labels (with cardinality stripped off for restrictions) to some abbriviations. addnodes : bool Whether to add missing target nodes in relations. addconstructs : bool Whether to add nodes representing class constructs. included_namespaces : sequence In combination with `root`, only include classes with one of the listed namespaces. If empty (the default), nothing is excluded. included_ontologies : sequence In combination with `root`, only include classes defined in one of the listed ontologies. If empty (default), nothing is excluded. parents : int Include `parents` levels of parents. excluded_nodes : None | sequence Sequence of labels of nodes to exclude. graph : None | pydot.Dot instance Graphviz Digraph object to plot into. If None, a new graph object is created using the keyword arguments. imported : bool Whether to include imported classes if `entities` is None. kwargs : Passed to graphviz.Digraph. \"\"\" def __init__ ( # pylint: disable=too-many-arguments,too-many-locals self , ontology , root = None , leafs = None , entities = None , relations = \"isA\" , style = None , edgelabels = None , addnodes = False , addconstructs = False , included_namespaces = (), included_ontologies = (), parents = 0 , excluded_nodes = None , graph = None , imported = False , ** kwargs , ): if style is None or style == \"default\" : style = _default_style if graph is None : graphtype = style . get ( \"graphtype\" , \"Digraph\" ) dotcls = getattr ( graphviz , graphtype ) graph_attr = kwargs . pop ( \"graph_attr\" , {}) for key , value in style . get ( \"graph\" , {}) . items (): graph_attr . setdefault ( key , value ) self . dot = dotcls ( graph_attr = graph_attr , ** kwargs ) self . nodes = set () self . edges = set () else : if ontology != graph . ontology : ValueError ( \"the same ontology must be used when extending a graph\" ) self . dot = graph . dot . copy () self . nodes = graph . nodes . copy () self . edges = graph . edges . copy () self . ontology = ontology self . relations = set ( [ relations ] if isinstance ( relations , str ) else relations ) self . style = style self . edgelabels = edgelabels self . addnodes = addnodes self . addconstructs = addconstructs self . excluded_nodes = set ( excluded_nodes ) if excluded_nodes else set () self . imported = imported if root == ALL : self . add_entities ( relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ) elif root : self . add_branch ( root , leafs , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) if parents : self . add_parents ( root , levels = parents , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ) if entities : self . add_entities ( entities = entities , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ) def add_entities ( # pylint: disable=too-many-arguments self , entities = None , relations = \"isA\" , edgelabels = None , addnodes = False , addconstructs = False , nodeattrs = None , ** attrs , ): \"\"\"Adds a sequence of entities to the graph. If `entities` is None, all classes are added to the graph. `nodeattrs` is a dict mapping node names to are attributes for dedicated nodes. \"\"\" if entities is None : entities = self . ontology . classes ( imported = self . imported ) self . add_nodes ( entities , nodeattrs = nodeattrs , ** attrs ) self . add_edges ( relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ** attrs , ) def add_branch ( # pylint: disable=too-many-arguments,too-many-locals self , root , leafs = None , include_leafs = True , strict_leafs = False , exclude = None , relations = \"isA\" , edgelabels = None , addnodes = False , addconstructs = False , included_namespaces = (), included_ontologies = (), include_parents = \"closest\" , ** attrs , ): \"\"\"Adds branch under `root` ending at any entiry included in the sequence `leafs`. If `include_leafs` is true, leafs classes are also included.\"\"\" if leafs is None : leafs = () classes = self . ontology . get_branch ( root = root , leafs = leafs , include_leafs = include_leafs , strict_leafs = strict_leafs , exclude = exclude , ) classes = filter_classes ( classes , included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) nodeattrs = {} nodeattrs [ get_label ( root )] = self . style . get ( \"root\" , {}) for leaf in leafs : nodeattrs [ get_label ( leaf )] = self . style . get ( \"leaf\" , {}) self . add_entities ( entities = classes , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , nodeattrs = nodeattrs , ** attrs , ) parents = self . ontology . get_ancestors ( classes , include = include_parents , strict = True ) if parents : for parent in parents : nodeattrs [ get_label ( parent )] = self . style . get ( \"parent_node\" , {}) self . add_entities ( entities = parents , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , nodeattrs = nodeattrs , ** attrs , ) def add_parents ( # pylint: disable=too-many-arguments self , name , levels = 1 , relations = \"isA\" , edgelabels = None , addnodes = False , addconstructs = False , ** attrs , ): \"\"\"Add `levels` levels of strict parents of entity `name`.\"\"\" def addparents ( entity , nodes , parents ): if nodes > 0 : for parent in entity . get_parents ( strict = True ): parents . add ( parent ) addparents ( parent , nodes - 1 , parents ) entity = self . ontology [ name ] if isinstance ( name , str ) else name parents = set () addparents ( entity , levels , parents ) self . add_entities ( entities = parents , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ** attrs , ) def add_node ( self , name , nodeattrs = None , ** attrs ): \"\"\"Add node with given name. `attrs` are graphviz node attributes.\"\"\" entity = self . ontology [ name ] if isinstance ( name , str ) else name label = get_label ( entity ) if label not in self . nodes . union ( self . excluded_nodes ): kwargs = self . get_node_attrs ( entity , nodeattrs = nodeattrs , attrs = attrs ) if hasattr ( entity , \"iri\" ): kwargs . setdefault ( \"URL\" , entity . iri ) self . dot . node ( label , label = label , ** kwargs ) self . nodes . add ( label ) def add_nodes ( self , names , nodeattrs , ** attrs ): \"\"\"Add nodes with given names. `attrs` are graphviz node attributes.\"\"\" for name in names : self . add_node ( name , nodeattrs = nodeattrs , ** attrs ) def add_edge ( self , subject , predicate , obj , edgelabel = None , ** attrs ): \"\"\"Add edge corresponding for ``(subject, predicate, object)`` triplet.\"\"\" subject = subject if isinstance ( subject , str ) else get_label ( subject ) predicate = ( predicate if isinstance ( predicate , str ) else get_label ( predicate ) ) obj = obj if isinstance ( obj , str ) else get_label ( obj ) if subject in self . excluded_nodes or obj in self . excluded_nodes : return if not isinstance ( subject , str ) or not isinstance ( obj , str ): raise TypeError ( \"`subject` and `object` must be strings\" ) if subject not in self . nodes : raise RuntimeError ( f '`subject` \" { subject } \" must have been added' ) if obj not in self . nodes : raise RuntimeError ( f '`object` \" { obj } \" must have been added' ) key = ( subject , predicate , obj ) if key not in self . edges : if edgelabel is None : edgelabel = self . edgelabels label = None if edgelabel is None : tokens = predicate . split () if len ( tokens ) == 2 and tokens [ 1 ] in ( \"some\" , \"only\" ): label = tokens [ 1 ] elif len ( tokens ) == 3 and tokens [ 1 ] in ( \"exactly\" , \"min\" , \"max\" , ): label = f \" { tokens [ 1 ] } { tokens [ 2 ] } \" elif isinstance ( edgelabel , str ): label = edgelabel elif isinstance ( edgelabel , dict ): label = edgelabel . get ( predicate , predicate ) elif edgelabel : label = predicate kwargs = self . get_edge_attrs ( predicate , attrs = attrs ) self . dot . edge ( subject , obj , label = label , ** kwargs ) self . edges . add ( key ) def add_source_edges ( # pylint: disable=too-many-arguments,too-many-branches self , source , relations = None , edgelabels = None , addnodes = None , addconstructs = None , ** attrs , ): \"\"\"Adds all relations originating from entity `source` who's type are listed in `relations`.\"\"\" if relations is None : relations = self . relations elif isinstance ( relations , str ): relations = set ([ relations ]) else : relations = set ( relations ) edgelabels = self . edgelabels if edgelabels is None else edgelabels addconstructs = ( self . addconstructs if addconstructs is None else addconstructs ) entity = self . ontology [ source ] if isinstance ( source , str ) else source label = get_label ( entity ) for relation in entity . is_a : # isA if isinstance ( relation , ( owlready2 . ThingClass , owlready2 . ObjectPropertyClass ) ): if \"all\" in relations or \"isA\" in relations : rlabel = get_label ( relation ) # FIXME - we actually want to include individuals... if isinstance ( entity , owlready2 . Thing ): continue if relation not in entity . get_parents ( strict = True ): continue if not self . add_missing_node ( relation , addnodes = addnodes ): continue self . add_edge ( subject = label , predicate = \"isA\" , obj = rlabel , edgelabel = edgelabels , ** attrs , ) # restriction elif isinstance ( relation , owlready2 . Restriction ): rname = get_label ( relation . property ) if \"all\" in relations or rname in relations : rlabel = f \" { rname } { typenames [ relation . type ] } \" if isinstance ( relation . value , owlready2 . ThingClass ): obj = get_label ( relation . value ) if not self . add_missing_node ( relation . value , addnodes ): continue elif ( isinstance ( relation . value , owlready2 . ClassConstruct ) and self . addconstructs ): obj = self . add_class_construct ( relation . value ) else : continue pred = asstring ( relation , exclude_object = True ) self . add_edge ( label , pred , obj , edgelabel = edgelabels , ** attrs ) # inverse if isinstance ( relation , owlready2 . Inverse ): if \"all\" in relations or \"inverse\" in relations : rlabel = get_label ( relation ) if not self . add_missing_node ( relation , addnodes = addnodes ): continue if relation not in entity . get_parents ( strict = True ): continue self . add_edge ( subject = label , predicate = \"inverse\" , obj = rlabel , edgelabel = edgelabels , ** attrs , ) def add_edges ( # pylint: disable=too-many-arguments self , sources = None , relations = None , edgelabels = None , addnodes = None , addconstructs = None , ** attrs , ): \"\"\"Adds all relations originating from entities `sources` who's type are listed in `relations`. If `sources` is None, edges are added between all current nodes.\"\"\" if sources is None : sources = self . nodes for source in sources . copy (): self . add_source_edges ( source , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ** attrs , ) def add_missing_node ( self , name , addnodes = None ): \"\"\"Checks if `name` corresponds to a missing node and add it if `addnodes` is true. Returns true if the node exists or is added, false otherwise.\"\"\" addnodes = self . addnodes if addnodes is None else addnodes entity = self . ontology [ name ] if isinstance ( name , str ) else name label = get_label ( entity ) if label not in self . nodes : if addnodes : self . add_node ( entity , ** self . style . get ( \"added_node\" , {})) else : return False return True def add_class_construct ( self , construct ): \"\"\"Adds class construct and return its label.\"\"\" self . add_node ( construct , ** self . style . get ( \"class_construct\" , {})) label = get_label ( construct ) if isinstance ( construct , owlready2 . Or ): for cls in construct . Classes : clslabel = get_label ( cls ) if clslabel not in self . nodes and self . addnodes : self . add_node ( cls ) if clslabel in self . nodes : self . add_edge ( get_label ( cls ), \"isA\" , label ) elif isinstance ( construct , owlready2 . And ): for cls in construct . Classes : clslabel = get_label ( cls ) if clslabel not in self . nodes and self . addnodes : self . add_node ( cls ) if clslabel in self . nodes : self . add_edge ( label , \"isA\" , get_label ( cls )) elif isinstance ( construct , owlready2 . Not ): clslabel = get_label ( construct . Class ) if clslabel not in self . nodes and self . addnodes : self . add_node ( construct . Class ) if clslabel in self . nodes : self . add_edge ( clslabel , \"not\" , label ) # Neither and nor inverse constructs are return label def get_node_attrs ( self , name , nodeattrs , attrs ): \"\"\"Returns attributes for node or edge `name`. `attrs` overrides the default style.\"\"\" entity = self . ontology [ name ] if isinstance ( name , str ) else name label = get_label ( entity ) # class if isinstance ( entity , owlready2 . ThingClass ): if self . ontology . is_defined ( entity ): kwargs = self . style . get ( \"defined_class\" , {}) else : kwargs = self . style . get ( \"class\" , {}) # class construct elif isinstance ( entity , owlready2 . ClassConstruct ): kwargs = self . style . get ( \"class_construct\" , {}) # individual elif isinstance ( entity , owlready2 . Thing ): kwargs = self . style . get ( \"individual\" , {}) # object property elif isinstance ( entity , owlready2 . ObjectPropertyClass ): kwargs = self . style . get ( \"object_property\" , {}) # data property elif isinstance ( entity , owlready2 . DataPropertyClass ): kwargs = self . style . get ( \"data_property\" , {}) # annotation property elif isinstance ( entity , owlready2 . AnnotationPropertyClass ): kwargs = self . style . get ( \"annotation_property\" , {}) else : raise TypeError ( f \"Unknown entity type: { entity !r} \" ) kwargs = kwargs . copy () kwargs . update ( self . style . get ( \"nodes\" , {}) . get ( label , {})) if nodeattrs : kwargs . update ( nodeattrs . get ( label , {})) kwargs . update ( attrs ) return kwargs def get_edge_attrs ( self , predicate , attrs ): \"\"\"Returns attributes for node or edge `name`. `attrs` overrides the default style.\"\"\" # given type types = ( \"isA\" , \"equivalent_to\" , \"disjoint_with\" , \"inverse_of\" ) if predicate in types : kwargs = self . style . get ( predicate , {}) . copy () else : kwargs = {} name = predicate . split ( None , 1 )[ 0 ] match = re . match ( r \"Inverse\\((.*)\\)\" , name ) if match : ( name ,) = match . groups () attrs = attrs . copy () for key , value in self . style . get ( \"inverse\" , {}) . items (): attrs . setdefault ( key , value ) if not isinstance ( name , str ) or name in self . ontology : entity = self . ontology [ name ] if isinstance ( name , str ) else name relations = self . style . get ( \"relations\" , {}) rels = set ( self . ontology [ _ ] for _ in relations if _ in self . ontology ) for relation in entity . mro (): if relation in rels : rattrs = ( relations [ get_label ( relation )] if relation in rels else {} ) break else : warnings . warn ( f \"Style not defined for relation { name } . \" \"Resorting to default style.\" ) rattrs = self . style . get ( \"default_relation\" , {}) # object property if isinstance ( entity , ( owlready2 . ObjectPropertyClass , owlready2 . ObjectProperty ), ): kwargs = self . style . get ( \"default_relation\" , {}) . copy () kwargs . update ( rattrs ) # data property elif isinstance ( entity , ( owlready2 . DataPropertyClass , owlready2 . DataProperty ), ): kwargs = self . style . get ( \"default_dataprop\" , {}) . copy () kwargs . update ( rattrs ) else : raise TypeError ( f \"Unknown entity type: { entity !r} \" ) kwargs . update ( self . style . get ( \"edges\" , {}) . get ( predicate , {})) kwargs . update ( attrs ) return kwargs def add_legend ( self , relations = None ): \"\"\"Adds legend for specified relations to the graph. If `relations` is \"all\", the legend will contain all relations that are defined in the style. By default the legend will only contain relations that are currently included in the graph. Hence, you usually want to call add_legend() as the last method before saving or displaying. \"\"\" rels = self . style . get ( \"relations\" , {}) if relations is None : relations = self . get_relations ( sort = True ) elif relations == \"all\" : relations = [ \"isA\" ] + list ( rels . keys ()) + [ \"inverse\" ] elif isinstance ( relations , str ): relations = relations . split ( \",\" ) nrelations = len ( relations ) if nrelations == 0 : return table = ( '<<table border=\"0\" cellpadding=\"2\" cellspacing=\"0\" cellborder=\"0\">' ) label1 = [ table ] label2 = [ table ] for index , relation in enumerate ( relations ): label1 . append ( f '<tr><td align=\"right\" port=\"i { index } \"> { relation } </td></tr>' ) label2 . append ( f '<tr><td port=\"i { index } \">&nbsp;</td></tr>' ) label1 . append ( \"</table>>\" ) label2 . append ( \"</table>>\" ) self . dot . node ( \"key1\" , label = \" \\n \" . join ( label1 ), shape = \"plaintext\" ) self . dot . node ( \"key2\" , label = \" \\n \" . join ( label2 ), shape = \"plaintext\" ) rankdir = self . dot . graph_attr . get ( \"rankdir\" , \"TB\" ) constraint = \"false\" if rankdir in ( \"TB\" , \"BT\" ) else \"true\" inv = rankdir in ( \"BT\" ,) for index in range ( nrelations ): relation = ( relations [ nrelations - 1 - index ] if inv else relations [ index ] ) if relation == \"inverse\" : kwargs = self . style . get ( \"inverse\" , {}) . copy () else : kwargs = self . get_edge_attrs ( relation , {}) . copy () kwargs [ \"constraint\" ] = constraint with self . dot . subgraph ( name = f \"sub { index } \" ) as subgraph : subgraph . attr ( rank = \"same\" ) if rankdir in ( \"BT\" , \"LR\" ): self . dot . edge ( f \"key1:i { index } :e\" , f \"key2:i { index } :w\" , ** kwargs ) else : self . dot . edge ( f \"key2:i { index } :w\" , f \"key1:i { index } :e\" , ** kwargs ) def get_relations ( self , sort = True ): \"\"\"Returns a set of relations in current graph. If `sort` is true, a sorted list is returned.\"\"\" relations = set () for _ , predicate , _ in self . edges : if predicate . startswith ( \"Inverse\" ): relations . add ( \"inverse\" ) match = re . match ( r \"Inverse\\((.+)\\)\" , predicate ) if match is None : raise ValueError ( \"Could unexpectedly not find the inverse relation \" f \"just added in: { predicate } \" ) relations . add ( match . groups ()[ 0 ]) else : relations . add ( predicate . split ( None , 1 )[ 0 ]) # Sort, but place 'isA' first and 'inverse' last if sort : start , end = [], [] if \"isA\" in relations : relations . remove ( \"isA\" ) start . append ( \"isA\" ) if \"inverse\" in relations : relations . remove ( \"inverse\" ) end . append ( \"inverse\" ) relations = start + sorted ( relations ) + end return relations def save ( self , filename , fmt = None , ** kwargs ): \"\"\"Saves graph to `filename`. If format is not given, it is inferred from `filename`.\"\"\" base , ext = os . path . splitext ( filename ) if fmt is None : fmt = ext . lstrip ( \".\" ) kwargs . setdefault ( \"cleanup\" , True ) if fmt in ( \"graphviz\" , \"gv\" ): if \"dictionary\" in kwargs : self . dot . save ( filename , dictionary = kwargs [ \"dictionary\" ]) else : self . dot . save ( filename ) else : fmt = kwargs . pop ( \"format\" , fmt ) self . dot . render ( base , format = fmt , ** kwargs ) def view ( self ): \"\"\"Shows the graph in a viewer.\"\"\" self . dot . view ( cleanup = True ) def get_figsize ( self ): \"\"\"Returns the default figure size (width, height) in points.\"\"\" with tempfile . TemporaryDirectory () as tmpdir : tmpfile = os . path . join ( tmpdir , \"graph.svg\" ) self . save ( tmpfile ) xml = ET . parse ( tmpfile ) svg = xml . getroot () width = svg . attrib [ \"width\" ] height = svg . attrib [ \"height\" ] if not width . endswith ( \"pt\" ): # ensure that units are in points raise ValueError ( \"The width attribute should always be given in 'pt', \" f \"but it is: { width } \" ) def asfloat ( string ): return float ( re . match ( r \"^[\\d.]+\" , string ) . group ()) return asfloat ( width ), asfloat ( height )","title":"Parameters"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.add_branch","text":"Adds branch under root ending at any entiry included in the sequence leafs . If include_leafs is true, leafs classes are also included. Source code in ontopy/graph.py def add_branch ( # pylint: disable=too-many-arguments,too-many-locals self , root , leafs = None , include_leafs = True , strict_leafs = False , exclude = None , relations = \"isA\" , edgelabels = None , addnodes = False , addconstructs = False , included_namespaces = (), included_ontologies = (), include_parents = \"closest\" , ** attrs , ): \"\"\"Adds branch under `root` ending at any entiry included in the sequence `leafs`. If `include_leafs` is true, leafs classes are also included.\"\"\" if leafs is None : leafs = () classes = self . ontology . get_branch ( root = root , leafs = leafs , include_leafs = include_leafs , strict_leafs = strict_leafs , exclude = exclude , ) classes = filter_classes ( classes , included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) nodeattrs = {} nodeattrs [ get_label ( root )] = self . style . get ( \"root\" , {}) for leaf in leafs : nodeattrs [ get_label ( leaf )] = self . style . get ( \"leaf\" , {}) self . add_entities ( entities = classes , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , nodeattrs = nodeattrs , ** attrs , ) parents = self . ontology . get_ancestors ( classes , include = include_parents , strict = True ) if parents : for parent in parents : nodeattrs [ get_label ( parent )] = self . style . get ( \"parent_node\" , {}) self . add_entities ( entities = parents , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , nodeattrs = nodeattrs , ** attrs , )","title":"add_branch()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.add_class_construct","text":"Adds class construct and return its label. Source code in ontopy/graph.py def add_class_construct ( self , construct ): \"\"\"Adds class construct and return its label.\"\"\" self . add_node ( construct , ** self . style . get ( \"class_construct\" , {})) label = get_label ( construct ) if isinstance ( construct , owlready2 . Or ): for cls in construct . Classes : clslabel = get_label ( cls ) if clslabel not in self . nodes and self . addnodes : self . add_node ( cls ) if clslabel in self . nodes : self . add_edge ( get_label ( cls ), \"isA\" , label ) elif isinstance ( construct , owlready2 . And ): for cls in construct . Classes : clslabel = get_label ( cls ) if clslabel not in self . nodes and self . addnodes : self . add_node ( cls ) if clslabel in self . nodes : self . add_edge ( label , \"isA\" , get_label ( cls )) elif isinstance ( construct , owlready2 . Not ): clslabel = get_label ( construct . Class ) if clslabel not in self . nodes and self . addnodes : self . add_node ( construct . Class ) if clslabel in self . nodes : self . add_edge ( clslabel , \"not\" , label ) # Neither and nor inverse constructs are return label","title":"add_class_construct()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.add_edge","text":"Add edge corresponding for (subject, predicate, object) triplet. Source code in ontopy/graph.py def add_edge ( self , subject , predicate , obj , edgelabel = None , ** attrs ): \"\"\"Add edge corresponding for ``(subject, predicate, object)`` triplet.\"\"\" subject = subject if isinstance ( subject , str ) else get_label ( subject ) predicate = ( predicate if isinstance ( predicate , str ) else get_label ( predicate ) ) obj = obj if isinstance ( obj , str ) else get_label ( obj ) if subject in self . excluded_nodes or obj in self . excluded_nodes : return if not isinstance ( subject , str ) or not isinstance ( obj , str ): raise TypeError ( \"`subject` and `object` must be strings\" ) if subject not in self . nodes : raise RuntimeError ( f '`subject` \" { subject } \" must have been added' ) if obj not in self . nodes : raise RuntimeError ( f '`object` \" { obj } \" must have been added' ) key = ( subject , predicate , obj ) if key not in self . edges : if edgelabel is None : edgelabel = self . edgelabels label = None if edgelabel is None : tokens = predicate . split () if len ( tokens ) == 2 and tokens [ 1 ] in ( \"some\" , \"only\" ): label = tokens [ 1 ] elif len ( tokens ) == 3 and tokens [ 1 ] in ( \"exactly\" , \"min\" , \"max\" , ): label = f \" { tokens [ 1 ] } { tokens [ 2 ] } \" elif isinstance ( edgelabel , str ): label = edgelabel elif isinstance ( edgelabel , dict ): label = edgelabel . get ( predicate , predicate ) elif edgelabel : label = predicate kwargs = self . get_edge_attrs ( predicate , attrs = attrs ) self . dot . edge ( subject , obj , label = label , ** kwargs ) self . edges . add ( key )","title":"add_edge()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.add_edges","text":"Adds all relations originating from entities sources who's type are listed in relations . If sources is None, edges are added between all current nodes. Source code in ontopy/graph.py def add_edges ( # pylint: disable=too-many-arguments self , sources = None , relations = None , edgelabels = None , addnodes = None , addconstructs = None , ** attrs , ): \"\"\"Adds all relations originating from entities `sources` who's type are listed in `relations`. If `sources` is None, edges are added between all current nodes.\"\"\" if sources is None : sources = self . nodes for source in sources . copy (): self . add_source_edges ( source , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ** attrs , )","title":"add_edges()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.add_entities","text":"Adds a sequence of entities to the graph. If entities is None, all classes are added to the graph. nodeattrs is a dict mapping node names to are attributes for dedicated nodes. Source code in ontopy/graph.py def add_entities ( # pylint: disable=too-many-arguments self , entities = None , relations = \"isA\" , edgelabels = None , addnodes = False , addconstructs = False , nodeattrs = None , ** attrs , ): \"\"\"Adds a sequence of entities to the graph. If `entities` is None, all classes are added to the graph. `nodeattrs` is a dict mapping node names to are attributes for dedicated nodes. \"\"\" if entities is None : entities = self . ontology . classes ( imported = self . imported ) self . add_nodes ( entities , nodeattrs = nodeattrs , ** attrs ) self . add_edges ( relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ** attrs , )","title":"add_entities()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.add_legend","text":"Adds legend for specified relations to the graph. If relations is \"all\", the legend will contain all relations that are defined in the style. By default the legend will only contain relations that are currently included in the graph. Hence, you usually want to call add_legend() as the last method before saving or displaying. Source code in ontopy/graph.py def add_legend ( self , relations = None ): \"\"\"Adds legend for specified relations to the graph. If `relations` is \"all\", the legend will contain all relations that are defined in the style. By default the legend will only contain relations that are currently included in the graph. Hence, you usually want to call add_legend() as the last method before saving or displaying. \"\"\" rels = self . style . get ( \"relations\" , {}) if relations is None : relations = self . get_relations ( sort = True ) elif relations == \"all\" : relations = [ \"isA\" ] + list ( rels . keys ()) + [ \"inverse\" ] elif isinstance ( relations , str ): relations = relations . split ( \",\" ) nrelations = len ( relations ) if nrelations == 0 : return table = ( '<<table border=\"0\" cellpadding=\"2\" cellspacing=\"0\" cellborder=\"0\">' ) label1 = [ table ] label2 = [ table ] for index , relation in enumerate ( relations ): label1 . append ( f '<tr><td align=\"right\" port=\"i { index } \"> { relation } </td></tr>' ) label2 . append ( f '<tr><td port=\"i { index } \">&nbsp;</td></tr>' ) label1 . append ( \"</table>>\" ) label2 . append ( \"</table>>\" ) self . dot . node ( \"key1\" , label = \" \\n \" . join ( label1 ), shape = \"plaintext\" ) self . dot . node ( \"key2\" , label = \" \\n \" . join ( label2 ), shape = \"plaintext\" ) rankdir = self . dot . graph_attr . get ( \"rankdir\" , \"TB\" ) constraint = \"false\" if rankdir in ( \"TB\" , \"BT\" ) else \"true\" inv = rankdir in ( \"BT\" ,) for index in range ( nrelations ): relation = ( relations [ nrelations - 1 - index ] if inv else relations [ index ] ) if relation == \"inverse\" : kwargs = self . style . get ( \"inverse\" , {}) . copy () else : kwargs = self . get_edge_attrs ( relation , {}) . copy () kwargs [ \"constraint\" ] = constraint with self . dot . subgraph ( name = f \"sub { index } \" ) as subgraph : subgraph . attr ( rank = \"same\" ) if rankdir in ( \"BT\" , \"LR\" ): self . dot . edge ( f \"key1:i { index } :e\" , f \"key2:i { index } :w\" , ** kwargs ) else : self . dot . edge ( f \"key2:i { index } :w\" , f \"key1:i { index } :e\" , ** kwargs )","title":"add_legend()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.add_missing_node","text":"Checks if name corresponds to a missing node and add it if addnodes is true. Returns true if the node exists or is added, false otherwise. Source code in ontopy/graph.py def add_missing_node ( self , name , addnodes = None ): \"\"\"Checks if `name` corresponds to a missing node and add it if `addnodes` is true. Returns true if the node exists or is added, false otherwise.\"\"\" addnodes = self . addnodes if addnodes is None else addnodes entity = self . ontology [ name ] if isinstance ( name , str ) else name label = get_label ( entity ) if label not in self . nodes : if addnodes : self . add_node ( entity , ** self . style . get ( \"added_node\" , {})) else : return False return True","title":"add_missing_node()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.add_node","text":"Add node with given name. attrs are graphviz node attributes. Source code in ontopy/graph.py def add_node ( self , name , nodeattrs = None , ** attrs ): \"\"\"Add node with given name. `attrs` are graphviz node attributes.\"\"\" entity = self . ontology [ name ] if isinstance ( name , str ) else name label = get_label ( entity ) if label not in self . nodes . union ( self . excluded_nodes ): kwargs = self . get_node_attrs ( entity , nodeattrs = nodeattrs , attrs = attrs ) if hasattr ( entity , \"iri\" ): kwargs . setdefault ( \"URL\" , entity . iri ) self . dot . node ( label , label = label , ** kwargs ) self . nodes . add ( label )","title":"add_node()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.add_nodes","text":"Add nodes with given names. attrs are graphviz node attributes. Source code in ontopy/graph.py def add_nodes ( self , names , nodeattrs , ** attrs ): \"\"\"Add nodes with given names. `attrs` are graphviz node attributes.\"\"\" for name in names : self . add_node ( name , nodeattrs = nodeattrs , ** attrs )","title":"add_nodes()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.add_parents","text":"Add levels levels of strict parents of entity name . Source code in ontopy/graph.py def add_parents ( # pylint: disable=too-many-arguments self , name , levels = 1 , relations = \"isA\" , edgelabels = None , addnodes = False , addconstructs = False , ** attrs , ): \"\"\"Add `levels` levels of strict parents of entity `name`.\"\"\" def addparents ( entity , nodes , parents ): if nodes > 0 : for parent in entity . get_parents ( strict = True ): parents . add ( parent ) addparents ( parent , nodes - 1 , parents ) entity = self . ontology [ name ] if isinstance ( name , str ) else name parents = set () addparents ( entity , levels , parents ) self . add_entities ( entities = parents , relations = relations , edgelabels = edgelabels , addnodes = addnodes , addconstructs = addconstructs , ** attrs , )","title":"add_parents()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.add_source_edges","text":"Adds all relations originating from entity source who's type are listed in relations . Source code in ontopy/graph.py def add_source_edges ( # pylint: disable=too-many-arguments,too-many-branches self , source , relations = None , edgelabels = None , addnodes = None , addconstructs = None , ** attrs , ): \"\"\"Adds all relations originating from entity `source` who's type are listed in `relations`.\"\"\" if relations is None : relations = self . relations elif isinstance ( relations , str ): relations = set ([ relations ]) else : relations = set ( relations ) edgelabels = self . edgelabels if edgelabels is None else edgelabels addconstructs = ( self . addconstructs if addconstructs is None else addconstructs ) entity = self . ontology [ source ] if isinstance ( source , str ) else source label = get_label ( entity ) for relation in entity . is_a : # isA if isinstance ( relation , ( owlready2 . ThingClass , owlready2 . ObjectPropertyClass ) ): if \"all\" in relations or \"isA\" in relations : rlabel = get_label ( relation ) # FIXME - we actually want to include individuals... if isinstance ( entity , owlready2 . Thing ): continue if relation not in entity . get_parents ( strict = True ): continue if not self . add_missing_node ( relation , addnodes = addnodes ): continue self . add_edge ( subject = label , predicate = \"isA\" , obj = rlabel , edgelabel = edgelabels , ** attrs , ) # restriction elif isinstance ( relation , owlready2 . Restriction ): rname = get_label ( relation . property ) if \"all\" in relations or rname in relations : rlabel = f \" { rname } { typenames [ relation . type ] } \" if isinstance ( relation . value , owlready2 . ThingClass ): obj = get_label ( relation . value ) if not self . add_missing_node ( relation . value , addnodes ): continue elif ( isinstance ( relation . value , owlready2 . ClassConstruct ) and self . addconstructs ): obj = self . add_class_construct ( relation . value ) else : continue pred = asstring ( relation , exclude_object = True ) self . add_edge ( label , pred , obj , edgelabel = edgelabels , ** attrs ) # inverse if isinstance ( relation , owlready2 . Inverse ): if \"all\" in relations or \"inverse\" in relations : rlabel = get_label ( relation ) if not self . add_missing_node ( relation , addnodes = addnodes ): continue if relation not in entity . get_parents ( strict = True ): continue self . add_edge ( subject = label , predicate = \"inverse\" , obj = rlabel , edgelabel = edgelabels , ** attrs , )","title":"add_source_edges()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.get_edge_attrs","text":"Returns attributes for node or edge name . attrs overrides the default style. Source code in ontopy/graph.py def get_edge_attrs ( self , predicate , attrs ): \"\"\"Returns attributes for node or edge `name`. `attrs` overrides the default style.\"\"\" # given type types = ( \"isA\" , \"equivalent_to\" , \"disjoint_with\" , \"inverse_of\" ) if predicate in types : kwargs = self . style . get ( predicate , {}) . copy () else : kwargs = {} name = predicate . split ( None , 1 )[ 0 ] match = re . match ( r \"Inverse\\((.*)\\)\" , name ) if match : ( name ,) = match . groups () attrs = attrs . copy () for key , value in self . style . get ( \"inverse\" , {}) . items (): attrs . setdefault ( key , value ) if not isinstance ( name , str ) or name in self . ontology : entity = self . ontology [ name ] if isinstance ( name , str ) else name relations = self . style . get ( \"relations\" , {}) rels = set ( self . ontology [ _ ] for _ in relations if _ in self . ontology ) for relation in entity . mro (): if relation in rels : rattrs = ( relations [ get_label ( relation )] if relation in rels else {} ) break else : warnings . warn ( f \"Style not defined for relation { name } . \" \"Resorting to default style.\" ) rattrs = self . style . get ( \"default_relation\" , {}) # object property if isinstance ( entity , ( owlready2 . ObjectPropertyClass , owlready2 . ObjectProperty ), ): kwargs = self . style . get ( \"default_relation\" , {}) . copy () kwargs . update ( rattrs ) # data property elif isinstance ( entity , ( owlready2 . DataPropertyClass , owlready2 . DataProperty ), ): kwargs = self . style . get ( \"default_dataprop\" , {}) . copy () kwargs . update ( rattrs ) else : raise TypeError ( f \"Unknown entity type: { entity !r} \" ) kwargs . update ( self . style . get ( \"edges\" , {}) . get ( predicate , {})) kwargs . update ( attrs ) return kwargs","title":"get_edge_attrs()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.get_figsize","text":"Returns the default figure size (width, height) in points. Source code in ontopy/graph.py def get_figsize ( self ): \"\"\"Returns the default figure size (width, height) in points.\"\"\" with tempfile . TemporaryDirectory () as tmpdir : tmpfile = os . path . join ( tmpdir , \"graph.svg\" ) self . save ( tmpfile ) xml = ET . parse ( tmpfile ) svg = xml . getroot () width = svg . attrib [ \"width\" ] height = svg . attrib [ \"height\" ] if not width . endswith ( \"pt\" ): # ensure that units are in points raise ValueError ( \"The width attribute should always be given in 'pt', \" f \"but it is: { width } \" ) def asfloat ( string ): return float ( re . match ( r \"^[\\d.]+\" , string ) . group ()) return asfloat ( width ), asfloat ( height )","title":"get_figsize()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.get_node_attrs","text":"Returns attributes for node or edge name . attrs overrides the default style. Source code in ontopy/graph.py def get_node_attrs ( self , name , nodeattrs , attrs ): \"\"\"Returns attributes for node or edge `name`. `attrs` overrides the default style.\"\"\" entity = self . ontology [ name ] if isinstance ( name , str ) else name label = get_label ( entity ) # class if isinstance ( entity , owlready2 . ThingClass ): if self . ontology . is_defined ( entity ): kwargs = self . style . get ( \"defined_class\" , {}) else : kwargs = self . style . get ( \"class\" , {}) # class construct elif isinstance ( entity , owlready2 . ClassConstruct ): kwargs = self . style . get ( \"class_construct\" , {}) # individual elif isinstance ( entity , owlready2 . Thing ): kwargs = self . style . get ( \"individual\" , {}) # object property elif isinstance ( entity , owlready2 . ObjectPropertyClass ): kwargs = self . style . get ( \"object_property\" , {}) # data property elif isinstance ( entity , owlready2 . DataPropertyClass ): kwargs = self . style . get ( \"data_property\" , {}) # annotation property elif isinstance ( entity , owlready2 . AnnotationPropertyClass ): kwargs = self . style . get ( \"annotation_property\" , {}) else : raise TypeError ( f \"Unknown entity type: { entity !r} \" ) kwargs = kwargs . copy () kwargs . update ( self . style . get ( \"nodes\" , {}) . get ( label , {})) if nodeattrs : kwargs . update ( nodeattrs . get ( label , {})) kwargs . update ( attrs ) return kwargs","title":"get_node_attrs()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.get_relations","text":"Returns a set of relations in current graph. If sort is true, a sorted list is returned. Source code in ontopy/graph.py def get_relations ( self , sort = True ): \"\"\"Returns a set of relations in current graph. If `sort` is true, a sorted list is returned.\"\"\" relations = set () for _ , predicate , _ in self . edges : if predicate . startswith ( \"Inverse\" ): relations . add ( \"inverse\" ) match = re . match ( r \"Inverse\\((.+)\\)\" , predicate ) if match is None : raise ValueError ( \"Could unexpectedly not find the inverse relation \" f \"just added in: { predicate } \" ) relations . add ( match . groups ()[ 0 ]) else : relations . add ( predicate . split ( None , 1 )[ 0 ]) # Sort, but place 'isA' first and 'inverse' last if sort : start , end = [], [] if \"isA\" in relations : relations . remove ( \"isA\" ) start . append ( \"isA\" ) if \"inverse\" in relations : relations . remove ( \"inverse\" ) end . append ( \"inverse\" ) relations = start + sorted ( relations ) + end return relations","title":"get_relations()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.save","text":"Saves graph to filename . If format is not given, it is inferred from filename . Source code in ontopy/graph.py def save ( self , filename , fmt = None , ** kwargs ): \"\"\"Saves graph to `filename`. If format is not given, it is inferred from `filename`.\"\"\" base , ext = os . path . splitext ( filename ) if fmt is None : fmt = ext . lstrip ( \".\" ) kwargs . setdefault ( \"cleanup\" , True ) if fmt in ( \"graphviz\" , \"gv\" ): if \"dictionary\" in kwargs : self . dot . save ( filename , dictionary = kwargs [ \"dictionary\" ]) else : self . dot . save ( filename ) else : fmt = kwargs . pop ( \"format\" , fmt ) self . dot . render ( base , format = fmt , ** kwargs )","title":"save()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.OntoGraph.view","text":"Shows the graph in a viewer. Source code in ontopy/graph.py def view ( self ): \"\"\"Shows the graph in a viewer.\"\"\" self . dot . view ( cleanup = True )","title":"view()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.check_module_dependencies","text":"Check module dependencies and return a copy of modules with redundant dependencies removed. If verbose is true, warnings are printed for each module that If modules is given, it should be a dict returned by get_module_dependencies(). Source code in ontopy/graph.py def check_module_dependencies ( modules , verbose = True ): \"\"\"Check module dependencies and return a copy of modules with redundant dependencies removed. If `verbose` is true, warnings are printed for each module that If `modules` is given, it should be a dict returned by get_module_dependencies(). \"\"\" visited = set () def get_deps ( iri , excl = None ): \"\"\"Returns a set with all dependencies of `iri`, excluding `excl` and its dependencies.\"\"\" if iri in visited : return set () visited . add ( iri ) deps = set () for dependency in modules [ iri ]: if dependency != excl : deps . add ( dependency ) deps . update ( get_deps ( dependency )) return deps mods = {} redundant = [] for iri , deps in modules . items (): if not deps : mods [ iri ] = set () for dep in deps : if dep in get_deps ( iri , dep ): redundant . append (( iri , dep )) elif iri in mods : mods [ iri ] . add ( dep ) else : mods [ iri ] = set ([ dep ]) if redundant and verbose : print ( \"** Warning: Redundant module dependency:\" ) for iri , dep in redundant : print ( f \" { iri } -> { dep } \" ) return mods","title":"check_module_dependencies()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.cytoscape_style","text":"Get list of color, style and fills. Source code in ontopy/graph.py def cytoscape_style ( style = None ): # pylint: disable=too-many-branches \"\"\"Get list of color, style and fills.\"\"\" if not style : style = _default_style colours = {} styles = {} fill = {} for key , value in style . items (): if isinstance ( value , dict ): if \"color\" in value : colours [ key ] = value [ \"color\" ] else : colours [ key ] = \"black\" if \"style\" in value : styles [ key ] = value [ \"style\" ] else : styles [ key ] = \"solid\" if \"arrowhead\" in value : if value [ \"arrowhead\" ] == \"empty\" : fill [ key ] = \"hollow\" else : fill [ key ] = \"filled\" for key , value in style . get ( \"relations\" , {}) . items (): if isinstance ( value , dict ): if \"color\" in value : colours [ key ] = value [ \"color\" ] else : colours [ key ] = \"black\" if \"style\" in value : styles [ key ] = value [ \"style\" ] else : styles [ key ] = \"solid\" if \"arrowhead\" in value : if value [ \"arrowhead\" ] == \"empty\" : fill [ key ] = \"hollow\" else : fill [ key ] = \"filled\" return [ colours , styles , fill ]","title":"cytoscape_style()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.cytoscapegraph","text":"Returns and instance of icytoscape-figure for an instance Graph of OntoGraph, the accompanying ontology is required for mouse actions. Parameters: Name Type Description Default graph OntoGraph graph generated with OntoGraph with edgelabels=True. required onto Optional[ontopy.ontology.Ontology] ontology to be used for mouse actions. None infobox str \"left\" or \"right\". Placement of infbox with respect to graph. None force bool force generate graph withour correct edgelabels. False Returns: Type Description GridspecLayout cytoscapewidget with graph and infobox to be visualized in jupyter lab. Source code in ontopy/graph.py def cytoscapegraph ( graph : OntoGraph , onto : Optional [ Ontology ] = None , infobox : str = None , force : bool = False , ) -> \"GridspecLayout\" : # pylint: disable=too-many-locals,too-many-statements \"\"\"Returns and instance of icytoscape-figure for an instance Graph of OntoGraph, the accompanying ontology is required for mouse actions. Args: graph: graph generated with OntoGraph with edgelabels=True. onto: ontology to be used for mouse actions. infobox: \"left\" or \"right\". Placement of infbox with respect to graph. force: force generate graph withour correct edgelabels. Returns: cytoscapewidget with graph and infobox to be visualized in jupyter lab. \"\"\" # pylint: disable=import-error,import-outside-toplevel from ipywidgets import Output , VBox , GridspecLayout from IPython.display import display , Image from pathlib import Path import networkx as nx import pydotplus import ipycytoscape from networkx.readwrite.json_graph import cytoscape_data # Define the styles, this has to be aligned with the graphviz values dotplus = pydotplus . graph_from_dot_data ( graph . dot . source ) # if graph doesn't have multiedges, use dotplus.set_strict(true) pydot_graph = nx . nx_pydot . from_pydot ( dotplus ) colours , styles , fill = cytoscape_style () data = cytoscape_data ( pydot_graph )[ \"elements\" ] for datum in data [ \"edges\" ]: try : datum [ \"data\" ][ \"label\" ] = ( datum [ \"data\" ][ \"label\" ] . rsplit ( \" \" , 1 )[ 0 ] . lstrip ( '\"' ) ) except KeyError as err : if not force : raise EMMOntoPyException ( \"Edge label is not defined. Are you sure that the OntoGraph\" \"instance you provided was generated with \" \"\u00b4edgelabels=True\u00b4?\" ) from err warnings . warn ( \"ARROWS WILL NOT BE DISPLAYED CORRECTLY. \" \"Edge label is not defined. Are you sure that the OntoGraph \" \"instance you provided was generated with \u00b4edgelabels=True\u00b4?\" ) datum [ \"data\" ][ \"label\" ] = \"\" lab = datum [ \"data\" ][ \"label\" ] . replace ( \"Inverse(\" , \"\" ) . rstrip ( \")\" ) try : datum [ \"data\" ][ \"colour\" ] = colours [ lab ] except KeyError : datum [ \"data\" ][ \"colour\" ] = \"black\" try : datum [ \"data\" ][ \"style\" ] = styles [ lab ] except KeyError : datum [ \"data\" ][ \"style\" ] = \"solid\" if datum [ \"data\" ][ \"label\" ] . startswith ( \"Inverse(\" ): datum [ \"data\" ][ \"targetarrow\" ] = \"diamond\" datum [ \"data\" ][ \"sourcearrow\" ] = \"none\" else : datum [ \"data\" ][ \"targetarrow\" ] = \"triangle\" datum [ \"data\" ][ \"sourcearrow\" ] = \"none\" try : datum [ \"data\" ][ \"fill\" ] = fill [ lab ] except KeyError : datum [ \"data\" ][ \"fill\" ] = \"filled\" cytofig = ipycytoscape . CytoscapeWidget () cytofig . graph . add_graph_from_json ( data , directed = True ) cytofig . set_style ( [ { \"selector\" : \"node\" , \"css\" : { \"content\" : \"data(label)\" , # \"text-valign\": \"center\", # \"color\": \"white\", # \"text-outline-width\": 2, # \"text-outline-color\": \"red\", \"background-color\" : \"blue\" , }, }, { \"selector\" : \"node:parent\" , \"css\" : { \"background-opacity\" : 0.333 }}, { \"selector\" : \"edge\" , \"style\" : { \"width\" : 2 , \"line-color\" : \"data(colour)\" , # \"content\": \"data(label)\"\", \"line-style\" : \"data(style)\" , }, }, { \"selector\" : \"edge.directed\" , \"style\" : { \"curve-style\" : \"bezier\" , \"target-arrow-shape\" : \"data(targetarrow)\" , \"target-arrow-color\" : \"data(colour)\" , \"target-arrow-fill\" : \"data(fill)\" , \"mid-source-arrow-shape\" : \"data(sourcearrow)\" , \"mid-source-arrow-color\" : \"data(colour)\" , }, }, { \"selector\" : \"edge.multiple_edges\" , \"style\" : { \"curve-style\" : \"bezier\" }, }, { \"selector\" : \":selected\" , \"css\" : { \"background-color\" : \"black\" , \"line-color\" : \"black\" , \"target-arrow-color\" : \"black\" , \"source-arrow-color\" : \"black\" , \"text-outline-color\" : \"black\" , }, }, ] ) if onto is not None : out = Output ( layout = { \"border\" : \"1px solid black\" }) def log_clicks ( node ): with out : print (( onto . get_by_label ( node [ \"data\" ][ \"label\" ]))) parent = onto . get_by_label ( node [ \"data\" ][ \"label\" ]) . get_parents () print ( f \"parents: { parent } \" ) try : elucidation = onto . get_by_label ( node [ \"data\" ][ \"label\" ] ) . elucidation print ( f \"elucidation: { elucidation [ 0 ] } \" ) except ( AttributeError , IndexError ): pass try : annotations = onto . get_by_label ( node [ \"data\" ][ \"label\" ] ) . annotations for _ in annotations : print ( f \"annotation: { _ } \" ) except AttributeError : pass # Try does not work... try : iri = onto . get_by_label ( node [ \"data\" ][ \"label\" ]) . iri print ( f \"iri: { iri } \" ) except ( AttributeError , IndexError ): pass try : fig = node [ \"data\" ][ \"label\" ] if os . path . exists ( Path ( fig + \".png\" )): display ( Image ( fig + \".png\" , width = 100 )) elif os . path . exists ( Path ( fig + \".jpg\" )): display ( Image ( fig + \".jpg\" , width = 100 )) except ( AttributeError , IndexError ): pass out . clear_output ( wait = True ) def log_mouseovers ( node ): with out : print ( onto . get_by_label ( node [ \"data\" ][ \"label\" ])) # print(f'mouseover: {pformat(node)}') out . clear_output ( wait = True ) cytofig . on ( \"node\" , \"click\" , log_clicks ) cytofig . on ( \"node\" , \"mouseover\" , log_mouseovers ) # , remove=True) cytofig . on ( \"node\" , \"mouseout\" , out . clear_output ( wait = True )) grid = GridspecLayout ( 1 , 3 , height = \"400px\" ) if infobox == \"left\" : grid [ 0 , 0 ] = out grid [ 0 , 1 :] = cytofig elif infobox == \"right\" : grid [ 0 , 0 : - 1 ] = cytofig grid [ 0 , 2 ] = out else : return VBox ([ cytofig , out ]) return grid return cytofig","title":"cytoscapegraph()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.filter_classes","text":"Filter out classes whos namespace is not in included_namespaces or whos ontology name is not in one of the ontologies in included_ontologies . classes should be a sequence of classes. Source code in ontopy/graph.py def filter_classes ( classes , included_namespaces = (), included_ontologies = ()): \"\"\"Filter out classes whos namespace is not in `included_namespaces` or whos ontology name is not in one of the ontologies in `included_ontologies`. `classes` should be a sequence of classes. \"\"\" filtered = set ( classes ) if included_namespaces : filtered = set ( c for c in filtered if c . namespace . name in included_namespaces ) if included_ontologies : filtered = set ( c for c in filtered if c . namespace . ontology . name in included_ontologies ) return filtered","title":"filter_classes()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.get_module_dependencies","text":"Reads iri_or_onto and returns a dict mapping ontology names to a list of ontologies that they depends on. If strip_base is true, the base IRI is stripped from ontology names. If it is a string, it lstrip'ped from the base iri. Source code in ontopy/graph.py def get_module_dependencies ( iri_or_onto , strip_base = None ): \"\"\"Reads `iri_or_onto` and returns a dict mapping ontology names to a list of ontologies that they depends on. If `strip_base` is true, the base IRI is stripped from ontology names. If it is a string, it lstrip'ped from the base iri. \"\"\" from ontopy.ontology import ( # pylint: disable=import-outside-toplevel get_ontology , ) if isinstance ( iri_or_onto , str ): onto = get_ontology ( iri_or_onto ) onto . load () else : onto = iri_or_onto modules = { onto . base_iri : set ()} def strip ( base_iri ): if isinstance ( strip_base , str ): return base_iri . lstrip ( strip_base ) if strip_base : return base_iri . strip ( onto . base_iri ) return base_iri visited = set () def setmodules ( onto ): for imported_onto in onto . imported_ontologies : if onto . base_iri in modules : modules [ strip ( onto . base_iri )] . add ( strip ( imported_onto . base_iri )) else : modules [ strip ( onto . base_iri )] = set ( [ strip ( imported_onto . base_iri )] ) if imported_onto . base_iri not in modules : modules [ strip ( imported_onto . base_iri )] = set () if imported_onto not in visited : visited . add ( imported_onto ) setmodules ( imported_onto ) setmodules ( onto ) return modules","title":"get_module_dependencies()"},{"location":"api_reference/ontopy/graph/#ontopy.graph.plot_modules","text":"Plot module dependency graph for src and return a graph object. Here src may be an IRI, a path the the ontology or a dict returned by get_module_dependencies(). If filename is given, write the graph to this file. If fmt is None, the output format is inferred from filename . If show is true, the graph is displayed. strip_base is passed on to get_module_dependencies() if src is not a dict. If ignore_redundant is true, redundant dependencies are not plotted. Source code in ontopy/graph.py def plot_modules ( # pylint: disable=too-many-arguments src , filename = None , fmt = None , show = False , strip_base = None , ignore_redundant = True , ): \"\"\"Plot module dependency graph for `src` and return a graph object. Here `src` may be an IRI, a path the the ontology or a dict returned by get_module_dependencies(). If `filename` is given, write the graph to this file. If `fmt` is None, the output format is inferred from `filename`. If `show` is true, the graph is displayed. `strip_base` is passed on to get_module_dependencies() if `src` is not a dict. If `ignore_redundant` is true, redundant dependencies are not plotted. \"\"\" if isinstance ( src , dict ): modules = src else : modules = get_module_dependencies ( src , strip_base = strip_base ) if ignore_redundant : modules = check_module_dependencies ( modules , verbose = False ) dot = graphviz . Digraph ( comment = \"Module dependencies\" ) dot . attr ( rankdir = \"TB\" ) dot . node_attr . update ( style = \"filled\" , fillcolor = \"lightblue\" , shape = \"box\" , edgecolor = \"blue\" ) dot . edge_attr . update ( arrowtail = \"open\" , dir = \"back\" ) for iri in modules . keys (): iriname = iri . split ( \":\" , 1 )[ 1 ] dot . node ( iriname , label = iri , URL = iri ) for iri , deps in modules . items (): for dep in deps : iriname = iri . split ( \":\" , 1 )[ 1 ] depname = dep . split ( \":\" , 1 )[ 1 ] dot . edge ( depname , iriname ) if filename : base , ext = os . path . splitext ( filename ) if fmt is None : fmt = ext . lstrip ( \".\" ) dot . render ( base , format = fmt , view = False , cleanup = True ) if show : dot . view ( cleanup = True ) return dot","title":"plot_modules()"},{"location":"api_reference/ontopy/manchester/","text":"manchester \u00b6 Evaluate Manchester syntax This module compiles restrictions and logical constructs in Manchester syntax into Owlready2 classes. The main function in this module is manchester.evaluate() , see its docstring for usage example. Pyparsing is used under the hood for parsing. ManchesterError ( EMMOntoPyException ) \u00b6 Raised on invalid Manchester notation. Source code in ontopy/manchester.py class ManchesterError ( EMMOntoPyException ): \"\"\"Raised on invalid Manchester notation.\"\"\" evaluate ( ontology , expr ) \u00b6 Evaluate expression in Manchester syntax. Parameters: Name Type Description Default ontology Ontology The ontology within which the expression will be evaluated. required expr str Manchester expression to be evaluated. required Returns: Type Description Construct An Owlready2 construct that corresponds to the expression. Examples: from ontopy.manchester import evaluate from ontopy import get_ontology emmo = get_ontology.load() restriction = evaluate(emmo, 'hasPart some Atom') cls = evaluate(emmo, 'Atom') expr = evaluate(emmo, 'Atom or Molecule') Note Logical expressions (with not , and and or ) are supported as well as object property restrictions. For data properterties are only value restrictions supported so far. Source code in ontopy/manchester.py def evaluate ( ontology : owlready2 . Ontology , expr : str ) -> owlready2 . Construct : \"\"\"Evaluate expression in Manchester syntax. Args: ontology: The ontology within which the expression will be evaluated. expr: Manchester expression to be evaluated. Returns: An Owlready2 construct that corresponds to the expression. Example: >>> from ontopy.manchester import evaluate >>> from ontopy import get_ontology >>> emmo = get_ontology.load() >>> restriction = evaluate(emmo, 'hasPart some Atom') >>> cls = evaluate(emmo, 'Atom') >>> expr = evaluate(emmo, 'Atom or Molecule') Note: Logical expressions (with `not`, `and` and `or`) are supported as well as object property restrictions. For data properterties are only value restrictions supported so far. \"\"\" # pylint: disable=invalid-name def _parse_literal ( r ): \"\"\"Compiles literal to Owlready2 type.\"\"\" if r . language : v = owlready2 . locstr ( r . string , r . language ) elif r . number : v = r . number else : v = r . string return v # pylint: disable=invalid-name,no-else-return,too-many-return-statements # pylint: disable=too-many-branches def _eval ( r ): \"\"\"Recursively evaluate expression produced by pyparsing into an Owlready2 construct.\"\"\" def fneg ( x ): \"\"\"Negates the argument if `neg` is true.\"\"\" return owlready2 . Not ( x ) if neg else x if isinstance ( r , str ): # r is atomic, returns its owlready2 repr return ontology [ r ] neg = False # whether the expression starts with \"not\" while r [ 0 ] == \"not\" : r . pop ( 0 ) # strip off the \"not\" and proceed neg = not neg if len ( r ) == 1 : # r is either a atomic or a parenthesised # subexpression that should be further evaluated if isinstance ( r [ 0 ], str ): return fneg ( ontology [ r [ 0 ]]) else : return fneg ( _eval ( r [ 0 ])) elif r . op : # r contains a logical operator: and/or ops = { \"and\" : owlready2 . And , \"or\" : owlready2 . Or } op = ops [ r . op ] if len ( r ) == 3 : return op ([ fneg ( _eval ( r [ 0 ])), _eval ( r [ 2 ])]) else : arg1 = fneg ( _eval ( r [ 0 ])) r . pop ( 0 ) r . pop ( 0 ) return op ([ arg1 , _eval ( r )]) elif r . objProp : # r is a restriction if r [ 0 ] == \"inverse\" : r . pop ( 0 ) prop = owlready2 . Inverse ( ontology [ r [ 0 ]]) else : prop = ontology [ r [ 0 ]] rtype = r [ 1 ] if rtype == \"Self\" : return fneg ( prop . has_self ()) r . pop ( 0 ) r . pop ( 0 ) f = getattr ( prop , rtype ) if rtype == \"value\" : return fneg ( f ( _eval ( r ))) elif rtype in ( \"some\" , \"only\" ): return fneg ( f ( _eval ( r ))) elif rtype in ( \"min\" , \"max\" , \"exactly\" ): cardinality = r . pop ( 0 ) return fneg ( f ( cardinality , _eval ( r ))) else : raise ManchesterError ( f \"invalid restriction type: { rtype } \" ) elif r . dataProp : # r is a data property restriction prop = ontology [ r [ 0 ]] rtype = r [ 1 ] r . pop ( 0 ) r . pop ( 0 ) f = getattr ( prop , rtype ) if rtype == \"value\" : return f ( _parse_literal ( r )) else : raise ManchesterError ( f \"unimplemented data property restriction: \" f \" { prop } { rtype } { r } \" ) else : raise ManchesterError ( f \"invalid expression: { r } \" ) grammar = manchester_expression () return _eval ( grammar . parseString ( expr , parseAll = True )) manchester_expression () \u00b6 Returns pyparsing grammar for a Manchester expression. This function is mostly for internal use. See also: https://www.w3.org/TR/owl2-manchester-syntax/ Source code in ontopy/manchester.py def manchester_expression (): \"\"\"Returns pyparsing grammar for a Manchester expression. This function is mostly for internal use. See also: https://www.w3.org/TR/owl2-manchester-syntax/ \"\"\" # pylint: disable=global-statement,invalid-name,too-many-locals global GRAMMAR if GRAMMAR : return GRAMMAR # Subset of the Manchester grammar for expressions # It is based on https://www.w3.org/TR/owl2-manchester-syntax/ # but allows logical constructs within restrictions (like Protege) ident = pp . Word ( pp . alphas + \"_:-\" , pp . alphanums + \"_:-\" , asKeyword = True ) uint = pp . Word ( pp . nums ) alphas = pp . Word ( pp . alphas ) string = pp . Word ( pp . alphanums + \":\" ) quotedString = ( pp . QuotedString ( '\"\"\"' , multiline = True ) | pp . QuotedString ( '\"' ) )( \"string\" ) typedLiteral = pp . Combine ( quotedString + \"^^\" + string ( \"datatype\" )) stringLanguageLiteral = pp . Combine ( quotedString + \"@\" + alphas ( \"language\" )) stringLiteral = quotedString numberLiteral = pp . pyparsing_common . number ( \"number\" ) literal = ( typedLiteral | stringLanguageLiteral | stringLiteral | numberLiteral ) logOp = pp . oneOf ([ \"and\" , \"or\" ], asKeyword = True ) expr = pp . Forward () restriction = pp . Forward () primary = pp . Keyword ( \"not\" )[ ... ] + ( restriction | ident ( \"cls\" ) | pp . nestedExpr ( \"(\" , \")\" , expr ) ) objPropExpr = ( pp . Literal ( \"inverse\" ) + pp . Suppress ( \"(\" ) + ident ( \"objProp\" ) + pp . Suppress ( \")\" ) | pp . Literal ( \"inverse\" ) + ident ( \"objProp\" ) | ident ( \"objProp\" ) ) dataPropExpr = ident ( \"dataProp\" ) restriction <<= ( objPropExpr + pp . Keyword ( \"some\" ) + expr | objPropExpr + pp . Keyword ( \"only\" ) + expr | objPropExpr + pp . Keyword ( \"Self\" ) | objPropExpr + pp . Keyword ( \"value\" ) + ident ( \"individual\" ) | objPropExpr + pp . Keyword ( \"min\" ) + uint + expr | objPropExpr + pp . Keyword ( \"max\" ) + uint + expr | objPropExpr + pp . Keyword ( \"exactly\" ) + uint + expr | dataPropExpr + pp . Keyword ( \"value\" ) + literal ) expr <<= primary + ( logOp ( \"op\" ) + expr )[ ... ] GRAMMAR = expr return expr","title":"manchester"},{"location":"api_reference/ontopy/manchester/#manchester","text":"Evaluate Manchester syntax This module compiles restrictions and logical constructs in Manchester syntax into Owlready2 classes. The main function in this module is manchester.evaluate() , see its docstring for usage example. Pyparsing is used under the hood for parsing.","title":"manchester"},{"location":"api_reference/ontopy/manchester/#ontopy.manchester.ManchesterError","text":"Raised on invalid Manchester notation. Source code in ontopy/manchester.py class ManchesterError ( EMMOntoPyException ): \"\"\"Raised on invalid Manchester notation.\"\"\"","title":"ManchesterError"},{"location":"api_reference/ontopy/manchester/#ontopy.manchester.evaluate","text":"Evaluate expression in Manchester syntax. Parameters: Name Type Description Default ontology Ontology The ontology within which the expression will be evaluated. required expr str Manchester expression to be evaluated. required Returns: Type Description Construct An Owlready2 construct that corresponds to the expression. Examples: from ontopy.manchester import evaluate from ontopy import get_ontology emmo = get_ontology.load() restriction = evaluate(emmo, 'hasPart some Atom') cls = evaluate(emmo, 'Atom') expr = evaluate(emmo, 'Atom or Molecule') Note Logical expressions (with not , and and or ) are supported as well as object property restrictions. For data properterties are only value restrictions supported so far. Source code in ontopy/manchester.py def evaluate ( ontology : owlready2 . Ontology , expr : str ) -> owlready2 . Construct : \"\"\"Evaluate expression in Manchester syntax. Args: ontology: The ontology within which the expression will be evaluated. expr: Manchester expression to be evaluated. Returns: An Owlready2 construct that corresponds to the expression. Example: >>> from ontopy.manchester import evaluate >>> from ontopy import get_ontology >>> emmo = get_ontology.load() >>> restriction = evaluate(emmo, 'hasPart some Atom') >>> cls = evaluate(emmo, 'Atom') >>> expr = evaluate(emmo, 'Atom or Molecule') Note: Logical expressions (with `not`, `and` and `or`) are supported as well as object property restrictions. For data properterties are only value restrictions supported so far. \"\"\" # pylint: disable=invalid-name def _parse_literal ( r ): \"\"\"Compiles literal to Owlready2 type.\"\"\" if r . language : v = owlready2 . locstr ( r . string , r . language ) elif r . number : v = r . number else : v = r . string return v # pylint: disable=invalid-name,no-else-return,too-many-return-statements # pylint: disable=too-many-branches def _eval ( r ): \"\"\"Recursively evaluate expression produced by pyparsing into an Owlready2 construct.\"\"\" def fneg ( x ): \"\"\"Negates the argument if `neg` is true.\"\"\" return owlready2 . Not ( x ) if neg else x if isinstance ( r , str ): # r is atomic, returns its owlready2 repr return ontology [ r ] neg = False # whether the expression starts with \"not\" while r [ 0 ] == \"not\" : r . pop ( 0 ) # strip off the \"not\" and proceed neg = not neg if len ( r ) == 1 : # r is either a atomic or a parenthesised # subexpression that should be further evaluated if isinstance ( r [ 0 ], str ): return fneg ( ontology [ r [ 0 ]]) else : return fneg ( _eval ( r [ 0 ])) elif r . op : # r contains a logical operator: and/or ops = { \"and\" : owlready2 . And , \"or\" : owlready2 . Or } op = ops [ r . op ] if len ( r ) == 3 : return op ([ fneg ( _eval ( r [ 0 ])), _eval ( r [ 2 ])]) else : arg1 = fneg ( _eval ( r [ 0 ])) r . pop ( 0 ) r . pop ( 0 ) return op ([ arg1 , _eval ( r )]) elif r . objProp : # r is a restriction if r [ 0 ] == \"inverse\" : r . pop ( 0 ) prop = owlready2 . Inverse ( ontology [ r [ 0 ]]) else : prop = ontology [ r [ 0 ]] rtype = r [ 1 ] if rtype == \"Self\" : return fneg ( prop . has_self ()) r . pop ( 0 ) r . pop ( 0 ) f = getattr ( prop , rtype ) if rtype == \"value\" : return fneg ( f ( _eval ( r ))) elif rtype in ( \"some\" , \"only\" ): return fneg ( f ( _eval ( r ))) elif rtype in ( \"min\" , \"max\" , \"exactly\" ): cardinality = r . pop ( 0 ) return fneg ( f ( cardinality , _eval ( r ))) else : raise ManchesterError ( f \"invalid restriction type: { rtype } \" ) elif r . dataProp : # r is a data property restriction prop = ontology [ r [ 0 ]] rtype = r [ 1 ] r . pop ( 0 ) r . pop ( 0 ) f = getattr ( prop , rtype ) if rtype == \"value\" : return f ( _parse_literal ( r )) else : raise ManchesterError ( f \"unimplemented data property restriction: \" f \" { prop } { rtype } { r } \" ) else : raise ManchesterError ( f \"invalid expression: { r } \" ) grammar = manchester_expression () return _eval ( grammar . parseString ( expr , parseAll = True ))","title":"evaluate()"},{"location":"api_reference/ontopy/manchester/#ontopy.manchester.manchester_expression","text":"Returns pyparsing grammar for a Manchester expression. This function is mostly for internal use. See also: https://www.w3.org/TR/owl2-manchester-syntax/ Source code in ontopy/manchester.py def manchester_expression (): \"\"\"Returns pyparsing grammar for a Manchester expression. This function is mostly for internal use. See also: https://www.w3.org/TR/owl2-manchester-syntax/ \"\"\" # pylint: disable=global-statement,invalid-name,too-many-locals global GRAMMAR if GRAMMAR : return GRAMMAR # Subset of the Manchester grammar for expressions # It is based on https://www.w3.org/TR/owl2-manchester-syntax/ # but allows logical constructs within restrictions (like Protege) ident = pp . Word ( pp . alphas + \"_:-\" , pp . alphanums + \"_:-\" , asKeyword = True ) uint = pp . Word ( pp . nums ) alphas = pp . Word ( pp . alphas ) string = pp . Word ( pp . alphanums + \":\" ) quotedString = ( pp . QuotedString ( '\"\"\"' , multiline = True ) | pp . QuotedString ( '\"' ) )( \"string\" ) typedLiteral = pp . Combine ( quotedString + \"^^\" + string ( \"datatype\" )) stringLanguageLiteral = pp . Combine ( quotedString + \"@\" + alphas ( \"language\" )) stringLiteral = quotedString numberLiteral = pp . pyparsing_common . number ( \"number\" ) literal = ( typedLiteral | stringLanguageLiteral | stringLiteral | numberLiteral ) logOp = pp . oneOf ([ \"and\" , \"or\" ], asKeyword = True ) expr = pp . Forward () restriction = pp . Forward () primary = pp . Keyword ( \"not\" )[ ... ] + ( restriction | ident ( \"cls\" ) | pp . nestedExpr ( \"(\" , \")\" , expr ) ) objPropExpr = ( pp . Literal ( \"inverse\" ) + pp . Suppress ( \"(\" ) + ident ( \"objProp\" ) + pp . Suppress ( \")\" ) | pp . Literal ( \"inverse\" ) + ident ( \"objProp\" ) | ident ( \"objProp\" ) ) dataPropExpr = ident ( \"dataProp\" ) restriction <<= ( objPropExpr + pp . Keyword ( \"some\" ) + expr | objPropExpr + pp . Keyword ( \"only\" ) + expr | objPropExpr + pp . Keyword ( \"Self\" ) | objPropExpr + pp . Keyword ( \"value\" ) + ident ( \"individual\" ) | objPropExpr + pp . Keyword ( \"min\" ) + uint + expr | objPropExpr + pp . Keyword ( \"max\" ) + uint + expr | objPropExpr + pp . Keyword ( \"exactly\" ) + uint + expr | dataPropExpr + pp . Keyword ( \"value\" ) + literal ) expr <<= primary + ( logOp ( \"op\" ) + expr )[ ... ] GRAMMAR = expr return expr","title":"manchester_expression()"},{"location":"api_reference/ontopy/nadict/","text":"nadict \u00b6 A nested dict with both attribute and item access. NA stands for Nested and Attribute. NADict \u00b6 A nested dict with both attribute and item access. It is intended to be used with keys that are valid Python identifiers. However, except for string keys containing a dot, there are actually no hard limitations. If a key equals an existing attribute name, attribute access is of cause not possible. Nested items can be accessed via a dot notation, as shown in the example below. Examples \u00b6 n = NADict(a=1, b=NADict(c=3, d=4)) n['a'] 1 n.a 1 n['b.c'] 3 n.b.c 3 n['b.e'] = 5 n.b.e 5 Attributes \u00b6 _dict : dict Dictionary holding the actial items. Source code in ontopy/nadict.py class NADict : \"\"\"A nested dict with both attribute and item access. It is intended to be used with keys that are valid Python identifiers. However, except for string keys containing a dot, there are actually no hard limitations. If a key equals an existing attribute name, attribute access is of cause not possible. Nested items can be accessed via a dot notation, as shown in the example below. Examples -------- >>> n = NADict(a=1, b=NADict(c=3, d=4)) >>> n['a'] 1 >>> n.a 1 >>> n['b.c'] 3 >>> n.b.c 3 >>> n['b.e'] = 5 >>> n.b.e 5 Attributes ---------- _dict : dict Dictionary holding the actial items. \"\"\" def __init__ ( self , * args , ** kw ): object . __setattr__ ( self , \"_dict\" , {}) self . update ( * args , ** kw ) def __getitem__ ( self , key ): if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return self . _dict [ key1 ][ key2 ] return self . _dict [ key ] def __setitem__ ( self , key , value ): if key in ( \"clear\" , \"copy\" , \"fromkeys\" , \"get\" , \"items\" , \"keys\" , \"pop\" , \"popitem\" , \"setdefault\" , \"update\" , \"values\" , ): raise ValueError ( f \"invalid key { key !r} : must not override supported dict method\" \" names\" ) if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) if key1 not in self . _dict : self . _dict [ key1 ] = NADict () self . _dict [ key1 ][ key2 ] = value elif key in self . _dict : if isinstance ( self . _dict [ key ], NADict ): self . _dict [ key ] . update ( value ) else : self . _dict [ key ] = value else : if isinstance ( value , Mapping ): self . _dict [ key ] = NADict ( value ) else : self . _dict [ key ] = value def __delitem__ ( self , key ): if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) del self . _dict [ key1 ][ key2 ] else : del self . _dict [ key ] def __getattr__ ( self , key ): if key not in self . _dict : raise AttributeError ( f \"No such key: { key } \" ) return self . _dict [ key ] def __setattr__ ( self , key , value ): if key in self . _dict : self . _dict [ key ] = value else : object . __setattr__ ( self , key , value ) def __delattr__ ( self , key ): if key in self . _dict : del self . _dict [ key ] else : object . __delattr__ ( self , key ) def __len__ ( self ): return len ( self . _dict ) def __contains__ ( self , key ): if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return key2 in self . _dict [ key1 ] return key in self . _dict def __iter__ ( self , prefix = \"\" ): for key , value in self . _dict . items (): key = f \" { prefix } . { key } \" if prefix else key if isinstance ( value , NADict ): yield from value . __iter__ ( key ) else : yield key def __repr__ ( self ): return ( f \" { self . __class__ . __name__ } (\" f \" { ', ' . join ( f ' { key } = { value !r} ' for key , value in self . _dict . items ()) } )\" # pylint: disable=line-too-long ) def clear ( self ): \"\"\"Clear all keys.\"\"\" self . _dict . clear () def copy ( self ): \"\"\"Returns a deep copy of self.\"\"\" return copy . deepcopy ( self ) @staticmethod def fromkeys ( iterable , value = None ): \"\"\"Returns a new NADict with keys from `iterable` and values set to `value`.\"\"\" res = NADict () for key in iterable : res [ key ] = value return res def get ( self , key , default = None ): \"\"\"Returns the value for `key` if `key` is in self, else return `default`.\"\"\" if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return self . _dict [ key1 ] . get ( key2 , default ) return self . _dict . get ( key , default ) def items ( self , prefix = \"\" ): \"\"\"Returns an iterator over all items as (key, value) pairs.\"\"\" for key , value in self . _dict . items (): key = f \" { prefix } . { key } \" if prefix else key if isinstance ( value , NADict ): yield from value . items ( key ) else : yield ( key , value ) def keys ( self , prefix = \"\" ): \"\"\"Returns an iterator over all keys.\"\"\" for key , value in self . _dict . items (): key = f \" { prefix } . { key } \" if prefix else key if isinstance ( value , NADict ): yield from value . keys ( key ) else : yield key def pop ( self , key , default = None ): \"\"\"Removed `key` and returns corresponding value. If `key` is not found, `default` is returned if given, otherwise KeyError is raised.\"\"\" if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return self . _dict [ key1 ] . pop ( key2 , default ) return self . _dict . pop ( key , default ) def popitem ( self , prefix = \"\" ): \"\"\"Removes and returns some (key, value). Raises KeyError if empty.\"\"\" item = self . _dict . popitem () if isinstance ( item , NADict ): key , value = item item2 = item . popitem ( key ) self . _dict [ key ] = value return item2 key , value = self . _dict . popitem () key = f \" { prefix } . { key } \" if prefix else key return ( key , value ) def setdefault ( self , key , value = None ): \"\"\"Inserts `key` and `value` pair if key is not found. Returns the new value for `key`.\"\"\" if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return self . _dict [ key1 ] . setdefault ( key2 , value ) return self . _dict . setdefault ( key , value ) def update ( self , * args , ** kwargs ): \"\"\"Updates self with dict/iterable from `args` and keyword arguments from `kw`.\"\"\" for arg in args : if hasattr ( arg , \"keys\" ): for _ in arg : self [ _ ] = arg [ _ ] else : for key , value in arg : self [ key ] = value for key , value in kwargs . items (): self [ key ] = value def values ( self ): \"\"\"Returns a set-like providing a view of all style values.\"\"\" return self . _dict . values () clear ( self ) \u00b6 Clear all keys. Source code in ontopy/nadict.py def clear ( self ): \"\"\"Clear all keys.\"\"\" self . _dict . clear () copy ( self ) \u00b6 Returns a deep copy of self. Source code in ontopy/nadict.py def copy ( self ): \"\"\"Returns a deep copy of self.\"\"\" return copy . deepcopy ( self ) fromkeys ( iterable , value = None ) staticmethod \u00b6 Returns a new NADict with keys from iterable and values set to value . Source code in ontopy/nadict.py @staticmethod def fromkeys ( iterable , value = None ): \"\"\"Returns a new NADict with keys from `iterable` and values set to `value`.\"\"\" res = NADict () for key in iterable : res [ key ] = value return res get ( self , key , default = None ) \u00b6 Returns the value for key if key is in self, else return default . Source code in ontopy/nadict.py def get ( self , key , default = None ): \"\"\"Returns the value for `key` if `key` is in self, else return `default`.\"\"\" if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return self . _dict [ key1 ] . get ( key2 , default ) return self . _dict . get ( key , default ) items ( self , prefix = '' ) \u00b6 Returns an iterator over all items as (key, value) pairs. Source code in ontopy/nadict.py def items ( self , prefix = \"\" ): \"\"\"Returns an iterator over all items as (key, value) pairs.\"\"\" for key , value in self . _dict . items (): key = f \" { prefix } . { key } \" if prefix else key if isinstance ( value , NADict ): yield from value . items ( key ) else : yield ( key , value ) keys ( self , prefix = '' ) \u00b6 Returns an iterator over all keys. Source code in ontopy/nadict.py def keys ( self , prefix = \"\" ): \"\"\"Returns an iterator over all keys.\"\"\" for key , value in self . _dict . items (): key = f \" { prefix } . { key } \" if prefix else key if isinstance ( value , NADict ): yield from value . keys ( key ) else : yield key pop ( self , key , default = None ) \u00b6 Removed key and returns corresponding value. If key is not found, default is returned if given, otherwise KeyError is raised. Source code in ontopy/nadict.py def pop ( self , key , default = None ): \"\"\"Removed `key` and returns corresponding value. If `key` is not found, `default` is returned if given, otherwise KeyError is raised.\"\"\" if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return self . _dict [ key1 ] . pop ( key2 , default ) return self . _dict . pop ( key , default ) popitem ( self , prefix = '' ) \u00b6 Removes and returns some (key, value). Raises KeyError if empty. Source code in ontopy/nadict.py def popitem ( self , prefix = \"\" ): \"\"\"Removes and returns some (key, value). Raises KeyError if empty.\"\"\" item = self . _dict . popitem () if isinstance ( item , NADict ): key , value = item item2 = item . popitem ( key ) self . _dict [ key ] = value return item2 key , value = self . _dict . popitem () key = f \" { prefix } . { key } \" if prefix else key return ( key , value ) setdefault ( self , key , value = None ) \u00b6 Inserts key and value pair if key is not found. Returns the new value for key . Source code in ontopy/nadict.py def setdefault ( self , key , value = None ): \"\"\"Inserts `key` and `value` pair if key is not found. Returns the new value for `key`.\"\"\" if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return self . _dict [ key1 ] . setdefault ( key2 , value ) return self . _dict . setdefault ( key , value ) update ( self , * args , ** kwargs ) \u00b6 Updates self with dict/iterable from args and keyword arguments from kw . Source code in ontopy/nadict.py def update ( self , * args , ** kwargs ): \"\"\"Updates self with dict/iterable from `args` and keyword arguments from `kw`.\"\"\" for arg in args : if hasattr ( arg , \"keys\" ): for _ in arg : self [ _ ] = arg [ _ ] else : for key , value in arg : self [ key ] = value for key , value in kwargs . items (): self [ key ] = value values ( self ) \u00b6 Returns a set-like providing a view of all style values. Source code in ontopy/nadict.py def values ( self ): \"\"\"Returns a set-like providing a view of all style values.\"\"\" return self . _dict . values ()","title":"nadict"},{"location":"api_reference/ontopy/nadict/#nadict","text":"A nested dict with both attribute and item access. NA stands for Nested and Attribute.","title":"nadict"},{"location":"api_reference/ontopy/nadict/#ontopy.nadict.NADict","text":"A nested dict with both attribute and item access. It is intended to be used with keys that are valid Python identifiers. However, except for string keys containing a dot, there are actually no hard limitations. If a key equals an existing attribute name, attribute access is of cause not possible. Nested items can be accessed via a dot notation, as shown in the example below.","title":"NADict"},{"location":"api_reference/ontopy/nadict/#ontopy.nadict.NADict--examples","text":"n = NADict(a=1, b=NADict(c=3, d=4)) n['a'] 1 n.a 1 n['b.c'] 3 n.b.c 3 n['b.e'] = 5 n.b.e 5","title":"Examples"},{"location":"api_reference/ontopy/nadict/#ontopy.nadict.NADict--attributes","text":"_dict : dict Dictionary holding the actial items. Source code in ontopy/nadict.py class NADict : \"\"\"A nested dict with both attribute and item access. It is intended to be used with keys that are valid Python identifiers. However, except for string keys containing a dot, there are actually no hard limitations. If a key equals an existing attribute name, attribute access is of cause not possible. Nested items can be accessed via a dot notation, as shown in the example below. Examples -------- >>> n = NADict(a=1, b=NADict(c=3, d=4)) >>> n['a'] 1 >>> n.a 1 >>> n['b.c'] 3 >>> n.b.c 3 >>> n['b.e'] = 5 >>> n.b.e 5 Attributes ---------- _dict : dict Dictionary holding the actial items. \"\"\" def __init__ ( self , * args , ** kw ): object . __setattr__ ( self , \"_dict\" , {}) self . update ( * args , ** kw ) def __getitem__ ( self , key ): if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return self . _dict [ key1 ][ key2 ] return self . _dict [ key ] def __setitem__ ( self , key , value ): if key in ( \"clear\" , \"copy\" , \"fromkeys\" , \"get\" , \"items\" , \"keys\" , \"pop\" , \"popitem\" , \"setdefault\" , \"update\" , \"values\" , ): raise ValueError ( f \"invalid key { key !r} : must not override supported dict method\" \" names\" ) if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) if key1 not in self . _dict : self . _dict [ key1 ] = NADict () self . _dict [ key1 ][ key2 ] = value elif key in self . _dict : if isinstance ( self . _dict [ key ], NADict ): self . _dict [ key ] . update ( value ) else : self . _dict [ key ] = value else : if isinstance ( value , Mapping ): self . _dict [ key ] = NADict ( value ) else : self . _dict [ key ] = value def __delitem__ ( self , key ): if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) del self . _dict [ key1 ][ key2 ] else : del self . _dict [ key ] def __getattr__ ( self , key ): if key not in self . _dict : raise AttributeError ( f \"No such key: { key } \" ) return self . _dict [ key ] def __setattr__ ( self , key , value ): if key in self . _dict : self . _dict [ key ] = value else : object . __setattr__ ( self , key , value ) def __delattr__ ( self , key ): if key in self . _dict : del self . _dict [ key ] else : object . __delattr__ ( self , key ) def __len__ ( self ): return len ( self . _dict ) def __contains__ ( self , key ): if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return key2 in self . _dict [ key1 ] return key in self . _dict def __iter__ ( self , prefix = \"\" ): for key , value in self . _dict . items (): key = f \" { prefix } . { key } \" if prefix else key if isinstance ( value , NADict ): yield from value . __iter__ ( key ) else : yield key def __repr__ ( self ): return ( f \" { self . __class__ . __name__ } (\" f \" { ', ' . join ( f ' { key } = { value !r} ' for key , value in self . _dict . items ()) } )\" # pylint: disable=line-too-long ) def clear ( self ): \"\"\"Clear all keys.\"\"\" self . _dict . clear () def copy ( self ): \"\"\"Returns a deep copy of self.\"\"\" return copy . deepcopy ( self ) @staticmethod def fromkeys ( iterable , value = None ): \"\"\"Returns a new NADict with keys from `iterable` and values set to `value`.\"\"\" res = NADict () for key in iterable : res [ key ] = value return res def get ( self , key , default = None ): \"\"\"Returns the value for `key` if `key` is in self, else return `default`.\"\"\" if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return self . _dict [ key1 ] . get ( key2 , default ) return self . _dict . get ( key , default ) def items ( self , prefix = \"\" ): \"\"\"Returns an iterator over all items as (key, value) pairs.\"\"\" for key , value in self . _dict . items (): key = f \" { prefix } . { key } \" if prefix else key if isinstance ( value , NADict ): yield from value . items ( key ) else : yield ( key , value ) def keys ( self , prefix = \"\" ): \"\"\"Returns an iterator over all keys.\"\"\" for key , value in self . _dict . items (): key = f \" { prefix } . { key } \" if prefix else key if isinstance ( value , NADict ): yield from value . keys ( key ) else : yield key def pop ( self , key , default = None ): \"\"\"Removed `key` and returns corresponding value. If `key` is not found, `default` is returned if given, otherwise KeyError is raised.\"\"\" if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return self . _dict [ key1 ] . pop ( key2 , default ) return self . _dict . pop ( key , default ) def popitem ( self , prefix = \"\" ): \"\"\"Removes and returns some (key, value). Raises KeyError if empty.\"\"\" item = self . _dict . popitem () if isinstance ( item , NADict ): key , value = item item2 = item . popitem ( key ) self . _dict [ key ] = value return item2 key , value = self . _dict . popitem () key = f \" { prefix } . { key } \" if prefix else key return ( key , value ) def setdefault ( self , key , value = None ): \"\"\"Inserts `key` and `value` pair if key is not found. Returns the new value for `key`.\"\"\" if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return self . _dict [ key1 ] . setdefault ( key2 , value ) return self . _dict . setdefault ( key , value ) def update ( self , * args , ** kwargs ): \"\"\"Updates self with dict/iterable from `args` and keyword arguments from `kw`.\"\"\" for arg in args : if hasattr ( arg , \"keys\" ): for _ in arg : self [ _ ] = arg [ _ ] else : for key , value in arg : self [ key ] = value for key , value in kwargs . items (): self [ key ] = value def values ( self ): \"\"\"Returns a set-like providing a view of all style values.\"\"\" return self . _dict . values ()","title":"Attributes"},{"location":"api_reference/ontopy/nadict/#ontopy.nadict.NADict.clear","text":"Clear all keys. Source code in ontopy/nadict.py def clear ( self ): \"\"\"Clear all keys.\"\"\" self . _dict . clear ()","title":"clear()"},{"location":"api_reference/ontopy/nadict/#ontopy.nadict.NADict.copy","text":"Returns a deep copy of self. Source code in ontopy/nadict.py def copy ( self ): \"\"\"Returns a deep copy of self.\"\"\" return copy . deepcopy ( self )","title":"copy()"},{"location":"api_reference/ontopy/nadict/#ontopy.nadict.NADict.fromkeys","text":"Returns a new NADict with keys from iterable and values set to value . Source code in ontopy/nadict.py @staticmethod def fromkeys ( iterable , value = None ): \"\"\"Returns a new NADict with keys from `iterable` and values set to `value`.\"\"\" res = NADict () for key in iterable : res [ key ] = value return res","title":"fromkeys()"},{"location":"api_reference/ontopy/nadict/#ontopy.nadict.NADict.get","text":"Returns the value for key if key is in self, else return default . Source code in ontopy/nadict.py def get ( self , key , default = None ): \"\"\"Returns the value for `key` if `key` is in self, else return `default`.\"\"\" if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return self . _dict [ key1 ] . get ( key2 , default ) return self . _dict . get ( key , default )","title":"get()"},{"location":"api_reference/ontopy/nadict/#ontopy.nadict.NADict.items","text":"Returns an iterator over all items as (key, value) pairs. Source code in ontopy/nadict.py def items ( self , prefix = \"\" ): \"\"\"Returns an iterator over all items as (key, value) pairs.\"\"\" for key , value in self . _dict . items (): key = f \" { prefix } . { key } \" if prefix else key if isinstance ( value , NADict ): yield from value . items ( key ) else : yield ( key , value )","title":"items()"},{"location":"api_reference/ontopy/nadict/#ontopy.nadict.NADict.keys","text":"Returns an iterator over all keys. Source code in ontopy/nadict.py def keys ( self , prefix = \"\" ): \"\"\"Returns an iterator over all keys.\"\"\" for key , value in self . _dict . items (): key = f \" { prefix } . { key } \" if prefix else key if isinstance ( value , NADict ): yield from value . keys ( key ) else : yield key","title":"keys()"},{"location":"api_reference/ontopy/nadict/#ontopy.nadict.NADict.pop","text":"Removed key and returns corresponding value. If key is not found, default is returned if given, otherwise KeyError is raised. Source code in ontopy/nadict.py def pop ( self , key , default = None ): \"\"\"Removed `key` and returns corresponding value. If `key` is not found, `default` is returned if given, otherwise KeyError is raised.\"\"\" if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return self . _dict [ key1 ] . pop ( key2 , default ) return self . _dict . pop ( key , default )","title":"pop()"},{"location":"api_reference/ontopy/nadict/#ontopy.nadict.NADict.popitem","text":"Removes and returns some (key, value). Raises KeyError if empty. Source code in ontopy/nadict.py def popitem ( self , prefix = \"\" ): \"\"\"Removes and returns some (key, value). Raises KeyError if empty.\"\"\" item = self . _dict . popitem () if isinstance ( item , NADict ): key , value = item item2 = item . popitem ( key ) self . _dict [ key ] = value return item2 key , value = self . _dict . popitem () key = f \" { prefix } . { key } \" if prefix else key return ( key , value )","title":"popitem()"},{"location":"api_reference/ontopy/nadict/#ontopy.nadict.NADict.setdefault","text":"Inserts key and value pair if key is not found. Returns the new value for key . Source code in ontopy/nadict.py def setdefault ( self , key , value = None ): \"\"\"Inserts `key` and `value` pair if key is not found. Returns the new value for `key`.\"\"\" if \".\" in key : key1 , key2 = key . split ( \".\" , 1 ) return self . _dict [ key1 ] . setdefault ( key2 , value ) return self . _dict . setdefault ( key , value )","title":"setdefault()"},{"location":"api_reference/ontopy/nadict/#ontopy.nadict.NADict.update","text":"Updates self with dict/iterable from args and keyword arguments from kw . Source code in ontopy/nadict.py def update ( self , * args , ** kwargs ): \"\"\"Updates self with dict/iterable from `args` and keyword arguments from `kw`.\"\"\" for arg in args : if hasattr ( arg , \"keys\" ): for _ in arg : self [ _ ] = arg [ _ ] else : for key , value in arg : self [ key ] = value for key , value in kwargs . items (): self [ key ] = value","title":"update()"},{"location":"api_reference/ontopy/nadict/#ontopy.nadict.NADict.values","text":"Returns a set-like providing a view of all style values. Source code in ontopy/nadict.py def values ( self ): \"\"\"Returns a set-like providing a view of all style values.\"\"\" return self . _dict . values ()","title":"values()"},{"location":"api_reference/ontopy/ontodoc/","text":"ontodoc \u00b6 A module for documenting ontologies. AttributeDict ( dict ) \u00b6 A dict with attribute access. Note that methods like key() and update() may be overridden. Source code in ontopy/ontodoc.py class AttributeDict ( dict ): \"\"\"A dict with attribute access. Note that methods like key() and update() may be overridden.\"\"\" def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . __dict__ = self DocPP \u00b6 Documentation pre-processor. It supports the following features: Comment lines %% Comment line... Insert header with given level %HEADER label [level=1] Insert figure with optional caption and width. filepath should be relative to basedir . If width is 0, no width will be specified. %FIGURE filepath [caption='' width=0px] Include other markdown files. Header levels may be up or down with shift %INCLUDE filepath [shift=0] Insert generated documentation for ontology entity. The header level may be set with header_level . %ENTITY name [header_level=3] Insert generated documentation for ontology branch name . Options: header_level: Header level. terminated: Whether to branch should be terminated at all branch names in the final document. include_leafs: Whether to include leaf. %BRANCH name [header_level=3 terminated=1 include_leafs=0 namespaces='' ontologies=''] Insert generated figure of ontology branch name . The figure is written to path . The default path is figdir / name , where figdir is given at class initiation. It is recommended to exclude the file extension from path . In this case, the default figformat will be used (and easily adjusted to the correct format required by the backend). leafs may be a comma- separated list of leaf node names. %BRANCHFIG name [path='' caption='' terminated=1 include_leafs=1 strict_leafs=1, width=0px leafs='' relations=all edgelabels=0 namespaces='' ontologies=''] This is a combination of the %HEADER and %BRANCHFIG directives. %BRANCHHEAD name [level=2 path='' caption='' terminated=1 include_leafs=1 width=0px leafs=''] This is a combination of the %HEADER, %BRANCHFIG and %BRANCH directives. It inserts documentation of branch name , with a header followed by a figure and then documentation of each element. %BRANCHDOC name [level=2 path='' title='' caption='' terminated=1 strict_leafs=1 width=0px leafs='' relations='all' rankdir='BT' legend=1 namespaces='' ontologies=''] Insert generated documentation for all entities of the given type. Valid values of type are: \"classes\", \"individuals\", \"object_properties\", \"data_properties\", \"annotations_properties\" %ALL type [header_level=3, namespaces='', ontologies=''] Insert generated figure of all entities of the given type. Valid values of type are: \"classes\", \"object_properties\" and \"data_properties\". %ALLFIG type Parameters \u00b6 template : str Input template. ontodoc : OntoDoc instance Instance of OntoDoc basedir : str Base directory for including relative file paths. figdir : str Default directory to store generated figures. figformat : str Default format for generated figures. figscale : float Default scaling of generated figures. maxwidth : float Maximum figure width. Figures larger than this will be rescaled. imported : bool Whether to include imported entities. Source code in ontopy/ontodoc.py class DocPP : # pylint: disable=too-many-instance-attributes \"\"\"Documentation pre-processor. It supports the following features: * Comment lines %% Comment line... * Insert header with given level %HEADER label [level=1] * Insert figure with optional caption and width. `filepath` should be relative to `basedir`. If width is 0, no width will be specified. %FIGURE filepath [caption='' width=0px] * Include other markdown files. Header levels may be up or down with `shift` %INCLUDE filepath [shift=0] * Insert generated documentation for ontology entity. The header level may be set with `header_level`. %ENTITY name [header_level=3] * Insert generated documentation for ontology branch `name`. Options: - header_level: Header level. - terminated: Whether to branch should be terminated at all branch names in the final document. - include_leafs: Whether to include leaf. %BRANCH name [header_level=3 terminated=1 include_leafs=0 namespaces='' ontologies=''] * Insert generated figure of ontology branch `name`. The figure is written to `path`. The default path is `figdir`/`name`, where `figdir` is given at class initiation. It is recommended to exclude the file extension from `path`. In this case, the default figformat will be used (and easily adjusted to the correct format required by the backend). `leafs` may be a comma- separated list of leaf node names. %BRANCHFIG name [path='' caption='' terminated=1 include_leafs=1 strict_leafs=1, width=0px leafs='' relations=all edgelabels=0 namespaces='' ontologies=''] * This is a combination of the %HEADER and %BRANCHFIG directives. %BRANCHHEAD name [level=2 path='' caption='' terminated=1 include_leafs=1 width=0px leafs=''] * This is a combination of the %HEADER, %BRANCHFIG and %BRANCH directives. It inserts documentation of branch `name`, with a header followed by a figure and then documentation of each element. %BRANCHDOC name [level=2 path='' title='' caption='' terminated=1 strict_leafs=1 width=0px leafs='' relations='all' rankdir='BT' legend=1 namespaces='' ontologies=''] * Insert generated documentation for all entities of the given type. Valid values of `type` are: \"classes\", \"individuals\", \"object_properties\", \"data_properties\", \"annotations_properties\" %ALL type [header_level=3, namespaces='', ontologies=''] * Insert generated figure of all entities of the given type. Valid values of `type` are: \"classes\", \"object_properties\" and \"data_properties\". %ALLFIG type Parameters ---------- template : str Input template. ontodoc : OntoDoc instance Instance of OntoDoc basedir : str Base directory for including relative file paths. figdir : str Default directory to store generated figures. figformat : str Default format for generated figures. figscale : float Default scaling of generated figures. maxwidth : float Maximum figure width. Figures larger than this will be rescaled. imported : bool Whether to include imported entities. \"\"\" # FIXME - this class should be refractured: # * Instead of rescan the entire document for each pre-processer # directive, we should scan the source like by line and handle # each directive as they occour. # * The current implementation has a lot of dublicated code. # * Instead of modifying the source in-place, we should copy to a # result list. This will make good error reporting much easier. # * Branch leaves are only looked up in the file witht the %BRANCH # directive, not in all included files as expedted. def __init__ ( # pylint: disable=too-many-arguments self , template , ontodoc , basedir = \".\" , figdir = \"genfigs\" , figformat = \"png\" , figscale = 1.0 , maxwidth = None , imported = False , ): self . lines = template . split ( \" \\n \" ) self . ontodoc = ontodoc self . basedir = basedir self . figdir = os . path . join ( basedir , figdir ) self . figformat = figformat self . figscale = figscale self . maxwidth = maxwidth self . imported = imported self . _branch_cache = None self . _processed = False # Whether process() has been called def __str__ ( self ): return self . get_buffer () def get_buffer ( self ): \"\"\"Returns the current buffer.\"\"\" return \" \\n \" . join ( self . lines ) def copy ( self ): \"\"\"Returns a copy of self.\"\"\" docpp = DocPP ( \"\" , self . ontodoc , self . basedir , figformat = self . figformat , figscale = self . figscale , maxwidth = self . maxwidth , ) docpp . lines [:] = self . lines docpp . figdir = self . figdir return docpp def get_branches ( self ): \"\"\"Returns a list with all branch names as specified with %BRANCH (in current and all included documents). The returned value is cached for efficiency purposes and so that it is not lost after processing branches.\"\"\" if self . _branch_cache is None : names = [] docpp = self . copy () docpp . process_includes () for line in docpp . lines : if line . startswith ( \"%BRANCH\" ): names . append ( shlex . split ( line )[ 1 ]) self . _branch_cache = names return self . _branch_cache def shift_header_levels ( self , shift ): \"\"\"Shift header level of all hashtag-headers in buffer. Underline headers are ignored.\"\"\" if not shift : return pat = re . compile ( \"^#+ \" ) for i , line in enumerate ( self . lines ): match = pat . match ( line ) if match : if shift > 0 : self . lines [ i ] = \"#\" * shift + line elif shift < 0 : counter = match . end () if shift > counter : self . lines [ i ] = line . lstrip ( \"# \" ) else : self . lines [ i ] = line [ counter :] def process_comments ( self ): \"\"\"Strips out comment lines starting with \"%%\".\"\"\" self . lines = [ line for line in self . lines if not line . startswith ( \" %% \" )] def process_headers ( self ): \"\"\"Expand all %HEADER specifications.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%HEADER \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], level = 1 ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . get_header ( name , int ( opts . level ) # pylint: disable=no-member ) . split ( \" \\n \" ) def process_figures ( self ): \"\"\"Expand all %FIGURE specifications.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \" %F IGURE \" ): tokens = shlex . split ( line ) path = tokens [ 1 ] opts = get_options ( tokens [ 2 :], caption = \"\" , width = 0 ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . get_figure ( os . path . join ( self . basedir , path ), caption = opts . caption , # pylint: disable=no-member width = opts . width , # pylint: disable=no-member ) . split ( \" \\n \" ) def process_entities ( self ): \"\"\"Expand all %ENTITY specifications.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \" %E NTITY \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], header_level = 3 ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . itemdoc ( name , int ( opts . header_level ) # pylint: disable=no-member ) . split ( \" \\n \" ) def process_branches ( self ): \"\"\"Expand all %BRANCH specifications.\"\"\" onto = self . ontodoc . onto # Get all branch names in final document names = self . get_branches () for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%BRANCH \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], header_level = 3 , terminated = 1 , include_leafs = 0 , namespaces = \"\" , ontologies = \"\" , ) leafs = ( names if opts . terminated else () ) # pylint: disable=no-member included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) branch = filter_classes ( onto . get_branch ( name , leafs , opts . include_leafs ), # pylint: disable=no-member included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . itemsdoc ( branch , int ( opts . header_level ) # pylint: disable=no-member ) . split ( \" \\n \" ) def _make_branchfig ( # pylint: disable=too-many-arguments,too-many-locals self , name : str , path : \"Union[Path, str]\" , terminated : bool , include_leafs : bool , strict_leafs : bool , width : float , leafs : \"Union[str, list[str]]\" , relations : str , edgelabels : str , rankdir : str , legend : bool , included_namespaces : \"Iterable[str]\" , included_ontologies : \"Iterable[str]\" , ) -> \"tuple[str, list[str], float]\" : \"\"\"Help method for process_branchfig(). Args: name: name of branch root path: optional figure path name include_leafs: whether to include leafs strict_leafs: whether strictly exclude leafs descendants terminated: whether the graph should be terminated at leaf nodes width: optional figure width leafs: optional leafs node names for graph termination relations: comma-separated list of relations to include edgelabels: whether to include edgelabels rankdir: graph direction (BT, TB, RL, LR) legend: whether to add legend included_namespaces: sequence of names of namespaces to be included included_ontologies: sequence of names of ontologies to be included Returns: filepath: path to generated figure leafs: used list of leaf node names width: actual figure width \"\"\" onto = self . ontodoc . onto if leafs : if isinstance ( leafs , str ): leafs = leafs . split ( \",\" ) elif terminated : leafs = set ( self . get_branches ()) leafs . discard ( name ) else : leafs = None if path : figdir = os . path . dirname ( path ) formatext = os . path . splitext ( path )[ 1 ] if formatext : fmt = formatext . lstrip ( \".\" ) else : fmt = self . figformat path += f \". { fmt } \" else : figdir = self . figdir fmt = self . figformat term = \"T\" if terminated else \"\" path = os . path . join ( figdir , name + term ) + f \". { fmt } \" # Create graph graph = OntoGraph ( onto , graph_attr = { \"rankdir\" : rankdir }) graph . add_branch ( root = name , leafs = leafs , include_leafs = include_leafs , strict_leafs = strict_leafs , relations = relations , edgelabels = edgelabels , included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) if legend : graph . add_legend () if not width : figwidth , _ = graph . get_figsize () width = self . figscale * figwidth if self . maxwidth and width > self . maxwidth : width = self . maxwidth filepath = os . path . join ( self . basedir , path ) destdir = os . path . dirname ( filepath ) if not os . path . exists ( destdir ): os . makedirs ( destdir ) graph . save ( filepath , fmt = fmt ) return filepath , leafs , width def process_branchfigs ( self ): \"\"\"Process all %BRANCHFIG directives.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%BRANCHFIG \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], path = \"\" , caption = \"\" , terminated = 1 , include_leafs = 1 , strict_leafs = 1 , width = 0 , leafs = \"\" , relations = \"all\" , edgelabels = 0 , rankdir = \"BT\" , legend = 1 , namespaces = \"\" , ontologies = \"\" , ) included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) filepath , _ , width = self . _make_branchfig ( name , opts . path , # pylint: disable=no-member opts . terminated , # pylint: disable=no-member opts . include_leafs , # pylint: disable=no-member opts . strict_leafs , # pylint: disable=no-member opts . width , # pylint: disable=no-member opts . leafs , # pylint: disable=no-member opts . relations , # pylint: disable=no-member opts . edgelabels , # pylint: disable=no-member opts . rankdir , # pylint: disable=no-member opts . legend , # pylint: disable=no-member included_namespaces , included_ontologies , ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . get_figure ( filepath , caption = opts . caption , width = width , # pylint: disable=no-member ) . split ( \" \\n \" ) def process_branchdocs ( self ): # pylint: disable=too-many-locals \"\"\"Process all %BRANCHDOC and %BRANCHEAD directives.\"\"\" onto = self . ontodoc . onto for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%BRANCHDOC \" ) or line . startswith ( \"%BRANCHHEAD \" ): with_branch = bool ( line . startswith ( \"%BRANCHDOC \" )) tokens = shlex . split ( line ) name = tokens [ 1 ] title = camelsplit ( name ) title = title [ 0 ] . upper () + title [ 1 :] + \" branch\" opts = get_options ( tokens [ 2 :], level = 2 , path = \"\" , title = title , caption = title + \".\" , terminated = 1 , strict_leafs = 1 , width = 0 , leafs = \"\" , relations = \"all\" , edgelabels = 0 , rankdir = \"BT\" , legend = 1 , namespaces = \"\" , ontologies = \"\" , ) included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) include_leafs = 1 filepath , leafs , width = self . _make_branchfig ( name , opts . path , # pylint: disable=no-member opts . terminated , # pylint: disable=no-member include_leafs , opts . strict_leafs , # pylint: disable=no-member opts . width , # pylint: disable=no-member opts . leafs , # pylint: disable=no-member opts . relations , # pylint: disable=no-member opts . edgelabels , # pylint: disable=no-member opts . rankdir , # pylint: disable=no-member opts . legend , # pylint: disable=no-member included_namespaces , included_ontologies , ) sec = [] sec . append ( self . ontodoc . get_header ( opts . title , int ( opts . level )) ) # pylint: disable=no-member sec . append ( self . ontodoc . get_figure ( filepath , caption = opts . caption , width = width , # pylint: disable=no-member ) ) if with_branch : include_leafs = 0 branch = filter_classes ( onto . get_branch ( name , leafs , include_leafs ), included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) sec . append ( self . ontodoc . itemsdoc ( branch , int ( opts . level + 1 ) ) # pylint: disable=no-member ) del self . lines [ i ] self . lines [ i : i ] = sec def process_alls ( self ): \"\"\"Expand all %ALL specifications.\"\"\" onto = self . ontodoc . onto for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%ALL \" ): tokens = shlex . split ( line ) token = tokens [ 1 ] opts = get_options ( tokens [ 2 :], header_level = 3 ) if token == \"classes\" : # nosec items = onto . classes ( imported = self . imported ) elif token in ( \"object_properties\" , \"relations\" ): items = onto . object_properties ( imported = self . imported ) elif token == \"data_properties\" : # nosec items = onto . data_properties ( imported = self . imported ) elif token == \"annotation_properties\" : # nosec items = onto . annotation_properties ( imported = self . imported ) elif token == \"individuals\" : # nosec items = onto . individuals ( imported = self . imported ) else : raise InvalidTemplateError ( f \"Invalid argument to %%ALL: { token } \" ) items = sorted ( items , key = asstring ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . itemsdoc ( items , int ( opts . header_level ) # pylint: disable=no-member ) . split ( \" \\n \" ) def process_allfig ( self ): # pylint: disable=too-many-locals \"\"\"Process all %ALLFIG directives.\"\"\" onto = self . ontodoc . onto for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%ALLFIG \" ): tokens = shlex . split ( line ) token = tokens [ 1 ] opts = get_options ( tokens [ 2 :], path = \"\" , level = 3 , terminated = 0 , include_leafs = 1 , strict_leafs = 1 , width = 0 , leafs = \"\" , relations = \"isA\" , edgelabels = 0 , rankdir = \"BT\" , legend = 1 , namespaces = \"\" , ontologies = \"\" , ) if token == \"classes\" : # nosec roots = onto . get_root_classes ( imported = self . imported ) elif token in ( \"object_properties\" , \"relations\" ): roots = onto . get_root_object_properties ( imported = self . imported ) elif token == \"data_properties\" : # nosec roots = onto . get_root_data_properties ( imported = self . imported ) else : raise InvalidTemplateError ( f \"Invalid argument to %%ALLFIG: { token } \" ) included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) sec = [] for root in roots : name = asstring ( root ) filepath , _ , width = self . _make_branchfig ( name , opts . path , # pylint: disable=no-member opts . terminated , # pylint: disable=no-member opts . include_leafs , # pylint: disable=no-member opts . strict_leafs , # pylint: disable=no-member opts . width , # pylint: disable=no-member opts . leafs , # pylint: disable=no-member opts . relations , # pylint: disable=no-member opts . edgelabels , # pylint: disable=no-member opts . rankdir , # pylint: disable=no-member opts . legend , # pylint: disable=no-member included_namespaces , included_ontologies , ) title = f \"Taxonomy of { name } .\" sec . append ( self . ontodoc . get_header ( title , int ( opts . level )) ) # pylint: disable=no-member sec . extend ( self . ontodoc . get_figure ( filepath , caption = title , width = width ) . split ( \" \\n \" ) ) del self . lines [ i ] self . lines [ i : i ] = sec def process_includes ( self ): \"\"\"Process all %INCLUDE directives.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%INCLUDE \" ): tokens = shlex . split ( line ) filepath = tokens [ 1 ] opts = get_options ( tokens [ 2 :], shift = 0 ) with open ( os . path . join ( self . basedir , filepath ), \"rt\" , encoding = \"utf8\" ) as handle : docpp = DocPP ( handle . read (), self . ontodoc , basedir = os . path . dirname ( filepath ), figformat = self . figformat , figscale = self . figscale , maxwidth = self . maxwidth , ) docpp . figdir = self . figdir if opts . shift : # pylint: disable=no-member docpp . shift_header_levels ( int ( opts . shift ) ) # pylint: disable=no-member docpp . process () del self . lines [ i ] self . lines [ i : i ] = docpp . lines def process ( self ): \"\"\"Perform all pre-processing steps.\"\"\" if not self . _processed : self . process_comments () self . process_headers () self . process_figures () self . process_entities () self . process_branches () self . process_branchfigs () self . process_branchdocs () self . process_alls () self . process_allfig () self . process_includes () self . _processed = True def write ( # pylint: disable=too-many-arguments self , outfile , fmt = None , pandoc_option_files = (), pandoc_options = (), genfile = None , verbose = True , ): \"\"\"Writes documentation to `outfile`. Parameters ---------- outfile : str File that the documentation is written to. fmt : str Output format. If it is \"md\" or \"simple-html\", the built-in template generator is used. Otherwise pandoc is used. If not given, the format is inferred from the `outfile` name extension. pandoc_option_files : sequence Sequence with command line arguments provided to pandoc. pandoc_options : sequence Additional pandoc options overriding options read from `pandoc_option_files`. genfile : str Store temporary generated markdown input file to pandoc to this file (for debugging). verbose : bool Whether to show some messages when running pandoc. \"\"\" self . process () content = self . get_buffer () substitutions = self . ontodoc . style . get ( \"substitutions\" , []) for reg , sub in substitutions : content = re . sub ( reg , sub , content ) fmt = get_format ( outfile , fmt ) if fmt not in ( \"simple-html\" , \"markdown\" , \"md\" ): # Run pandoc if not genfile : with NamedTemporaryFile ( mode = \"w+t\" , suffix = \".md\" ) as temp_file : temp_file . write ( content ) temp_file . flush () genfile = temp_file . name run_pandoc ( genfile , outfile , fmt , pandoc_option_files = pandoc_option_files , pandoc_options = pandoc_options , verbose = verbose , ) else : with open ( genfile , \"wt\" ) as handle : handle . write ( content ) run_pandoc ( genfile , outfile , fmt , pandoc_option_files = pandoc_option_files , pandoc_options = pandoc_options , verbose = verbose , ) else : if verbose : print ( \"Writing:\" , outfile ) with open ( outfile , \"wt\" ) as handle : handle . write ( content ) copy ( self ) \u00b6 Returns a copy of self. Source code in ontopy/ontodoc.py def copy ( self ): \"\"\"Returns a copy of self.\"\"\" docpp = DocPP ( \"\" , self . ontodoc , self . basedir , figformat = self . figformat , figscale = self . figscale , maxwidth = self . maxwidth , ) docpp . lines [:] = self . lines docpp . figdir = self . figdir return docpp get_branches ( self ) \u00b6 Returns a list with all branch names as specified with %BRANCH (in current and all included documents). The returned value is cached for efficiency purposes and so that it is not lost after processing branches. Source code in ontopy/ontodoc.py def get_branches ( self ): \"\"\"Returns a list with all branch names as specified with %BRANCH (in current and all included documents). The returned value is cached for efficiency purposes and so that it is not lost after processing branches.\"\"\" if self . _branch_cache is None : names = [] docpp = self . copy () docpp . process_includes () for line in docpp . lines : if line . startswith ( \"%BRANCH\" ): names . append ( shlex . split ( line )[ 1 ]) self . _branch_cache = names return self . _branch_cache get_buffer ( self ) \u00b6 Returns the current buffer. Source code in ontopy/ontodoc.py def get_buffer ( self ): \"\"\"Returns the current buffer.\"\"\" return \" \\n \" . join ( self . lines ) process ( self ) \u00b6 Perform all pre-processing steps. Source code in ontopy/ontodoc.py def process ( self ): \"\"\"Perform all pre-processing steps.\"\"\" if not self . _processed : self . process_comments () self . process_headers () self . process_figures () self . process_entities () self . process_branches () self . process_branchfigs () self . process_branchdocs () self . process_alls () self . process_allfig () self . process_includes () self . _processed = True process_allfig ( self ) \u00b6 Process all %ALLFIG directives. Source code in ontopy/ontodoc.py def process_allfig ( self ): # pylint: disable=too-many-locals \"\"\"Process all %ALLFIG directives.\"\"\" onto = self . ontodoc . onto for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%ALLFIG \" ): tokens = shlex . split ( line ) token = tokens [ 1 ] opts = get_options ( tokens [ 2 :], path = \"\" , level = 3 , terminated = 0 , include_leafs = 1 , strict_leafs = 1 , width = 0 , leafs = \"\" , relations = \"isA\" , edgelabels = 0 , rankdir = \"BT\" , legend = 1 , namespaces = \"\" , ontologies = \"\" , ) if token == \"classes\" : # nosec roots = onto . get_root_classes ( imported = self . imported ) elif token in ( \"object_properties\" , \"relations\" ): roots = onto . get_root_object_properties ( imported = self . imported ) elif token == \"data_properties\" : # nosec roots = onto . get_root_data_properties ( imported = self . imported ) else : raise InvalidTemplateError ( f \"Invalid argument to %%ALLFIG: { token } \" ) included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) sec = [] for root in roots : name = asstring ( root ) filepath , _ , width = self . _make_branchfig ( name , opts . path , # pylint: disable=no-member opts . terminated , # pylint: disable=no-member opts . include_leafs , # pylint: disable=no-member opts . strict_leafs , # pylint: disable=no-member opts . width , # pylint: disable=no-member opts . leafs , # pylint: disable=no-member opts . relations , # pylint: disable=no-member opts . edgelabels , # pylint: disable=no-member opts . rankdir , # pylint: disable=no-member opts . legend , # pylint: disable=no-member included_namespaces , included_ontologies , ) title = f \"Taxonomy of { name } .\" sec . append ( self . ontodoc . get_header ( title , int ( opts . level )) ) # pylint: disable=no-member sec . extend ( self . ontodoc . get_figure ( filepath , caption = title , width = width ) . split ( \" \\n \" ) ) del self . lines [ i ] self . lines [ i : i ] = sec process_alls ( self ) \u00b6 Expand all %ALL specifications. Source code in ontopy/ontodoc.py def process_alls ( self ): \"\"\"Expand all %ALL specifications.\"\"\" onto = self . ontodoc . onto for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%ALL \" ): tokens = shlex . split ( line ) token = tokens [ 1 ] opts = get_options ( tokens [ 2 :], header_level = 3 ) if token == \"classes\" : # nosec items = onto . classes ( imported = self . imported ) elif token in ( \"object_properties\" , \"relations\" ): items = onto . object_properties ( imported = self . imported ) elif token == \"data_properties\" : # nosec items = onto . data_properties ( imported = self . imported ) elif token == \"annotation_properties\" : # nosec items = onto . annotation_properties ( imported = self . imported ) elif token == \"individuals\" : # nosec items = onto . individuals ( imported = self . imported ) else : raise InvalidTemplateError ( f \"Invalid argument to %%ALL: { token } \" ) items = sorted ( items , key = asstring ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . itemsdoc ( items , int ( opts . header_level ) # pylint: disable=no-member ) . split ( \" \\n \" ) process_branchdocs ( self ) \u00b6 Process all %BRANCHDOC and %BRANCHEAD directives. Source code in ontopy/ontodoc.py def process_branchdocs ( self ): # pylint: disable=too-many-locals \"\"\"Process all %BRANCHDOC and %BRANCHEAD directives.\"\"\" onto = self . ontodoc . onto for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%BRANCHDOC \" ) or line . startswith ( \"%BRANCHHEAD \" ): with_branch = bool ( line . startswith ( \"%BRANCHDOC \" )) tokens = shlex . split ( line ) name = tokens [ 1 ] title = camelsplit ( name ) title = title [ 0 ] . upper () + title [ 1 :] + \" branch\" opts = get_options ( tokens [ 2 :], level = 2 , path = \"\" , title = title , caption = title + \".\" , terminated = 1 , strict_leafs = 1 , width = 0 , leafs = \"\" , relations = \"all\" , edgelabels = 0 , rankdir = \"BT\" , legend = 1 , namespaces = \"\" , ontologies = \"\" , ) included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) include_leafs = 1 filepath , leafs , width = self . _make_branchfig ( name , opts . path , # pylint: disable=no-member opts . terminated , # pylint: disable=no-member include_leafs , opts . strict_leafs , # pylint: disable=no-member opts . width , # pylint: disable=no-member opts . leafs , # pylint: disable=no-member opts . relations , # pylint: disable=no-member opts . edgelabels , # pylint: disable=no-member opts . rankdir , # pylint: disable=no-member opts . legend , # pylint: disable=no-member included_namespaces , included_ontologies , ) sec = [] sec . append ( self . ontodoc . get_header ( opts . title , int ( opts . level )) ) # pylint: disable=no-member sec . append ( self . ontodoc . get_figure ( filepath , caption = opts . caption , width = width , # pylint: disable=no-member ) ) if with_branch : include_leafs = 0 branch = filter_classes ( onto . get_branch ( name , leafs , include_leafs ), included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) sec . append ( self . ontodoc . itemsdoc ( branch , int ( opts . level + 1 ) ) # pylint: disable=no-member ) del self . lines [ i ] self . lines [ i : i ] = sec process_branches ( self ) \u00b6 Expand all %BRANCH specifications. Source code in ontopy/ontodoc.py def process_branches ( self ): \"\"\"Expand all %BRANCH specifications.\"\"\" onto = self . ontodoc . onto # Get all branch names in final document names = self . get_branches () for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%BRANCH \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], header_level = 3 , terminated = 1 , include_leafs = 0 , namespaces = \"\" , ontologies = \"\" , ) leafs = ( names if opts . terminated else () ) # pylint: disable=no-member included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) branch = filter_classes ( onto . get_branch ( name , leafs , opts . include_leafs ), # pylint: disable=no-member included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . itemsdoc ( branch , int ( opts . header_level ) # pylint: disable=no-member ) . split ( \" \\n \" ) process_branchfigs ( self ) \u00b6 Process all %BRANCHFIG directives. Source code in ontopy/ontodoc.py def process_branchfigs ( self ): \"\"\"Process all %BRANCHFIG directives.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%BRANCHFIG \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], path = \"\" , caption = \"\" , terminated = 1 , include_leafs = 1 , strict_leafs = 1 , width = 0 , leafs = \"\" , relations = \"all\" , edgelabels = 0 , rankdir = \"BT\" , legend = 1 , namespaces = \"\" , ontologies = \"\" , ) included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) filepath , _ , width = self . _make_branchfig ( name , opts . path , # pylint: disable=no-member opts . terminated , # pylint: disable=no-member opts . include_leafs , # pylint: disable=no-member opts . strict_leafs , # pylint: disable=no-member opts . width , # pylint: disable=no-member opts . leafs , # pylint: disable=no-member opts . relations , # pylint: disable=no-member opts . edgelabels , # pylint: disable=no-member opts . rankdir , # pylint: disable=no-member opts . legend , # pylint: disable=no-member included_namespaces , included_ontologies , ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . get_figure ( filepath , caption = opts . caption , width = width , # pylint: disable=no-member ) . split ( \" \\n \" ) process_comments ( self ) \u00b6 Strips out comment lines starting with \"%%\". Source code in ontopy/ontodoc.py def process_comments ( self ): \"\"\"Strips out comment lines starting with \"%%\".\"\"\" self . lines = [ line for line in self . lines if not line . startswith ( \" %% \" )] process_entities ( self ) \u00b6 Expand all %ENTITY specifications. Source code in ontopy/ontodoc.py def process_entities ( self ): \"\"\"Expand all %ENTITY specifications.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \" %E NTITY \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], header_level = 3 ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . itemdoc ( name , int ( opts . header_level ) # pylint: disable=no-member ) . split ( \" \\n \" ) process_figures ( self ) \u00b6 Expand all %FIGURE specifications. Source code in ontopy/ontodoc.py def process_figures ( self ): \"\"\"Expand all %FIGURE specifications.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \" %F IGURE \" ): tokens = shlex . split ( line ) path = tokens [ 1 ] opts = get_options ( tokens [ 2 :], caption = \"\" , width = 0 ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . get_figure ( os . path . join ( self . basedir , path ), caption = opts . caption , # pylint: disable=no-member width = opts . width , # pylint: disable=no-member ) . split ( \" \\n \" ) process_headers ( self ) \u00b6 Expand all %HEADER specifications. Source code in ontopy/ontodoc.py def process_headers ( self ): \"\"\"Expand all %HEADER specifications.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%HEADER \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], level = 1 ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . get_header ( name , int ( opts . level ) # pylint: disable=no-member ) . split ( \" \\n \" ) process_includes ( self ) \u00b6 Process all %INCLUDE directives. Source code in ontopy/ontodoc.py def process_includes ( self ): \"\"\"Process all %INCLUDE directives.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%INCLUDE \" ): tokens = shlex . split ( line ) filepath = tokens [ 1 ] opts = get_options ( tokens [ 2 :], shift = 0 ) with open ( os . path . join ( self . basedir , filepath ), \"rt\" , encoding = \"utf8\" ) as handle : docpp = DocPP ( handle . read (), self . ontodoc , basedir = os . path . dirname ( filepath ), figformat = self . figformat , figscale = self . figscale , maxwidth = self . maxwidth , ) docpp . figdir = self . figdir if opts . shift : # pylint: disable=no-member docpp . shift_header_levels ( int ( opts . shift ) ) # pylint: disable=no-member docpp . process () del self . lines [ i ] self . lines [ i : i ] = docpp . lines shift_header_levels ( self , shift ) \u00b6 Shift header level of all hashtag-headers in buffer. Underline headers are ignored. Source code in ontopy/ontodoc.py def shift_header_levels ( self , shift ): \"\"\"Shift header level of all hashtag-headers in buffer. Underline headers are ignored.\"\"\" if not shift : return pat = re . compile ( \"^#+ \" ) for i , line in enumerate ( self . lines ): match = pat . match ( line ) if match : if shift > 0 : self . lines [ i ] = \"#\" * shift + line elif shift < 0 : counter = match . end () if shift > counter : self . lines [ i ] = line . lstrip ( \"# \" ) else : self . lines [ i ] = line [ counter :] write ( self , outfile , fmt = None , pandoc_option_files = (), pandoc_options = (), genfile = None , verbose = True ) \u00b6 Writes documentation to outfile . Parameters \u00b6 outfile : str File that the documentation is written to. fmt : str Output format. If it is \"md\" or \"simple-html\", the built-in template generator is used. Otherwise pandoc is used. If not given, the format is inferred from the outfile name extension. pandoc_option_files : sequence Sequence with command line arguments provided to pandoc. pandoc_options : sequence Additional pandoc options overriding options read from pandoc_option_files . genfile : str Store temporary generated markdown input file to pandoc to this file (for debugging). verbose : bool Whether to show some messages when running pandoc. Source code in ontopy/ontodoc.py def write ( # pylint: disable=too-many-arguments self , outfile , fmt = None , pandoc_option_files = (), pandoc_options = (), genfile = None , verbose = True , ): \"\"\"Writes documentation to `outfile`. Parameters ---------- outfile : str File that the documentation is written to. fmt : str Output format. If it is \"md\" or \"simple-html\", the built-in template generator is used. Otherwise pandoc is used. If not given, the format is inferred from the `outfile` name extension. pandoc_option_files : sequence Sequence with command line arguments provided to pandoc. pandoc_options : sequence Additional pandoc options overriding options read from `pandoc_option_files`. genfile : str Store temporary generated markdown input file to pandoc to this file (for debugging). verbose : bool Whether to show some messages when running pandoc. \"\"\" self . process () content = self . get_buffer () substitutions = self . ontodoc . style . get ( \"substitutions\" , []) for reg , sub in substitutions : content = re . sub ( reg , sub , content ) fmt = get_format ( outfile , fmt ) if fmt not in ( \"simple-html\" , \"markdown\" , \"md\" ): # Run pandoc if not genfile : with NamedTemporaryFile ( mode = \"w+t\" , suffix = \".md\" ) as temp_file : temp_file . write ( content ) temp_file . flush () genfile = temp_file . name run_pandoc ( genfile , outfile , fmt , pandoc_option_files = pandoc_option_files , pandoc_options = pandoc_options , verbose = verbose , ) else : with open ( genfile , \"wt\" ) as handle : handle . write ( content ) run_pandoc ( genfile , outfile , fmt , pandoc_option_files = pandoc_option_files , pandoc_options = pandoc_options , verbose = verbose , ) else : if verbose : print ( \"Writing:\" , outfile ) with open ( outfile , \"wt\" ) as handle : handle . write ( content ) InvalidTemplateError ( NameError ) \u00b6 Raised on errors in template files. Source code in ontopy/ontodoc.py class InvalidTemplateError ( NameError ): \"\"\"Raised on errors in template files.\"\"\" OntoDoc \u00b6 A class for helping documentating ontologies. Parameters \u00b6 onto : Ontology instance The ontology that should be documented. style : dict | \"html\" | \"markdown\" | \"markdown_tex\" A dict defining the following template strings (and substitutions): :header: Formats an header. Substitutions: {level}, {label} :link: Formats a link. Substitutions: {name} :point: Formats a point (list item). Substitutions: {point}, {ontology} :points: Formats a list of points. Used within annotations. Substitutions: {points}, {ontology} :annotation: Formats an annotation. Substitutions: {key}, {value}, {ontology} :substitutions: list of ``(regex, sub)`` pairs for substituting annotation values. Source code in ontopy/ontodoc.py class OntoDoc : \"\"\"A class for helping documentating ontologies. Parameters ---------- onto : Ontology instance The ontology that should be documented. style : dict | \"html\" | \"markdown\" | \"markdown_tex\" A dict defining the following template strings (and substitutions): :header: Formats an header. Substitutions: {level}, {label} :link: Formats a link. Substitutions: {name} :point: Formats a point (list item). Substitutions: {point}, {ontology} :points: Formats a list of points. Used within annotations. Substitutions: {points}, {ontology} :annotation: Formats an annotation. Substitutions: {key}, {value}, {ontology} :substitutions: list of ``(regex, sub)`` pairs for substituting annotation values. \"\"\" _markdown_style = dict ( sep = \" \\n \" , figwidth = \"{{ width= {width:.0f} px }}\" , figure = \"![ {caption} ]( {path} ) {figwidth} \\n \" , header = \" \\n {:#< {level} } {label} \" , link = \"[ {name} ]( {lowerurl} )\" , point = \" - {point} \\n \" , points = \" \\n\\n {points} \\n \" , annotation = \"** {key} :** {value} \\n \" , substitutions = [], ) # Extra style settings for markdown+tex (e.g. pdf generation with pandoc) _markdown_tex_extra_style = dict ( substitutions = [ # logic/math symbols ( \" \\u2200 \" , r \"$ \\\\ forall$\" ), ( \" \\u2203 \" , r \"$ \\\\ exists$\" ), ( \" \\u2206 \" , r \"$ \\\\ nabla$\" ), ( \" \\u2227 \" , r \"$ \\\\ land$\" ), ( \" \\u2228 \" , r \"$ \\\\ lor$\" ), ( \" \\u2207 \" , r \"$ \\\\ nabla$\" ), ( \" \\u2212 \" , r \"-\" ), ( \"->\" , r \"$ \\\\ rightarrow$\" ), # uppercase greek letters ( \" \\u0391 \" , r \"$ \\\\ Upalpha$\" ), ( \" \\u0392 \" , r \"$ \\\\ Upbeta$\" ), ( \" \\u0393 \" , r \"$ \\\\ Upgamma$\" ), ( \" \\u0394 \" , r \"$ \\\\ Updelta$\" ), ( \" \\u0395 \" , r \"$ \\\\ Upepsilon$\" ), ( \" \\u0396 \" , r \"$ \\\\ Upzeta$\" ), ( \" \\u0397 \" , r \"$ \\\\ Upeta$\" ), ( \" \\u0398 \" , r \"$ \\\\ Uptheta$\" ), ( \" \\u0399 \" , r \"$ \\\\ Upiota$\" ), ( \" \\u039a \" , r \"$ \\\\ Upkappa$\" ), ( \" \\u039b \" , r \"$ \\\\ Uplambda$\" ), ( \" \\u039c \" , r \"$ \\\\ Upmu$\" ), ( \" \\u039d \" , r \"$ \\\\ Upnu$\" ), ( \" \\u039e \" , r \"$ \\\\ Upxi$\" ), ( \" \\u039f \" , r \"$ \\\\ Upomekron$\" ), ( \" \\u03a0 \" , r \"$ \\\\ Uppi$\" ), ( \" \\u03a1 \" , r \"$ \\\\ Uprho$\" ), ( \" \\u03a3 \" , r \"$ \\\\ Upsigma$\" ), # no \\u0302 ( \" \\u03a4 \" , r \"$ \\\\ Uptau$\" ), ( \" \\u03a5 \" , r \"$ \\\\ Upupsilon$\" ), ( \" \\u03a6 \" , r \"$ \\\\ Upvarphi$\" ), ( \" \\u03a7 \" , r \"$ \\\\ Upchi$\" ), ( \" \\u03a8 \" , r \"$ \\\\ Uppsi$\" ), ( \" \\u03a9 \" , r \"$ \\\\ Upomega$\" ), # lowercase greek letters ( \" \\u03b1 \" , r \"$ \\\\ upalpha$\" ), ( \" \\u03b2 \" , r \"$ \\\\ upbeta$\" ), ( \" \\u03b3 \" , r \"$ \\\\ upgamma$\" ), ( \" \\u03b4 \" , r \"$ \\\\ updelta$\" ), ( \" \\u03b5 \" , r \"$ \\\\ upepsilon$\" ), ( \" \\u03b6 \" , r \"$ \\\\ upzeta$\" ), ( \" \\u03b7 \" , r \"$ \\\\ upeta$\" ), ( \" \\u03b8 \" , r \"$ \\\\ uptheta$\" ), ( \" \\u03b9 \" , r \"$ \\\\ upiota$\" ), ( \" \\u03ba \" , r \"$ \\\\ upkappa$\" ), ( \" \\u03bb \" , r \"$ \\\\ uplambda$\" ), ( \" \\u03bc \" , r \"$ \\\\ upmu$\" ), ( \" \\u03bd \" , r \"$ \\\\ upnu$\" ), ( \" \\u03be \" , r \"$ \\\\ upxi$\" ), ( \" \\u03bf \" , r \"o\" ), # no \\upomicron ( \" \\u03c0 \" , r \"$ \\\\ uppi$\" ), ( \" \\u03c1 \" , r \"$ \\\\ uprho$\" ), ( \" \\u03c2 \" , r \"$ \\\\ upvarsigma$\" ), ( \" \\u03c3 \" , r \"$ \\\\ upsigma$\" ), ( \" \\u03c4 \" , r \"$ \\\\ uptau$\" ), ( \" \\u03c5 \" , r \"$ \\\\ upupsilon$\" ), ( \" \\u03c6 \" , r \"$ \\\\ upvarphi$\" ), ( \" \\u03c7 \" , r \"$ \\\\ upchi$\" ), ( \" \\u03c8 \" , r \"$ \\\\ uppsi$\" ), ( \" \\u03c9 \" , r \"$ \\\\ upomega$\" ), # acutes, accents, etc... ( \" \\u03ae \" , r \"$ \\\\ acute{ \\\\ upeta}$\" ), ( \" \\u1e17 \" , r \"$ \\\\ acute{ \\\\ bar{ \\\\ mathrm {e} }}$\" ), ( \" \\u03ac \" , r \"$ \\\\ acute{ \\\\ upalpha}$\" ), ( \" \\u00e1 \" , r \"$ \\\\ acute{ \\\\ mathrm {a} }$\" ), ( \" \\u03cc \" , r \"$ \\\\ acute {o} $\" ), # no \\upomicron ( \" \\u014d \" , r \"$ \\\\ bar{ \\\\ mathrm {o} }$\" ), ( \" \\u1f45 \" , r \"$ \\\\ acute {o} $\" ), # no \\omicron ], ) _html_style = dict ( sep = \"<p> \\n \" , figwidth = 'width=\" {width:.0f} \"' , figure = '<img src=\" {path} \" alt=\" {caption} \" {figwidth} >' , header = '<h {level} id=\" {lowerlabel} \"> {label} </h {level} >' , link = '<a href=\" {lowerurl} \"> {name} </a>' , point = \" <li> {point} </li> \\n \" , points = \" <ul> \\n {points} \\n </ul> \\n \" , annotation = \" <dd><strong> {key} :</strong> \\n {value} </dd> \\n \" , substitutions = [ ( r \"&\" , r \"&#8210;\" ), ( r \"<p>\" , r \"<p>\\n\\n\" ), ( r \"\\u2018([^\\u2019]*)\\u2019\" , r \"<q>\\1</q>\" ), ( r \"\\u2019\" , r \"'\" ), ( r \"\\u2260\" , r \"&ne;\" ), ( r \"\\u2264\" , r \"&le;\" ), ( r \"\\u2265\" , r \"&ge;\" ), ( r \"\\u226A\" , r \"&x226A;\" ), ( r \"\\u226B\" , r \"&x226B;\" ), ( r '\"Y$' , r \"\" ), # strange noice added by owlready2 ], ) def __init__ ( self , onto , style = \"markdown\" ): if isinstance ( style , str ): if style == \"markdown_tex\" : style = self . _markdown_style . copy () style . update ( self . _markdown_tex_extra_style ) else : style = getattr ( self , f \"_ { style } _style\" ) self . onto = onto self . style = style self . url_regex = re . compile ( r \"https?:\\/\\/[^\\s ]+\" ) def get_default_template ( self ): \"\"\"Returns default template.\"\"\" title = os . path . splitext ( os . path . basename ( self . onto . base_iri . rstrip ( \"/#\" )) )[ 0 ] irilink = self . style . get ( \"link\" , \" {name} \" ) . format ( name = self . onto . base_iri , url = self . onto . base_iri , lowerurl = self . onto . base_iri , ) template = dedent ( \"\"\"\\ %HEADER {title} Documentation of {irilink} %HEADER Relations level=2 %ALL object_properties %HEADER Classes level=2 %ALL classes %HEADER Individuals level=2 %ALL individuals %HEADER Appendix level=1 %HEADER \"Relation taxonomies\" level=2 %ALLFIG object_properties %HEADER \"Class taxonomies\" level=2 %ALLFIG classes \"\"\" ) . format ( ontology = self . onto , title = title , irilink = irilink ) return template def get_header ( self , label , header_level = 1 ): \"\"\"Returns `label` formatted as a header of given level.\"\"\" header_style = self . style . get ( \"header\" , \" {label} \\n \" ) return header_style . format ( \"\" , level = header_level , label = label , lowerlabel = label . lower () ) def get_figure ( self , path , caption = \"\" , width = None ): \"\"\"Returns a formatted insert-figure-directive.\"\"\" figwidth_style = self . style . get ( \"figwidth\" , \"\" ) figure_style = self . style . get ( \"figure\" , \"\" ) figwidth = figwidth_style . format ( width = width ) if width else \"\" return figure_style . format ( path = path , caption = caption , figwidth = figwidth ) def itemdoc ( self , item , header_level = 3 , show_disjoints = False ): # pylint: disable=too-many-locals,too-many-branches,too-many-statements \"\"\"Returns documentation of `item`. Parameters ---------- item : obj | label The class, individual or relation to document. header_level : int Header level. Defaults to 3. show_disjoints : Bool Whether to show `disjoint_with` relations. \"\"\" onto = self . onto if isinstance ( item , str ): item = self . onto . get_by_label ( item ) header_style = self . style . get ( \"header\" , \" {label} \\n \" ) link_style = self . style . get ( \"link\" , \" {name} \" ) point_style = self . style . get ( \"point\" , \" {point} \" ) points_style = self . style . get ( \"points\" , \" {points} \" ) annotation_style = self . style . get ( \"annotation\" , \" {key} : {value} \\n \" ) substitutions = self . style . get ( \"substitutions\" , []) # Logical \"sorting\" of annotations order = dict ( definition = \"00\" , axiom = \"01\" , theorem = \"02\" , elucidation = \"03\" , domain = \"04\" , range = \"05\" , example = \"06\" , ) doc = [] # Header label = get_label ( item ) doc . append ( header_style . format ( \"\" , level = header_level , label = label , lowerlabel = label . lower () ) ) # Add warning about missing prefLabel if not hasattr ( item , \"prefLabel\" ) or not item . prefLabel . first (): doc . append ( annotation_style . format ( key = \"Warning\" , value = \"Missing prefLabel\" ) ) # Add iri doc . append ( annotation_style . format ( key = \"IRI\" , value = asstring ( item . iri , link_style ), ontology = onto ) ) # Add annotations if isinstance ( item , owlready2 . Thing ): annotations = item . get_individual_annotations () else : annotations = item . get_annotations () for key in sorted ( annotations . keys (), key = lambda key : order . get ( key , key ) ): for value in annotations [ key ]: if self . url_regex . match ( value ): doc . append ( annotation_style . format ( key = key , value = asstring ( value , link_style ) ) ) else : for reg , sub in substitutions : value = re . sub ( reg , sub , value ) doc . append ( annotation_style . format ( key = key , value = value )) # ...add relations from is_a points = [] non_prop = ( owlready2 . ThingClass , # owlready2.Restriction, owlready2 . And , owlready2 . Or , owlready2 . Not , ) for prop in item . is_a : if isinstance ( prop , non_prop ) or ( isinstance ( item , owlready2 . PropertyClass ) and isinstance ( prop , owlready2 . PropertyClass ) ): points . append ( point_style . format ( point = \"is_a \" + asstring ( prop , link_style ), ontology = onto , ) ) else : points . append ( point_style . format ( point = asstring ( prop , link_style ), ontology = onto ) ) # ...add equivalent_to relations for entity in item . equivalent_to : points . append ( point_style . format ( point = \"equivalent_to \" + asstring ( entity , link_style ) ) ) # ...add disjoint_with relations if show_disjoints and hasattr ( item , \"disjoint_with\" ): subjects = set ( item . disjoint_with ( reduce = True )) points . append ( point_style . format ( point = \"disjoint_with \" + \", \" . join ( asstring ( _ , link_style ) for _ in subjects ), ontology = onto , ) ) # ...add disjoint_unions if hasattr ( item , \"disjoint_unions\" ): for unions in item . disjoint_unions : string = \", \" . join ( asstring ( _ , link_style ) for _ in unions ) points . append ( point_style . format ( point = f \"disjoint_union_of { string } \" , ontology = onto ) ) # ...add inverse_of relations if hasattr ( item , \"inverse_property\" ) and item . inverse_property : points . append ( point_style . format ( point = \"inverse_of \" + asstring ( item . inverse_property , link_style ) ) ) # ...add domain restrictions for domain in getattr ( item , \"domain\" , ()): points . append ( point_style . format ( point = f \"domain { asstring ( domain , link_style ) } \" ) ) # ...add range restrictions for restriction in getattr ( item , \"range\" , ()): points . append ( point_style . format ( point = f \"range { asstring ( restriction , link_style ) } \" ) ) # Add points (from is_a) if points : value = points_style . format ( points = \"\" . join ( points ), ontology = onto ) doc . append ( annotation_style . format ( key = \"Subclass of\" , value = value , ontology = onto ) ) # Instances (individuals) if hasattr ( item , \"instances\" ): points = [] for entity in [ _ for _ in item . instances () if item in _ . is_instance_of ]: points . append ( point_style . format ( point = asstring ( entity , link_style ), ontology = onto ) ) if points : value = points_style . format ( points = \"\" . join ( points ), ontology = onto ) doc . append ( annotation_style . format ( key = \"Individuals\" , value = value , ontology = onto ) ) return \" \\n \" . join ( doc ) def itemsdoc ( self , items , header_level = 3 ): \"\"\"Returns documentation of `items`.\"\"\" sep_style = self . style . get ( \"sep\" , \" \\n \" ) doc = [] for item in items : doc . append ( self . itemdoc ( item , header_level )) doc . append ( sep_style . format ( ontology = self . onto )) return \" \\n \" . join ( doc ) get_default_template ( self ) \u00b6 Returns default template. Source code in ontopy/ontodoc.py def get_default_template ( self ): \"\"\"Returns default template.\"\"\" title = os . path . splitext ( os . path . basename ( self . onto . base_iri . rstrip ( \"/#\" )) )[ 0 ] irilink = self . style . get ( \"link\" , \" {name} \" ) . format ( name = self . onto . base_iri , url = self . onto . base_iri , lowerurl = self . onto . base_iri , ) template = dedent ( \"\"\"\\ %HEADER {title} Documentation of {irilink} %HEADER Relations level=2 %ALL object_properties %HEADER Classes level=2 %ALL classes %HEADER Individuals level=2 %ALL individuals %HEADER Appendix level=1 %HEADER \"Relation taxonomies\" level=2 %ALLFIG object_properties %HEADER \"Class taxonomies\" level=2 %ALLFIG classes \"\"\" ) . format ( ontology = self . onto , title = title , irilink = irilink ) return template get_figure ( self , path , caption = '' , width = None ) \u00b6 Returns a formatted insert-figure-directive. Source code in ontopy/ontodoc.py def get_figure ( self , path , caption = \"\" , width = None ): \"\"\"Returns a formatted insert-figure-directive.\"\"\" figwidth_style = self . style . get ( \"figwidth\" , \"\" ) figure_style = self . style . get ( \"figure\" , \"\" ) figwidth = figwidth_style . format ( width = width ) if width else \"\" return figure_style . format ( path = path , caption = caption , figwidth = figwidth ) get_header ( self , label , header_level = 1 ) \u00b6 Returns label formatted as a header of given level. Source code in ontopy/ontodoc.py def get_header ( self , label , header_level = 1 ): \"\"\"Returns `label` formatted as a header of given level.\"\"\" header_style = self . style . get ( \"header\" , \" {label} \\n \" ) return header_style . format ( \"\" , level = header_level , label = label , lowerlabel = label . lower () ) itemdoc ( self , item , header_level = 3 , show_disjoints = False ) \u00b6 Returns documentation of item . Parameters \u00b6 item : obj | label The class, individual or relation to document. header_level : int Header level. Defaults to 3. show_disjoints : Bool Whether to show disjoint_with relations. Source code in ontopy/ontodoc.py def itemdoc ( self , item , header_level = 3 , show_disjoints = False ): # pylint: disable=too-many-locals,too-many-branches,too-many-statements \"\"\"Returns documentation of `item`. Parameters ---------- item : obj | label The class, individual or relation to document. header_level : int Header level. Defaults to 3. show_disjoints : Bool Whether to show `disjoint_with` relations. \"\"\" onto = self . onto if isinstance ( item , str ): item = self . onto . get_by_label ( item ) header_style = self . style . get ( \"header\" , \" {label} \\n \" ) link_style = self . style . get ( \"link\" , \" {name} \" ) point_style = self . style . get ( \"point\" , \" {point} \" ) points_style = self . style . get ( \"points\" , \" {points} \" ) annotation_style = self . style . get ( \"annotation\" , \" {key} : {value} \\n \" ) substitutions = self . style . get ( \"substitutions\" , []) # Logical \"sorting\" of annotations order = dict ( definition = \"00\" , axiom = \"01\" , theorem = \"02\" , elucidation = \"03\" , domain = \"04\" , range = \"05\" , example = \"06\" , ) doc = [] # Header label = get_label ( item ) doc . append ( header_style . format ( \"\" , level = header_level , label = label , lowerlabel = label . lower () ) ) # Add warning about missing prefLabel if not hasattr ( item , \"prefLabel\" ) or not item . prefLabel . first (): doc . append ( annotation_style . format ( key = \"Warning\" , value = \"Missing prefLabel\" ) ) # Add iri doc . append ( annotation_style . format ( key = \"IRI\" , value = asstring ( item . iri , link_style ), ontology = onto ) ) # Add annotations if isinstance ( item , owlready2 . Thing ): annotations = item . get_individual_annotations () else : annotations = item . get_annotations () for key in sorted ( annotations . keys (), key = lambda key : order . get ( key , key ) ): for value in annotations [ key ]: if self . url_regex . match ( value ): doc . append ( annotation_style . format ( key = key , value = asstring ( value , link_style ) ) ) else : for reg , sub in substitutions : value = re . sub ( reg , sub , value ) doc . append ( annotation_style . format ( key = key , value = value )) # ...add relations from is_a points = [] non_prop = ( owlready2 . ThingClass , # owlready2.Restriction, owlready2 . And , owlready2 . Or , owlready2 . Not , ) for prop in item . is_a : if isinstance ( prop , non_prop ) or ( isinstance ( item , owlready2 . PropertyClass ) and isinstance ( prop , owlready2 . PropertyClass ) ): points . append ( point_style . format ( point = \"is_a \" + asstring ( prop , link_style ), ontology = onto , ) ) else : points . append ( point_style . format ( point = asstring ( prop , link_style ), ontology = onto ) ) # ...add equivalent_to relations for entity in item . equivalent_to : points . append ( point_style . format ( point = \"equivalent_to \" + asstring ( entity , link_style ) ) ) # ...add disjoint_with relations if show_disjoints and hasattr ( item , \"disjoint_with\" ): subjects = set ( item . disjoint_with ( reduce = True )) points . append ( point_style . format ( point = \"disjoint_with \" + \", \" . join ( asstring ( _ , link_style ) for _ in subjects ), ontology = onto , ) ) # ...add disjoint_unions if hasattr ( item , \"disjoint_unions\" ): for unions in item . disjoint_unions : string = \", \" . join ( asstring ( _ , link_style ) for _ in unions ) points . append ( point_style . format ( point = f \"disjoint_union_of { string } \" , ontology = onto ) ) # ...add inverse_of relations if hasattr ( item , \"inverse_property\" ) and item . inverse_property : points . append ( point_style . format ( point = \"inverse_of \" + asstring ( item . inverse_property , link_style ) ) ) # ...add domain restrictions for domain in getattr ( item , \"domain\" , ()): points . append ( point_style . format ( point = f \"domain { asstring ( domain , link_style ) } \" ) ) # ...add range restrictions for restriction in getattr ( item , \"range\" , ()): points . append ( point_style . format ( point = f \"range { asstring ( restriction , link_style ) } \" ) ) # Add points (from is_a) if points : value = points_style . format ( points = \"\" . join ( points ), ontology = onto ) doc . append ( annotation_style . format ( key = \"Subclass of\" , value = value , ontology = onto ) ) # Instances (individuals) if hasattr ( item , \"instances\" ): points = [] for entity in [ _ for _ in item . instances () if item in _ . is_instance_of ]: points . append ( point_style . format ( point = asstring ( entity , link_style ), ontology = onto ) ) if points : value = points_style . format ( points = \"\" . join ( points ), ontology = onto ) doc . append ( annotation_style . format ( key = \"Individuals\" , value = value , ontology = onto ) ) return \" \\n \" . join ( doc ) itemsdoc ( self , items , header_level = 3 ) \u00b6 Returns documentation of items . Source code in ontopy/ontodoc.py def itemsdoc ( self , items , header_level = 3 ): \"\"\"Returns documentation of `items`.\"\"\" sep_style = self . style . get ( \"sep\" , \" \\n \" ) doc = [] for item in items : doc . append ( self . itemdoc ( item , header_level )) doc . append ( sep_style . format ( ontology = self . onto )) return \" \\n \" . join ( doc ) append_pandoc_options ( options , updates ) \u00b6 Append updates to pandoc options options . Parameters \u00b6 options : sequence Sequence with initial Pandoc options. updates : sequence of str Sequence of strings of the form \"--longoption=value\", where longoption is a valid pandoc long option and value is the new value. The \"=value\" part is optional. Strings of the form \"no-longoption\" will filter out \"--longoption\" from `options`. Returns \u00b6 new_options : list Updated pandoc options. Source code in ontopy/ontodoc.py def append_pandoc_options ( options , updates ): \"\"\"Append `updates` to pandoc options `options`. Parameters ---------- options : sequence Sequence with initial Pandoc options. updates : sequence of str Sequence of strings of the form \"--longoption=value\", where ``longoption`` is a valid pandoc long option and ``value`` is the new value. The \"=value\" part is optional. Strings of the form \"no-longoption\" will filter out \"--longoption\" from `options`. Returns ------- new_options : list Updated pandoc options. \"\"\" # Valid pandoc options starting with \"--no-XXX\" no_options = set ( \"no-highlight\" ) if not updates : return list ( options ) curated_updates = {} for update in updates : key , sep , value = update . partition ( \"=\" ) curated_updates [ key . lstrip ( \"-\" )] = value if sep else None filter_out = set ( _ for _ in curated_updates if _ . startswith ( \"no-\" ) and _ not in no_options ) _filter_out = set ( f \"-- { _ [ 3 :] } \" for _ in filter_out ) new_options = [ opt for opt in options if opt . partition ( \"=\" )[ 0 ] not in _filter_out ] new_options . extend ( [ f \"-- { key } \" if value is None else f \"-- { key } = { value } \" for key , value in curated_updates . items () if key not in filter_out ] ) return new_options get_docpp ( ontodoc , infile , figdir = 'genfigs' , figformat = 'png' , maxwidth = None , imported = False ) \u00b6 Read infile and return a new docpp instance. Source code in ontopy/ontodoc.py def get_docpp ( # pylint: disable=too-many-arguments ontodoc , infile , figdir = \"genfigs\" , figformat = \"png\" , maxwidth = None , imported = False , ): \"\"\"Read `infile` and return a new docpp instance.\"\"\" if infile : with open ( infile , \"rt\" ) as handle : template = handle . read () basedir = os . path . dirname ( infile ) else : template = ontodoc . get_default_template () basedir = \".\" docpp = DocPP ( template , ontodoc , basedir = basedir , figdir = figdir , figformat = figformat , maxwidth = maxwidth , imported = imported , ) return docpp get_figformat ( fmt ) \u00b6 Infer preferred figure format from output format. Source code in ontopy/ontodoc.py def get_figformat ( fmt ): \"\"\"Infer preferred figure format from output format.\"\"\" if fmt == \"pdf\" : figformat = \"pdf\" # XXX elif \"html\" in fmt : figformat = \"svg\" else : figformat = \"png\" return figformat get_format ( outfile , fmt = None ) \u00b6 Infer format from outfile and format. Source code in ontopy/ontodoc.py def get_format ( outfile , fmt = None ): \"\"\"Infer format from outfile and format.\"\"\" if fmt is None : fmt = os . path . splitext ( outfile )[ 1 ] if not fmt : fmt = \"html\" if fmt . startswith ( \".\" ): fmt = fmt [ 1 :] return fmt get_maxwidth ( fmt ) \u00b6 Infer preferred max figure width from output format. Source code in ontopy/ontodoc.py def get_maxwidth ( fmt ): \"\"\"Infer preferred max figure width from output format.\"\"\" if fmt == \"pdf\" : maxwidth = 668 else : maxwidth = 1024 return maxwidth get_options ( opts , ** kwargs ) \u00b6 Returns a dict with options from the sequence opts with \"name=value\" pairs. Valid option names and default values are provided with the keyword arguments. Source code in ontopy/ontodoc.py def get_options ( opts , ** kwargs ): \"\"\"Returns a dict with options from the sequence `opts` with \"name=value\" pairs. Valid option names and default values are provided with the keyword arguments.\"\"\" res = AttributeDict ( kwargs ) for opt in opts : if \"=\" not in opt : raise InvalidTemplateError ( f 'Missing \"=\" in template option: { opt !r} ' ) name , value = opt . split ( \"=\" , 1 ) if name not in res : raise InvalidTemplateError ( f \"Invalid template option: { name !r} \" ) res_type = type ( res [ name ]) res [ name ] = res_type ( value ) return res get_style ( fmt ) \u00b6 Infer style from output format. Source code in ontopy/ontodoc.py def get_style ( fmt ): \"\"\"Infer style from output format.\"\"\" if fmt == \"simple-html\" : style = \"html\" elif fmt in ( \"tex\" , \"latex\" , \"pdf\" ): style = \"markdown_tex\" else : style = \"markdown\" return style load_pandoc_option_file ( yamlfile ) \u00b6 Loads pandoc options from yamlfile and return a list with corresponding pandoc command line arguments. Source code in ontopy/ontodoc.py def load_pandoc_option_file ( yamlfile ): \"\"\"Loads pandoc options from `yamlfile` and return a list with corresponding pandoc command line arguments.\"\"\" with open ( yamlfile ) as handle : pandoc_options = yaml . safe_load ( handle ) options = pandoc_options . pop ( \"input-files\" , []) variables = pandoc_options . pop ( \"variables\" , {}) for key , value in pandoc_options . items (): if isinstance ( value , bool ): if value : options . append ( f \"-- { key } \" ) else : options . append ( f \"-- { key } = { value } \" ) for key , value in variables . items (): if key == \"date\" and value == \"now\" : value = time . strftime ( \"%B %d , %Y\" ) options . append ( f \"--variable= { key } : { value } \" ) return options run_pandoc ( genfile , outfile , fmt , pandoc_option_files = (), pandoc_options = (), verbose = True ) \u00b6 Runs pandoc. Parameters \u00b6 genfile : str Name of markdown input file. outfile : str Output file name. fmt : str Output format. pandoc_option_files : sequence List of files with additional pandoc options. Default is to read \"pandoc-options.yaml\" and \"pandoc-FORMAT-options.yml\", where FORMAT is the output format. pandoc_options : sequence Additional pandoc options overriding options read from pandoc_option_files . verbose : bool Whether to print the pandoc command before execution. Raises \u00b6 subprocess.CalledProcessError If the pandoc process returns with non-zero status. The returncode attribute will hold the exit code. Source code in ontopy/ontodoc.py def run_pandoc ( # pylint: disable=too-many-arguments genfile , outfile , fmt , pandoc_option_files = (), pandoc_options = (), verbose = True , ): \"\"\"Runs pandoc. Parameters ---------- genfile : str Name of markdown input file. outfile : str Output file name. fmt : str Output format. pandoc_option_files : sequence List of files with additional pandoc options. Default is to read \"pandoc-options.yaml\" and \"pandoc-FORMAT-options.yml\", where `FORMAT` is the output format. pandoc_options : sequence Additional pandoc options overriding options read from `pandoc_option_files`. verbose : bool Whether to print the pandoc command before execution. Raises ------ subprocess.CalledProcessError If the pandoc process returns with non-zero status. The `returncode` attribute will hold the exit code. \"\"\" # Create pandoc argument list args = [ genfile ] files = [ \"pandoc-options.yaml\" , f \"pandoc- { fmt } -options.yaml\" ] if pandoc_option_files : files = pandoc_option_files for fname in files : if os . path . exists ( fname ): args . extend ( load_pandoc_option_file ( fname )) else : warnings . warn ( f \"missing pandoc option file: { fname } \" ) # Update pandoc argument list args = append_pandoc_options ( args , pandoc_options ) # pdf output requires a special attention... if fmt == \"pdf\" : pdf_engine = \"pdflatex\" for arg in args : if arg . startswith ( \"--pdf-engine\" ): pdf_engine = arg . split ( \"=\" , 1 )[ 1 ] break with TemporaryDirectory () as tmpdir : run_pandoc_pdf ( tmpdir , pdf_engine , outfile , args , verbose = verbose ) else : args . append ( f \"--output= { outfile } \" ) cmd = [ \"pandoc\" ] + args if verbose : print () print ( \"* Executing command:\" ) print ( \" \" . join ( shlex . quote ( _ ) for _ in cmd )) subprocess . check_call ( cmd ) # nosec run_pandoc_pdf ( latex_dir , pdf_engine , outfile , args , verbose = True ) \u00b6 Run pandoc for pdf generation. Source code in ontopy/ontodoc.py def run_pandoc_pdf ( latex_dir , pdf_engine , outfile , args , verbose = True ): \"\"\"Run pandoc for pdf generation.\"\"\" basename = os . path . join ( latex_dir , os . path . splitext ( os . path . basename ( outfile ))[ 0 ] ) # Run pandoc texfile = basename + \".tex\" args . append ( f \"--output= { texfile } \" ) cmd = [ \"pandoc\" ] + args if verbose : print () print ( \"* Executing commands:\" ) print ( \" \" . join ( shlex . quote ( s ) for s in cmd )) subprocess . check_call ( cmd ) # nosec # Fixing tex output texfile2 = basename + \"2.tex\" with open ( texfile , \"rt\" ) as handle : content = handle . read () . replace ( r \"\\$\\Uptheta\\$\" , r \"$\\Uptheta$\" ) with open ( texfile2 , \"wt\" ) as handle : handle . write ( content ) # Run latex pdffile = basename + \"2.pdf\" cmd = [ pdf_engine , texfile2 , \"-halt-on-error\" , f \"-output-directory= { latex_dir } \" , ] if verbose : print () print ( \" \" . join ( shlex . quote ( s ) for s in cmd )) output = subprocess . check_output ( cmd , timeout = 60 ) # nosec output = subprocess . check_output ( cmd , timeout = 60 ) # nosec # Workaround for non-working \"-output-directory\" latex option if not os . path . exists ( pdffile ): if os . path . exists ( os . path . basename ( pdffile )): pdffile = os . path . basename ( pdffile ) for ext in \"aux\" , \"out\" , \"toc\" , \"log\" : filename = os . path . splitext ( pdffile )[ 0 ] + \".\" + ext if os . path . exists ( filename ): os . remove ( filename ) else : print () print ( output ) print () raise RuntimeError ( \"latex did not produce pdf file: \" + pdffile ) # Copy pdffile if not os . path . exists ( outfile ) or not os . path . samefile ( pdffile , outfile ): if verbose : print () print ( f \"move { pdffile } to { outfile } \" ) shutil . move ( pdffile , outfile )","title":"ontodoc"},{"location":"api_reference/ontopy/ontodoc/#ontodoc","text":"A module for documenting ontologies.","title":"ontodoc"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.AttributeDict","text":"A dict with attribute access. Note that methods like key() and update() may be overridden. Source code in ontopy/ontodoc.py class AttributeDict ( dict ): \"\"\"A dict with attribute access. Note that methods like key() and update() may be overridden.\"\"\" def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . __dict__ = self","title":"AttributeDict"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP","text":"Documentation pre-processor. It supports the following features: Comment lines %% Comment line... Insert header with given level %HEADER label [level=1] Insert figure with optional caption and width. filepath should be relative to basedir . If width is 0, no width will be specified. %FIGURE filepath [caption='' width=0px] Include other markdown files. Header levels may be up or down with shift %INCLUDE filepath [shift=0] Insert generated documentation for ontology entity. The header level may be set with header_level . %ENTITY name [header_level=3] Insert generated documentation for ontology branch name . Options: header_level: Header level. terminated: Whether to branch should be terminated at all branch names in the final document. include_leafs: Whether to include leaf. %BRANCH name [header_level=3 terminated=1 include_leafs=0 namespaces='' ontologies=''] Insert generated figure of ontology branch name . The figure is written to path . The default path is figdir / name , where figdir is given at class initiation. It is recommended to exclude the file extension from path . In this case, the default figformat will be used (and easily adjusted to the correct format required by the backend). leafs may be a comma- separated list of leaf node names. %BRANCHFIG name [path='' caption='' terminated=1 include_leafs=1 strict_leafs=1, width=0px leafs='' relations=all edgelabels=0 namespaces='' ontologies=''] This is a combination of the %HEADER and %BRANCHFIG directives. %BRANCHHEAD name [level=2 path='' caption='' terminated=1 include_leafs=1 width=0px leafs=''] This is a combination of the %HEADER, %BRANCHFIG and %BRANCH directives. It inserts documentation of branch name , with a header followed by a figure and then documentation of each element. %BRANCHDOC name [level=2 path='' title='' caption='' terminated=1 strict_leafs=1 width=0px leafs='' relations='all' rankdir='BT' legend=1 namespaces='' ontologies=''] Insert generated documentation for all entities of the given type. Valid values of type are: \"classes\", \"individuals\", \"object_properties\", \"data_properties\", \"annotations_properties\" %ALL type [header_level=3, namespaces='', ontologies=''] Insert generated figure of all entities of the given type. Valid values of type are: \"classes\", \"object_properties\" and \"data_properties\". %ALLFIG type","title":"DocPP"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP--parameters","text":"template : str Input template. ontodoc : OntoDoc instance Instance of OntoDoc basedir : str Base directory for including relative file paths. figdir : str Default directory to store generated figures. figformat : str Default format for generated figures. figscale : float Default scaling of generated figures. maxwidth : float Maximum figure width. Figures larger than this will be rescaled. imported : bool Whether to include imported entities. Source code in ontopy/ontodoc.py class DocPP : # pylint: disable=too-many-instance-attributes \"\"\"Documentation pre-processor. It supports the following features: * Comment lines %% Comment line... * Insert header with given level %HEADER label [level=1] * Insert figure with optional caption and width. `filepath` should be relative to `basedir`. If width is 0, no width will be specified. %FIGURE filepath [caption='' width=0px] * Include other markdown files. Header levels may be up or down with `shift` %INCLUDE filepath [shift=0] * Insert generated documentation for ontology entity. The header level may be set with `header_level`. %ENTITY name [header_level=3] * Insert generated documentation for ontology branch `name`. Options: - header_level: Header level. - terminated: Whether to branch should be terminated at all branch names in the final document. - include_leafs: Whether to include leaf. %BRANCH name [header_level=3 terminated=1 include_leafs=0 namespaces='' ontologies=''] * Insert generated figure of ontology branch `name`. The figure is written to `path`. The default path is `figdir`/`name`, where `figdir` is given at class initiation. It is recommended to exclude the file extension from `path`. In this case, the default figformat will be used (and easily adjusted to the correct format required by the backend). `leafs` may be a comma- separated list of leaf node names. %BRANCHFIG name [path='' caption='' terminated=1 include_leafs=1 strict_leafs=1, width=0px leafs='' relations=all edgelabels=0 namespaces='' ontologies=''] * This is a combination of the %HEADER and %BRANCHFIG directives. %BRANCHHEAD name [level=2 path='' caption='' terminated=1 include_leafs=1 width=0px leafs=''] * This is a combination of the %HEADER, %BRANCHFIG and %BRANCH directives. It inserts documentation of branch `name`, with a header followed by a figure and then documentation of each element. %BRANCHDOC name [level=2 path='' title='' caption='' terminated=1 strict_leafs=1 width=0px leafs='' relations='all' rankdir='BT' legend=1 namespaces='' ontologies=''] * Insert generated documentation for all entities of the given type. Valid values of `type` are: \"classes\", \"individuals\", \"object_properties\", \"data_properties\", \"annotations_properties\" %ALL type [header_level=3, namespaces='', ontologies=''] * Insert generated figure of all entities of the given type. Valid values of `type` are: \"classes\", \"object_properties\" and \"data_properties\". %ALLFIG type Parameters ---------- template : str Input template. ontodoc : OntoDoc instance Instance of OntoDoc basedir : str Base directory for including relative file paths. figdir : str Default directory to store generated figures. figformat : str Default format for generated figures. figscale : float Default scaling of generated figures. maxwidth : float Maximum figure width. Figures larger than this will be rescaled. imported : bool Whether to include imported entities. \"\"\" # FIXME - this class should be refractured: # * Instead of rescan the entire document for each pre-processer # directive, we should scan the source like by line and handle # each directive as they occour. # * The current implementation has a lot of dublicated code. # * Instead of modifying the source in-place, we should copy to a # result list. This will make good error reporting much easier. # * Branch leaves are only looked up in the file witht the %BRANCH # directive, not in all included files as expedted. def __init__ ( # pylint: disable=too-many-arguments self , template , ontodoc , basedir = \".\" , figdir = \"genfigs\" , figformat = \"png\" , figscale = 1.0 , maxwidth = None , imported = False , ): self . lines = template . split ( \" \\n \" ) self . ontodoc = ontodoc self . basedir = basedir self . figdir = os . path . join ( basedir , figdir ) self . figformat = figformat self . figscale = figscale self . maxwidth = maxwidth self . imported = imported self . _branch_cache = None self . _processed = False # Whether process() has been called def __str__ ( self ): return self . get_buffer () def get_buffer ( self ): \"\"\"Returns the current buffer.\"\"\" return \" \\n \" . join ( self . lines ) def copy ( self ): \"\"\"Returns a copy of self.\"\"\" docpp = DocPP ( \"\" , self . ontodoc , self . basedir , figformat = self . figformat , figscale = self . figscale , maxwidth = self . maxwidth , ) docpp . lines [:] = self . lines docpp . figdir = self . figdir return docpp def get_branches ( self ): \"\"\"Returns a list with all branch names as specified with %BRANCH (in current and all included documents). The returned value is cached for efficiency purposes and so that it is not lost after processing branches.\"\"\" if self . _branch_cache is None : names = [] docpp = self . copy () docpp . process_includes () for line in docpp . lines : if line . startswith ( \"%BRANCH\" ): names . append ( shlex . split ( line )[ 1 ]) self . _branch_cache = names return self . _branch_cache def shift_header_levels ( self , shift ): \"\"\"Shift header level of all hashtag-headers in buffer. Underline headers are ignored.\"\"\" if not shift : return pat = re . compile ( \"^#+ \" ) for i , line in enumerate ( self . lines ): match = pat . match ( line ) if match : if shift > 0 : self . lines [ i ] = \"#\" * shift + line elif shift < 0 : counter = match . end () if shift > counter : self . lines [ i ] = line . lstrip ( \"# \" ) else : self . lines [ i ] = line [ counter :] def process_comments ( self ): \"\"\"Strips out comment lines starting with \"%%\".\"\"\" self . lines = [ line for line in self . lines if not line . startswith ( \" %% \" )] def process_headers ( self ): \"\"\"Expand all %HEADER specifications.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%HEADER \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], level = 1 ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . get_header ( name , int ( opts . level ) # pylint: disable=no-member ) . split ( \" \\n \" ) def process_figures ( self ): \"\"\"Expand all %FIGURE specifications.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \" %F IGURE \" ): tokens = shlex . split ( line ) path = tokens [ 1 ] opts = get_options ( tokens [ 2 :], caption = \"\" , width = 0 ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . get_figure ( os . path . join ( self . basedir , path ), caption = opts . caption , # pylint: disable=no-member width = opts . width , # pylint: disable=no-member ) . split ( \" \\n \" ) def process_entities ( self ): \"\"\"Expand all %ENTITY specifications.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \" %E NTITY \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], header_level = 3 ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . itemdoc ( name , int ( opts . header_level ) # pylint: disable=no-member ) . split ( \" \\n \" ) def process_branches ( self ): \"\"\"Expand all %BRANCH specifications.\"\"\" onto = self . ontodoc . onto # Get all branch names in final document names = self . get_branches () for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%BRANCH \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], header_level = 3 , terminated = 1 , include_leafs = 0 , namespaces = \"\" , ontologies = \"\" , ) leafs = ( names if opts . terminated else () ) # pylint: disable=no-member included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) branch = filter_classes ( onto . get_branch ( name , leafs , opts . include_leafs ), # pylint: disable=no-member included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . itemsdoc ( branch , int ( opts . header_level ) # pylint: disable=no-member ) . split ( \" \\n \" ) def _make_branchfig ( # pylint: disable=too-many-arguments,too-many-locals self , name : str , path : \"Union[Path, str]\" , terminated : bool , include_leafs : bool , strict_leafs : bool , width : float , leafs : \"Union[str, list[str]]\" , relations : str , edgelabels : str , rankdir : str , legend : bool , included_namespaces : \"Iterable[str]\" , included_ontologies : \"Iterable[str]\" , ) -> \"tuple[str, list[str], float]\" : \"\"\"Help method for process_branchfig(). Args: name: name of branch root path: optional figure path name include_leafs: whether to include leafs strict_leafs: whether strictly exclude leafs descendants terminated: whether the graph should be terminated at leaf nodes width: optional figure width leafs: optional leafs node names for graph termination relations: comma-separated list of relations to include edgelabels: whether to include edgelabels rankdir: graph direction (BT, TB, RL, LR) legend: whether to add legend included_namespaces: sequence of names of namespaces to be included included_ontologies: sequence of names of ontologies to be included Returns: filepath: path to generated figure leafs: used list of leaf node names width: actual figure width \"\"\" onto = self . ontodoc . onto if leafs : if isinstance ( leafs , str ): leafs = leafs . split ( \",\" ) elif terminated : leafs = set ( self . get_branches ()) leafs . discard ( name ) else : leafs = None if path : figdir = os . path . dirname ( path ) formatext = os . path . splitext ( path )[ 1 ] if formatext : fmt = formatext . lstrip ( \".\" ) else : fmt = self . figformat path += f \". { fmt } \" else : figdir = self . figdir fmt = self . figformat term = \"T\" if terminated else \"\" path = os . path . join ( figdir , name + term ) + f \". { fmt } \" # Create graph graph = OntoGraph ( onto , graph_attr = { \"rankdir\" : rankdir }) graph . add_branch ( root = name , leafs = leafs , include_leafs = include_leafs , strict_leafs = strict_leafs , relations = relations , edgelabels = edgelabels , included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) if legend : graph . add_legend () if not width : figwidth , _ = graph . get_figsize () width = self . figscale * figwidth if self . maxwidth and width > self . maxwidth : width = self . maxwidth filepath = os . path . join ( self . basedir , path ) destdir = os . path . dirname ( filepath ) if not os . path . exists ( destdir ): os . makedirs ( destdir ) graph . save ( filepath , fmt = fmt ) return filepath , leafs , width def process_branchfigs ( self ): \"\"\"Process all %BRANCHFIG directives.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%BRANCHFIG \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], path = \"\" , caption = \"\" , terminated = 1 , include_leafs = 1 , strict_leafs = 1 , width = 0 , leafs = \"\" , relations = \"all\" , edgelabels = 0 , rankdir = \"BT\" , legend = 1 , namespaces = \"\" , ontologies = \"\" , ) included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) filepath , _ , width = self . _make_branchfig ( name , opts . path , # pylint: disable=no-member opts . terminated , # pylint: disable=no-member opts . include_leafs , # pylint: disable=no-member opts . strict_leafs , # pylint: disable=no-member opts . width , # pylint: disable=no-member opts . leafs , # pylint: disable=no-member opts . relations , # pylint: disable=no-member opts . edgelabels , # pylint: disable=no-member opts . rankdir , # pylint: disable=no-member opts . legend , # pylint: disable=no-member included_namespaces , included_ontologies , ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . get_figure ( filepath , caption = opts . caption , width = width , # pylint: disable=no-member ) . split ( \" \\n \" ) def process_branchdocs ( self ): # pylint: disable=too-many-locals \"\"\"Process all %BRANCHDOC and %BRANCHEAD directives.\"\"\" onto = self . ontodoc . onto for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%BRANCHDOC \" ) or line . startswith ( \"%BRANCHHEAD \" ): with_branch = bool ( line . startswith ( \"%BRANCHDOC \" )) tokens = shlex . split ( line ) name = tokens [ 1 ] title = camelsplit ( name ) title = title [ 0 ] . upper () + title [ 1 :] + \" branch\" opts = get_options ( tokens [ 2 :], level = 2 , path = \"\" , title = title , caption = title + \".\" , terminated = 1 , strict_leafs = 1 , width = 0 , leafs = \"\" , relations = \"all\" , edgelabels = 0 , rankdir = \"BT\" , legend = 1 , namespaces = \"\" , ontologies = \"\" , ) included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) include_leafs = 1 filepath , leafs , width = self . _make_branchfig ( name , opts . path , # pylint: disable=no-member opts . terminated , # pylint: disable=no-member include_leafs , opts . strict_leafs , # pylint: disable=no-member opts . width , # pylint: disable=no-member opts . leafs , # pylint: disable=no-member opts . relations , # pylint: disable=no-member opts . edgelabels , # pylint: disable=no-member opts . rankdir , # pylint: disable=no-member opts . legend , # pylint: disable=no-member included_namespaces , included_ontologies , ) sec = [] sec . append ( self . ontodoc . get_header ( opts . title , int ( opts . level )) ) # pylint: disable=no-member sec . append ( self . ontodoc . get_figure ( filepath , caption = opts . caption , width = width , # pylint: disable=no-member ) ) if with_branch : include_leafs = 0 branch = filter_classes ( onto . get_branch ( name , leafs , include_leafs ), included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) sec . append ( self . ontodoc . itemsdoc ( branch , int ( opts . level + 1 ) ) # pylint: disable=no-member ) del self . lines [ i ] self . lines [ i : i ] = sec def process_alls ( self ): \"\"\"Expand all %ALL specifications.\"\"\" onto = self . ontodoc . onto for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%ALL \" ): tokens = shlex . split ( line ) token = tokens [ 1 ] opts = get_options ( tokens [ 2 :], header_level = 3 ) if token == \"classes\" : # nosec items = onto . classes ( imported = self . imported ) elif token in ( \"object_properties\" , \"relations\" ): items = onto . object_properties ( imported = self . imported ) elif token == \"data_properties\" : # nosec items = onto . data_properties ( imported = self . imported ) elif token == \"annotation_properties\" : # nosec items = onto . annotation_properties ( imported = self . imported ) elif token == \"individuals\" : # nosec items = onto . individuals ( imported = self . imported ) else : raise InvalidTemplateError ( f \"Invalid argument to %%ALL: { token } \" ) items = sorted ( items , key = asstring ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . itemsdoc ( items , int ( opts . header_level ) # pylint: disable=no-member ) . split ( \" \\n \" ) def process_allfig ( self ): # pylint: disable=too-many-locals \"\"\"Process all %ALLFIG directives.\"\"\" onto = self . ontodoc . onto for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%ALLFIG \" ): tokens = shlex . split ( line ) token = tokens [ 1 ] opts = get_options ( tokens [ 2 :], path = \"\" , level = 3 , terminated = 0 , include_leafs = 1 , strict_leafs = 1 , width = 0 , leafs = \"\" , relations = \"isA\" , edgelabels = 0 , rankdir = \"BT\" , legend = 1 , namespaces = \"\" , ontologies = \"\" , ) if token == \"classes\" : # nosec roots = onto . get_root_classes ( imported = self . imported ) elif token in ( \"object_properties\" , \"relations\" ): roots = onto . get_root_object_properties ( imported = self . imported ) elif token == \"data_properties\" : # nosec roots = onto . get_root_data_properties ( imported = self . imported ) else : raise InvalidTemplateError ( f \"Invalid argument to %%ALLFIG: { token } \" ) included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) sec = [] for root in roots : name = asstring ( root ) filepath , _ , width = self . _make_branchfig ( name , opts . path , # pylint: disable=no-member opts . terminated , # pylint: disable=no-member opts . include_leafs , # pylint: disable=no-member opts . strict_leafs , # pylint: disable=no-member opts . width , # pylint: disable=no-member opts . leafs , # pylint: disable=no-member opts . relations , # pylint: disable=no-member opts . edgelabels , # pylint: disable=no-member opts . rankdir , # pylint: disable=no-member opts . legend , # pylint: disable=no-member included_namespaces , included_ontologies , ) title = f \"Taxonomy of { name } .\" sec . append ( self . ontodoc . get_header ( title , int ( opts . level )) ) # pylint: disable=no-member sec . extend ( self . ontodoc . get_figure ( filepath , caption = title , width = width ) . split ( \" \\n \" ) ) del self . lines [ i ] self . lines [ i : i ] = sec def process_includes ( self ): \"\"\"Process all %INCLUDE directives.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%INCLUDE \" ): tokens = shlex . split ( line ) filepath = tokens [ 1 ] opts = get_options ( tokens [ 2 :], shift = 0 ) with open ( os . path . join ( self . basedir , filepath ), \"rt\" , encoding = \"utf8\" ) as handle : docpp = DocPP ( handle . read (), self . ontodoc , basedir = os . path . dirname ( filepath ), figformat = self . figformat , figscale = self . figscale , maxwidth = self . maxwidth , ) docpp . figdir = self . figdir if opts . shift : # pylint: disable=no-member docpp . shift_header_levels ( int ( opts . shift ) ) # pylint: disable=no-member docpp . process () del self . lines [ i ] self . lines [ i : i ] = docpp . lines def process ( self ): \"\"\"Perform all pre-processing steps.\"\"\" if not self . _processed : self . process_comments () self . process_headers () self . process_figures () self . process_entities () self . process_branches () self . process_branchfigs () self . process_branchdocs () self . process_alls () self . process_allfig () self . process_includes () self . _processed = True def write ( # pylint: disable=too-many-arguments self , outfile , fmt = None , pandoc_option_files = (), pandoc_options = (), genfile = None , verbose = True , ): \"\"\"Writes documentation to `outfile`. Parameters ---------- outfile : str File that the documentation is written to. fmt : str Output format. If it is \"md\" or \"simple-html\", the built-in template generator is used. Otherwise pandoc is used. If not given, the format is inferred from the `outfile` name extension. pandoc_option_files : sequence Sequence with command line arguments provided to pandoc. pandoc_options : sequence Additional pandoc options overriding options read from `pandoc_option_files`. genfile : str Store temporary generated markdown input file to pandoc to this file (for debugging). verbose : bool Whether to show some messages when running pandoc. \"\"\" self . process () content = self . get_buffer () substitutions = self . ontodoc . style . get ( \"substitutions\" , []) for reg , sub in substitutions : content = re . sub ( reg , sub , content ) fmt = get_format ( outfile , fmt ) if fmt not in ( \"simple-html\" , \"markdown\" , \"md\" ): # Run pandoc if not genfile : with NamedTemporaryFile ( mode = \"w+t\" , suffix = \".md\" ) as temp_file : temp_file . write ( content ) temp_file . flush () genfile = temp_file . name run_pandoc ( genfile , outfile , fmt , pandoc_option_files = pandoc_option_files , pandoc_options = pandoc_options , verbose = verbose , ) else : with open ( genfile , \"wt\" ) as handle : handle . write ( content ) run_pandoc ( genfile , outfile , fmt , pandoc_option_files = pandoc_option_files , pandoc_options = pandoc_options , verbose = verbose , ) else : if verbose : print ( \"Writing:\" , outfile ) with open ( outfile , \"wt\" ) as handle : handle . write ( content )","title":"Parameters"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.copy","text":"Returns a copy of self. Source code in ontopy/ontodoc.py def copy ( self ): \"\"\"Returns a copy of self.\"\"\" docpp = DocPP ( \"\" , self . ontodoc , self . basedir , figformat = self . figformat , figscale = self . figscale , maxwidth = self . maxwidth , ) docpp . lines [:] = self . lines docpp . figdir = self . figdir return docpp","title":"copy()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.get_branches","text":"Returns a list with all branch names as specified with %BRANCH (in current and all included documents). The returned value is cached for efficiency purposes and so that it is not lost after processing branches. Source code in ontopy/ontodoc.py def get_branches ( self ): \"\"\"Returns a list with all branch names as specified with %BRANCH (in current and all included documents). The returned value is cached for efficiency purposes and so that it is not lost after processing branches.\"\"\" if self . _branch_cache is None : names = [] docpp = self . copy () docpp . process_includes () for line in docpp . lines : if line . startswith ( \"%BRANCH\" ): names . append ( shlex . split ( line )[ 1 ]) self . _branch_cache = names return self . _branch_cache","title":"get_branches()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.get_buffer","text":"Returns the current buffer. Source code in ontopy/ontodoc.py def get_buffer ( self ): \"\"\"Returns the current buffer.\"\"\" return \" \\n \" . join ( self . lines )","title":"get_buffer()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.process","text":"Perform all pre-processing steps. Source code in ontopy/ontodoc.py def process ( self ): \"\"\"Perform all pre-processing steps.\"\"\" if not self . _processed : self . process_comments () self . process_headers () self . process_figures () self . process_entities () self . process_branches () self . process_branchfigs () self . process_branchdocs () self . process_alls () self . process_allfig () self . process_includes () self . _processed = True","title":"process()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.process_allfig","text":"Process all %ALLFIG directives. Source code in ontopy/ontodoc.py def process_allfig ( self ): # pylint: disable=too-many-locals \"\"\"Process all %ALLFIG directives.\"\"\" onto = self . ontodoc . onto for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%ALLFIG \" ): tokens = shlex . split ( line ) token = tokens [ 1 ] opts = get_options ( tokens [ 2 :], path = \"\" , level = 3 , terminated = 0 , include_leafs = 1 , strict_leafs = 1 , width = 0 , leafs = \"\" , relations = \"isA\" , edgelabels = 0 , rankdir = \"BT\" , legend = 1 , namespaces = \"\" , ontologies = \"\" , ) if token == \"classes\" : # nosec roots = onto . get_root_classes ( imported = self . imported ) elif token in ( \"object_properties\" , \"relations\" ): roots = onto . get_root_object_properties ( imported = self . imported ) elif token == \"data_properties\" : # nosec roots = onto . get_root_data_properties ( imported = self . imported ) else : raise InvalidTemplateError ( f \"Invalid argument to %%ALLFIG: { token } \" ) included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) sec = [] for root in roots : name = asstring ( root ) filepath , _ , width = self . _make_branchfig ( name , opts . path , # pylint: disable=no-member opts . terminated , # pylint: disable=no-member opts . include_leafs , # pylint: disable=no-member opts . strict_leafs , # pylint: disable=no-member opts . width , # pylint: disable=no-member opts . leafs , # pylint: disable=no-member opts . relations , # pylint: disable=no-member opts . edgelabels , # pylint: disable=no-member opts . rankdir , # pylint: disable=no-member opts . legend , # pylint: disable=no-member included_namespaces , included_ontologies , ) title = f \"Taxonomy of { name } .\" sec . append ( self . ontodoc . get_header ( title , int ( opts . level )) ) # pylint: disable=no-member sec . extend ( self . ontodoc . get_figure ( filepath , caption = title , width = width ) . split ( \" \\n \" ) ) del self . lines [ i ] self . lines [ i : i ] = sec","title":"process_allfig()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.process_alls","text":"Expand all %ALL specifications. Source code in ontopy/ontodoc.py def process_alls ( self ): \"\"\"Expand all %ALL specifications.\"\"\" onto = self . ontodoc . onto for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%ALL \" ): tokens = shlex . split ( line ) token = tokens [ 1 ] opts = get_options ( tokens [ 2 :], header_level = 3 ) if token == \"classes\" : # nosec items = onto . classes ( imported = self . imported ) elif token in ( \"object_properties\" , \"relations\" ): items = onto . object_properties ( imported = self . imported ) elif token == \"data_properties\" : # nosec items = onto . data_properties ( imported = self . imported ) elif token == \"annotation_properties\" : # nosec items = onto . annotation_properties ( imported = self . imported ) elif token == \"individuals\" : # nosec items = onto . individuals ( imported = self . imported ) else : raise InvalidTemplateError ( f \"Invalid argument to %%ALL: { token } \" ) items = sorted ( items , key = asstring ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . itemsdoc ( items , int ( opts . header_level ) # pylint: disable=no-member ) . split ( \" \\n \" )","title":"process_alls()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.process_branchdocs","text":"Process all %BRANCHDOC and %BRANCHEAD directives. Source code in ontopy/ontodoc.py def process_branchdocs ( self ): # pylint: disable=too-many-locals \"\"\"Process all %BRANCHDOC and %BRANCHEAD directives.\"\"\" onto = self . ontodoc . onto for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%BRANCHDOC \" ) or line . startswith ( \"%BRANCHHEAD \" ): with_branch = bool ( line . startswith ( \"%BRANCHDOC \" )) tokens = shlex . split ( line ) name = tokens [ 1 ] title = camelsplit ( name ) title = title [ 0 ] . upper () + title [ 1 :] + \" branch\" opts = get_options ( tokens [ 2 :], level = 2 , path = \"\" , title = title , caption = title + \".\" , terminated = 1 , strict_leafs = 1 , width = 0 , leafs = \"\" , relations = \"all\" , edgelabels = 0 , rankdir = \"BT\" , legend = 1 , namespaces = \"\" , ontologies = \"\" , ) included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) include_leafs = 1 filepath , leafs , width = self . _make_branchfig ( name , opts . path , # pylint: disable=no-member opts . terminated , # pylint: disable=no-member include_leafs , opts . strict_leafs , # pylint: disable=no-member opts . width , # pylint: disable=no-member opts . leafs , # pylint: disable=no-member opts . relations , # pylint: disable=no-member opts . edgelabels , # pylint: disable=no-member opts . rankdir , # pylint: disable=no-member opts . legend , # pylint: disable=no-member included_namespaces , included_ontologies , ) sec = [] sec . append ( self . ontodoc . get_header ( opts . title , int ( opts . level )) ) # pylint: disable=no-member sec . append ( self . ontodoc . get_figure ( filepath , caption = opts . caption , width = width , # pylint: disable=no-member ) ) if with_branch : include_leafs = 0 branch = filter_classes ( onto . get_branch ( name , leafs , include_leafs ), included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) sec . append ( self . ontodoc . itemsdoc ( branch , int ( opts . level + 1 ) ) # pylint: disable=no-member ) del self . lines [ i ] self . lines [ i : i ] = sec","title":"process_branchdocs()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.process_branches","text":"Expand all %BRANCH specifications. Source code in ontopy/ontodoc.py def process_branches ( self ): \"\"\"Expand all %BRANCH specifications.\"\"\" onto = self . ontodoc . onto # Get all branch names in final document names = self . get_branches () for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%BRANCH \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], header_level = 3 , terminated = 1 , include_leafs = 0 , namespaces = \"\" , ontologies = \"\" , ) leafs = ( names if opts . terminated else () ) # pylint: disable=no-member included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) branch = filter_classes ( onto . get_branch ( name , leafs , opts . include_leafs ), # pylint: disable=no-member included_namespaces = included_namespaces , included_ontologies = included_ontologies , ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . itemsdoc ( branch , int ( opts . header_level ) # pylint: disable=no-member ) . split ( \" \\n \" )","title":"process_branches()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.process_branchfigs","text":"Process all %BRANCHFIG directives. Source code in ontopy/ontodoc.py def process_branchfigs ( self ): \"\"\"Process all %BRANCHFIG directives.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%BRANCHFIG \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], path = \"\" , caption = \"\" , terminated = 1 , include_leafs = 1 , strict_leafs = 1 , width = 0 , leafs = \"\" , relations = \"all\" , edgelabels = 0 , rankdir = \"BT\" , legend = 1 , namespaces = \"\" , ontologies = \"\" , ) included_namespaces = ( opts . namespaces . split ( \",\" ) if opts . namespaces else () # pylint: disable=no-member ) included_ontologies = ( opts . ontologies . split ( \",\" ) if opts . ontologies else () # pylint: disable=no-member ) filepath , _ , width = self . _make_branchfig ( name , opts . path , # pylint: disable=no-member opts . terminated , # pylint: disable=no-member opts . include_leafs , # pylint: disable=no-member opts . strict_leafs , # pylint: disable=no-member opts . width , # pylint: disable=no-member opts . leafs , # pylint: disable=no-member opts . relations , # pylint: disable=no-member opts . edgelabels , # pylint: disable=no-member opts . rankdir , # pylint: disable=no-member opts . legend , # pylint: disable=no-member included_namespaces , included_ontologies , ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . get_figure ( filepath , caption = opts . caption , width = width , # pylint: disable=no-member ) . split ( \" \\n \" )","title":"process_branchfigs()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.process_comments","text":"Strips out comment lines starting with \"%%\". Source code in ontopy/ontodoc.py def process_comments ( self ): \"\"\"Strips out comment lines starting with \"%%\".\"\"\" self . lines = [ line for line in self . lines if not line . startswith ( \" %% \" )]","title":"process_comments()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.process_entities","text":"Expand all %ENTITY specifications. Source code in ontopy/ontodoc.py def process_entities ( self ): \"\"\"Expand all %ENTITY specifications.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \" %E NTITY \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], header_level = 3 ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . itemdoc ( name , int ( opts . header_level ) # pylint: disable=no-member ) . split ( \" \\n \" )","title":"process_entities()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.process_figures","text":"Expand all %FIGURE specifications. Source code in ontopy/ontodoc.py def process_figures ( self ): \"\"\"Expand all %FIGURE specifications.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \" %F IGURE \" ): tokens = shlex . split ( line ) path = tokens [ 1 ] opts = get_options ( tokens [ 2 :], caption = \"\" , width = 0 ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . get_figure ( os . path . join ( self . basedir , path ), caption = opts . caption , # pylint: disable=no-member width = opts . width , # pylint: disable=no-member ) . split ( \" \\n \" )","title":"process_figures()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.process_headers","text":"Expand all %HEADER specifications. Source code in ontopy/ontodoc.py def process_headers ( self ): \"\"\"Expand all %HEADER specifications.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%HEADER \" ): tokens = shlex . split ( line ) name = tokens [ 1 ] opts = get_options ( tokens [ 2 :], level = 1 ) del self . lines [ i ] self . lines [ i : i ] = self . ontodoc . get_header ( name , int ( opts . level ) # pylint: disable=no-member ) . split ( \" \\n \" )","title":"process_headers()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.process_includes","text":"Process all %INCLUDE directives. Source code in ontopy/ontodoc.py def process_includes ( self ): \"\"\"Process all %INCLUDE directives.\"\"\" for i , line in reversed ( list ( enumerate ( self . lines ))): if line . startswith ( \"%INCLUDE \" ): tokens = shlex . split ( line ) filepath = tokens [ 1 ] opts = get_options ( tokens [ 2 :], shift = 0 ) with open ( os . path . join ( self . basedir , filepath ), \"rt\" , encoding = \"utf8\" ) as handle : docpp = DocPP ( handle . read (), self . ontodoc , basedir = os . path . dirname ( filepath ), figformat = self . figformat , figscale = self . figscale , maxwidth = self . maxwidth , ) docpp . figdir = self . figdir if opts . shift : # pylint: disable=no-member docpp . shift_header_levels ( int ( opts . shift ) ) # pylint: disable=no-member docpp . process () del self . lines [ i ] self . lines [ i : i ] = docpp . lines","title":"process_includes()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.shift_header_levels","text":"Shift header level of all hashtag-headers in buffer. Underline headers are ignored. Source code in ontopy/ontodoc.py def shift_header_levels ( self , shift ): \"\"\"Shift header level of all hashtag-headers in buffer. Underline headers are ignored.\"\"\" if not shift : return pat = re . compile ( \"^#+ \" ) for i , line in enumerate ( self . lines ): match = pat . match ( line ) if match : if shift > 0 : self . lines [ i ] = \"#\" * shift + line elif shift < 0 : counter = match . end () if shift > counter : self . lines [ i ] = line . lstrip ( \"# \" ) else : self . lines [ i ] = line [ counter :]","title":"shift_header_levels()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.write","text":"Writes documentation to outfile .","title":"write()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.DocPP.write--parameters","text":"outfile : str File that the documentation is written to. fmt : str Output format. If it is \"md\" or \"simple-html\", the built-in template generator is used. Otherwise pandoc is used. If not given, the format is inferred from the outfile name extension. pandoc_option_files : sequence Sequence with command line arguments provided to pandoc. pandoc_options : sequence Additional pandoc options overriding options read from pandoc_option_files . genfile : str Store temporary generated markdown input file to pandoc to this file (for debugging). verbose : bool Whether to show some messages when running pandoc. Source code in ontopy/ontodoc.py def write ( # pylint: disable=too-many-arguments self , outfile , fmt = None , pandoc_option_files = (), pandoc_options = (), genfile = None , verbose = True , ): \"\"\"Writes documentation to `outfile`. Parameters ---------- outfile : str File that the documentation is written to. fmt : str Output format. If it is \"md\" or \"simple-html\", the built-in template generator is used. Otherwise pandoc is used. If not given, the format is inferred from the `outfile` name extension. pandoc_option_files : sequence Sequence with command line arguments provided to pandoc. pandoc_options : sequence Additional pandoc options overriding options read from `pandoc_option_files`. genfile : str Store temporary generated markdown input file to pandoc to this file (for debugging). verbose : bool Whether to show some messages when running pandoc. \"\"\" self . process () content = self . get_buffer () substitutions = self . ontodoc . style . get ( \"substitutions\" , []) for reg , sub in substitutions : content = re . sub ( reg , sub , content ) fmt = get_format ( outfile , fmt ) if fmt not in ( \"simple-html\" , \"markdown\" , \"md\" ): # Run pandoc if not genfile : with NamedTemporaryFile ( mode = \"w+t\" , suffix = \".md\" ) as temp_file : temp_file . write ( content ) temp_file . flush () genfile = temp_file . name run_pandoc ( genfile , outfile , fmt , pandoc_option_files = pandoc_option_files , pandoc_options = pandoc_options , verbose = verbose , ) else : with open ( genfile , \"wt\" ) as handle : handle . write ( content ) run_pandoc ( genfile , outfile , fmt , pandoc_option_files = pandoc_option_files , pandoc_options = pandoc_options , verbose = verbose , ) else : if verbose : print ( \"Writing:\" , outfile ) with open ( outfile , \"wt\" ) as handle : handle . write ( content )","title":"Parameters"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.InvalidTemplateError","text":"Raised on errors in template files. Source code in ontopy/ontodoc.py class InvalidTemplateError ( NameError ): \"\"\"Raised on errors in template files.\"\"\"","title":"InvalidTemplateError"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.OntoDoc","text":"A class for helping documentating ontologies.","title":"OntoDoc"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.OntoDoc--parameters","text":"onto : Ontology instance The ontology that should be documented. style : dict | \"html\" | \"markdown\" | \"markdown_tex\" A dict defining the following template strings (and substitutions): :header: Formats an header. Substitutions: {level}, {label} :link: Formats a link. Substitutions: {name} :point: Formats a point (list item). Substitutions: {point}, {ontology} :points: Formats a list of points. Used within annotations. Substitutions: {points}, {ontology} :annotation: Formats an annotation. Substitutions: {key}, {value}, {ontology} :substitutions: list of ``(regex, sub)`` pairs for substituting annotation values. Source code in ontopy/ontodoc.py class OntoDoc : \"\"\"A class for helping documentating ontologies. Parameters ---------- onto : Ontology instance The ontology that should be documented. style : dict | \"html\" | \"markdown\" | \"markdown_tex\" A dict defining the following template strings (and substitutions): :header: Formats an header. Substitutions: {level}, {label} :link: Formats a link. Substitutions: {name} :point: Formats a point (list item). Substitutions: {point}, {ontology} :points: Formats a list of points. Used within annotations. Substitutions: {points}, {ontology} :annotation: Formats an annotation. Substitutions: {key}, {value}, {ontology} :substitutions: list of ``(regex, sub)`` pairs for substituting annotation values. \"\"\" _markdown_style = dict ( sep = \" \\n \" , figwidth = \"{{ width= {width:.0f} px }}\" , figure = \"![ {caption} ]( {path} ) {figwidth} \\n \" , header = \" \\n {:#< {level} } {label} \" , link = \"[ {name} ]( {lowerurl} )\" , point = \" - {point} \\n \" , points = \" \\n\\n {points} \\n \" , annotation = \"** {key} :** {value} \\n \" , substitutions = [], ) # Extra style settings for markdown+tex (e.g. pdf generation with pandoc) _markdown_tex_extra_style = dict ( substitutions = [ # logic/math symbols ( \" \\u2200 \" , r \"$ \\\\ forall$\" ), ( \" \\u2203 \" , r \"$ \\\\ exists$\" ), ( \" \\u2206 \" , r \"$ \\\\ nabla$\" ), ( \" \\u2227 \" , r \"$ \\\\ land$\" ), ( \" \\u2228 \" , r \"$ \\\\ lor$\" ), ( \" \\u2207 \" , r \"$ \\\\ nabla$\" ), ( \" \\u2212 \" , r \"-\" ), ( \"->\" , r \"$ \\\\ rightarrow$\" ), # uppercase greek letters ( \" \\u0391 \" , r \"$ \\\\ Upalpha$\" ), ( \" \\u0392 \" , r \"$ \\\\ Upbeta$\" ), ( \" \\u0393 \" , r \"$ \\\\ Upgamma$\" ), ( \" \\u0394 \" , r \"$ \\\\ Updelta$\" ), ( \" \\u0395 \" , r \"$ \\\\ Upepsilon$\" ), ( \" \\u0396 \" , r \"$ \\\\ Upzeta$\" ), ( \" \\u0397 \" , r \"$ \\\\ Upeta$\" ), ( \" \\u0398 \" , r \"$ \\\\ Uptheta$\" ), ( \" \\u0399 \" , r \"$ \\\\ Upiota$\" ), ( \" \\u039a \" , r \"$ \\\\ Upkappa$\" ), ( \" \\u039b \" , r \"$ \\\\ Uplambda$\" ), ( \" \\u039c \" , r \"$ \\\\ Upmu$\" ), ( \" \\u039d \" , r \"$ \\\\ Upnu$\" ), ( \" \\u039e \" , r \"$ \\\\ Upxi$\" ), ( \" \\u039f \" , r \"$ \\\\ Upomekron$\" ), ( \" \\u03a0 \" , r \"$ \\\\ Uppi$\" ), ( \" \\u03a1 \" , r \"$ \\\\ Uprho$\" ), ( \" \\u03a3 \" , r \"$ \\\\ Upsigma$\" ), # no \\u0302 ( \" \\u03a4 \" , r \"$ \\\\ Uptau$\" ), ( \" \\u03a5 \" , r \"$ \\\\ Upupsilon$\" ), ( \" \\u03a6 \" , r \"$ \\\\ Upvarphi$\" ), ( \" \\u03a7 \" , r \"$ \\\\ Upchi$\" ), ( \" \\u03a8 \" , r \"$ \\\\ Uppsi$\" ), ( \" \\u03a9 \" , r \"$ \\\\ Upomega$\" ), # lowercase greek letters ( \" \\u03b1 \" , r \"$ \\\\ upalpha$\" ), ( \" \\u03b2 \" , r \"$ \\\\ upbeta$\" ), ( \" \\u03b3 \" , r \"$ \\\\ upgamma$\" ), ( \" \\u03b4 \" , r \"$ \\\\ updelta$\" ), ( \" \\u03b5 \" , r \"$ \\\\ upepsilon$\" ), ( \" \\u03b6 \" , r \"$ \\\\ upzeta$\" ), ( \" \\u03b7 \" , r \"$ \\\\ upeta$\" ), ( \" \\u03b8 \" , r \"$ \\\\ uptheta$\" ), ( \" \\u03b9 \" , r \"$ \\\\ upiota$\" ), ( \" \\u03ba \" , r \"$ \\\\ upkappa$\" ), ( \" \\u03bb \" , r \"$ \\\\ uplambda$\" ), ( \" \\u03bc \" , r \"$ \\\\ upmu$\" ), ( \" \\u03bd \" , r \"$ \\\\ upnu$\" ), ( \" \\u03be \" , r \"$ \\\\ upxi$\" ), ( \" \\u03bf \" , r \"o\" ), # no \\upomicron ( \" \\u03c0 \" , r \"$ \\\\ uppi$\" ), ( \" \\u03c1 \" , r \"$ \\\\ uprho$\" ), ( \" \\u03c2 \" , r \"$ \\\\ upvarsigma$\" ), ( \" \\u03c3 \" , r \"$ \\\\ upsigma$\" ), ( \" \\u03c4 \" , r \"$ \\\\ uptau$\" ), ( \" \\u03c5 \" , r \"$ \\\\ upupsilon$\" ), ( \" \\u03c6 \" , r \"$ \\\\ upvarphi$\" ), ( \" \\u03c7 \" , r \"$ \\\\ upchi$\" ), ( \" \\u03c8 \" , r \"$ \\\\ uppsi$\" ), ( \" \\u03c9 \" , r \"$ \\\\ upomega$\" ), # acutes, accents, etc... ( \" \\u03ae \" , r \"$ \\\\ acute{ \\\\ upeta}$\" ), ( \" \\u1e17 \" , r \"$ \\\\ acute{ \\\\ bar{ \\\\ mathrm {e} }}$\" ), ( \" \\u03ac \" , r \"$ \\\\ acute{ \\\\ upalpha}$\" ), ( \" \\u00e1 \" , r \"$ \\\\ acute{ \\\\ mathrm {a} }$\" ), ( \" \\u03cc \" , r \"$ \\\\ acute {o} $\" ), # no \\upomicron ( \" \\u014d \" , r \"$ \\\\ bar{ \\\\ mathrm {o} }$\" ), ( \" \\u1f45 \" , r \"$ \\\\ acute {o} $\" ), # no \\omicron ], ) _html_style = dict ( sep = \"<p> \\n \" , figwidth = 'width=\" {width:.0f} \"' , figure = '<img src=\" {path} \" alt=\" {caption} \" {figwidth} >' , header = '<h {level} id=\" {lowerlabel} \"> {label} </h {level} >' , link = '<a href=\" {lowerurl} \"> {name} </a>' , point = \" <li> {point} </li> \\n \" , points = \" <ul> \\n {points} \\n </ul> \\n \" , annotation = \" <dd><strong> {key} :</strong> \\n {value} </dd> \\n \" , substitutions = [ ( r \"&\" , r \"&#8210;\" ), ( r \"<p>\" , r \"<p>\\n\\n\" ), ( r \"\\u2018([^\\u2019]*)\\u2019\" , r \"<q>\\1</q>\" ), ( r \"\\u2019\" , r \"'\" ), ( r \"\\u2260\" , r \"&ne;\" ), ( r \"\\u2264\" , r \"&le;\" ), ( r \"\\u2265\" , r \"&ge;\" ), ( r \"\\u226A\" , r \"&x226A;\" ), ( r \"\\u226B\" , r \"&x226B;\" ), ( r '\"Y$' , r \"\" ), # strange noice added by owlready2 ], ) def __init__ ( self , onto , style = \"markdown\" ): if isinstance ( style , str ): if style == \"markdown_tex\" : style = self . _markdown_style . copy () style . update ( self . _markdown_tex_extra_style ) else : style = getattr ( self , f \"_ { style } _style\" ) self . onto = onto self . style = style self . url_regex = re . compile ( r \"https?:\\/\\/[^\\s ]+\" ) def get_default_template ( self ): \"\"\"Returns default template.\"\"\" title = os . path . splitext ( os . path . basename ( self . onto . base_iri . rstrip ( \"/#\" )) )[ 0 ] irilink = self . style . get ( \"link\" , \" {name} \" ) . format ( name = self . onto . base_iri , url = self . onto . base_iri , lowerurl = self . onto . base_iri , ) template = dedent ( \"\"\"\\ %HEADER {title} Documentation of {irilink} %HEADER Relations level=2 %ALL object_properties %HEADER Classes level=2 %ALL classes %HEADER Individuals level=2 %ALL individuals %HEADER Appendix level=1 %HEADER \"Relation taxonomies\" level=2 %ALLFIG object_properties %HEADER \"Class taxonomies\" level=2 %ALLFIG classes \"\"\" ) . format ( ontology = self . onto , title = title , irilink = irilink ) return template def get_header ( self , label , header_level = 1 ): \"\"\"Returns `label` formatted as a header of given level.\"\"\" header_style = self . style . get ( \"header\" , \" {label} \\n \" ) return header_style . format ( \"\" , level = header_level , label = label , lowerlabel = label . lower () ) def get_figure ( self , path , caption = \"\" , width = None ): \"\"\"Returns a formatted insert-figure-directive.\"\"\" figwidth_style = self . style . get ( \"figwidth\" , \"\" ) figure_style = self . style . get ( \"figure\" , \"\" ) figwidth = figwidth_style . format ( width = width ) if width else \"\" return figure_style . format ( path = path , caption = caption , figwidth = figwidth ) def itemdoc ( self , item , header_level = 3 , show_disjoints = False ): # pylint: disable=too-many-locals,too-many-branches,too-many-statements \"\"\"Returns documentation of `item`. Parameters ---------- item : obj | label The class, individual or relation to document. header_level : int Header level. Defaults to 3. show_disjoints : Bool Whether to show `disjoint_with` relations. \"\"\" onto = self . onto if isinstance ( item , str ): item = self . onto . get_by_label ( item ) header_style = self . style . get ( \"header\" , \" {label} \\n \" ) link_style = self . style . get ( \"link\" , \" {name} \" ) point_style = self . style . get ( \"point\" , \" {point} \" ) points_style = self . style . get ( \"points\" , \" {points} \" ) annotation_style = self . style . get ( \"annotation\" , \" {key} : {value} \\n \" ) substitutions = self . style . get ( \"substitutions\" , []) # Logical \"sorting\" of annotations order = dict ( definition = \"00\" , axiom = \"01\" , theorem = \"02\" , elucidation = \"03\" , domain = \"04\" , range = \"05\" , example = \"06\" , ) doc = [] # Header label = get_label ( item ) doc . append ( header_style . format ( \"\" , level = header_level , label = label , lowerlabel = label . lower () ) ) # Add warning about missing prefLabel if not hasattr ( item , \"prefLabel\" ) or not item . prefLabel . first (): doc . append ( annotation_style . format ( key = \"Warning\" , value = \"Missing prefLabel\" ) ) # Add iri doc . append ( annotation_style . format ( key = \"IRI\" , value = asstring ( item . iri , link_style ), ontology = onto ) ) # Add annotations if isinstance ( item , owlready2 . Thing ): annotations = item . get_individual_annotations () else : annotations = item . get_annotations () for key in sorted ( annotations . keys (), key = lambda key : order . get ( key , key ) ): for value in annotations [ key ]: if self . url_regex . match ( value ): doc . append ( annotation_style . format ( key = key , value = asstring ( value , link_style ) ) ) else : for reg , sub in substitutions : value = re . sub ( reg , sub , value ) doc . append ( annotation_style . format ( key = key , value = value )) # ...add relations from is_a points = [] non_prop = ( owlready2 . ThingClass , # owlready2.Restriction, owlready2 . And , owlready2 . Or , owlready2 . Not , ) for prop in item . is_a : if isinstance ( prop , non_prop ) or ( isinstance ( item , owlready2 . PropertyClass ) and isinstance ( prop , owlready2 . PropertyClass ) ): points . append ( point_style . format ( point = \"is_a \" + asstring ( prop , link_style ), ontology = onto , ) ) else : points . append ( point_style . format ( point = asstring ( prop , link_style ), ontology = onto ) ) # ...add equivalent_to relations for entity in item . equivalent_to : points . append ( point_style . format ( point = \"equivalent_to \" + asstring ( entity , link_style ) ) ) # ...add disjoint_with relations if show_disjoints and hasattr ( item , \"disjoint_with\" ): subjects = set ( item . disjoint_with ( reduce = True )) points . append ( point_style . format ( point = \"disjoint_with \" + \", \" . join ( asstring ( _ , link_style ) for _ in subjects ), ontology = onto , ) ) # ...add disjoint_unions if hasattr ( item , \"disjoint_unions\" ): for unions in item . disjoint_unions : string = \", \" . join ( asstring ( _ , link_style ) for _ in unions ) points . append ( point_style . format ( point = f \"disjoint_union_of { string } \" , ontology = onto ) ) # ...add inverse_of relations if hasattr ( item , \"inverse_property\" ) and item . inverse_property : points . append ( point_style . format ( point = \"inverse_of \" + asstring ( item . inverse_property , link_style ) ) ) # ...add domain restrictions for domain in getattr ( item , \"domain\" , ()): points . append ( point_style . format ( point = f \"domain { asstring ( domain , link_style ) } \" ) ) # ...add range restrictions for restriction in getattr ( item , \"range\" , ()): points . append ( point_style . format ( point = f \"range { asstring ( restriction , link_style ) } \" ) ) # Add points (from is_a) if points : value = points_style . format ( points = \"\" . join ( points ), ontology = onto ) doc . append ( annotation_style . format ( key = \"Subclass of\" , value = value , ontology = onto ) ) # Instances (individuals) if hasattr ( item , \"instances\" ): points = [] for entity in [ _ for _ in item . instances () if item in _ . is_instance_of ]: points . append ( point_style . format ( point = asstring ( entity , link_style ), ontology = onto ) ) if points : value = points_style . format ( points = \"\" . join ( points ), ontology = onto ) doc . append ( annotation_style . format ( key = \"Individuals\" , value = value , ontology = onto ) ) return \" \\n \" . join ( doc ) def itemsdoc ( self , items , header_level = 3 ): \"\"\"Returns documentation of `items`.\"\"\" sep_style = self . style . get ( \"sep\" , \" \\n \" ) doc = [] for item in items : doc . append ( self . itemdoc ( item , header_level )) doc . append ( sep_style . format ( ontology = self . onto )) return \" \\n \" . join ( doc )","title":"Parameters"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.OntoDoc.get_default_template","text":"Returns default template. Source code in ontopy/ontodoc.py def get_default_template ( self ): \"\"\"Returns default template.\"\"\" title = os . path . splitext ( os . path . basename ( self . onto . base_iri . rstrip ( \"/#\" )) )[ 0 ] irilink = self . style . get ( \"link\" , \" {name} \" ) . format ( name = self . onto . base_iri , url = self . onto . base_iri , lowerurl = self . onto . base_iri , ) template = dedent ( \"\"\"\\ %HEADER {title} Documentation of {irilink} %HEADER Relations level=2 %ALL object_properties %HEADER Classes level=2 %ALL classes %HEADER Individuals level=2 %ALL individuals %HEADER Appendix level=1 %HEADER \"Relation taxonomies\" level=2 %ALLFIG object_properties %HEADER \"Class taxonomies\" level=2 %ALLFIG classes \"\"\" ) . format ( ontology = self . onto , title = title , irilink = irilink ) return template","title":"get_default_template()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.OntoDoc.get_figure","text":"Returns a formatted insert-figure-directive. Source code in ontopy/ontodoc.py def get_figure ( self , path , caption = \"\" , width = None ): \"\"\"Returns a formatted insert-figure-directive.\"\"\" figwidth_style = self . style . get ( \"figwidth\" , \"\" ) figure_style = self . style . get ( \"figure\" , \"\" ) figwidth = figwidth_style . format ( width = width ) if width else \"\" return figure_style . format ( path = path , caption = caption , figwidth = figwidth )","title":"get_figure()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.OntoDoc.get_header","text":"Returns label formatted as a header of given level. Source code in ontopy/ontodoc.py def get_header ( self , label , header_level = 1 ): \"\"\"Returns `label` formatted as a header of given level.\"\"\" header_style = self . style . get ( \"header\" , \" {label} \\n \" ) return header_style . format ( \"\" , level = header_level , label = label , lowerlabel = label . lower () )","title":"get_header()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.OntoDoc.itemdoc","text":"Returns documentation of item .","title":"itemdoc()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.OntoDoc.itemdoc--parameters","text":"item : obj | label The class, individual or relation to document. header_level : int Header level. Defaults to 3. show_disjoints : Bool Whether to show disjoint_with relations. Source code in ontopy/ontodoc.py def itemdoc ( self , item , header_level = 3 , show_disjoints = False ): # pylint: disable=too-many-locals,too-many-branches,too-many-statements \"\"\"Returns documentation of `item`. Parameters ---------- item : obj | label The class, individual or relation to document. header_level : int Header level. Defaults to 3. show_disjoints : Bool Whether to show `disjoint_with` relations. \"\"\" onto = self . onto if isinstance ( item , str ): item = self . onto . get_by_label ( item ) header_style = self . style . get ( \"header\" , \" {label} \\n \" ) link_style = self . style . get ( \"link\" , \" {name} \" ) point_style = self . style . get ( \"point\" , \" {point} \" ) points_style = self . style . get ( \"points\" , \" {points} \" ) annotation_style = self . style . get ( \"annotation\" , \" {key} : {value} \\n \" ) substitutions = self . style . get ( \"substitutions\" , []) # Logical \"sorting\" of annotations order = dict ( definition = \"00\" , axiom = \"01\" , theorem = \"02\" , elucidation = \"03\" , domain = \"04\" , range = \"05\" , example = \"06\" , ) doc = [] # Header label = get_label ( item ) doc . append ( header_style . format ( \"\" , level = header_level , label = label , lowerlabel = label . lower () ) ) # Add warning about missing prefLabel if not hasattr ( item , \"prefLabel\" ) or not item . prefLabel . first (): doc . append ( annotation_style . format ( key = \"Warning\" , value = \"Missing prefLabel\" ) ) # Add iri doc . append ( annotation_style . format ( key = \"IRI\" , value = asstring ( item . iri , link_style ), ontology = onto ) ) # Add annotations if isinstance ( item , owlready2 . Thing ): annotations = item . get_individual_annotations () else : annotations = item . get_annotations () for key in sorted ( annotations . keys (), key = lambda key : order . get ( key , key ) ): for value in annotations [ key ]: if self . url_regex . match ( value ): doc . append ( annotation_style . format ( key = key , value = asstring ( value , link_style ) ) ) else : for reg , sub in substitutions : value = re . sub ( reg , sub , value ) doc . append ( annotation_style . format ( key = key , value = value )) # ...add relations from is_a points = [] non_prop = ( owlready2 . ThingClass , # owlready2.Restriction, owlready2 . And , owlready2 . Or , owlready2 . Not , ) for prop in item . is_a : if isinstance ( prop , non_prop ) or ( isinstance ( item , owlready2 . PropertyClass ) and isinstance ( prop , owlready2 . PropertyClass ) ): points . append ( point_style . format ( point = \"is_a \" + asstring ( prop , link_style ), ontology = onto , ) ) else : points . append ( point_style . format ( point = asstring ( prop , link_style ), ontology = onto ) ) # ...add equivalent_to relations for entity in item . equivalent_to : points . append ( point_style . format ( point = \"equivalent_to \" + asstring ( entity , link_style ) ) ) # ...add disjoint_with relations if show_disjoints and hasattr ( item , \"disjoint_with\" ): subjects = set ( item . disjoint_with ( reduce = True )) points . append ( point_style . format ( point = \"disjoint_with \" + \", \" . join ( asstring ( _ , link_style ) for _ in subjects ), ontology = onto , ) ) # ...add disjoint_unions if hasattr ( item , \"disjoint_unions\" ): for unions in item . disjoint_unions : string = \", \" . join ( asstring ( _ , link_style ) for _ in unions ) points . append ( point_style . format ( point = f \"disjoint_union_of { string } \" , ontology = onto ) ) # ...add inverse_of relations if hasattr ( item , \"inverse_property\" ) and item . inverse_property : points . append ( point_style . format ( point = \"inverse_of \" + asstring ( item . inverse_property , link_style ) ) ) # ...add domain restrictions for domain in getattr ( item , \"domain\" , ()): points . append ( point_style . format ( point = f \"domain { asstring ( domain , link_style ) } \" ) ) # ...add range restrictions for restriction in getattr ( item , \"range\" , ()): points . append ( point_style . format ( point = f \"range { asstring ( restriction , link_style ) } \" ) ) # Add points (from is_a) if points : value = points_style . format ( points = \"\" . join ( points ), ontology = onto ) doc . append ( annotation_style . format ( key = \"Subclass of\" , value = value , ontology = onto ) ) # Instances (individuals) if hasattr ( item , \"instances\" ): points = [] for entity in [ _ for _ in item . instances () if item in _ . is_instance_of ]: points . append ( point_style . format ( point = asstring ( entity , link_style ), ontology = onto ) ) if points : value = points_style . format ( points = \"\" . join ( points ), ontology = onto ) doc . append ( annotation_style . format ( key = \"Individuals\" , value = value , ontology = onto ) ) return \" \\n \" . join ( doc )","title":"Parameters"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.OntoDoc.itemsdoc","text":"Returns documentation of items . Source code in ontopy/ontodoc.py def itemsdoc ( self , items , header_level = 3 ): \"\"\"Returns documentation of `items`.\"\"\" sep_style = self . style . get ( \"sep\" , \" \\n \" ) doc = [] for item in items : doc . append ( self . itemdoc ( item , header_level )) doc . append ( sep_style . format ( ontology = self . onto )) return \" \\n \" . join ( doc )","title":"itemsdoc()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.append_pandoc_options","text":"Append updates to pandoc options options .","title":"append_pandoc_options()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.append_pandoc_options--parameters","text":"options : sequence Sequence with initial Pandoc options. updates : sequence of str Sequence of strings of the form \"--longoption=value\", where longoption is a valid pandoc long option and value is the new value. The \"=value\" part is optional. Strings of the form \"no-longoption\" will filter out \"--longoption\" from `options`.","title":"Parameters"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.append_pandoc_options--returns","text":"new_options : list Updated pandoc options. Source code in ontopy/ontodoc.py def append_pandoc_options ( options , updates ): \"\"\"Append `updates` to pandoc options `options`. Parameters ---------- options : sequence Sequence with initial Pandoc options. updates : sequence of str Sequence of strings of the form \"--longoption=value\", where ``longoption`` is a valid pandoc long option and ``value`` is the new value. The \"=value\" part is optional. Strings of the form \"no-longoption\" will filter out \"--longoption\" from `options`. Returns ------- new_options : list Updated pandoc options. \"\"\" # Valid pandoc options starting with \"--no-XXX\" no_options = set ( \"no-highlight\" ) if not updates : return list ( options ) curated_updates = {} for update in updates : key , sep , value = update . partition ( \"=\" ) curated_updates [ key . lstrip ( \"-\" )] = value if sep else None filter_out = set ( _ for _ in curated_updates if _ . startswith ( \"no-\" ) and _ not in no_options ) _filter_out = set ( f \"-- { _ [ 3 :] } \" for _ in filter_out ) new_options = [ opt for opt in options if opt . partition ( \"=\" )[ 0 ] not in _filter_out ] new_options . extend ( [ f \"-- { key } \" if value is None else f \"-- { key } = { value } \" for key , value in curated_updates . items () if key not in filter_out ] ) return new_options","title":"Returns"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.get_docpp","text":"Read infile and return a new docpp instance. Source code in ontopy/ontodoc.py def get_docpp ( # pylint: disable=too-many-arguments ontodoc , infile , figdir = \"genfigs\" , figformat = \"png\" , maxwidth = None , imported = False , ): \"\"\"Read `infile` and return a new docpp instance.\"\"\" if infile : with open ( infile , \"rt\" ) as handle : template = handle . read () basedir = os . path . dirname ( infile ) else : template = ontodoc . get_default_template () basedir = \".\" docpp = DocPP ( template , ontodoc , basedir = basedir , figdir = figdir , figformat = figformat , maxwidth = maxwidth , imported = imported , ) return docpp","title":"get_docpp()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.get_figformat","text":"Infer preferred figure format from output format. Source code in ontopy/ontodoc.py def get_figformat ( fmt ): \"\"\"Infer preferred figure format from output format.\"\"\" if fmt == \"pdf\" : figformat = \"pdf\" # XXX elif \"html\" in fmt : figformat = \"svg\" else : figformat = \"png\" return figformat","title":"get_figformat()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.get_format","text":"Infer format from outfile and format. Source code in ontopy/ontodoc.py def get_format ( outfile , fmt = None ): \"\"\"Infer format from outfile and format.\"\"\" if fmt is None : fmt = os . path . splitext ( outfile )[ 1 ] if not fmt : fmt = \"html\" if fmt . startswith ( \".\" ): fmt = fmt [ 1 :] return fmt","title":"get_format()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.get_maxwidth","text":"Infer preferred max figure width from output format. Source code in ontopy/ontodoc.py def get_maxwidth ( fmt ): \"\"\"Infer preferred max figure width from output format.\"\"\" if fmt == \"pdf\" : maxwidth = 668 else : maxwidth = 1024 return maxwidth","title":"get_maxwidth()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.get_options","text":"Returns a dict with options from the sequence opts with \"name=value\" pairs. Valid option names and default values are provided with the keyword arguments. Source code in ontopy/ontodoc.py def get_options ( opts , ** kwargs ): \"\"\"Returns a dict with options from the sequence `opts` with \"name=value\" pairs. Valid option names and default values are provided with the keyword arguments.\"\"\" res = AttributeDict ( kwargs ) for opt in opts : if \"=\" not in opt : raise InvalidTemplateError ( f 'Missing \"=\" in template option: { opt !r} ' ) name , value = opt . split ( \"=\" , 1 ) if name not in res : raise InvalidTemplateError ( f \"Invalid template option: { name !r} \" ) res_type = type ( res [ name ]) res [ name ] = res_type ( value ) return res","title":"get_options()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.get_style","text":"Infer style from output format. Source code in ontopy/ontodoc.py def get_style ( fmt ): \"\"\"Infer style from output format.\"\"\" if fmt == \"simple-html\" : style = \"html\" elif fmt in ( \"tex\" , \"latex\" , \"pdf\" ): style = \"markdown_tex\" else : style = \"markdown\" return style","title":"get_style()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.load_pandoc_option_file","text":"Loads pandoc options from yamlfile and return a list with corresponding pandoc command line arguments. Source code in ontopy/ontodoc.py def load_pandoc_option_file ( yamlfile ): \"\"\"Loads pandoc options from `yamlfile` and return a list with corresponding pandoc command line arguments.\"\"\" with open ( yamlfile ) as handle : pandoc_options = yaml . safe_load ( handle ) options = pandoc_options . pop ( \"input-files\" , []) variables = pandoc_options . pop ( \"variables\" , {}) for key , value in pandoc_options . items (): if isinstance ( value , bool ): if value : options . append ( f \"-- { key } \" ) else : options . append ( f \"-- { key } = { value } \" ) for key , value in variables . items (): if key == \"date\" and value == \"now\" : value = time . strftime ( \"%B %d , %Y\" ) options . append ( f \"--variable= { key } : { value } \" ) return options","title":"load_pandoc_option_file()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.run_pandoc","text":"Runs pandoc.","title":"run_pandoc()"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.run_pandoc--parameters","text":"genfile : str Name of markdown input file. outfile : str Output file name. fmt : str Output format. pandoc_option_files : sequence List of files with additional pandoc options. Default is to read \"pandoc-options.yaml\" and \"pandoc-FORMAT-options.yml\", where FORMAT is the output format. pandoc_options : sequence Additional pandoc options overriding options read from pandoc_option_files . verbose : bool Whether to print the pandoc command before execution.","title":"Parameters"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.run_pandoc--raises","text":"subprocess.CalledProcessError If the pandoc process returns with non-zero status. The returncode attribute will hold the exit code. Source code in ontopy/ontodoc.py def run_pandoc ( # pylint: disable=too-many-arguments genfile , outfile , fmt , pandoc_option_files = (), pandoc_options = (), verbose = True , ): \"\"\"Runs pandoc. Parameters ---------- genfile : str Name of markdown input file. outfile : str Output file name. fmt : str Output format. pandoc_option_files : sequence List of files with additional pandoc options. Default is to read \"pandoc-options.yaml\" and \"pandoc-FORMAT-options.yml\", where `FORMAT` is the output format. pandoc_options : sequence Additional pandoc options overriding options read from `pandoc_option_files`. verbose : bool Whether to print the pandoc command before execution. Raises ------ subprocess.CalledProcessError If the pandoc process returns with non-zero status. The `returncode` attribute will hold the exit code. \"\"\" # Create pandoc argument list args = [ genfile ] files = [ \"pandoc-options.yaml\" , f \"pandoc- { fmt } -options.yaml\" ] if pandoc_option_files : files = pandoc_option_files for fname in files : if os . path . exists ( fname ): args . extend ( load_pandoc_option_file ( fname )) else : warnings . warn ( f \"missing pandoc option file: { fname } \" ) # Update pandoc argument list args = append_pandoc_options ( args , pandoc_options ) # pdf output requires a special attention... if fmt == \"pdf\" : pdf_engine = \"pdflatex\" for arg in args : if arg . startswith ( \"--pdf-engine\" ): pdf_engine = arg . split ( \"=\" , 1 )[ 1 ] break with TemporaryDirectory () as tmpdir : run_pandoc_pdf ( tmpdir , pdf_engine , outfile , args , verbose = verbose ) else : args . append ( f \"--output= { outfile } \" ) cmd = [ \"pandoc\" ] + args if verbose : print () print ( \"* Executing command:\" ) print ( \" \" . join ( shlex . quote ( _ ) for _ in cmd )) subprocess . check_call ( cmd ) # nosec","title":"Raises"},{"location":"api_reference/ontopy/ontodoc/#ontopy.ontodoc.run_pandoc_pdf","text":"Run pandoc for pdf generation. Source code in ontopy/ontodoc.py def run_pandoc_pdf ( latex_dir , pdf_engine , outfile , args , verbose = True ): \"\"\"Run pandoc for pdf generation.\"\"\" basename = os . path . join ( latex_dir , os . path . splitext ( os . path . basename ( outfile ))[ 0 ] ) # Run pandoc texfile = basename + \".tex\" args . append ( f \"--output= { texfile } \" ) cmd = [ \"pandoc\" ] + args if verbose : print () print ( \"* Executing commands:\" ) print ( \" \" . join ( shlex . quote ( s ) for s in cmd )) subprocess . check_call ( cmd ) # nosec # Fixing tex output texfile2 = basename + \"2.tex\" with open ( texfile , \"rt\" ) as handle : content = handle . read () . replace ( r \"\\$\\Uptheta\\$\" , r \"$\\Uptheta$\" ) with open ( texfile2 , \"wt\" ) as handle : handle . write ( content ) # Run latex pdffile = basename + \"2.pdf\" cmd = [ pdf_engine , texfile2 , \"-halt-on-error\" , f \"-output-directory= { latex_dir } \" , ] if verbose : print () print ( \" \" . join ( shlex . quote ( s ) for s in cmd )) output = subprocess . check_output ( cmd , timeout = 60 ) # nosec output = subprocess . check_output ( cmd , timeout = 60 ) # nosec # Workaround for non-working \"-output-directory\" latex option if not os . path . exists ( pdffile ): if os . path . exists ( os . path . basename ( pdffile )): pdffile = os . path . basename ( pdffile ) for ext in \"aux\" , \"out\" , \"toc\" , \"log\" : filename = os . path . splitext ( pdffile )[ 0 ] + \".\" + ext if os . path . exists ( filename ): os . remove ( filename ) else : print () print ( output ) print () raise RuntimeError ( \"latex did not produce pdf file: \" + pdffile ) # Copy pdffile if not os . path . exists ( outfile ) or not os . path . samefile ( pdffile , outfile ): if verbose : print () print ( f \"move { pdffile } to { outfile } \" ) shutil . move ( pdffile , outfile )","title":"run_pandoc_pdf()"},{"location":"api_reference/ontopy/ontology/","text":"ontology \u00b6 A module adding additional functionality to owlready2. If desirable some of these additions may be moved back into owlready2. BlankNode \u00b6 Represents a blank node. A blank node is a node that is not a literal and has no IRI. Resources represented by blank nodes are also called anonumous resources. Only the subject or object in an RDF triple can be a blank node. Source code in ontopy/ontology.py class BlankNode : \"\"\"Represents a blank node. A blank node is a node that is not a literal and has no IRI. Resources represented by blank nodes are also called anonumous resources. Only the subject or object in an RDF triple can be a blank node. \"\"\" def __init__ ( self , onto : Union [ World , Ontology ], storid : int ): \"\"\"Initiate a blank node. Args: onto: Ontology or World instance. storid: The storage id of the blank node. \"\"\" if storid >= 0 : raise ValueError ( f \"A BlankNode is supposed to have a negative storid: { storid } \" ) self . onto = onto self . storid = storid def __repr__ ( self ): return repr ( f \"_:b { - self . storid } \" ) def __hash__ ( self ): return hash (( self . onto , self . storid )) def __eq__ ( self , other ): \"\"\"For now blank nodes always compare true against each other.\"\"\" return isinstance ( other , BlankNode ) __init__ ( self , onto , storid ) special \u00b6 Initiate a blank node. Parameters: Name Type Description Default onto Union[ontopy.ontology.World, ontopy.ontology.Ontology] Ontology or World instance. required storid int The storage id of the blank node. required Source code in ontopy/ontology.py def __init__ ( self , onto : Union [ World , Ontology ], storid : int ): \"\"\"Initiate a blank node. Args: onto: Ontology or World instance. storid: The storage id of the blank node. \"\"\" if storid >= 0 : raise ValueError ( f \"A BlankNode is supposed to have a negative storid: { storid } \" ) self . onto = onto self . storid = storid Ontology ( Ontology ) \u00b6 A generic class extending owlready2.Ontology. Source code in ontopy/ontology.py class Ontology ( owlready2 . Ontology ): # pylint: disable=too-many-public-methods \"\"\"A generic class extending owlready2.Ontology.\"\"\" def __init__ ( self , * args , ** kwargs ): # Properties controlling what annotations that are considered by # get_by_label() super () . __init__ ( * args , ** kwargs ) self . _label_annotations = None self . prefix = None # Properties controlling what annotations that are considered by # get_by_label() label_annotations = property ( fget = lambda self : self . _label_annotations , doc = \"List of label annotation searched for by get_by_label().\" , ) # Name of special unlabeled entities, like Thing, Nothing, etc... _special_labels = None # Some properties for customising dir() listing - useful in # interactive sessions... _dir_preflabel = isinteractive () _dir_label = isinteractive () _dir_name = False _dir_imported = isinteractive () dir_preflabel = property ( fget = lambda self : self . _dir_preflabel , fset = lambda self , v : setattr ( self , \"_dir_preflabel\" , bool ( v )), doc = \"Whether to include entity prefLabel in dir() listing.\" , ) dir_label = property ( fget = lambda self : self . _dir_label , fset = lambda self , v : setattr ( self , \"_dir_label\" , bool ( v )), doc = \"Whether to include entity label in dir() listing.\" , ) dir_name = property ( fget = lambda self : self . _dir_name , fset = lambda self , v : setattr ( self , \"_dir_name\" , bool ( v )), doc = \"Whether to include entity name in dir() listing.\" , ) dir_imported = property ( fget = lambda self : self . _dir_imported , fset = lambda self , v : setattr ( self , \"_dir_imported\" , bool ( v )), doc = \"Whether to include imported ontologies in dir() listing.\" , ) def __dir__ ( self ): set_dir = set ( super () . __dir__ ()) lst = list ( self . get_entities ( imported = self . _dir_imported )) if self . _dir_preflabel : set_dir . update ( _ . prefLabel . first () for _ in lst if hasattr ( _ , \"prefLabel\" ) ) if self . _dir_label : set_dir . update ( _ . label . first () for _ in lst if hasattr ( _ , \"label\" )) if self . _dir_name : set_dir . update ( _ . name for _ in lst if hasattr ( _ , \"name\" )) set_dir . difference_update ({ None }) # get rid of possible None return sorted ( set_dir ) def __getitem__ ( self , name ): item = super () . __getitem__ ( name ) if not item : item = self . get_by_label ( name ) return item def __getattr__ ( self , name ): attr = super () . __getattr__ ( name ) if not attr : attr = self . get_by_label ( name ) return attr def __contains__ ( self , other ): if self . world [ other ]: return True try : self . get_by_label ( other ) except NoSuchLabelError : return False else : return True def __objclass__ ( self ): # Play nice with inspect... pass def __hash__ ( self ): \"\"\"Returns a hash based on base_iri. This is done to keep Ontology hashable when defining __eq__. \"\"\" return hash ( self . base_iri ) def __eq__ ( self , other ): \"\"\"Checks if this ontology is equal to `other`. This function compares the result of ``set(self.get_unabbreviated_triples(label='_:b'))``, i.e. blank nodes are not distinguished, but relations to blank nodes are included. \"\"\" return set ( self . get_unabbreviated_triples ( blank = \"_:b\" )) == set ( other . get_unabbreviated_triples ( blank = \"_:b\" ) ) def get_unabbreviated_triples ( self , subject = None , predicate = None , obj = None , blank = None ): \"\"\"Returns all matching triples unabbreviated. If `blank` is given, it will be used to represent blank nodes. \"\"\" # pylint: disable=invalid-name return _get_unabbreviated_triples ( self , subject = subject , predicate = predicate , obj = obj , blank = blank ) def get_by_label ( self , label : str , label_annotations : str = None , prefix : str = None ): \"\"\"Returns entity with label annotation `label`. Args: label: label so serach for. May be written as 'label' or 'prefix:label'. get_by_label('prefix:label') == get_by_label('label', prefix='prefix'). label_annotations: a sequence of label annotation names to look up. Defaults to the `label_annotations` property. prefix: if provided, it should be the last component of the base iri of an ontology (with trailing slash (/) or hash (#) stripped off). The search for a matching label will be limited to this namespace. If several entities have the same label, only the one which is found first is returned.Use get_by_label_all() to get all matches. A NoSuchLabelError is raised if `label` cannot be found. Note ---- The current implementation also supports \"*\" as a wildcard matching any number of characters. This may change in the future. \"\"\" # pylint: disable=too-many-arguments,too-many-branches if not isinstance ( label , str ): raise TypeError ( f \"Invalid label definition, must be a string: { label !r} \" ) if \" \" in label : raise ValueError ( f \"Invalid label definition, { label !r} contains spaces.\" ) if self . _label_annotations is None : for iri in DEFAULT_LABEL_ANNOTATIONS : try : self . add_label_annotation ( iri ) except ValueError : pass splitlabel = label . split ( \":\" ) if len ( splitlabel ) > 2 : raise ValueError ( f \"Invalid label definition, { label !r} \" \" contains more than one ':' .\" \"The string before ':' indicates the prefix. \" \"The string after ':' indicates the label.\" ) if len ( splitlabel ) == 2 : label = splitlabel [ 1 ] if prefix and prefix != splitlabel [ 0 ]: warnings . warn ( f \"Prefix given both as argument ( { prefix } ) \" f \"and in label ( { splitlabel [ 0 ] } ). \" \"Prefix given in label takes presendence \" ) prefix = splitlabel [ 0 ] if prefix : entitylist = self . get_by_label_all ( label , label_annotations = label_annotations , prefix = prefix , ) if len ( entitylist ) > 0 : return entitylist [ 0 ] raise NoSuchLabelError ( f \"No label annotations matches { label !r} with prefix \" f \" { prefix !r} \" ) # if label in self._namespaces: # return self._namespaces[label] if label_annotations is None : annotations = ( a . name for a in self . label_annotations ) else : annotations = ( a . name if hasattr ( a , \"storid\" ) else a for a in label_annotations ) for key in annotations : entity = self . search_one ( ** { key : label }) if entity : return entity if self . _special_labels and label in self . _special_labels : return self . _special_labels [ label ] entity = self . world [ self . base_iri + label ] if entity : return entity raise NoSuchLabelError ( f \"No label annotations matches { label !r} \" ) def get_by_label_all ( self , label , label_annotations = None , prefix = None ): \"\"\"Like get_by_label(), but returns a list with all matching labels. Returns an empty list if no matches could be found. \"\"\" if not isinstance ( label , str ): raise TypeError ( f \"Invalid label definition, \" f \"must be a string: { label !r} \" ) if \" \" in label : raise ValueError ( f \"Invalid label definition, { label !r} contains spaces.\" ) if label_annotations is None : annotations = ( _ . name for _ in self . label_annotations ) else : annotations = ( _ . name if hasattr ( _ , \"storid\" ) else _ for _ in label_annotations ) entity = self . world . search ( ** { next ( annotations ): label }) for key in annotations : entity . extend ( self . world . search ( ** { key : label })) if self . _special_labels and label in self . _special_labels : entity . append ( self . _special_labels [ label ]) if prefix : return [ _ for _ in entity if _ . namespace . ontology . prefix == prefix ] return entity def add_label_annotation ( self , iri ): \"\"\"Adds label annotation used by get_by_label(). May be provided either as an IRI or as its owlready2 representation. \"\"\" if self . _label_annotations is None : self . _label_annotations = [] label_annotation = iri if hasattr ( iri , \"storid\" ) else self . world [ iri ] if label_annotation is None : warnings . warn ( f \"adding new IRI to ontology: { iri } \" ) name = iri . rsplit ( \"/\" )[ - 1 ] . rsplit ( \"#\" )[ - 1 ] bases = ( owlready2 . AnnotationProperty ,) with self : label_annotation = types . new_class ( name , bases ) if label_annotation not in self . _label_annotations : self . _label_annotations . append ( label_annotation ) def remove_label_annotation ( self , iri ): \"\"\"Removes label annotation used by get_by_label(). May be provided either as an IRI or as its owlready2 representation. \"\"\" label_annotation = iri if hasattr ( iri , \"storid\" ) else self . world [ iri ] if not label_annotation : raise ValueError ( f \"IRI not in ontology: { iri } \" ) self . _label_annotations . remove ( label_annotation ) def set_common_prefix ( self , iri_base : str = \"http://emmo.info/emmo\" , prefix : str = \"emmo\" , ) -> None : \"\"\"Set a common prefix for all imported ontologies with the same first part of the base_iri. Args: iri_base: The start of the base_iri to look for. Defaults to the emmo base_iri http://emmo.info/emmo prefix: the desired prefix. Defaults to emmo. \"\"\" if self . base_iri . startswith ( iri_base ): self . prefix = prefix for onto in self . imported_ontologies : onto . set_common_prefix ( iri_base = iri_base , prefix = prefix ) def load ( # pylint: disable=too-many-arguments,arguments-renamed self , only_local = False , filename = None , format = None , # pylint: disable=redefined-builtin reload = None , reload_if_newer = False , url_from_catalog = None , catalog_file = \"catalog-v001.xml\" , emmo_based = True , prefix = None , prefix_emmo = None , ** kwargs , ): \"\"\"Load the ontology. Parameters ---------- only_local: bool Whether to only read local files. This requires that you have appended the path to the ontology to owlready2.onto_path. filename: str Path to file to load the ontology from. Defaults to `base_iri` provided to get_ontology(). format: str Format of `filename`. Default is inferred from `filename` extension. reload: bool Whether to reload the ontology if it is already loaded. reload_if_newer: bool Whether to reload the ontology if the source has changed since last time it was loaded. url_from_catalog: bool | None Whether to use catalog file to resolve the location of `base_iri`. If None, the catalog file is used if it exists in the same directory as `filename`. catalog_file: str Name of Prot\u00e8g\u00e8 catalog file in the same folder as the ontology. This option is used together with `only_local` and defaults to \"catalog-v001.xml\". emmo_based: bool Whether this is an EMMO-based ontology or not, default `True`. prefix: defaults to self.get_namespace.name if prefix_emmo: bool, default None. If emmo_based is True it defaults to True and sets the prefix of all imported ontologies with base_iri starting with 'http://emmo.info/emmo' to emmo kwargs: Additional keyword arguments are passed on to owlready2.Ontology.load(). \"\"\" # TODO: make sure that `only_local` argument is respected... if self . loaded : return self self . _load ( only_local = only_local , filename = filename , format = format , reload = reload , reload_if_newer = reload_if_newer , url_from_catalog = url_from_catalog , catalog_file = catalog_file , ** kwargs , ) # Enable optimised search by get_by_label() if self . _special_labels is None and emmo_based : for iri in DEFAULT_LABEL_ANNOTATIONS : self . add_label_annotation ( iri ) top = self . world [ \"http://www.w3.org/2002/07/owl#topObjectProperty\" ] self . _special_labels = { \"Thing\" : owlready2 . Thing , \"Nothing\" : owlready2 . Nothing , \"topObjectProperty\" : top , \"owl:Thing\" : owlready2 . Thing , \"owl:Nothing\" : owlready2 . Nothing , \"owl:topObjectProperty\" : top , } # set prefix if another prefix is desired # if we do this, shouldn't we make the name of all # entities of the given ontology to the same? if prefix : self . prefix = prefix else : self . prefix = self . name if emmo_based and prefix_emmo is None : prefix_emmo = True if prefix_emmo : self . set_common_prefix () return self def _load ( # pylint: disable=too-many-arguments,too-many-locals,too-many-branches,too-many-statements self , only_local = False , filename = None , format = None , # pylint: disable=redefined-builtin reload = None , reload_if_newer = False , url_from_catalog = None , catalog_file = \"catalog-v001.xml\" , ** kwargs , ): \"\"\"Help function for load().\"\"\" web_protocol = \"http://\" , \"https://\" , \"ftp://\" url = str ( filename ) if filename else self . base_iri . rstrip ( \"/#\" ) if url . startswith ( web_protocol ): baseurl = os . path . dirname ( url ) catalogurl = baseurl + \"/\" + catalog_file else : if url . startswith ( \"file://\" ): url = url [ 7 :] url = os . path . normpath ( os . path . abspath ( url )) baseurl = os . path . dirname ( url ) catalogurl = os . path . join ( baseurl , catalog_file ) def getmtime ( path ): if os . path . exists ( path ): return os . path . getmtime ( path ) return 0.0 # Resolve url from catalog file iris = {} dirs = set () if url_from_catalog or url_from_catalog is None : not_reload = not reload and ( not reload_if_newer or getmtime ( catalogurl ) > self . world . _cached_catalogs [ catalogurl ][ 0 ] ) # get iris from catalog already in cached catalogs if catalogurl in self . world . _cached_catalogs and not_reload : _ , iris , dirs = self . world . _cached_catalogs [ catalogurl ] # do not update cached_catalogs if url already in _iri_mappings # and reload not forced elif url in self . world . _iri_mappings and not_reload : pass # update iris from current catalogurl else : try : iris , dirs = read_catalog ( uri = catalogurl , recursive = False , return_paths = True , catalog_file = catalog_file , ) except ReadCatalogError : if url_from_catalog is not None : raise self . world . _cached_catalogs [ catalogurl ] = ( 0.0 , {}, set ()) else : self . world . _cached_catalogs [ catalogurl ] = ( getmtime ( catalogurl ), iris , dirs , ) self . world . _iri_mappings . update ( iris ) resolved_url = self . world . _iri_mappings . get ( url , url ) # Append paths from catalog file to onto_path for path in sorted ( dirs , reverse = True ): if path not in owlready2 . onto_path : owlready2 . onto_path . append ( path ) # Use catalog file to update IRIs of imported ontologies # in internal store and try to load again... if self . world . _iri_mappings : for abbrev_iri in self . world . _get_obj_triples_sp_o ( self . storid , owlready2 . owl_imports ): iri = self . _unabbreviate ( abbrev_iri ) if iri in self . world . _iri_mappings : self . _del_obj_triple_spo ( self . storid , owlready2 . owl_imports , abbrev_iri ) self . _add_obj_triple_spo ( self . storid , owlready2 . owl_imports , self . _abbreviate ( self . world . _iri_mappings [ iri ]), ) # Load ontology try : self . loaded = False fmt = format if format else guess_format ( resolved_url , fmap = FMAP ) if fmt and fmt not in OWLREADY2_FORMATS : # Convert filename to rdfxml before passing it to owlready2 graph = rdflib . Graph () try : graph . parse ( resolved_url , format = fmt ) except URLError as err : raise EMMOntoPyException ( \"URL error\" , err , resolved_url ) from err with tempfile . NamedTemporaryFile () as handle : graph . serialize ( destination = handle , format = \"xml\" ) handle . seek ( 0 ) return super () . load ( only_local = True , fileobj = handle , reload = reload , reload_if_newer = reload_if_newer , format = \"rdfxml\" , ** kwargs , ) elif resolved_url . startswith ( web_protocol ): return super () . load ( only_local = only_local , reload = reload , reload_if_newer = reload_if_newer , ** kwargs , ) else : with open ( resolved_url , \"rb\" ) as handle : return super () . load ( only_local = only_local , fileobj = handle , reload = reload , reload_if_newer = reload_if_newer , ** kwargs , ) except owlready2 . OwlReadyOntologyParsingError : # Owlready2 is not able to parse the ontology - most # likely because imported ontologies must be resolved # using the catalog file. # Reraise if we don't want to read from the catalog file if not url_from_catalog and url_from_catalog is not None : raise warnings . warn ( \"Recovering from Owlready2 parsing error... might be deprecated\" ) # Copy the ontology into a local folder and try again with tempfile . TemporaryDirectory () as handle : output = os . path . join ( handle , os . path . basename ( resolved_url )) convert_imported ( input_ontology = resolved_url , output_ontology = output , input_format = fmt , output_format = \"xml\" , url_from_catalog = url_from_catalog , catalog_file = catalog_file , ) self . loaded = False with open ( output , \"rb\" ) as handle : try : return super () . load ( only_local = True , fileobj = handle , reload = reload , reload_if_newer = reload_if_newer , format = \"rdfxml\" , ** kwargs , ) except HTTPError as exc : # Add url to HTTPError message raise HTTPError ( url = exc . url , code = exc . code , msg = f \" { exc . url } : { exc . msg } \" , hdrs = exc . hdrs , fp = exc . fp , ) . with_traceback ( exc . __traceback__ ) except HTTPError as exc : # Add url to HTTPError message raise HTTPError ( url = exc . url , code = exc . code , msg = f \" { exc . url } : { exc . msg } \" , hdrs = exc . hdrs , fp = exc . fp , ) . with_traceback ( exc . __traceback__ ) def save ( self , filename = None , format = None , dir = \".\" , mkdir = False , overwrite = False , recursive = False , squash = False , write_catalog_file = False , append_catalog = False , catalog_file = \"catalog-v001.xml\" , ): \"\"\"Writes the ontology to file. Parameters ---------- filename: None | str | Path Name of file to write to. If None, it defaults to the name of the ontology with `format` as file extension. format: str Output format. The default is to infer it from `filename`. dir: str | Path If `filename` is a relative path, it is a relative path to `dir`. mkdir: bool Whether to create output directory if it does not exists. owerwrite: bool If true and `filename` exists, remove the existing file before saving. The default is to append to an existing ontology. recursive: bool Whether to save imported ontologies recursively. This is commonly combined with `filename=None`, `dir` and `mkdir`. squash: bool If true, rdflib will be used to save the current ontology together with all its sub-ontologies into `filename`. It make no sense to combine this with `recursive`. write_catalog_file: bool Whether to also write a catalog file to disk. append_catalog: bool Whether to append to an existing catalog file. catalog_file: str | Path Name of catalog file. If not an absolute path, it is prepended to `dir`. \"\"\" # pylint: disable=redefined-builtin,too-many-arguments # pylint: disable=too-many-statements,too-many-branches # pylint: disable=too-many-locals,arguments-renamed if not _validate_installed_version ( package = \"rdflib\" , min_version = \"6.0.0\" ) and format == FMAP . get ( \"ttl\" , \"\" ): from rdflib import ( # pylint: disable=import-outside-toplevel __version__ as __rdflib_version__ , ) warnings . warn ( IncompatibleVersion ( \"To correctly convert to Turtle format, rdflib must be \" \"version 6.0.0 or greater, however, the detected rdflib \" \"version used by your Python interpreter is \" f \" { __rdflib_version__ !r} . For more information see the \" \"'Known issues' section of the README.\" ) ) revmap = { value : key for key , value in FMAP . items ()} if filename is None : if format : fmt = revmap . get ( format , format ) filename = f \" { self . name } . { fmt } \" else : TypeError ( \"`filename` and `format` cannot both be None.\" ) filename = os . path . join ( dir , filename ) dir = Path ( filename ) . resolve () . parent if mkdir : outdir = Path ( filename ) . parent . resolve () if not outdir . exists (): outdir . mkdir ( parents = True ) if not format : format = guess_format ( filename , fmap = FMAP ) fmt = revmap . get ( format , format ) if overwrite and filename and os . path . exists ( filename ): os . remove ( filename ) EMMO = rdflib . Namespace ( # pylint:disable=invalid-name \"http://emmo.info/emmo#\" ) if recursive : if squash : raise ValueError ( \"`recursive` and `squash` should not both be true\" ) base = self . base_iri . rstrip ( \"#/\" ) for onto in self . imported_ontologies : obase = onto . base_iri . rstrip ( \"#/\" ) newdir = Path ( dir ) / os . path . relpath ( obase , base ) onto . save ( filename = None , format = format , dir = newdir . resolve (), mkdir = mkdir , overwrite = overwrite , recursive = recursive , squash = squash , write_catalog_file = write_catalog_file , append_catalog = append_catalog , catalog_file = catalog_file , ) if squash : from rdflib import ( # pylint:disable=import-outside-toplevel URIRef , RDF , OWL , ) graph = self . world . as_rdflib_graph () graph . namespace_manager . bind ( \"emmo\" , EMMO ) # Remove anonymous namespace and imports graph . remove (( URIRef ( \"http://anonymous\" ), RDF . type , OWL . Ontology )) imports = list ( graph . triples (( None , OWL . imports , None ))) for triple in imports : graph . remove ( triple ) graph . serialize ( destination = filename , format = format ) elif format in OWLREADY2_FORMATS : super () . save ( file = filename , format = fmt ) else : # The try-finally clause is needed for cleanup and because # we have to provide delete=False to NamedTemporaryFile # since Windows does not allow to reopen an already open # file. try : with tempfile . NamedTemporaryFile ( suffix = \".owl\" , delete = False ) as handle : tmpfile = handle . name super () . save ( tmpfile , format = \"rdfxml\" ) graph = rdflib . Graph () graph . parse ( tmpfile , format = \"xml\" ) graph . serialize ( destination = filename , format = format ) finally : os . remove ( tmpfile ) if write_catalog_file : mappings = {} base = self . base_iri . rstrip ( \"#/\" ) def append ( onto ): obase = onto . base_iri . rstrip ( \"#/\" ) newdir = Path ( dir ) / os . path . relpath ( obase , base ) newpath = newdir . resolve () / f \" { onto . name } . { fmt } \" relpath = os . path . relpath ( newpath , dir ) mappings [ onto . get_version ( as_iri = True )] = str ( relpath ) for imported in onto . imported_ontologies : append ( imported ) if recursive : append ( self ) write_catalog ( mappings , output = catalog_file , directory = dir , append = append_catalog , ) def get_imported_ontologies ( self , recursive = False ): \"\"\"Return a list with imported ontologies. If `recursive` is `True`, ontologies imported by imported ontologies are also returned. \"\"\" def rec_imported ( onto ): for ontology in onto . imported_ontologies : if ontology not in imported : imported . add ( ontology ) rec_imported ( ontology ) if recursive : imported = set () rec_imported ( self ) return list ( imported ) return self . imported_ontologies def get_entities ( # pylint: disable=too-many-arguments self , imported = True , classes = True , individuals = True , object_properties = True , data_properties = True , annotation_properties = True , ): \"\"\"Return a generator over (optionally) all classes, individuals, object_properties, data_properties and annotation_properties. If `imported` is `True`, entities in imported ontologies will also be included. \"\"\" generator = [] if classes : generator . append ( self . classes ( imported )) if individuals : generator . append ( self . individuals ( imported )) if object_properties : generator . append ( self . object_properties ( imported )) if data_properties : generator . append ( self . data_properties ( imported )) if annotation_properties : generator . append ( self . annotation_properties ( imported )) for entity in itertools . chain ( * generator ): yield entity def classes ( self , imported = False ): \"\"\"Returns an generator over all classes. If `imported` is `True`, will imported classes are also returned. \"\"\" if imported : return self . world . classes () return super () . classes () def individuals ( self , imported = False ): \"\"\"Returns an generator over all individuals. If `imported` is `True`, will imported individuals are also returned. \"\"\" if imported : return self . world . individuals () return super () . individuals () def object_properties ( self , imported = False ): \"\"\"Returns an generator over all object properties. If `imported` is true, will imported object properties are also returned. \"\"\" if imported : return self . world . object_properties () return super () . object_properties () def data_properties ( self , imported = False ): \"\"\"Returns an generator over all data properties. If `imported` is true, will imported data properties are also returned. \"\"\" if imported : return self . world . data_properties () return super () . data_properties () def annotation_properties ( self , imported = False ): \"\"\"Returns a generator iterating over all annotation properties defined in the current ontology. If `imported` is true, annotation properties in imported ontologies will also be included. \"\"\" if imported : return self . world . annotation_properties () return super () . annotation_properties () def get_root_classes ( self , imported = False ): \"\"\"Returns a list or root classes.\"\"\" return [ cls for cls in self . classes ( imported = imported ) if not cls . ancestors () . difference ( set ([ cls , owlready2 . Thing ])) ] def get_root_object_properties ( self , imported = False ): \"\"\"Returns a list of root object properties.\"\"\" props = set ( self . object_properties ( imported = imported )) return [ p for p in props if not props . intersection ( p . is_a )] def get_root_data_properties ( self , imported = False ): \"\"\"Returns a list of root object properties.\"\"\" props = set ( self . data_properties ( imported = imported )) return [ p for p in props if not props . intersection ( p . is_a )] def get_roots ( self , imported = False ): \"\"\"Returns all class, object_property and data_property roots.\"\"\" roots = self . get_root_classes ( imported = imported ) roots . extend ( self . get_root_object_properties ( imported = imported )) roots . extend ( self . get_root_data_properties ( imported = imported )) return roots def sync_python_names ( self , annotations = ( \"prefLabel\" , \"label\" , \"altLabel\" )): \"\"\"Update the `python_name` attribute of all properties. The python_name attribute will be set to the first non-empty annotation in the sequence of annotations in `annotations` for the property. \"\"\" def update ( gen ): for prop in gen : for annotation in annotations : if hasattr ( prop , annotation ) and getattr ( prop , annotation ): prop . python_name = getattr ( prop , annotation ) . first () break update ( self . get_entities ( classes = False , individuals = False , object_properties = False , data_properties = False , ) ) update ( self . get_entities ( classes = False , individuals = False , annotation_properties = False ) ) def rename_entities ( self , annotations = ( \"prefLabel\" , \"label\" , \"altLabel\" ), ): \"\"\"Set `name` of all entities to the first non-empty annotation in `annotations`. Warning, this method changes all IRIs in the ontology. However, it may be useful to make the ontology more readable and to work with it together with a triple store. \"\"\" for entity in self . get_entities (): for annotation in annotations : if hasattr ( entity , annotation ): name = getattr ( entity , annotation ) . first () if name : entity . name = name break def sync_reasoner ( self , reasoner = \"FaCT++\" , include_imported = False , ** kwargs ): \"\"\"Update current ontology by running the given reasoner. Supported values for `reasoner` are 'Pellet', 'HermiT' and 'FaCT++'. If `include_imported` is true, the reasoner will also reason over imported ontologies. Note that this may be **very** slow with Pellet and HermiT. Keyword arguments are passed to the underlying owlready2 function. \"\"\" if reasoner == \"FaCT++\" : sync = sync_reasoner_factpp elif reasoner == \"Pellet\" : sync = owlready2 . sync_reasoner_pellet elif reasoner == \"HermiT\" : sync = owlready2 . sync_reasoner_hermit else : raise ValueError ( f \"unknown reasoner { reasoner !r} . Supported reasoners \" 'are \"Pellet\", \"HermiT\" and \"FaCT++\".' ) # For some reason we must visit all entities once before running # the reasoner... list ( self . get_entities ()) with self : if include_imported : sync ( self . world , ** kwargs ) else : sync ( self , ** kwargs ) def sync_attributes ( # pylint: disable=too-many-branches self , name_policy = None , name_prefix = \"\" , class_docstring = \"comment\" , sync_imported = False , ): \"\"\"This method is intended to be called after you have added new classes (typically via Python) to make sure that attributes like `label` and `comments` are defined. If a class, object property, data property or annotation property in the current ontology has no label, the name of the corresponding Python class will be assigned as label. If a class, object property, data property or annotation property has no comment, it will be assigned the docstring of the corresponding Python class. `name_policy` specify wether and how the names in the ontology should be updated. Valid values are: None not changed \"uuid\" `name_prefix` followed by a global unique id (UUID). \"sequential\" `name_prefix` followed a sequantial number. EMMO conventions imply ``name_policy=='uuid'``. If `sync_imported` is true, all imported ontologies are also updated. The `class_docstring` argument specifies the annotation that class docstrings are mapped to. Defaults to \"comment\". \"\"\" for cls in itertools . chain ( self . classes (), self . object_properties (), self . data_properties (), self . annotation_properties (), ): if not hasattr ( cls , \"prefLabel\" ): # no prefLabel - create new annotation property.. with self : # pylint: disable=invalid-name,missing-class-docstring # pylint: disable=unused-variable class prefLabel ( owlready2 . label ): pass cls . prefLabel = [ locstr ( cls . __name__ , lang = \"en\" )] elif not cls . prefLabel : cls . prefLabel . append ( locstr ( cls . __name__ , lang = \"en\" )) if class_docstring and hasattr ( cls , \"__doc__\" ) and cls . __doc__ : getattr ( cls , class_docstring ) . append ( locstr ( inspect . cleandoc ( cls . __doc__ ), lang = \"en\" ) ) for ind in self . individuals (): if not hasattr ( ind , \"prefLabel\" ): # no prefLabel - create new annotation property.. with self : # pylint: disable=invalid-name,missing-class-docstring # pylint: disable=function-redefined class prefLabel ( owlready2 . label ): iri = \"http://www.w3.org/2004/02/skos/core#prefLabel\" ind . prefLabel = [ locstr ( ind . name , lang = \"en\" )] elif not ind . prefLabel : ind . prefLabel . append ( locstr ( ind . name , lang = \"en\" )) chain = itertools . chain ( self . classes (), self . individuals (), self . object_properties (), self . data_properties (), self . annotation_properties (), ) if name_policy == \"uuid\" : for obj in chain : obj . name = name_prefix + str ( uuid . uuid5 ( uuid . NAMESPACE_DNS , obj . name ) ) elif name_policy == \"sequential\" : for obj in chain : counter = 0 while f \" { self . base_iri }{ name_prefix }{ counter } \" in self : counter += 1 obj . name = f \" { name_prefix }{ counter } \" elif name_policy is not None : raise TypeError ( f \"invalid name_policy: { name_policy !r} \" ) if sync_imported : for onto in self . imported_ontologies : onto . sync_attributes () def get_relations ( self ): \"\"\"Returns a generator for all relations.\"\"\" warnings . warn ( \"Ontology.get_relations() is deprecated. Use \" \"onto.object_properties() instead.\" , DeprecationWarning , ) return self . object_properties () def get_annotations ( self , entity ): \"\"\"Returns a dict with annotations for `entity`. Entity may be given either as a ThingClass object or as a label.\"\"\" warnings . warn ( \"Ontology.get_annotations(entity) is deprecated. Use \" \"entity.get_annotations() instead.\" , DeprecationWarning , ) if isinstance ( entity , str ): entity = self . get_by_label ( entity ) res = { \"comment\" : getattr ( entity , \"comment\" , \"\" )} for annotation in self . annotation_properties (): res [ annotation . label . first ()] = [ obj . strip ( '\"' ) for _ , _ , obj in self . get_triples ( entity . storid , annotation . storid , None ) ] return res def get_branch ( # pylint: disable=too-many-arguments self , root , leafs = (), include_leafs = True , strict_leafs = False , exclude = None , sort = False , ): \"\"\"Returns a set with all direct and indirect subclasses of `root`. Any subclass found in the sequence `leafs` will be included in the returned list, but its subclasses will not. The elements of `leafs` may be ThingClass objects or labels. Subclasses of any subclass found in the sequence `leafs` will be excluded from the returned list, where the elements of `leafs` may be ThingClass objects or labels. If `include_leafs` is true, the leafs are included in the returned list, otherwise they are not. If `strict_leafs` is true, any descendant of a leaf will be excluded in the returned set. If given, `exclude` may be a sequence of classes, including their subclasses, to exclude from the output. If `sort` is True, a list sorted according to depth and label will be returned instead of a set. \"\"\" def _branch ( root , leafs ): if root not in leafs : branch = { root , } for cls in root . subclasses (): # Defining a branch is actually quite tricky. Consider # the case: # # L isA R # A isA L # A isA R # # where R is the root, L is a leaf and A is a direct # child of both. Logically, since A is a child of the # leaf we want to skip A. But a strait forward imple- # mentation will see that A is a child of the root and # include it. Requireing that the R should be a strict # parent of A solves this. if root in cls . get_parents ( strict = True ): branch . update ( _branch ( cls , leafs )) else : branch = ( { root , } if include_leafs else set () ) return branch if isinstance ( root , str ): root = self . get_by_label ( root ) leafs = set ( self . get_by_label ( leaf ) if isinstance ( leaf , str ) else leaf for leaf in leafs ) leafs . discard ( root ) if exclude : exclude = set ( self . get_by_label ( e ) if isinstance ( e , str ) else e for e in exclude ) leafs . update ( exclude ) branch = _branch ( root , leafs ) # Exclude all descendants of any leaf if strict_leafs : descendants = root . descendants () for leaf in leafs : if leaf in descendants : branch . difference_update ( leaf . descendants ( include_self = False ) ) if exclude : branch . difference_update ( exclude ) # Sort according to depth, then by label if sort : branch = sorted ( sorted ( branch , key = asstring ), key = lambda x : len ( x . mro ()), ) return branch def is_individual ( self , entity ): \"\"\"Returns true if entity is an individual.\"\"\" if isinstance ( entity , str ): entity = self . get_by_label ( entity ) return isinstance ( entity , owlready2 . Thing ) # FIXME - deprecate this method as soon the ThingClass property # `defined_class` works correct in Owlready2 def is_defined ( self , entity ): \"\"\"Returns true if the entity is a defined class.\"\"\" if isinstance ( entity , str ): entity = self . get_by_label ( entity ) return hasattr ( entity , \"equivalent_to\" ) and bool ( entity . equivalent_to ) def get_version ( self , as_iri = False ) -> str : \"\"\"Returns the version number of the ontology as inferred from the owl:versionIRI tag or, if owl:versionIRI is not found, from owl:versionINFO. If `as_iri` is True, the full versionIRI is returned. \"\"\" version_iri_storid = self . world . _abbreviate ( \"http://www.w3.org/2002/07/owl#versionIRI\" ) tokens = self . get_triples ( s = self . storid , p = version_iri_storid ) if ( not tokens ) and ( as_iri is True ): raise TypeError ( \"No owl:versionIRI \" f \"in Ontology { self . base_iri !r} . \" \"Search for owl:versionInfo with as_iri=False\" ) if tokens : _ , _ , obj = tokens [ 0 ] version_iri = self . world . _unabbreviate ( obj ) if as_iri : return version_iri return infer_version ( self . base_iri , version_iri ) version_info_storid = self . world . _abbreviate ( \"http://www.w3.org/2002/07/owl#versionInfo\" ) tokens = self . get_triples ( s = self . storid , p = version_info_storid ) if not tokens : raise TypeError ( \"No versionIRI or versionInfo \" f \"in Ontology { self . base_iri !r} \" ) _ , _ , version_info = tokens [ 0 ] return version_info . strip ( '\"' ) . strip ( \"'\" ) def set_version ( self , version = None , version_iri = None ): \"\"\"Assign version to ontology by asigning owl:versionIRI. If `version` but not `version_iri` is provided, the version IRI will be the combination of `base_iri` and `version`. \"\"\" _version_iri = \"http://www.w3.org/2002/07/owl#versionIRI\" version_iri_storid = self . world . _abbreviate ( _version_iri ) if self . _has_obj_triple_spo ( # pylint: disable=unexpected-keyword-arg # For some reason _has_obj_triples_spo exists in both # owlready2.namespace.Namespace (with arguments subject/predicate) # and in owlready2.triplelite._GraphManager (with arguments s/p) # owlready2.Ontology inherits from Namespace directly # and pylint checks that. # It actually accesses the one in triplelite. # subject=self.storid, predicate=version_iri_storid s = self . storid , p = version_iri_storid , ): self . _del_obj_triple_spo ( s = self . storid , p = version_iri_storid ) if not version_iri : if not version : raise TypeError ( \"Either `version` or `version_iri` must be provided\" ) head , tail = self . base_iri . rstrip ( \"#/\" ) . rsplit ( \"/\" , 1 ) version_iri = \"/\" . join ([ head , version , tail ]) self . _add_obj_triple_spo ( s = self . storid , p = self . world . _abbreviate ( _version_iri ), o = self . world . _abbreviate ( version_iri ), ) def get_graph ( self , ** kwargs ): \"\"\"Returns a new graph object. See emmo.graph.OntoGraph. Note that this method requires the Python graphviz package. \"\"\" # pylint: disable=import-outside-toplevel,cyclic-import from ontopy.graph import OntoGraph return OntoGraph ( self , ** kwargs ) @staticmethod def common_ancestors ( cls1 , cls2 ): \"\"\"Return a list of common ancestors for `cls1` and `cls2`.\"\"\" return set ( cls1 . ancestors ()) . intersection ( cls2 . ancestors ()) def number_of_generations ( self , descendant , ancestor ): \"\"\"Return shortest distance from ancestor to descendant\"\"\" if ancestor not in descendant . ancestors (): raise ValueError ( \"Descendant is not a descendant of ancestor\" ) return self . _number_of_generations ( descendant , ancestor , 0 ) def _number_of_generations ( self , descendant , ancestor , counter ): \"\"\"Recursive help function to number_of_generations(), return distance between a ancestor-descendant pair (counter+1).\"\"\" if descendant . name == ancestor . name : return counter try : return min ( self . _number_of_generations ( parent , ancestor , counter + 1 ) for parent in descendant . get_parents () if ancestor in parent . ancestors () ) except ValueError : return counter def closest_common_ancestors ( self , cls1 , cls2 ): \"\"\"Returns a list with closest_common_ancestor for cls1 and cls2\"\"\" distances = {} for ancestor in self . common_ancestors ( cls1 , cls2 ): distances [ ancestor ] = self . number_of_generations ( cls1 , ancestor ) + self . number_of_generations ( cls2 , ancestor ) return [ ancestor for ancestor , distance in distances . items () if distance == min ( distances . values ()) ] @staticmethod def closest_common_ancestor ( * classes ): \"\"\"Returns closest_common_ancestor for the given classes.\"\"\" mros = [ cls . mro () for cls in classes ] track = defaultdict ( int ) while mros : for mro in mros : cur = mro . pop ( 0 ) track [ cur ] += 1 if track [ cur ] == len ( classes ): return cur if len ( mro ) == 0 : mros . remove ( mro ) raise Exception ( \"A closest common ancestor should always exist !\" ) def get_ancestors ( self , classes , include = \"all\" , strict = True ): \"\"\"Return ancestors of all classes in `classes`. classes to be provided as list The values of `include` may be: - None: ignore this argument - \"all\": Include all ancestors. - \"closest\": Include all ancestors up to the closest common ancestor of all classes. - int: Include this number of ancestor levels. Here `include` may be an integer or a string that can be converted to int. \"\"\" ancestors = set () if not classes : return ancestors def addancestors ( entity , counter , subject ): if counter > 0 : for parent in entity . get_parents ( strict = True ): subject . add ( parent ) addancestors ( parent , counter - 1 , subject ) if isinstance ( include , str ) and include . isdigit (): include = int ( include ) if include == \"all\" : ancestors . update ( * ( _ . ancestors () for _ in classes )) elif include == \"closest\" : closest = self . closest_common_ancestor ( * classes ) for cls in classes : ancestors . update ( _ for _ in cls . ancestors () if closest in _ . ancestors () ) elif isinstance ( include , int ): for entity in classes : addancestors ( entity , int ( include ), ancestors ) elif include not in ( None , \"None\" , \"none\" , \"\" ): raise ValueError ( 'include must be \"all\", \"closest\" or None' ) if strict : return ancestors . difference ( classes ) return ancestors def get_descendants ( self , classes : \"Union[List, ThingClass]\" , common : bool = False , generations : int = None , ) -> set : \"\"\"Return descendants/subclasses of all classes in `classes`. Args: classes: to be provided as list. common: whether to only return descendants common to all classes. generations: Include this number of generations, default is all. Returns: A set of descendants for given number of generations. If 'common'=True, the common descendants are returned within the specified number of generations. 'generations' defaults to all. \"\"\" if not isinstance ( classes , Sequence ): classes = [ classes ] descendants = { name : [] for name in classes } def _children_recursively ( num , newentity , parent , descendants ): \"\"\"Helper function to get all children up to generation.\"\"\" for child in self . get_children_of ( newentity ): descendants [ parent ] . append ( child ) if num < generations : _children_recursively ( num + 1 , child , parent , descendants ) if generations == 0 : return set () if not generations : for entity in classes : descendants [ entity ] = entity . descendants () # only include proper descendants descendants [ entity ] . remove ( entity ) else : for entity in classes : _children_recursively ( 1 , entity , entity , descendants ) results = descendants . values () if common is True : return set . intersection ( * map ( set , results )) return set ( flatten ( results )) def get_wu_palmer_measure ( self , cls1 , cls2 ): \"\"\"Return Wu-Palmer measure for semantic similarity. Returns Wu-Palmer measure for semantic similarity between two concepts. Wu, Palmer; ACL 94: Proceedings of the 32nd annual meeting on Association for Computational Linguistics, June 1994. \"\"\" cca = self . closest_common_ancestor ( cls1 , cls2 ) ccadepth = self . number_of_generations ( cca , self . Thing ) generations1 = self . number_of_generations ( cls1 , cca ) generations2 = self . number_of_generations ( cls2 , cca ) return 2 * ccadepth / ( generations1 + generations2 + 2 * ccadepth ) def new_entity ( self , name : str , parent : Union [ ThingClass , Iterable ] ) -> ThingClass : \"\"\"Create and return new entity Makes a new entity in the ontology with given parent(s). Return the new entity. Throws exception if name consists of more than one word. \"\"\" if len ( name . split ( \" \" )) > 1 : raise LabelDefinitionError ( f \"Error in label name definition ' { name } ': \" f \"Label consists of more than one word.\" ) parents = tuple ( parent ) if isinstance ( parent , Iterable ) else ( parent ,) for thing in parents : if not isinstance ( thing , owlready2 . ThingClass ): raise ThingClassDefinitionError ( f \"Error in parent definition: \" f \"' { thing } ' is not an owlready2.ThingClass.\" ) with self : entity = types . new_class ( name , parents ) return entity dir_imported property writable \u00b6 Whether to include imported ontologies in dir() listing. dir_label property writable \u00b6 Whether to include entity label in dir() listing. dir_name property writable \u00b6 Whether to include entity name in dir() listing. dir_preflabel property writable \u00b6 Whether to include entity prefLabel in dir() listing. label_annotations property readonly \u00b6 List of label annotation searched for by get_by_label(). add_label_annotation ( self , iri ) \u00b6 Adds label annotation used by get_by_label(). May be provided either as an IRI or as its owlready2 representation. Source code in ontopy/ontology.py def add_label_annotation ( self , iri ): \"\"\"Adds label annotation used by get_by_label(). May be provided either as an IRI or as its owlready2 representation. \"\"\" if self . _label_annotations is None : self . _label_annotations = [] label_annotation = iri if hasattr ( iri , \"storid\" ) else self . world [ iri ] if label_annotation is None : warnings . warn ( f \"adding new IRI to ontology: { iri } \" ) name = iri . rsplit ( \"/\" )[ - 1 ] . rsplit ( \"#\" )[ - 1 ] bases = ( owlready2 . AnnotationProperty ,) with self : label_annotation = types . new_class ( name , bases ) if label_annotation not in self . _label_annotations : self . _label_annotations . append ( label_annotation ) annotation_properties ( self , imported = False ) \u00b6 Returns a generator iterating over all annotation properties defined in the current ontology. If imported is true, annotation properties in imported ontologies will also be included. Source code in ontopy/ontology.py def annotation_properties ( self , imported = False ): \"\"\"Returns a generator iterating over all annotation properties defined in the current ontology. If `imported` is true, annotation properties in imported ontologies will also be included. \"\"\" if imported : return self . world . annotation_properties () return super () . annotation_properties () classes ( self , imported = False ) \u00b6 Returns an generator over all classes. If imported is True , will imported classes are also returned. Source code in ontopy/ontology.py def classes ( self , imported = False ): \"\"\"Returns an generator over all classes. If `imported` is `True`, will imported classes are also returned. \"\"\" if imported : return self . world . classes () return super () . classes () closest_common_ancestor ( * classes ) staticmethod \u00b6 Returns closest_common_ancestor for the given classes. Source code in ontopy/ontology.py @staticmethod def closest_common_ancestor ( * classes ): \"\"\"Returns closest_common_ancestor for the given classes.\"\"\" mros = [ cls . mro () for cls in classes ] track = defaultdict ( int ) while mros : for mro in mros : cur = mro . pop ( 0 ) track [ cur ] += 1 if track [ cur ] == len ( classes ): return cur if len ( mro ) == 0 : mros . remove ( mro ) raise Exception ( \"A closest common ancestor should always exist !\" ) closest_common_ancestors ( self , cls1 , cls2 ) \u00b6 Returns a list with closest_common_ancestor for cls1 and cls2 Source code in ontopy/ontology.py def closest_common_ancestors ( self , cls1 , cls2 ): \"\"\"Returns a list with closest_common_ancestor for cls1 and cls2\"\"\" distances = {} for ancestor in self . common_ancestors ( cls1 , cls2 ): distances [ ancestor ] = self . number_of_generations ( cls1 , ancestor ) + self . number_of_generations ( cls2 , ancestor ) return [ ancestor for ancestor , distance in distances . items () if distance == min ( distances . values ()) ] common_ancestors ( cls1 , cls2 ) staticmethod \u00b6 Return a list of common ancestors for cls1 and cls2 . Source code in ontopy/ontology.py @staticmethod def common_ancestors ( cls1 , cls2 ): \"\"\"Return a list of common ancestors for `cls1` and `cls2`.\"\"\" return set ( cls1 . ancestors ()) . intersection ( cls2 . ancestors ()) data_properties ( self , imported = False ) \u00b6 Returns an generator over all data properties. If imported is true, will imported data properties are also returned. Source code in ontopy/ontology.py def data_properties ( self , imported = False ): \"\"\"Returns an generator over all data properties. If `imported` is true, will imported data properties are also returned. \"\"\" if imported : return self . world . data_properties () return super () . data_properties () get_ancestors ( self , classes , include = 'all' , strict = True ) \u00b6 Return ancestors of all classes in classes . classes to be provided as list The values of include may be: - None: ignore this argument - \"all\": Include all ancestors. - \"closest\": Include all ancestors up to the closest common ancestor of all classes. - int: Include this number of ancestor levels. Here include may be an integer or a string that can be converted to int. Source code in ontopy/ontology.py def get_ancestors ( self , classes , include = \"all\" , strict = True ): \"\"\"Return ancestors of all classes in `classes`. classes to be provided as list The values of `include` may be: - None: ignore this argument - \"all\": Include all ancestors. - \"closest\": Include all ancestors up to the closest common ancestor of all classes. - int: Include this number of ancestor levels. Here `include` may be an integer or a string that can be converted to int. \"\"\" ancestors = set () if not classes : return ancestors def addancestors ( entity , counter , subject ): if counter > 0 : for parent in entity . get_parents ( strict = True ): subject . add ( parent ) addancestors ( parent , counter - 1 , subject ) if isinstance ( include , str ) and include . isdigit (): include = int ( include ) if include == \"all\" : ancestors . update ( * ( _ . ancestors () for _ in classes )) elif include == \"closest\" : closest = self . closest_common_ancestor ( * classes ) for cls in classes : ancestors . update ( _ for _ in cls . ancestors () if closest in _ . ancestors () ) elif isinstance ( include , int ): for entity in classes : addancestors ( entity , int ( include ), ancestors ) elif include not in ( None , \"None\" , \"none\" , \"\" ): raise ValueError ( 'include must be \"all\", \"closest\" or None' ) if strict : return ancestors . difference ( classes ) return ancestors get_annotations ( self , entity ) \u00b6 Returns a dict with annotations for entity . Entity may be given either as a ThingClass object or as a label. Source code in ontopy/ontology.py def get_annotations ( self , entity ): \"\"\"Returns a dict with annotations for `entity`. Entity may be given either as a ThingClass object or as a label.\"\"\" warnings . warn ( \"Ontology.get_annotations(entity) is deprecated. Use \" \"entity.get_annotations() instead.\" , DeprecationWarning , ) if isinstance ( entity , str ): entity = self . get_by_label ( entity ) res = { \"comment\" : getattr ( entity , \"comment\" , \"\" )} for annotation in self . annotation_properties (): res [ annotation . label . first ()] = [ obj . strip ( '\"' ) for _ , _ , obj in self . get_triples ( entity . storid , annotation . storid , None ) ] return res get_branch ( self , root , leafs = (), include_leafs = True , strict_leafs = False , exclude = None , sort = False ) \u00b6 Returns a set with all direct and indirect subclasses of root . Any subclass found in the sequence leafs will be included in the returned list, but its subclasses will not. The elements of leafs may be ThingClass objects or labels. Subclasses of any subclass found in the sequence leafs will be excluded from the returned list, where the elements of leafs may be ThingClass objects or labels. If include_leafs is true, the leafs are included in the returned list, otherwise they are not. If strict_leafs is true, any descendant of a leaf will be excluded in the returned set. If given, exclude may be a sequence of classes, including their subclasses, to exclude from the output. If sort is True, a list sorted according to depth and label will be returned instead of a set. Source code in ontopy/ontology.py def get_branch ( # pylint: disable=too-many-arguments self , root , leafs = (), include_leafs = True , strict_leafs = False , exclude = None , sort = False , ): \"\"\"Returns a set with all direct and indirect subclasses of `root`. Any subclass found in the sequence `leafs` will be included in the returned list, but its subclasses will not. The elements of `leafs` may be ThingClass objects or labels. Subclasses of any subclass found in the sequence `leafs` will be excluded from the returned list, where the elements of `leafs` may be ThingClass objects or labels. If `include_leafs` is true, the leafs are included in the returned list, otherwise they are not. If `strict_leafs` is true, any descendant of a leaf will be excluded in the returned set. If given, `exclude` may be a sequence of classes, including their subclasses, to exclude from the output. If `sort` is True, a list sorted according to depth and label will be returned instead of a set. \"\"\" def _branch ( root , leafs ): if root not in leafs : branch = { root , } for cls in root . subclasses (): # Defining a branch is actually quite tricky. Consider # the case: # # L isA R # A isA L # A isA R # # where R is the root, L is a leaf and A is a direct # child of both. Logically, since A is a child of the # leaf we want to skip A. But a strait forward imple- # mentation will see that A is a child of the root and # include it. Requireing that the R should be a strict # parent of A solves this. if root in cls . get_parents ( strict = True ): branch . update ( _branch ( cls , leafs )) else : branch = ( { root , } if include_leafs else set () ) return branch if isinstance ( root , str ): root = self . get_by_label ( root ) leafs = set ( self . get_by_label ( leaf ) if isinstance ( leaf , str ) else leaf for leaf in leafs ) leafs . discard ( root ) if exclude : exclude = set ( self . get_by_label ( e ) if isinstance ( e , str ) else e for e in exclude ) leafs . update ( exclude ) branch = _branch ( root , leafs ) # Exclude all descendants of any leaf if strict_leafs : descendants = root . descendants () for leaf in leafs : if leaf in descendants : branch . difference_update ( leaf . descendants ( include_self = False ) ) if exclude : branch . difference_update ( exclude ) # Sort according to depth, then by label if sort : branch = sorted ( sorted ( branch , key = asstring ), key = lambda x : len ( x . mro ()), ) return branch get_by_label ( self , label , label_annotations = None , prefix = None ) \u00b6 Returns entity with label annotation label . Parameters: Name Type Description Default label str label so serach for. May be written as 'label' or 'prefix:label'. get_by_label('prefix:label') == get_by_label('label', prefix='prefix'). required label_annotations str a sequence of label annotation names to look up. Defaults to the label_annotations property. None prefix str if provided, it should be the last component of the base iri of an ontology (with trailing slash (/) or hash (#) stripped off). The search for a matching label will be limited to this namespace. None If several entities have the same label, only the one which is found first is returned.Use get_by_label_all() to get all matches. A NoSuchLabelError is raised if label cannot be found. Note \u00b6 The current implementation also supports \"*\" as a wildcard matching any number of characters. This may change in the future. Source code in ontopy/ontology.py def get_by_label ( self , label : str , label_annotations : str = None , prefix : str = None ): \"\"\"Returns entity with label annotation `label`. Args: label: label so serach for. May be written as 'label' or 'prefix:label'. get_by_label('prefix:label') == get_by_label('label', prefix='prefix'). label_annotations: a sequence of label annotation names to look up. Defaults to the `label_annotations` property. prefix: if provided, it should be the last component of the base iri of an ontology (with trailing slash (/) or hash (#) stripped off). The search for a matching label will be limited to this namespace. If several entities have the same label, only the one which is found first is returned.Use get_by_label_all() to get all matches. A NoSuchLabelError is raised if `label` cannot be found. Note ---- The current implementation also supports \"*\" as a wildcard matching any number of characters. This may change in the future. \"\"\" # pylint: disable=too-many-arguments,too-many-branches if not isinstance ( label , str ): raise TypeError ( f \"Invalid label definition, must be a string: { label !r} \" ) if \" \" in label : raise ValueError ( f \"Invalid label definition, { label !r} contains spaces.\" ) if self . _label_annotations is None : for iri in DEFAULT_LABEL_ANNOTATIONS : try : self . add_label_annotation ( iri ) except ValueError : pass splitlabel = label . split ( \":\" ) if len ( splitlabel ) > 2 : raise ValueError ( f \"Invalid label definition, { label !r} \" \" contains more than one ':' .\" \"The string before ':' indicates the prefix. \" \"The string after ':' indicates the label.\" ) if len ( splitlabel ) == 2 : label = splitlabel [ 1 ] if prefix and prefix != splitlabel [ 0 ]: warnings . warn ( f \"Prefix given both as argument ( { prefix } ) \" f \"and in label ( { splitlabel [ 0 ] } ). \" \"Prefix given in label takes presendence \" ) prefix = splitlabel [ 0 ] if prefix : entitylist = self . get_by_label_all ( label , label_annotations = label_annotations , prefix = prefix , ) if len ( entitylist ) > 0 : return entitylist [ 0 ] raise NoSuchLabelError ( f \"No label annotations matches { label !r} with prefix \" f \" { prefix !r} \" ) # if label in self._namespaces: # return self._namespaces[label] if label_annotations is None : annotations = ( a . name for a in self . label_annotations ) else : annotations = ( a . name if hasattr ( a , \"storid\" ) else a for a in label_annotations ) for key in annotations : entity = self . search_one ( ** { key : label }) if entity : return entity if self . _special_labels and label in self . _special_labels : return self . _special_labels [ label ] entity = self . world [ self . base_iri + label ] if entity : return entity raise NoSuchLabelError ( f \"No label annotations matches { label !r} \" ) get_by_label_all ( self , label , label_annotations = None , prefix = None ) \u00b6 Like get_by_label(), but returns a list with all matching labels. Returns an empty list if no matches could be found. Source code in ontopy/ontology.py def get_by_label_all ( self , label , label_annotations = None , prefix = None ): \"\"\"Like get_by_label(), but returns a list with all matching labels. Returns an empty list if no matches could be found. \"\"\" if not isinstance ( label , str ): raise TypeError ( f \"Invalid label definition, \" f \"must be a string: { label !r} \" ) if \" \" in label : raise ValueError ( f \"Invalid label definition, { label !r} contains spaces.\" ) if label_annotations is None : annotations = ( _ . name for _ in self . label_annotations ) else : annotations = ( _ . name if hasattr ( _ , \"storid\" ) else _ for _ in label_annotations ) entity = self . world . search ( ** { next ( annotations ): label }) for key in annotations : entity . extend ( self . world . search ( ** { key : label })) if self . _special_labels and label in self . _special_labels : entity . append ( self . _special_labels [ label ]) if prefix : return [ _ for _ in entity if _ . namespace . ontology . prefix == prefix ] return entity get_descendants ( self , classes , common = False , generations = None ) \u00b6 Return descendants/subclasses of all classes in classes . Parameters: Name Type Description Default classes Union[List, ThingClass] to be provided as list. required common bool whether to only return descendants common to all classes. False generations int Include this number of generations, default is all. None Returns: Type Description set A set of descendants for given number of generations. If 'common'=True, the common descendants are returned within the specified number of generations. 'generations' defaults to all. Source code in ontopy/ontology.py def get_descendants ( self , classes : \"Union[List, ThingClass]\" , common : bool = False , generations : int = None , ) -> set : \"\"\"Return descendants/subclasses of all classes in `classes`. Args: classes: to be provided as list. common: whether to only return descendants common to all classes. generations: Include this number of generations, default is all. Returns: A set of descendants for given number of generations. If 'common'=True, the common descendants are returned within the specified number of generations. 'generations' defaults to all. \"\"\" if not isinstance ( classes , Sequence ): classes = [ classes ] descendants = { name : [] for name in classes } def _children_recursively ( num , newentity , parent , descendants ): \"\"\"Helper function to get all children up to generation.\"\"\" for child in self . get_children_of ( newentity ): descendants [ parent ] . append ( child ) if num < generations : _children_recursively ( num + 1 , child , parent , descendants ) if generations == 0 : return set () if not generations : for entity in classes : descendants [ entity ] = entity . descendants () # only include proper descendants descendants [ entity ] . remove ( entity ) else : for entity in classes : _children_recursively ( 1 , entity , entity , descendants ) results = descendants . values () if common is True : return set . intersection ( * map ( set , results )) return set ( flatten ( results )) get_entities ( self , imported = True , classes = True , individuals = True , object_properties = True , data_properties = True , annotation_properties = True ) \u00b6 Return a generator over (optionally) all classes, individuals, object_properties, data_properties and annotation_properties. If imported is True , entities in imported ontologies will also be included. Source code in ontopy/ontology.py def get_entities ( # pylint: disable=too-many-arguments self , imported = True , classes = True , individuals = True , object_properties = True , data_properties = True , annotation_properties = True , ): \"\"\"Return a generator over (optionally) all classes, individuals, object_properties, data_properties and annotation_properties. If `imported` is `True`, entities in imported ontologies will also be included. \"\"\" generator = [] if classes : generator . append ( self . classes ( imported )) if individuals : generator . append ( self . individuals ( imported )) if object_properties : generator . append ( self . object_properties ( imported )) if data_properties : generator . append ( self . data_properties ( imported )) if annotation_properties : generator . append ( self . annotation_properties ( imported )) for entity in itertools . chain ( * generator ): yield entity get_graph ( self , ** kwargs ) \u00b6 Returns a new graph object. See emmo.graph.OntoGraph. Note that this method requires the Python graphviz package. Source code in ontopy/ontology.py def get_graph ( self , ** kwargs ): \"\"\"Returns a new graph object. See emmo.graph.OntoGraph. Note that this method requires the Python graphviz package. \"\"\" # pylint: disable=import-outside-toplevel,cyclic-import from ontopy.graph import OntoGraph return OntoGraph ( self , ** kwargs ) get_imported_ontologies ( self , recursive = False ) \u00b6 Return a list with imported ontologies. If recursive is True , ontologies imported by imported ontologies are also returned. Source code in ontopy/ontology.py def get_imported_ontologies ( self , recursive = False ): \"\"\"Return a list with imported ontologies. If `recursive` is `True`, ontologies imported by imported ontologies are also returned. \"\"\" def rec_imported ( onto ): for ontology in onto . imported_ontologies : if ontology not in imported : imported . add ( ontology ) rec_imported ( ontology ) if recursive : imported = set () rec_imported ( self ) return list ( imported ) return self . imported_ontologies get_relations ( self ) \u00b6 Returns a generator for all relations. Source code in ontopy/ontology.py def get_relations ( self ): \"\"\"Returns a generator for all relations.\"\"\" warnings . warn ( \"Ontology.get_relations() is deprecated. Use \" \"onto.object_properties() instead.\" , DeprecationWarning , ) return self . object_properties () get_root_classes ( self , imported = False ) \u00b6 Returns a list or root classes. Source code in ontopy/ontology.py def get_root_classes ( self , imported = False ): \"\"\"Returns a list or root classes.\"\"\" return [ cls for cls in self . classes ( imported = imported ) if not cls . ancestors () . difference ( set ([ cls , owlready2 . Thing ])) ] get_root_data_properties ( self , imported = False ) \u00b6 Returns a list of root object properties. Source code in ontopy/ontology.py def get_root_data_properties ( self , imported = False ): \"\"\"Returns a list of root object properties.\"\"\" props = set ( self . data_properties ( imported = imported )) return [ p for p in props if not props . intersection ( p . is_a )] get_root_object_properties ( self , imported = False ) \u00b6 Returns a list of root object properties. Source code in ontopy/ontology.py def get_root_object_properties ( self , imported = False ): \"\"\"Returns a list of root object properties.\"\"\" props = set ( self . object_properties ( imported = imported )) return [ p for p in props if not props . intersection ( p . is_a )] get_roots ( self , imported = False ) \u00b6 Returns all class, object_property and data_property roots. Source code in ontopy/ontology.py def get_roots ( self , imported = False ): \"\"\"Returns all class, object_property and data_property roots.\"\"\" roots = self . get_root_classes ( imported = imported ) roots . extend ( self . get_root_object_properties ( imported = imported )) roots . extend ( self . get_root_data_properties ( imported = imported )) return roots get_unabbreviated_triples ( self , subject = None , predicate = None , obj = None , blank = None ) \u00b6 Returns all matching triples unabbreviated. If blank is given, it will be used to represent blank nodes. Source code in ontopy/ontology.py def get_unabbreviated_triples ( self , subject = None , predicate = None , obj = None , blank = None ): \"\"\"Returns all matching triples unabbreviated. If `blank` is given, it will be used to represent blank nodes. \"\"\" # pylint: disable=invalid-name return _get_unabbreviated_triples ( self , subject = subject , predicate = predicate , obj = obj , blank = blank ) get_version ( self , as_iri = False ) \u00b6 Returns the version number of the ontology as inferred from the owl:versionIRI tag or, if owl:versionIRI is not found, from owl:versionINFO. If as_iri is True, the full versionIRI is returned. Source code in ontopy/ontology.py def get_version ( self , as_iri = False ) -> str : \"\"\"Returns the version number of the ontology as inferred from the owl:versionIRI tag or, if owl:versionIRI is not found, from owl:versionINFO. If `as_iri` is True, the full versionIRI is returned. \"\"\" version_iri_storid = self . world . _abbreviate ( \"http://www.w3.org/2002/07/owl#versionIRI\" ) tokens = self . get_triples ( s = self . storid , p = version_iri_storid ) if ( not tokens ) and ( as_iri is True ): raise TypeError ( \"No owl:versionIRI \" f \"in Ontology { self . base_iri !r} . \" \"Search for owl:versionInfo with as_iri=False\" ) if tokens : _ , _ , obj = tokens [ 0 ] version_iri = self . world . _unabbreviate ( obj ) if as_iri : return version_iri return infer_version ( self . base_iri , version_iri ) version_info_storid = self . world . _abbreviate ( \"http://www.w3.org/2002/07/owl#versionInfo\" ) tokens = self . get_triples ( s = self . storid , p = version_info_storid ) if not tokens : raise TypeError ( \"No versionIRI or versionInfo \" f \"in Ontology { self . base_iri !r} \" ) _ , _ , version_info = tokens [ 0 ] return version_info . strip ( '\"' ) . strip ( \"'\" ) get_wu_palmer_measure ( self , cls1 , cls2 ) \u00b6 Return Wu-Palmer measure for semantic similarity. Returns Wu-Palmer measure for semantic similarity between two concepts. Wu, Palmer; ACL 94: Proceedings of the 32nd annual meeting on Association for Computational Linguistics, June 1994. Source code in ontopy/ontology.py def get_wu_palmer_measure ( self , cls1 , cls2 ): \"\"\"Return Wu-Palmer measure for semantic similarity. Returns Wu-Palmer measure for semantic similarity between two concepts. Wu, Palmer; ACL 94: Proceedings of the 32nd annual meeting on Association for Computational Linguistics, June 1994. \"\"\" cca = self . closest_common_ancestor ( cls1 , cls2 ) ccadepth = self . number_of_generations ( cca , self . Thing ) generations1 = self . number_of_generations ( cls1 , cca ) generations2 = self . number_of_generations ( cls2 , cca ) return 2 * ccadepth / ( generations1 + generations2 + 2 * ccadepth ) individuals ( self , imported = False ) \u00b6 Returns an generator over all individuals. If imported is True , will imported individuals are also returned. Source code in ontopy/ontology.py def individuals ( self , imported = False ): \"\"\"Returns an generator over all individuals. If `imported` is `True`, will imported individuals are also returned. \"\"\" if imported : return self . world . individuals () return super () . individuals () is_defined ( self , entity ) \u00b6 Returns true if the entity is a defined class. Source code in ontopy/ontology.py def is_defined ( self , entity ): \"\"\"Returns true if the entity is a defined class.\"\"\" if isinstance ( entity , str ): entity = self . get_by_label ( entity ) return hasattr ( entity , \"equivalent_to\" ) and bool ( entity . equivalent_to ) is_individual ( self , entity ) \u00b6 Returns true if entity is an individual. Source code in ontopy/ontology.py def is_individual ( self , entity ): \"\"\"Returns true if entity is an individual.\"\"\" if isinstance ( entity , str ): entity = self . get_by_label ( entity ) return isinstance ( entity , owlready2 . Thing ) load ( self , only_local = False , filename = None , format = None , reload = None , reload_if_newer = False , url_from_catalog = None , catalog_file = 'catalog-v001.xml' , emmo_based = True , prefix = None , prefix_emmo = None , ** kwargs ) \u00b6 Load the ontology. Parameters \u00b6 bool Whether to only read local files. This requires that you have appended the path to the ontology to owlready2.onto_path. str Path to file to load the ontology from. Defaults to base_iri provided to get_ontology(). str Format of filename . Default is inferred from filename extension. bool Whether to reload the ontology if it is already loaded. bool Whether to reload the ontology if the source has changed since last time it was loaded. bool | None Whether to use catalog file to resolve the location of base_iri . If None, the catalog file is used if it exists in the same directory as filename . str Name of Prot\u00e8g\u00e8 catalog file in the same folder as the ontology. This option is used together with only_local and defaults to \"catalog-v001.xml\". bool Whether this is an EMMO-based ontology or not, default True . prefix: defaults to self.get_namespace.name if bool, default None. If emmo_based is True it defaults to True and sets the prefix of all imported ontologies with base_iri starting with 'http://emmo.info/emmo' to emmo Kwargs Additional keyword arguments are passed on to owlready2.Ontology.load(). Source code in ontopy/ontology.py def load ( # pylint: disable=too-many-arguments,arguments-renamed self , only_local = False , filename = None , format = None , # pylint: disable=redefined-builtin reload = None , reload_if_newer = False , url_from_catalog = None , catalog_file = \"catalog-v001.xml\" , emmo_based = True , prefix = None , prefix_emmo = None , ** kwargs , ): \"\"\"Load the ontology. Parameters ---------- only_local: bool Whether to only read local files. This requires that you have appended the path to the ontology to owlready2.onto_path. filename: str Path to file to load the ontology from. Defaults to `base_iri` provided to get_ontology(). format: str Format of `filename`. Default is inferred from `filename` extension. reload: bool Whether to reload the ontology if it is already loaded. reload_if_newer: bool Whether to reload the ontology if the source has changed since last time it was loaded. url_from_catalog: bool | None Whether to use catalog file to resolve the location of `base_iri`. If None, the catalog file is used if it exists in the same directory as `filename`. catalog_file: str Name of Prot\u00e8g\u00e8 catalog file in the same folder as the ontology. This option is used together with `only_local` and defaults to \"catalog-v001.xml\". emmo_based: bool Whether this is an EMMO-based ontology or not, default `True`. prefix: defaults to self.get_namespace.name if prefix_emmo: bool, default None. If emmo_based is True it defaults to True and sets the prefix of all imported ontologies with base_iri starting with 'http://emmo.info/emmo' to emmo kwargs: Additional keyword arguments are passed on to owlready2.Ontology.load(). \"\"\" # TODO: make sure that `only_local` argument is respected... if self . loaded : return self self . _load ( only_local = only_local , filename = filename , format = format , reload = reload , reload_if_newer = reload_if_newer , url_from_catalog = url_from_catalog , catalog_file = catalog_file , ** kwargs , ) # Enable optimised search by get_by_label() if self . _special_labels is None and emmo_based : for iri in DEFAULT_LABEL_ANNOTATIONS : self . add_label_annotation ( iri ) top = self . world [ \"http://www.w3.org/2002/07/owl#topObjectProperty\" ] self . _special_labels = { \"Thing\" : owlready2 . Thing , \"Nothing\" : owlready2 . Nothing , \"topObjectProperty\" : top , \"owl:Thing\" : owlready2 . Thing , \"owl:Nothing\" : owlready2 . Nothing , \"owl:topObjectProperty\" : top , } # set prefix if another prefix is desired # if we do this, shouldn't we make the name of all # entities of the given ontology to the same? if prefix : self . prefix = prefix else : self . prefix = self . name if emmo_based and prefix_emmo is None : prefix_emmo = True if prefix_emmo : self . set_common_prefix () return self new_entity ( self , name , parent ) \u00b6 Create and return new entity Makes a new entity in the ontology with given parent(s). Return the new entity. Throws exception if name consists of more than one word. Source code in ontopy/ontology.py def new_entity ( self , name : str , parent : Union [ ThingClass , Iterable ] ) -> ThingClass : \"\"\"Create and return new entity Makes a new entity in the ontology with given parent(s). Return the new entity. Throws exception if name consists of more than one word. \"\"\" if len ( name . split ( \" \" )) > 1 : raise LabelDefinitionError ( f \"Error in label name definition ' { name } ': \" f \"Label consists of more than one word.\" ) parents = tuple ( parent ) if isinstance ( parent , Iterable ) else ( parent ,) for thing in parents : if not isinstance ( thing , owlready2 . ThingClass ): raise ThingClassDefinitionError ( f \"Error in parent definition: \" f \"' { thing } ' is not an owlready2.ThingClass.\" ) with self : entity = types . new_class ( name , parents ) return entity number_of_generations ( self , descendant , ancestor ) \u00b6 Return shortest distance from ancestor to descendant Source code in ontopy/ontology.py def number_of_generations ( self , descendant , ancestor ): \"\"\"Return shortest distance from ancestor to descendant\"\"\" if ancestor not in descendant . ancestors (): raise ValueError ( \"Descendant is not a descendant of ancestor\" ) return self . _number_of_generations ( descendant , ancestor , 0 ) object_properties ( self , imported = False ) \u00b6 Returns an generator over all object properties. If imported is true, will imported object properties are also returned. Source code in ontopy/ontology.py def object_properties ( self , imported = False ): \"\"\"Returns an generator over all object properties. If `imported` is true, will imported object properties are also returned. \"\"\" if imported : return self . world . object_properties () return super () . object_properties () remove_label_annotation ( self , iri ) \u00b6 Removes label annotation used by get_by_label(). May be provided either as an IRI or as its owlready2 representation. Source code in ontopy/ontology.py def remove_label_annotation ( self , iri ): \"\"\"Removes label annotation used by get_by_label(). May be provided either as an IRI or as its owlready2 representation. \"\"\" label_annotation = iri if hasattr ( iri , \"storid\" ) else self . world [ iri ] if not label_annotation : raise ValueError ( f \"IRI not in ontology: { iri } \" ) self . _label_annotations . remove ( label_annotation ) rename_entities ( self , annotations = ( 'prefLabel' , 'label' , 'altLabel' )) \u00b6 Set name of all entities to the first non-empty annotation in annotations . Warning, this method changes all IRIs in the ontology. However, it may be useful to make the ontology more readable and to work with it together with a triple store. Source code in ontopy/ontology.py def rename_entities ( self , annotations = ( \"prefLabel\" , \"label\" , \"altLabel\" ), ): \"\"\"Set `name` of all entities to the first non-empty annotation in `annotations`. Warning, this method changes all IRIs in the ontology. However, it may be useful to make the ontology more readable and to work with it together with a triple store. \"\"\" for entity in self . get_entities (): for annotation in annotations : if hasattr ( entity , annotation ): name = getattr ( entity , annotation ) . first () if name : entity . name = name break save ( self , filename = None , format = None , dir = '.' , mkdir = False , overwrite = False , recursive = False , squash = False , write_catalog_file = False , append_catalog = False , catalog_file = 'catalog-v001.xml' ) \u00b6 Writes the ontology to file. Parameters \u00b6 None | str | Path Name of file to write to. If None, it defaults to the name of the ontology with format as file extension. str Output format. The default is to infer it from filename . str | Path If filename is a relative path, it is a relative path to dir . bool Whether to create output directory if it does not exists. bool If true and filename exists, remove the existing file before saving. The default is to append to an existing ontology. bool Whether to save imported ontologies recursively. This is commonly combined with filename=None , dir and mkdir . bool If true, rdflib will be used to save the current ontology together with all its sub-ontologies into filename . It make no sense to combine this with recursive . bool Whether to also write a catalog file to disk. bool Whether to append to an existing catalog file. str | Path Name of catalog file. If not an absolute path, it is prepended to dir . Source code in ontopy/ontology.py def save ( self , filename = None , format = None , dir = \".\" , mkdir = False , overwrite = False , recursive = False , squash = False , write_catalog_file = False , append_catalog = False , catalog_file = \"catalog-v001.xml\" , ): \"\"\"Writes the ontology to file. Parameters ---------- filename: None | str | Path Name of file to write to. If None, it defaults to the name of the ontology with `format` as file extension. format: str Output format. The default is to infer it from `filename`. dir: str | Path If `filename` is a relative path, it is a relative path to `dir`. mkdir: bool Whether to create output directory if it does not exists. owerwrite: bool If true and `filename` exists, remove the existing file before saving. The default is to append to an existing ontology. recursive: bool Whether to save imported ontologies recursively. This is commonly combined with `filename=None`, `dir` and `mkdir`. squash: bool If true, rdflib will be used to save the current ontology together with all its sub-ontologies into `filename`. It make no sense to combine this with `recursive`. write_catalog_file: bool Whether to also write a catalog file to disk. append_catalog: bool Whether to append to an existing catalog file. catalog_file: str | Path Name of catalog file. If not an absolute path, it is prepended to `dir`. \"\"\" # pylint: disable=redefined-builtin,too-many-arguments # pylint: disable=too-many-statements,too-many-branches # pylint: disable=too-many-locals,arguments-renamed if not _validate_installed_version ( package = \"rdflib\" , min_version = \"6.0.0\" ) and format == FMAP . get ( \"ttl\" , \"\" ): from rdflib import ( # pylint: disable=import-outside-toplevel __version__ as __rdflib_version__ , ) warnings . warn ( IncompatibleVersion ( \"To correctly convert to Turtle format, rdflib must be \" \"version 6.0.0 or greater, however, the detected rdflib \" \"version used by your Python interpreter is \" f \" { __rdflib_version__ !r} . For more information see the \" \"'Known issues' section of the README.\" ) ) revmap = { value : key for key , value in FMAP . items ()} if filename is None : if format : fmt = revmap . get ( format , format ) filename = f \" { self . name } . { fmt } \" else : TypeError ( \"`filename` and `format` cannot both be None.\" ) filename = os . path . join ( dir , filename ) dir = Path ( filename ) . resolve () . parent if mkdir : outdir = Path ( filename ) . parent . resolve () if not outdir . exists (): outdir . mkdir ( parents = True ) if not format : format = guess_format ( filename , fmap = FMAP ) fmt = revmap . get ( format , format ) if overwrite and filename and os . path . exists ( filename ): os . remove ( filename ) EMMO = rdflib . Namespace ( # pylint:disable=invalid-name \"http://emmo.info/emmo#\" ) if recursive : if squash : raise ValueError ( \"`recursive` and `squash` should not both be true\" ) base = self . base_iri . rstrip ( \"#/\" ) for onto in self . imported_ontologies : obase = onto . base_iri . rstrip ( \"#/\" ) newdir = Path ( dir ) / os . path . relpath ( obase , base ) onto . save ( filename = None , format = format , dir = newdir . resolve (), mkdir = mkdir , overwrite = overwrite , recursive = recursive , squash = squash , write_catalog_file = write_catalog_file , append_catalog = append_catalog , catalog_file = catalog_file , ) if squash : from rdflib import ( # pylint:disable=import-outside-toplevel URIRef , RDF , OWL , ) graph = self . world . as_rdflib_graph () graph . namespace_manager . bind ( \"emmo\" , EMMO ) # Remove anonymous namespace and imports graph . remove (( URIRef ( \"http://anonymous\" ), RDF . type , OWL . Ontology )) imports = list ( graph . triples (( None , OWL . imports , None ))) for triple in imports : graph . remove ( triple ) graph . serialize ( destination = filename , format = format ) elif format in OWLREADY2_FORMATS : super () . save ( file = filename , format = fmt ) else : # The try-finally clause is needed for cleanup and because # we have to provide delete=False to NamedTemporaryFile # since Windows does not allow to reopen an already open # file. try : with tempfile . NamedTemporaryFile ( suffix = \".owl\" , delete = False ) as handle : tmpfile = handle . name super () . save ( tmpfile , format = \"rdfxml\" ) graph = rdflib . Graph () graph . parse ( tmpfile , format = \"xml\" ) graph . serialize ( destination = filename , format = format ) finally : os . remove ( tmpfile ) if write_catalog_file : mappings = {} base = self . base_iri . rstrip ( \"#/\" ) def append ( onto ): obase = onto . base_iri . rstrip ( \"#/\" ) newdir = Path ( dir ) / os . path . relpath ( obase , base ) newpath = newdir . resolve () / f \" { onto . name } . { fmt } \" relpath = os . path . relpath ( newpath , dir ) mappings [ onto . get_version ( as_iri = True )] = str ( relpath ) for imported in onto . imported_ontologies : append ( imported ) if recursive : append ( self ) write_catalog ( mappings , output = catalog_file , directory = dir , append = append_catalog , ) set_common_prefix ( self , iri_base = 'http://emmo.info/emmo' , prefix = 'emmo' ) \u00b6 Set a common prefix for all imported ontologies with the same first part of the base_iri. Parameters: Name Type Description Default iri_base str The start of the base_iri to look for. Defaults to the emmo base_iri http://emmo.info/emmo 'http://emmo.info/emmo' prefix str the desired prefix. Defaults to emmo. 'emmo' Source code in ontopy/ontology.py def set_common_prefix ( self , iri_base : str = \"http://emmo.info/emmo\" , prefix : str = \"emmo\" , ) -> None : \"\"\"Set a common prefix for all imported ontologies with the same first part of the base_iri. Args: iri_base: The start of the base_iri to look for. Defaults to the emmo base_iri http://emmo.info/emmo prefix: the desired prefix. Defaults to emmo. \"\"\" if self . base_iri . startswith ( iri_base ): self . prefix = prefix for onto in self . imported_ontologies : onto . set_common_prefix ( iri_base = iri_base , prefix = prefix ) set_version ( self , version = None , version_iri = None ) \u00b6 Assign version to ontology by asigning owl:versionIRI. If version but not version_iri is provided, the version IRI will be the combination of base_iri and version . Source code in ontopy/ontology.py def set_version ( self , version = None , version_iri = None ): \"\"\"Assign version to ontology by asigning owl:versionIRI. If `version` but not `version_iri` is provided, the version IRI will be the combination of `base_iri` and `version`. \"\"\" _version_iri = \"http://www.w3.org/2002/07/owl#versionIRI\" version_iri_storid = self . world . _abbreviate ( _version_iri ) if self . _has_obj_triple_spo ( # pylint: disable=unexpected-keyword-arg # For some reason _has_obj_triples_spo exists in both # owlready2.namespace.Namespace (with arguments subject/predicate) # and in owlready2.triplelite._GraphManager (with arguments s/p) # owlready2.Ontology inherits from Namespace directly # and pylint checks that. # It actually accesses the one in triplelite. # subject=self.storid, predicate=version_iri_storid s = self . storid , p = version_iri_storid , ): self . _del_obj_triple_spo ( s = self . storid , p = version_iri_storid ) if not version_iri : if not version : raise TypeError ( \"Either `version` or `version_iri` must be provided\" ) head , tail = self . base_iri . rstrip ( \"#/\" ) . rsplit ( \"/\" , 1 ) version_iri = \"/\" . join ([ head , version , tail ]) self . _add_obj_triple_spo ( s = self . storid , p = self . world . _abbreviate ( _version_iri ), o = self . world . _abbreviate ( version_iri ), ) sync_attributes ( self , name_policy = None , name_prefix = '' , class_docstring = 'comment' , sync_imported = False ) \u00b6 This method is intended to be called after you have added new classes (typically via Python) to make sure that attributes like label and comments are defined. If a class, object property, data property or annotation property in the current ontology has no label, the name of the corresponding Python class will be assigned as label. If a class, object property, data property or annotation property has no comment, it will be assigned the docstring of the corresponding Python class. name_policy specify wether and how the names in the ontology should be updated. Valid values are: None not changed \"uuid\" name_prefix followed by a global unique id (UUID). \"sequential\" name_prefix followed a sequantial number. EMMO conventions imply name_policy=='uuid' . If sync_imported is true, all imported ontologies are also updated. The class_docstring argument specifies the annotation that class docstrings are mapped to. Defaults to \"comment\". Source code in ontopy/ontology.py def sync_attributes ( # pylint: disable=too-many-branches self , name_policy = None , name_prefix = \"\" , class_docstring = \"comment\" , sync_imported = False , ): \"\"\"This method is intended to be called after you have added new classes (typically via Python) to make sure that attributes like `label` and `comments` are defined. If a class, object property, data property or annotation property in the current ontology has no label, the name of the corresponding Python class will be assigned as label. If a class, object property, data property or annotation property has no comment, it will be assigned the docstring of the corresponding Python class. `name_policy` specify wether and how the names in the ontology should be updated. Valid values are: None not changed \"uuid\" `name_prefix` followed by a global unique id (UUID). \"sequential\" `name_prefix` followed a sequantial number. EMMO conventions imply ``name_policy=='uuid'``. If `sync_imported` is true, all imported ontologies are also updated. The `class_docstring` argument specifies the annotation that class docstrings are mapped to. Defaults to \"comment\". \"\"\" for cls in itertools . chain ( self . classes (), self . object_properties (), self . data_properties (), self . annotation_properties (), ): if not hasattr ( cls , \"prefLabel\" ): # no prefLabel - create new annotation property.. with self : # pylint: disable=invalid-name,missing-class-docstring # pylint: disable=unused-variable class prefLabel ( owlready2 . label ): pass cls . prefLabel = [ locstr ( cls . __name__ , lang = \"en\" )] elif not cls . prefLabel : cls . prefLabel . append ( locstr ( cls . __name__ , lang = \"en\" )) if class_docstring and hasattr ( cls , \"__doc__\" ) and cls . __doc__ : getattr ( cls , class_docstring ) . append ( locstr ( inspect . cleandoc ( cls . __doc__ ), lang = \"en\" ) ) for ind in self . individuals (): if not hasattr ( ind , \"prefLabel\" ): # no prefLabel - create new annotation property.. with self : # pylint: disable=invalid-name,missing-class-docstring # pylint: disable=function-redefined class prefLabel ( owlready2 . label ): iri = \"http://www.w3.org/2004/02/skos/core#prefLabel\" ind . prefLabel = [ locstr ( ind . name , lang = \"en\" )] elif not ind . prefLabel : ind . prefLabel . append ( locstr ( ind . name , lang = \"en\" )) chain = itertools . chain ( self . classes (), self . individuals (), self . object_properties (), self . data_properties (), self . annotation_properties (), ) if name_policy == \"uuid\" : for obj in chain : obj . name = name_prefix + str ( uuid . uuid5 ( uuid . NAMESPACE_DNS , obj . name ) ) elif name_policy == \"sequential\" : for obj in chain : counter = 0 while f \" { self . base_iri }{ name_prefix }{ counter } \" in self : counter += 1 obj . name = f \" { name_prefix }{ counter } \" elif name_policy is not None : raise TypeError ( f \"invalid name_policy: { name_policy !r} \" ) if sync_imported : for onto in self . imported_ontologies : onto . sync_attributes () sync_python_names ( self , annotations = ( 'prefLabel' , 'label' , 'altLabel' )) \u00b6 Update the python_name attribute of all properties. The python_name attribute will be set to the first non-empty annotation in the sequence of annotations in annotations for the property. Source code in ontopy/ontology.py def sync_python_names ( self , annotations = ( \"prefLabel\" , \"label\" , \"altLabel\" )): \"\"\"Update the `python_name` attribute of all properties. The python_name attribute will be set to the first non-empty annotation in the sequence of annotations in `annotations` for the property. \"\"\" def update ( gen ): for prop in gen : for annotation in annotations : if hasattr ( prop , annotation ) and getattr ( prop , annotation ): prop . python_name = getattr ( prop , annotation ) . first () break update ( self . get_entities ( classes = False , individuals = False , object_properties = False , data_properties = False , ) ) update ( self . get_entities ( classes = False , individuals = False , annotation_properties = False ) ) sync_reasoner ( self , reasoner = 'FaCT++' , include_imported = False , ** kwargs ) \u00b6 Update current ontology by running the given reasoner. Supported values for reasoner are 'Pellet', 'HermiT' and 'FaCT++'. If include_imported is true, the reasoner will also reason over imported ontologies. Note that this may be very slow with Pellet and HermiT. Keyword arguments are passed to the underlying owlready2 function. Source code in ontopy/ontology.py def sync_reasoner ( self , reasoner = \"FaCT++\" , include_imported = False , ** kwargs ): \"\"\"Update current ontology by running the given reasoner. Supported values for `reasoner` are 'Pellet', 'HermiT' and 'FaCT++'. If `include_imported` is true, the reasoner will also reason over imported ontologies. Note that this may be **very** slow with Pellet and HermiT. Keyword arguments are passed to the underlying owlready2 function. \"\"\" if reasoner == \"FaCT++\" : sync = sync_reasoner_factpp elif reasoner == \"Pellet\" : sync = owlready2 . sync_reasoner_pellet elif reasoner == \"HermiT\" : sync = owlready2 . sync_reasoner_hermit else : raise ValueError ( f \"unknown reasoner { reasoner !r} . Supported reasoners \" 'are \"Pellet\", \"HermiT\" and \"FaCT++\".' ) # For some reason we must visit all entities once before running # the reasoner... list ( self . get_entities ()) with self : if include_imported : sync ( self . world , ** kwargs ) else : sync ( self , ** kwargs ) World ( World ) \u00b6 A subclass of owlready2.World. Source code in ontopy/ontology.py class World ( owlready2 . World ): \"\"\"A subclass of owlready2.World.\"\"\" def __init__ ( self , * args , ** kwargs ): # Caches stored in the world self . _cached_catalogs = {} # maps url to (mtime, iris, dirs) self . _iri_mappings = {} # all iri mappings loaded so far super () . __init__ ( * args , ** kwargs ) def get_ontology ( self , base_iri = \"emmo-inferred\" ): \"\"\"Returns a new Ontology from `base_iri`. The `base_iri` argument may be one of: - valid URL (possible excluding final .owl or .ttl) - file name (possible excluding final .owl or .ttl) - \"emmo\": load latest version of asserted EMMO - \"emmo-inferred\": load latest version of inferred EMMO (default) - \"emmo-development\": load latest inferred development version of EMMO. Until first stable release emmo-inferred and emmo-development will be the same. \"\"\" base_iri = base_iri . as_uri () if isinstance ( base_iri , Path ) else base_iri if base_iri == \"emmo\" : base_iri = ( \"http://emmo-repo.github.io/versions/1.0.0-beta4/emmo.ttl\" ) elif base_iri == \"emmo-inferred\" : base_iri = ( \"https://emmo-repo.github.io/versions/1.0.0-beta4/\" \"emmo-inferred.ttl\" ) elif base_iri == \"emmo-development\" : base_iri = ( \"https://emmo-repo.github.io/versions/1.0.0-beta4/\" \"emmo-inferred.ttl\" ) if base_iri in self . ontologies : onto = self . ontologies [ base_iri ] elif base_iri + \"#\" in self . ontologies : onto = self . ontologies [ base_iri + \"#\" ] elif base_iri + \"/\" in self . ontologies : onto = self . ontologies [ base_iri + \"/\" ] else : if os . path . exists ( base_iri ): iri = os . path . abspath ( base_iri ) elif os . path . exists ( base_iri + \".ttl\" ): iri = os . path . abspath ( base_iri + \".ttl\" ) elif os . path . exists ( base_iri + \".owl\" ): iri = os . path . abspath ( base_iri + \".owl\" ) else : iri = base_iri if iri [ - 1 ] not in \"/#\" : iri += \"#\" onto = Ontology ( self , iri ) return onto def get_unabbreviated_triples ( self , subject = None , predicate = None , obj = None , blank = None ): # pylint: disable=invalid-name \"\"\"Returns all triples unabbreviated. If any of the `subject`, `predicate` or `obj` arguments are given, only matching triples will be returned. If `blank` is given, it will be used to represent blank nodes. \"\"\" return _get_unabbreviated_triples ( self , subject = subject , predicate = predicate , obj = obj , blank = blank ) get_ontology ( self , base_iri = 'emmo-inferred' ) \u00b6 Returns a new Ontology from base_iri . The base_iri argument may be one of: - valid URL (possible excluding final .owl or .ttl) - file name (possible excluding final .owl or .ttl) - \"emmo\": load latest version of asserted EMMO - \"emmo-inferred\": load latest version of inferred EMMO (default) - \"emmo-development\": load latest inferred development version of EMMO. Until first stable release emmo-inferred and emmo-development will be the same. Source code in ontopy/ontology.py def get_ontology ( self , base_iri = \"emmo-inferred\" ): \"\"\"Returns a new Ontology from `base_iri`. The `base_iri` argument may be one of: - valid URL (possible excluding final .owl or .ttl) - file name (possible excluding final .owl or .ttl) - \"emmo\": load latest version of asserted EMMO - \"emmo-inferred\": load latest version of inferred EMMO (default) - \"emmo-development\": load latest inferred development version of EMMO. Until first stable release emmo-inferred and emmo-development will be the same. \"\"\" base_iri = base_iri . as_uri () if isinstance ( base_iri , Path ) else base_iri if base_iri == \"emmo\" : base_iri = ( \"http://emmo-repo.github.io/versions/1.0.0-beta4/emmo.ttl\" ) elif base_iri == \"emmo-inferred\" : base_iri = ( \"https://emmo-repo.github.io/versions/1.0.0-beta4/\" \"emmo-inferred.ttl\" ) elif base_iri == \"emmo-development\" : base_iri = ( \"https://emmo-repo.github.io/versions/1.0.0-beta4/\" \"emmo-inferred.ttl\" ) if base_iri in self . ontologies : onto = self . ontologies [ base_iri ] elif base_iri + \"#\" in self . ontologies : onto = self . ontologies [ base_iri + \"#\" ] elif base_iri + \"/\" in self . ontologies : onto = self . ontologies [ base_iri + \"/\" ] else : if os . path . exists ( base_iri ): iri = os . path . abspath ( base_iri ) elif os . path . exists ( base_iri + \".ttl\" ): iri = os . path . abspath ( base_iri + \".ttl\" ) elif os . path . exists ( base_iri + \".owl\" ): iri = os . path . abspath ( base_iri + \".owl\" ) else : iri = base_iri if iri [ - 1 ] not in \"/#\" : iri += \"#\" onto = Ontology ( self , iri ) return onto get_unabbreviated_triples ( self , subject = None , predicate = None , obj = None , blank = None ) \u00b6 Returns all triples unabbreviated. If any of the subject , predicate or obj arguments are given, only matching triples will be returned. If blank is given, it will be used to represent blank nodes. Source code in ontopy/ontology.py def get_unabbreviated_triples ( self , subject = None , predicate = None , obj = None , blank = None ): # pylint: disable=invalid-name \"\"\"Returns all triples unabbreviated. If any of the `subject`, `predicate` or `obj` arguments are given, only matching triples will be returned. If `blank` is given, it will be used to represent blank nodes. \"\"\" return _get_unabbreviated_triples ( self , subject = subject , predicate = predicate , obj = obj , blank = blank ) flatten ( items ) \u00b6 Yield items from any nested iterable. Source code in ontopy/ontology.py def flatten ( items ): \"\"\"Yield items from any nested iterable.\"\"\" for item in items : if isinstance ( item , Iterable ) and not isinstance ( item , ( str , bytes )): for sub_item in flatten ( item ): yield sub_item else : yield item get_ontology ( * args , ** kwargs ) \u00b6 Returns a new Ontology from base_iri . This is a convenient function for calling World.get_ontology(). Source code in ontopy/ontology.py def get_ontology ( * args , ** kwargs ): \"\"\"Returns a new Ontology from `base_iri`. This is a convenient function for calling World.get_ontology().\"\"\" return World () . get_ontology ( * args , ** kwargs )","title":"ontology"},{"location":"api_reference/ontopy/ontology/#ontology","text":"A module adding additional functionality to owlready2. If desirable some of these additions may be moved back into owlready2.","title":"ontology"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.BlankNode","text":"Represents a blank node. A blank node is a node that is not a literal and has no IRI. Resources represented by blank nodes are also called anonumous resources. Only the subject or object in an RDF triple can be a blank node. Source code in ontopy/ontology.py class BlankNode : \"\"\"Represents a blank node. A blank node is a node that is not a literal and has no IRI. Resources represented by blank nodes are also called anonumous resources. Only the subject or object in an RDF triple can be a blank node. \"\"\" def __init__ ( self , onto : Union [ World , Ontology ], storid : int ): \"\"\"Initiate a blank node. Args: onto: Ontology or World instance. storid: The storage id of the blank node. \"\"\" if storid >= 0 : raise ValueError ( f \"A BlankNode is supposed to have a negative storid: { storid } \" ) self . onto = onto self . storid = storid def __repr__ ( self ): return repr ( f \"_:b { - self . storid } \" ) def __hash__ ( self ): return hash (( self . onto , self . storid )) def __eq__ ( self , other ): \"\"\"For now blank nodes always compare true against each other.\"\"\" return isinstance ( other , BlankNode )","title":"BlankNode"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.BlankNode.__init__","text":"Initiate a blank node. Parameters: Name Type Description Default onto Union[ontopy.ontology.World, ontopy.ontology.Ontology] Ontology or World instance. required storid int The storage id of the blank node. required Source code in ontopy/ontology.py def __init__ ( self , onto : Union [ World , Ontology ], storid : int ): \"\"\"Initiate a blank node. Args: onto: Ontology or World instance. storid: The storage id of the blank node. \"\"\" if storid >= 0 : raise ValueError ( f \"A BlankNode is supposed to have a negative storid: { storid } \" ) self . onto = onto self . storid = storid","title":"__init__()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology","text":"A generic class extending owlready2.Ontology. Source code in ontopy/ontology.py class Ontology ( owlready2 . Ontology ): # pylint: disable=too-many-public-methods \"\"\"A generic class extending owlready2.Ontology.\"\"\" def __init__ ( self , * args , ** kwargs ): # Properties controlling what annotations that are considered by # get_by_label() super () . __init__ ( * args , ** kwargs ) self . _label_annotations = None self . prefix = None # Properties controlling what annotations that are considered by # get_by_label() label_annotations = property ( fget = lambda self : self . _label_annotations , doc = \"List of label annotation searched for by get_by_label().\" , ) # Name of special unlabeled entities, like Thing, Nothing, etc... _special_labels = None # Some properties for customising dir() listing - useful in # interactive sessions... _dir_preflabel = isinteractive () _dir_label = isinteractive () _dir_name = False _dir_imported = isinteractive () dir_preflabel = property ( fget = lambda self : self . _dir_preflabel , fset = lambda self , v : setattr ( self , \"_dir_preflabel\" , bool ( v )), doc = \"Whether to include entity prefLabel in dir() listing.\" , ) dir_label = property ( fget = lambda self : self . _dir_label , fset = lambda self , v : setattr ( self , \"_dir_label\" , bool ( v )), doc = \"Whether to include entity label in dir() listing.\" , ) dir_name = property ( fget = lambda self : self . _dir_name , fset = lambda self , v : setattr ( self , \"_dir_name\" , bool ( v )), doc = \"Whether to include entity name in dir() listing.\" , ) dir_imported = property ( fget = lambda self : self . _dir_imported , fset = lambda self , v : setattr ( self , \"_dir_imported\" , bool ( v )), doc = \"Whether to include imported ontologies in dir() listing.\" , ) def __dir__ ( self ): set_dir = set ( super () . __dir__ ()) lst = list ( self . get_entities ( imported = self . _dir_imported )) if self . _dir_preflabel : set_dir . update ( _ . prefLabel . first () for _ in lst if hasattr ( _ , \"prefLabel\" ) ) if self . _dir_label : set_dir . update ( _ . label . first () for _ in lst if hasattr ( _ , \"label\" )) if self . _dir_name : set_dir . update ( _ . name for _ in lst if hasattr ( _ , \"name\" )) set_dir . difference_update ({ None }) # get rid of possible None return sorted ( set_dir ) def __getitem__ ( self , name ): item = super () . __getitem__ ( name ) if not item : item = self . get_by_label ( name ) return item def __getattr__ ( self , name ): attr = super () . __getattr__ ( name ) if not attr : attr = self . get_by_label ( name ) return attr def __contains__ ( self , other ): if self . world [ other ]: return True try : self . get_by_label ( other ) except NoSuchLabelError : return False else : return True def __objclass__ ( self ): # Play nice with inspect... pass def __hash__ ( self ): \"\"\"Returns a hash based on base_iri. This is done to keep Ontology hashable when defining __eq__. \"\"\" return hash ( self . base_iri ) def __eq__ ( self , other ): \"\"\"Checks if this ontology is equal to `other`. This function compares the result of ``set(self.get_unabbreviated_triples(label='_:b'))``, i.e. blank nodes are not distinguished, but relations to blank nodes are included. \"\"\" return set ( self . get_unabbreviated_triples ( blank = \"_:b\" )) == set ( other . get_unabbreviated_triples ( blank = \"_:b\" ) ) def get_unabbreviated_triples ( self , subject = None , predicate = None , obj = None , blank = None ): \"\"\"Returns all matching triples unabbreviated. If `blank` is given, it will be used to represent blank nodes. \"\"\" # pylint: disable=invalid-name return _get_unabbreviated_triples ( self , subject = subject , predicate = predicate , obj = obj , blank = blank ) def get_by_label ( self , label : str , label_annotations : str = None , prefix : str = None ): \"\"\"Returns entity with label annotation `label`. Args: label: label so serach for. May be written as 'label' or 'prefix:label'. get_by_label('prefix:label') == get_by_label('label', prefix='prefix'). label_annotations: a sequence of label annotation names to look up. Defaults to the `label_annotations` property. prefix: if provided, it should be the last component of the base iri of an ontology (with trailing slash (/) or hash (#) stripped off). The search for a matching label will be limited to this namespace. If several entities have the same label, only the one which is found first is returned.Use get_by_label_all() to get all matches. A NoSuchLabelError is raised if `label` cannot be found. Note ---- The current implementation also supports \"*\" as a wildcard matching any number of characters. This may change in the future. \"\"\" # pylint: disable=too-many-arguments,too-many-branches if not isinstance ( label , str ): raise TypeError ( f \"Invalid label definition, must be a string: { label !r} \" ) if \" \" in label : raise ValueError ( f \"Invalid label definition, { label !r} contains spaces.\" ) if self . _label_annotations is None : for iri in DEFAULT_LABEL_ANNOTATIONS : try : self . add_label_annotation ( iri ) except ValueError : pass splitlabel = label . split ( \":\" ) if len ( splitlabel ) > 2 : raise ValueError ( f \"Invalid label definition, { label !r} \" \" contains more than one ':' .\" \"The string before ':' indicates the prefix. \" \"The string after ':' indicates the label.\" ) if len ( splitlabel ) == 2 : label = splitlabel [ 1 ] if prefix and prefix != splitlabel [ 0 ]: warnings . warn ( f \"Prefix given both as argument ( { prefix } ) \" f \"and in label ( { splitlabel [ 0 ] } ). \" \"Prefix given in label takes presendence \" ) prefix = splitlabel [ 0 ] if prefix : entitylist = self . get_by_label_all ( label , label_annotations = label_annotations , prefix = prefix , ) if len ( entitylist ) > 0 : return entitylist [ 0 ] raise NoSuchLabelError ( f \"No label annotations matches { label !r} with prefix \" f \" { prefix !r} \" ) # if label in self._namespaces: # return self._namespaces[label] if label_annotations is None : annotations = ( a . name for a in self . label_annotations ) else : annotations = ( a . name if hasattr ( a , \"storid\" ) else a for a in label_annotations ) for key in annotations : entity = self . search_one ( ** { key : label }) if entity : return entity if self . _special_labels and label in self . _special_labels : return self . _special_labels [ label ] entity = self . world [ self . base_iri + label ] if entity : return entity raise NoSuchLabelError ( f \"No label annotations matches { label !r} \" ) def get_by_label_all ( self , label , label_annotations = None , prefix = None ): \"\"\"Like get_by_label(), but returns a list with all matching labels. Returns an empty list if no matches could be found. \"\"\" if not isinstance ( label , str ): raise TypeError ( f \"Invalid label definition, \" f \"must be a string: { label !r} \" ) if \" \" in label : raise ValueError ( f \"Invalid label definition, { label !r} contains spaces.\" ) if label_annotations is None : annotations = ( _ . name for _ in self . label_annotations ) else : annotations = ( _ . name if hasattr ( _ , \"storid\" ) else _ for _ in label_annotations ) entity = self . world . search ( ** { next ( annotations ): label }) for key in annotations : entity . extend ( self . world . search ( ** { key : label })) if self . _special_labels and label in self . _special_labels : entity . append ( self . _special_labels [ label ]) if prefix : return [ _ for _ in entity if _ . namespace . ontology . prefix == prefix ] return entity def add_label_annotation ( self , iri ): \"\"\"Adds label annotation used by get_by_label(). May be provided either as an IRI or as its owlready2 representation. \"\"\" if self . _label_annotations is None : self . _label_annotations = [] label_annotation = iri if hasattr ( iri , \"storid\" ) else self . world [ iri ] if label_annotation is None : warnings . warn ( f \"adding new IRI to ontology: { iri } \" ) name = iri . rsplit ( \"/\" )[ - 1 ] . rsplit ( \"#\" )[ - 1 ] bases = ( owlready2 . AnnotationProperty ,) with self : label_annotation = types . new_class ( name , bases ) if label_annotation not in self . _label_annotations : self . _label_annotations . append ( label_annotation ) def remove_label_annotation ( self , iri ): \"\"\"Removes label annotation used by get_by_label(). May be provided either as an IRI or as its owlready2 representation. \"\"\" label_annotation = iri if hasattr ( iri , \"storid\" ) else self . world [ iri ] if not label_annotation : raise ValueError ( f \"IRI not in ontology: { iri } \" ) self . _label_annotations . remove ( label_annotation ) def set_common_prefix ( self , iri_base : str = \"http://emmo.info/emmo\" , prefix : str = \"emmo\" , ) -> None : \"\"\"Set a common prefix for all imported ontologies with the same first part of the base_iri. Args: iri_base: The start of the base_iri to look for. Defaults to the emmo base_iri http://emmo.info/emmo prefix: the desired prefix. Defaults to emmo. \"\"\" if self . base_iri . startswith ( iri_base ): self . prefix = prefix for onto in self . imported_ontologies : onto . set_common_prefix ( iri_base = iri_base , prefix = prefix ) def load ( # pylint: disable=too-many-arguments,arguments-renamed self , only_local = False , filename = None , format = None , # pylint: disable=redefined-builtin reload = None , reload_if_newer = False , url_from_catalog = None , catalog_file = \"catalog-v001.xml\" , emmo_based = True , prefix = None , prefix_emmo = None , ** kwargs , ): \"\"\"Load the ontology. Parameters ---------- only_local: bool Whether to only read local files. This requires that you have appended the path to the ontology to owlready2.onto_path. filename: str Path to file to load the ontology from. Defaults to `base_iri` provided to get_ontology(). format: str Format of `filename`. Default is inferred from `filename` extension. reload: bool Whether to reload the ontology if it is already loaded. reload_if_newer: bool Whether to reload the ontology if the source has changed since last time it was loaded. url_from_catalog: bool | None Whether to use catalog file to resolve the location of `base_iri`. If None, the catalog file is used if it exists in the same directory as `filename`. catalog_file: str Name of Prot\u00e8g\u00e8 catalog file in the same folder as the ontology. This option is used together with `only_local` and defaults to \"catalog-v001.xml\". emmo_based: bool Whether this is an EMMO-based ontology or not, default `True`. prefix: defaults to self.get_namespace.name if prefix_emmo: bool, default None. If emmo_based is True it defaults to True and sets the prefix of all imported ontologies with base_iri starting with 'http://emmo.info/emmo' to emmo kwargs: Additional keyword arguments are passed on to owlready2.Ontology.load(). \"\"\" # TODO: make sure that `only_local` argument is respected... if self . loaded : return self self . _load ( only_local = only_local , filename = filename , format = format , reload = reload , reload_if_newer = reload_if_newer , url_from_catalog = url_from_catalog , catalog_file = catalog_file , ** kwargs , ) # Enable optimised search by get_by_label() if self . _special_labels is None and emmo_based : for iri in DEFAULT_LABEL_ANNOTATIONS : self . add_label_annotation ( iri ) top = self . world [ \"http://www.w3.org/2002/07/owl#topObjectProperty\" ] self . _special_labels = { \"Thing\" : owlready2 . Thing , \"Nothing\" : owlready2 . Nothing , \"topObjectProperty\" : top , \"owl:Thing\" : owlready2 . Thing , \"owl:Nothing\" : owlready2 . Nothing , \"owl:topObjectProperty\" : top , } # set prefix if another prefix is desired # if we do this, shouldn't we make the name of all # entities of the given ontology to the same? if prefix : self . prefix = prefix else : self . prefix = self . name if emmo_based and prefix_emmo is None : prefix_emmo = True if prefix_emmo : self . set_common_prefix () return self def _load ( # pylint: disable=too-many-arguments,too-many-locals,too-many-branches,too-many-statements self , only_local = False , filename = None , format = None , # pylint: disable=redefined-builtin reload = None , reload_if_newer = False , url_from_catalog = None , catalog_file = \"catalog-v001.xml\" , ** kwargs , ): \"\"\"Help function for load().\"\"\" web_protocol = \"http://\" , \"https://\" , \"ftp://\" url = str ( filename ) if filename else self . base_iri . rstrip ( \"/#\" ) if url . startswith ( web_protocol ): baseurl = os . path . dirname ( url ) catalogurl = baseurl + \"/\" + catalog_file else : if url . startswith ( \"file://\" ): url = url [ 7 :] url = os . path . normpath ( os . path . abspath ( url )) baseurl = os . path . dirname ( url ) catalogurl = os . path . join ( baseurl , catalog_file ) def getmtime ( path ): if os . path . exists ( path ): return os . path . getmtime ( path ) return 0.0 # Resolve url from catalog file iris = {} dirs = set () if url_from_catalog or url_from_catalog is None : not_reload = not reload and ( not reload_if_newer or getmtime ( catalogurl ) > self . world . _cached_catalogs [ catalogurl ][ 0 ] ) # get iris from catalog already in cached catalogs if catalogurl in self . world . _cached_catalogs and not_reload : _ , iris , dirs = self . world . _cached_catalogs [ catalogurl ] # do not update cached_catalogs if url already in _iri_mappings # and reload not forced elif url in self . world . _iri_mappings and not_reload : pass # update iris from current catalogurl else : try : iris , dirs = read_catalog ( uri = catalogurl , recursive = False , return_paths = True , catalog_file = catalog_file , ) except ReadCatalogError : if url_from_catalog is not None : raise self . world . _cached_catalogs [ catalogurl ] = ( 0.0 , {}, set ()) else : self . world . _cached_catalogs [ catalogurl ] = ( getmtime ( catalogurl ), iris , dirs , ) self . world . _iri_mappings . update ( iris ) resolved_url = self . world . _iri_mappings . get ( url , url ) # Append paths from catalog file to onto_path for path in sorted ( dirs , reverse = True ): if path not in owlready2 . onto_path : owlready2 . onto_path . append ( path ) # Use catalog file to update IRIs of imported ontologies # in internal store and try to load again... if self . world . _iri_mappings : for abbrev_iri in self . world . _get_obj_triples_sp_o ( self . storid , owlready2 . owl_imports ): iri = self . _unabbreviate ( abbrev_iri ) if iri in self . world . _iri_mappings : self . _del_obj_triple_spo ( self . storid , owlready2 . owl_imports , abbrev_iri ) self . _add_obj_triple_spo ( self . storid , owlready2 . owl_imports , self . _abbreviate ( self . world . _iri_mappings [ iri ]), ) # Load ontology try : self . loaded = False fmt = format if format else guess_format ( resolved_url , fmap = FMAP ) if fmt and fmt not in OWLREADY2_FORMATS : # Convert filename to rdfxml before passing it to owlready2 graph = rdflib . Graph () try : graph . parse ( resolved_url , format = fmt ) except URLError as err : raise EMMOntoPyException ( \"URL error\" , err , resolved_url ) from err with tempfile . NamedTemporaryFile () as handle : graph . serialize ( destination = handle , format = \"xml\" ) handle . seek ( 0 ) return super () . load ( only_local = True , fileobj = handle , reload = reload , reload_if_newer = reload_if_newer , format = \"rdfxml\" , ** kwargs , ) elif resolved_url . startswith ( web_protocol ): return super () . load ( only_local = only_local , reload = reload , reload_if_newer = reload_if_newer , ** kwargs , ) else : with open ( resolved_url , \"rb\" ) as handle : return super () . load ( only_local = only_local , fileobj = handle , reload = reload , reload_if_newer = reload_if_newer , ** kwargs , ) except owlready2 . OwlReadyOntologyParsingError : # Owlready2 is not able to parse the ontology - most # likely because imported ontologies must be resolved # using the catalog file. # Reraise if we don't want to read from the catalog file if not url_from_catalog and url_from_catalog is not None : raise warnings . warn ( \"Recovering from Owlready2 parsing error... might be deprecated\" ) # Copy the ontology into a local folder and try again with tempfile . TemporaryDirectory () as handle : output = os . path . join ( handle , os . path . basename ( resolved_url )) convert_imported ( input_ontology = resolved_url , output_ontology = output , input_format = fmt , output_format = \"xml\" , url_from_catalog = url_from_catalog , catalog_file = catalog_file , ) self . loaded = False with open ( output , \"rb\" ) as handle : try : return super () . load ( only_local = True , fileobj = handle , reload = reload , reload_if_newer = reload_if_newer , format = \"rdfxml\" , ** kwargs , ) except HTTPError as exc : # Add url to HTTPError message raise HTTPError ( url = exc . url , code = exc . code , msg = f \" { exc . url } : { exc . msg } \" , hdrs = exc . hdrs , fp = exc . fp , ) . with_traceback ( exc . __traceback__ ) except HTTPError as exc : # Add url to HTTPError message raise HTTPError ( url = exc . url , code = exc . code , msg = f \" { exc . url } : { exc . msg } \" , hdrs = exc . hdrs , fp = exc . fp , ) . with_traceback ( exc . __traceback__ ) def save ( self , filename = None , format = None , dir = \".\" , mkdir = False , overwrite = False , recursive = False , squash = False , write_catalog_file = False , append_catalog = False , catalog_file = \"catalog-v001.xml\" , ): \"\"\"Writes the ontology to file. Parameters ---------- filename: None | str | Path Name of file to write to. If None, it defaults to the name of the ontology with `format` as file extension. format: str Output format. The default is to infer it from `filename`. dir: str | Path If `filename` is a relative path, it is a relative path to `dir`. mkdir: bool Whether to create output directory if it does not exists. owerwrite: bool If true and `filename` exists, remove the existing file before saving. The default is to append to an existing ontology. recursive: bool Whether to save imported ontologies recursively. This is commonly combined with `filename=None`, `dir` and `mkdir`. squash: bool If true, rdflib will be used to save the current ontology together with all its sub-ontologies into `filename`. It make no sense to combine this with `recursive`. write_catalog_file: bool Whether to also write a catalog file to disk. append_catalog: bool Whether to append to an existing catalog file. catalog_file: str | Path Name of catalog file. If not an absolute path, it is prepended to `dir`. \"\"\" # pylint: disable=redefined-builtin,too-many-arguments # pylint: disable=too-many-statements,too-many-branches # pylint: disable=too-many-locals,arguments-renamed if not _validate_installed_version ( package = \"rdflib\" , min_version = \"6.0.0\" ) and format == FMAP . get ( \"ttl\" , \"\" ): from rdflib import ( # pylint: disable=import-outside-toplevel __version__ as __rdflib_version__ , ) warnings . warn ( IncompatibleVersion ( \"To correctly convert to Turtle format, rdflib must be \" \"version 6.0.0 or greater, however, the detected rdflib \" \"version used by your Python interpreter is \" f \" { __rdflib_version__ !r} . For more information see the \" \"'Known issues' section of the README.\" ) ) revmap = { value : key for key , value in FMAP . items ()} if filename is None : if format : fmt = revmap . get ( format , format ) filename = f \" { self . name } . { fmt } \" else : TypeError ( \"`filename` and `format` cannot both be None.\" ) filename = os . path . join ( dir , filename ) dir = Path ( filename ) . resolve () . parent if mkdir : outdir = Path ( filename ) . parent . resolve () if not outdir . exists (): outdir . mkdir ( parents = True ) if not format : format = guess_format ( filename , fmap = FMAP ) fmt = revmap . get ( format , format ) if overwrite and filename and os . path . exists ( filename ): os . remove ( filename ) EMMO = rdflib . Namespace ( # pylint:disable=invalid-name \"http://emmo.info/emmo#\" ) if recursive : if squash : raise ValueError ( \"`recursive` and `squash` should not both be true\" ) base = self . base_iri . rstrip ( \"#/\" ) for onto in self . imported_ontologies : obase = onto . base_iri . rstrip ( \"#/\" ) newdir = Path ( dir ) / os . path . relpath ( obase , base ) onto . save ( filename = None , format = format , dir = newdir . resolve (), mkdir = mkdir , overwrite = overwrite , recursive = recursive , squash = squash , write_catalog_file = write_catalog_file , append_catalog = append_catalog , catalog_file = catalog_file , ) if squash : from rdflib import ( # pylint:disable=import-outside-toplevel URIRef , RDF , OWL , ) graph = self . world . as_rdflib_graph () graph . namespace_manager . bind ( \"emmo\" , EMMO ) # Remove anonymous namespace and imports graph . remove (( URIRef ( \"http://anonymous\" ), RDF . type , OWL . Ontology )) imports = list ( graph . triples (( None , OWL . imports , None ))) for triple in imports : graph . remove ( triple ) graph . serialize ( destination = filename , format = format ) elif format in OWLREADY2_FORMATS : super () . save ( file = filename , format = fmt ) else : # The try-finally clause is needed for cleanup and because # we have to provide delete=False to NamedTemporaryFile # since Windows does not allow to reopen an already open # file. try : with tempfile . NamedTemporaryFile ( suffix = \".owl\" , delete = False ) as handle : tmpfile = handle . name super () . save ( tmpfile , format = \"rdfxml\" ) graph = rdflib . Graph () graph . parse ( tmpfile , format = \"xml\" ) graph . serialize ( destination = filename , format = format ) finally : os . remove ( tmpfile ) if write_catalog_file : mappings = {} base = self . base_iri . rstrip ( \"#/\" ) def append ( onto ): obase = onto . base_iri . rstrip ( \"#/\" ) newdir = Path ( dir ) / os . path . relpath ( obase , base ) newpath = newdir . resolve () / f \" { onto . name } . { fmt } \" relpath = os . path . relpath ( newpath , dir ) mappings [ onto . get_version ( as_iri = True )] = str ( relpath ) for imported in onto . imported_ontologies : append ( imported ) if recursive : append ( self ) write_catalog ( mappings , output = catalog_file , directory = dir , append = append_catalog , ) def get_imported_ontologies ( self , recursive = False ): \"\"\"Return a list with imported ontologies. If `recursive` is `True`, ontologies imported by imported ontologies are also returned. \"\"\" def rec_imported ( onto ): for ontology in onto . imported_ontologies : if ontology not in imported : imported . add ( ontology ) rec_imported ( ontology ) if recursive : imported = set () rec_imported ( self ) return list ( imported ) return self . imported_ontologies def get_entities ( # pylint: disable=too-many-arguments self , imported = True , classes = True , individuals = True , object_properties = True , data_properties = True , annotation_properties = True , ): \"\"\"Return a generator over (optionally) all classes, individuals, object_properties, data_properties and annotation_properties. If `imported` is `True`, entities in imported ontologies will also be included. \"\"\" generator = [] if classes : generator . append ( self . classes ( imported )) if individuals : generator . append ( self . individuals ( imported )) if object_properties : generator . append ( self . object_properties ( imported )) if data_properties : generator . append ( self . data_properties ( imported )) if annotation_properties : generator . append ( self . annotation_properties ( imported )) for entity in itertools . chain ( * generator ): yield entity def classes ( self , imported = False ): \"\"\"Returns an generator over all classes. If `imported` is `True`, will imported classes are also returned. \"\"\" if imported : return self . world . classes () return super () . classes () def individuals ( self , imported = False ): \"\"\"Returns an generator over all individuals. If `imported` is `True`, will imported individuals are also returned. \"\"\" if imported : return self . world . individuals () return super () . individuals () def object_properties ( self , imported = False ): \"\"\"Returns an generator over all object properties. If `imported` is true, will imported object properties are also returned. \"\"\" if imported : return self . world . object_properties () return super () . object_properties () def data_properties ( self , imported = False ): \"\"\"Returns an generator over all data properties. If `imported` is true, will imported data properties are also returned. \"\"\" if imported : return self . world . data_properties () return super () . data_properties () def annotation_properties ( self , imported = False ): \"\"\"Returns a generator iterating over all annotation properties defined in the current ontology. If `imported` is true, annotation properties in imported ontologies will also be included. \"\"\" if imported : return self . world . annotation_properties () return super () . annotation_properties () def get_root_classes ( self , imported = False ): \"\"\"Returns a list or root classes.\"\"\" return [ cls for cls in self . classes ( imported = imported ) if not cls . ancestors () . difference ( set ([ cls , owlready2 . Thing ])) ] def get_root_object_properties ( self , imported = False ): \"\"\"Returns a list of root object properties.\"\"\" props = set ( self . object_properties ( imported = imported )) return [ p for p in props if not props . intersection ( p . is_a )] def get_root_data_properties ( self , imported = False ): \"\"\"Returns a list of root object properties.\"\"\" props = set ( self . data_properties ( imported = imported )) return [ p for p in props if not props . intersection ( p . is_a )] def get_roots ( self , imported = False ): \"\"\"Returns all class, object_property and data_property roots.\"\"\" roots = self . get_root_classes ( imported = imported ) roots . extend ( self . get_root_object_properties ( imported = imported )) roots . extend ( self . get_root_data_properties ( imported = imported )) return roots def sync_python_names ( self , annotations = ( \"prefLabel\" , \"label\" , \"altLabel\" )): \"\"\"Update the `python_name` attribute of all properties. The python_name attribute will be set to the first non-empty annotation in the sequence of annotations in `annotations` for the property. \"\"\" def update ( gen ): for prop in gen : for annotation in annotations : if hasattr ( prop , annotation ) and getattr ( prop , annotation ): prop . python_name = getattr ( prop , annotation ) . first () break update ( self . get_entities ( classes = False , individuals = False , object_properties = False , data_properties = False , ) ) update ( self . get_entities ( classes = False , individuals = False , annotation_properties = False ) ) def rename_entities ( self , annotations = ( \"prefLabel\" , \"label\" , \"altLabel\" ), ): \"\"\"Set `name` of all entities to the first non-empty annotation in `annotations`. Warning, this method changes all IRIs in the ontology. However, it may be useful to make the ontology more readable and to work with it together with a triple store. \"\"\" for entity in self . get_entities (): for annotation in annotations : if hasattr ( entity , annotation ): name = getattr ( entity , annotation ) . first () if name : entity . name = name break def sync_reasoner ( self , reasoner = \"FaCT++\" , include_imported = False , ** kwargs ): \"\"\"Update current ontology by running the given reasoner. Supported values for `reasoner` are 'Pellet', 'HermiT' and 'FaCT++'. If `include_imported` is true, the reasoner will also reason over imported ontologies. Note that this may be **very** slow with Pellet and HermiT. Keyword arguments are passed to the underlying owlready2 function. \"\"\" if reasoner == \"FaCT++\" : sync = sync_reasoner_factpp elif reasoner == \"Pellet\" : sync = owlready2 . sync_reasoner_pellet elif reasoner == \"HermiT\" : sync = owlready2 . sync_reasoner_hermit else : raise ValueError ( f \"unknown reasoner { reasoner !r} . Supported reasoners \" 'are \"Pellet\", \"HermiT\" and \"FaCT++\".' ) # For some reason we must visit all entities once before running # the reasoner... list ( self . get_entities ()) with self : if include_imported : sync ( self . world , ** kwargs ) else : sync ( self , ** kwargs ) def sync_attributes ( # pylint: disable=too-many-branches self , name_policy = None , name_prefix = \"\" , class_docstring = \"comment\" , sync_imported = False , ): \"\"\"This method is intended to be called after you have added new classes (typically via Python) to make sure that attributes like `label` and `comments` are defined. If a class, object property, data property or annotation property in the current ontology has no label, the name of the corresponding Python class will be assigned as label. If a class, object property, data property or annotation property has no comment, it will be assigned the docstring of the corresponding Python class. `name_policy` specify wether and how the names in the ontology should be updated. Valid values are: None not changed \"uuid\" `name_prefix` followed by a global unique id (UUID). \"sequential\" `name_prefix` followed a sequantial number. EMMO conventions imply ``name_policy=='uuid'``. If `sync_imported` is true, all imported ontologies are also updated. The `class_docstring` argument specifies the annotation that class docstrings are mapped to. Defaults to \"comment\". \"\"\" for cls in itertools . chain ( self . classes (), self . object_properties (), self . data_properties (), self . annotation_properties (), ): if not hasattr ( cls , \"prefLabel\" ): # no prefLabel - create new annotation property.. with self : # pylint: disable=invalid-name,missing-class-docstring # pylint: disable=unused-variable class prefLabel ( owlready2 . label ): pass cls . prefLabel = [ locstr ( cls . __name__ , lang = \"en\" )] elif not cls . prefLabel : cls . prefLabel . append ( locstr ( cls . __name__ , lang = \"en\" )) if class_docstring and hasattr ( cls , \"__doc__\" ) and cls . __doc__ : getattr ( cls , class_docstring ) . append ( locstr ( inspect . cleandoc ( cls . __doc__ ), lang = \"en\" ) ) for ind in self . individuals (): if not hasattr ( ind , \"prefLabel\" ): # no prefLabel - create new annotation property.. with self : # pylint: disable=invalid-name,missing-class-docstring # pylint: disable=function-redefined class prefLabel ( owlready2 . label ): iri = \"http://www.w3.org/2004/02/skos/core#prefLabel\" ind . prefLabel = [ locstr ( ind . name , lang = \"en\" )] elif not ind . prefLabel : ind . prefLabel . append ( locstr ( ind . name , lang = \"en\" )) chain = itertools . chain ( self . classes (), self . individuals (), self . object_properties (), self . data_properties (), self . annotation_properties (), ) if name_policy == \"uuid\" : for obj in chain : obj . name = name_prefix + str ( uuid . uuid5 ( uuid . NAMESPACE_DNS , obj . name ) ) elif name_policy == \"sequential\" : for obj in chain : counter = 0 while f \" { self . base_iri }{ name_prefix }{ counter } \" in self : counter += 1 obj . name = f \" { name_prefix }{ counter } \" elif name_policy is not None : raise TypeError ( f \"invalid name_policy: { name_policy !r} \" ) if sync_imported : for onto in self . imported_ontologies : onto . sync_attributes () def get_relations ( self ): \"\"\"Returns a generator for all relations.\"\"\" warnings . warn ( \"Ontology.get_relations() is deprecated. Use \" \"onto.object_properties() instead.\" , DeprecationWarning , ) return self . object_properties () def get_annotations ( self , entity ): \"\"\"Returns a dict with annotations for `entity`. Entity may be given either as a ThingClass object or as a label.\"\"\" warnings . warn ( \"Ontology.get_annotations(entity) is deprecated. Use \" \"entity.get_annotations() instead.\" , DeprecationWarning , ) if isinstance ( entity , str ): entity = self . get_by_label ( entity ) res = { \"comment\" : getattr ( entity , \"comment\" , \"\" )} for annotation in self . annotation_properties (): res [ annotation . label . first ()] = [ obj . strip ( '\"' ) for _ , _ , obj in self . get_triples ( entity . storid , annotation . storid , None ) ] return res def get_branch ( # pylint: disable=too-many-arguments self , root , leafs = (), include_leafs = True , strict_leafs = False , exclude = None , sort = False , ): \"\"\"Returns a set with all direct and indirect subclasses of `root`. Any subclass found in the sequence `leafs` will be included in the returned list, but its subclasses will not. The elements of `leafs` may be ThingClass objects or labels. Subclasses of any subclass found in the sequence `leafs` will be excluded from the returned list, where the elements of `leafs` may be ThingClass objects or labels. If `include_leafs` is true, the leafs are included in the returned list, otherwise they are not. If `strict_leafs` is true, any descendant of a leaf will be excluded in the returned set. If given, `exclude` may be a sequence of classes, including their subclasses, to exclude from the output. If `sort` is True, a list sorted according to depth and label will be returned instead of a set. \"\"\" def _branch ( root , leafs ): if root not in leafs : branch = { root , } for cls in root . subclasses (): # Defining a branch is actually quite tricky. Consider # the case: # # L isA R # A isA L # A isA R # # where R is the root, L is a leaf and A is a direct # child of both. Logically, since A is a child of the # leaf we want to skip A. But a strait forward imple- # mentation will see that A is a child of the root and # include it. Requireing that the R should be a strict # parent of A solves this. if root in cls . get_parents ( strict = True ): branch . update ( _branch ( cls , leafs )) else : branch = ( { root , } if include_leafs else set () ) return branch if isinstance ( root , str ): root = self . get_by_label ( root ) leafs = set ( self . get_by_label ( leaf ) if isinstance ( leaf , str ) else leaf for leaf in leafs ) leafs . discard ( root ) if exclude : exclude = set ( self . get_by_label ( e ) if isinstance ( e , str ) else e for e in exclude ) leafs . update ( exclude ) branch = _branch ( root , leafs ) # Exclude all descendants of any leaf if strict_leafs : descendants = root . descendants () for leaf in leafs : if leaf in descendants : branch . difference_update ( leaf . descendants ( include_self = False ) ) if exclude : branch . difference_update ( exclude ) # Sort according to depth, then by label if sort : branch = sorted ( sorted ( branch , key = asstring ), key = lambda x : len ( x . mro ()), ) return branch def is_individual ( self , entity ): \"\"\"Returns true if entity is an individual.\"\"\" if isinstance ( entity , str ): entity = self . get_by_label ( entity ) return isinstance ( entity , owlready2 . Thing ) # FIXME - deprecate this method as soon the ThingClass property # `defined_class` works correct in Owlready2 def is_defined ( self , entity ): \"\"\"Returns true if the entity is a defined class.\"\"\" if isinstance ( entity , str ): entity = self . get_by_label ( entity ) return hasattr ( entity , \"equivalent_to\" ) and bool ( entity . equivalent_to ) def get_version ( self , as_iri = False ) -> str : \"\"\"Returns the version number of the ontology as inferred from the owl:versionIRI tag or, if owl:versionIRI is not found, from owl:versionINFO. If `as_iri` is True, the full versionIRI is returned. \"\"\" version_iri_storid = self . world . _abbreviate ( \"http://www.w3.org/2002/07/owl#versionIRI\" ) tokens = self . get_triples ( s = self . storid , p = version_iri_storid ) if ( not tokens ) and ( as_iri is True ): raise TypeError ( \"No owl:versionIRI \" f \"in Ontology { self . base_iri !r} . \" \"Search for owl:versionInfo with as_iri=False\" ) if tokens : _ , _ , obj = tokens [ 0 ] version_iri = self . world . _unabbreviate ( obj ) if as_iri : return version_iri return infer_version ( self . base_iri , version_iri ) version_info_storid = self . world . _abbreviate ( \"http://www.w3.org/2002/07/owl#versionInfo\" ) tokens = self . get_triples ( s = self . storid , p = version_info_storid ) if not tokens : raise TypeError ( \"No versionIRI or versionInfo \" f \"in Ontology { self . base_iri !r} \" ) _ , _ , version_info = tokens [ 0 ] return version_info . strip ( '\"' ) . strip ( \"'\" ) def set_version ( self , version = None , version_iri = None ): \"\"\"Assign version to ontology by asigning owl:versionIRI. If `version` but not `version_iri` is provided, the version IRI will be the combination of `base_iri` and `version`. \"\"\" _version_iri = \"http://www.w3.org/2002/07/owl#versionIRI\" version_iri_storid = self . world . _abbreviate ( _version_iri ) if self . _has_obj_triple_spo ( # pylint: disable=unexpected-keyword-arg # For some reason _has_obj_triples_spo exists in both # owlready2.namespace.Namespace (with arguments subject/predicate) # and in owlready2.triplelite._GraphManager (with arguments s/p) # owlready2.Ontology inherits from Namespace directly # and pylint checks that. # It actually accesses the one in triplelite. # subject=self.storid, predicate=version_iri_storid s = self . storid , p = version_iri_storid , ): self . _del_obj_triple_spo ( s = self . storid , p = version_iri_storid ) if not version_iri : if not version : raise TypeError ( \"Either `version` or `version_iri` must be provided\" ) head , tail = self . base_iri . rstrip ( \"#/\" ) . rsplit ( \"/\" , 1 ) version_iri = \"/\" . join ([ head , version , tail ]) self . _add_obj_triple_spo ( s = self . storid , p = self . world . _abbreviate ( _version_iri ), o = self . world . _abbreviate ( version_iri ), ) def get_graph ( self , ** kwargs ): \"\"\"Returns a new graph object. See emmo.graph.OntoGraph. Note that this method requires the Python graphviz package. \"\"\" # pylint: disable=import-outside-toplevel,cyclic-import from ontopy.graph import OntoGraph return OntoGraph ( self , ** kwargs ) @staticmethod def common_ancestors ( cls1 , cls2 ): \"\"\"Return a list of common ancestors for `cls1` and `cls2`.\"\"\" return set ( cls1 . ancestors ()) . intersection ( cls2 . ancestors ()) def number_of_generations ( self , descendant , ancestor ): \"\"\"Return shortest distance from ancestor to descendant\"\"\" if ancestor not in descendant . ancestors (): raise ValueError ( \"Descendant is not a descendant of ancestor\" ) return self . _number_of_generations ( descendant , ancestor , 0 ) def _number_of_generations ( self , descendant , ancestor , counter ): \"\"\"Recursive help function to number_of_generations(), return distance between a ancestor-descendant pair (counter+1).\"\"\" if descendant . name == ancestor . name : return counter try : return min ( self . _number_of_generations ( parent , ancestor , counter + 1 ) for parent in descendant . get_parents () if ancestor in parent . ancestors () ) except ValueError : return counter def closest_common_ancestors ( self , cls1 , cls2 ): \"\"\"Returns a list with closest_common_ancestor for cls1 and cls2\"\"\" distances = {} for ancestor in self . common_ancestors ( cls1 , cls2 ): distances [ ancestor ] = self . number_of_generations ( cls1 , ancestor ) + self . number_of_generations ( cls2 , ancestor ) return [ ancestor for ancestor , distance in distances . items () if distance == min ( distances . values ()) ] @staticmethod def closest_common_ancestor ( * classes ): \"\"\"Returns closest_common_ancestor for the given classes.\"\"\" mros = [ cls . mro () for cls in classes ] track = defaultdict ( int ) while mros : for mro in mros : cur = mro . pop ( 0 ) track [ cur ] += 1 if track [ cur ] == len ( classes ): return cur if len ( mro ) == 0 : mros . remove ( mro ) raise Exception ( \"A closest common ancestor should always exist !\" ) def get_ancestors ( self , classes , include = \"all\" , strict = True ): \"\"\"Return ancestors of all classes in `classes`. classes to be provided as list The values of `include` may be: - None: ignore this argument - \"all\": Include all ancestors. - \"closest\": Include all ancestors up to the closest common ancestor of all classes. - int: Include this number of ancestor levels. Here `include` may be an integer or a string that can be converted to int. \"\"\" ancestors = set () if not classes : return ancestors def addancestors ( entity , counter , subject ): if counter > 0 : for parent in entity . get_parents ( strict = True ): subject . add ( parent ) addancestors ( parent , counter - 1 , subject ) if isinstance ( include , str ) and include . isdigit (): include = int ( include ) if include == \"all\" : ancestors . update ( * ( _ . ancestors () for _ in classes )) elif include == \"closest\" : closest = self . closest_common_ancestor ( * classes ) for cls in classes : ancestors . update ( _ for _ in cls . ancestors () if closest in _ . ancestors () ) elif isinstance ( include , int ): for entity in classes : addancestors ( entity , int ( include ), ancestors ) elif include not in ( None , \"None\" , \"none\" , \"\" ): raise ValueError ( 'include must be \"all\", \"closest\" or None' ) if strict : return ancestors . difference ( classes ) return ancestors def get_descendants ( self , classes : \"Union[List, ThingClass]\" , common : bool = False , generations : int = None , ) -> set : \"\"\"Return descendants/subclasses of all classes in `classes`. Args: classes: to be provided as list. common: whether to only return descendants common to all classes. generations: Include this number of generations, default is all. Returns: A set of descendants for given number of generations. If 'common'=True, the common descendants are returned within the specified number of generations. 'generations' defaults to all. \"\"\" if not isinstance ( classes , Sequence ): classes = [ classes ] descendants = { name : [] for name in classes } def _children_recursively ( num , newentity , parent , descendants ): \"\"\"Helper function to get all children up to generation.\"\"\" for child in self . get_children_of ( newentity ): descendants [ parent ] . append ( child ) if num < generations : _children_recursively ( num + 1 , child , parent , descendants ) if generations == 0 : return set () if not generations : for entity in classes : descendants [ entity ] = entity . descendants () # only include proper descendants descendants [ entity ] . remove ( entity ) else : for entity in classes : _children_recursively ( 1 , entity , entity , descendants ) results = descendants . values () if common is True : return set . intersection ( * map ( set , results )) return set ( flatten ( results )) def get_wu_palmer_measure ( self , cls1 , cls2 ): \"\"\"Return Wu-Palmer measure for semantic similarity. Returns Wu-Palmer measure for semantic similarity between two concepts. Wu, Palmer; ACL 94: Proceedings of the 32nd annual meeting on Association for Computational Linguistics, June 1994. \"\"\" cca = self . closest_common_ancestor ( cls1 , cls2 ) ccadepth = self . number_of_generations ( cca , self . Thing ) generations1 = self . number_of_generations ( cls1 , cca ) generations2 = self . number_of_generations ( cls2 , cca ) return 2 * ccadepth / ( generations1 + generations2 + 2 * ccadepth ) def new_entity ( self , name : str , parent : Union [ ThingClass , Iterable ] ) -> ThingClass : \"\"\"Create and return new entity Makes a new entity in the ontology with given parent(s). Return the new entity. Throws exception if name consists of more than one word. \"\"\" if len ( name . split ( \" \" )) > 1 : raise LabelDefinitionError ( f \"Error in label name definition ' { name } ': \" f \"Label consists of more than one word.\" ) parents = tuple ( parent ) if isinstance ( parent , Iterable ) else ( parent ,) for thing in parents : if not isinstance ( thing , owlready2 . ThingClass ): raise ThingClassDefinitionError ( f \"Error in parent definition: \" f \"' { thing } ' is not an owlready2.ThingClass.\" ) with self : entity = types . new_class ( name , parents ) return entity","title":"Ontology"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.dir_imported","text":"Whether to include imported ontologies in dir() listing.","title":"dir_imported"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.dir_label","text":"Whether to include entity label in dir() listing.","title":"dir_label"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.dir_name","text":"Whether to include entity name in dir() listing.","title":"dir_name"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.dir_preflabel","text":"Whether to include entity prefLabel in dir() listing.","title":"dir_preflabel"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.label_annotations","text":"List of label annotation searched for by get_by_label().","title":"label_annotations"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.add_label_annotation","text":"Adds label annotation used by get_by_label(). May be provided either as an IRI or as its owlready2 representation. Source code in ontopy/ontology.py def add_label_annotation ( self , iri ): \"\"\"Adds label annotation used by get_by_label(). May be provided either as an IRI or as its owlready2 representation. \"\"\" if self . _label_annotations is None : self . _label_annotations = [] label_annotation = iri if hasattr ( iri , \"storid\" ) else self . world [ iri ] if label_annotation is None : warnings . warn ( f \"adding new IRI to ontology: { iri } \" ) name = iri . rsplit ( \"/\" )[ - 1 ] . rsplit ( \"#\" )[ - 1 ] bases = ( owlready2 . AnnotationProperty ,) with self : label_annotation = types . new_class ( name , bases ) if label_annotation not in self . _label_annotations : self . _label_annotations . append ( label_annotation )","title":"add_label_annotation()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.annotation_properties","text":"Returns a generator iterating over all annotation properties defined in the current ontology. If imported is true, annotation properties in imported ontologies will also be included. Source code in ontopy/ontology.py def annotation_properties ( self , imported = False ): \"\"\"Returns a generator iterating over all annotation properties defined in the current ontology. If `imported` is true, annotation properties in imported ontologies will also be included. \"\"\" if imported : return self . world . annotation_properties () return super () . annotation_properties ()","title":"annotation_properties()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.classes","text":"Returns an generator over all classes. If imported is True , will imported classes are also returned. Source code in ontopy/ontology.py def classes ( self , imported = False ): \"\"\"Returns an generator over all classes. If `imported` is `True`, will imported classes are also returned. \"\"\" if imported : return self . world . classes () return super () . classes ()","title":"classes()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.closest_common_ancestor","text":"Returns closest_common_ancestor for the given classes. Source code in ontopy/ontology.py @staticmethod def closest_common_ancestor ( * classes ): \"\"\"Returns closest_common_ancestor for the given classes.\"\"\" mros = [ cls . mro () for cls in classes ] track = defaultdict ( int ) while mros : for mro in mros : cur = mro . pop ( 0 ) track [ cur ] += 1 if track [ cur ] == len ( classes ): return cur if len ( mro ) == 0 : mros . remove ( mro ) raise Exception ( \"A closest common ancestor should always exist !\" )","title":"closest_common_ancestor()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.closest_common_ancestors","text":"Returns a list with closest_common_ancestor for cls1 and cls2 Source code in ontopy/ontology.py def closest_common_ancestors ( self , cls1 , cls2 ): \"\"\"Returns a list with closest_common_ancestor for cls1 and cls2\"\"\" distances = {} for ancestor in self . common_ancestors ( cls1 , cls2 ): distances [ ancestor ] = self . number_of_generations ( cls1 , ancestor ) + self . number_of_generations ( cls2 , ancestor ) return [ ancestor for ancestor , distance in distances . items () if distance == min ( distances . values ()) ]","title":"closest_common_ancestors()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.common_ancestors","text":"Return a list of common ancestors for cls1 and cls2 . Source code in ontopy/ontology.py @staticmethod def common_ancestors ( cls1 , cls2 ): \"\"\"Return a list of common ancestors for `cls1` and `cls2`.\"\"\" return set ( cls1 . ancestors ()) . intersection ( cls2 . ancestors ())","title":"common_ancestors()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.data_properties","text":"Returns an generator over all data properties. If imported is true, will imported data properties are also returned. Source code in ontopy/ontology.py def data_properties ( self , imported = False ): \"\"\"Returns an generator over all data properties. If `imported` is true, will imported data properties are also returned. \"\"\" if imported : return self . world . data_properties () return super () . data_properties ()","title":"data_properties()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_ancestors","text":"Return ancestors of all classes in classes . classes to be provided as list The values of include may be: - None: ignore this argument - \"all\": Include all ancestors. - \"closest\": Include all ancestors up to the closest common ancestor of all classes. - int: Include this number of ancestor levels. Here include may be an integer or a string that can be converted to int. Source code in ontopy/ontology.py def get_ancestors ( self , classes , include = \"all\" , strict = True ): \"\"\"Return ancestors of all classes in `classes`. classes to be provided as list The values of `include` may be: - None: ignore this argument - \"all\": Include all ancestors. - \"closest\": Include all ancestors up to the closest common ancestor of all classes. - int: Include this number of ancestor levels. Here `include` may be an integer or a string that can be converted to int. \"\"\" ancestors = set () if not classes : return ancestors def addancestors ( entity , counter , subject ): if counter > 0 : for parent in entity . get_parents ( strict = True ): subject . add ( parent ) addancestors ( parent , counter - 1 , subject ) if isinstance ( include , str ) and include . isdigit (): include = int ( include ) if include == \"all\" : ancestors . update ( * ( _ . ancestors () for _ in classes )) elif include == \"closest\" : closest = self . closest_common_ancestor ( * classes ) for cls in classes : ancestors . update ( _ for _ in cls . ancestors () if closest in _ . ancestors () ) elif isinstance ( include , int ): for entity in classes : addancestors ( entity , int ( include ), ancestors ) elif include not in ( None , \"None\" , \"none\" , \"\" ): raise ValueError ( 'include must be \"all\", \"closest\" or None' ) if strict : return ancestors . difference ( classes ) return ancestors","title":"get_ancestors()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_annotations","text":"Returns a dict with annotations for entity . Entity may be given either as a ThingClass object or as a label. Source code in ontopy/ontology.py def get_annotations ( self , entity ): \"\"\"Returns a dict with annotations for `entity`. Entity may be given either as a ThingClass object or as a label.\"\"\" warnings . warn ( \"Ontology.get_annotations(entity) is deprecated. Use \" \"entity.get_annotations() instead.\" , DeprecationWarning , ) if isinstance ( entity , str ): entity = self . get_by_label ( entity ) res = { \"comment\" : getattr ( entity , \"comment\" , \"\" )} for annotation in self . annotation_properties (): res [ annotation . label . first ()] = [ obj . strip ( '\"' ) for _ , _ , obj in self . get_triples ( entity . storid , annotation . storid , None ) ] return res","title":"get_annotations()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_branch","text":"Returns a set with all direct and indirect subclasses of root . Any subclass found in the sequence leafs will be included in the returned list, but its subclasses will not. The elements of leafs may be ThingClass objects or labels. Subclasses of any subclass found in the sequence leafs will be excluded from the returned list, where the elements of leafs may be ThingClass objects or labels. If include_leafs is true, the leafs are included in the returned list, otherwise they are not. If strict_leafs is true, any descendant of a leaf will be excluded in the returned set. If given, exclude may be a sequence of classes, including their subclasses, to exclude from the output. If sort is True, a list sorted according to depth and label will be returned instead of a set. Source code in ontopy/ontology.py def get_branch ( # pylint: disable=too-many-arguments self , root , leafs = (), include_leafs = True , strict_leafs = False , exclude = None , sort = False , ): \"\"\"Returns a set with all direct and indirect subclasses of `root`. Any subclass found in the sequence `leafs` will be included in the returned list, but its subclasses will not. The elements of `leafs` may be ThingClass objects or labels. Subclasses of any subclass found in the sequence `leafs` will be excluded from the returned list, where the elements of `leafs` may be ThingClass objects or labels. If `include_leafs` is true, the leafs are included in the returned list, otherwise they are not. If `strict_leafs` is true, any descendant of a leaf will be excluded in the returned set. If given, `exclude` may be a sequence of classes, including their subclasses, to exclude from the output. If `sort` is True, a list sorted according to depth and label will be returned instead of a set. \"\"\" def _branch ( root , leafs ): if root not in leafs : branch = { root , } for cls in root . subclasses (): # Defining a branch is actually quite tricky. Consider # the case: # # L isA R # A isA L # A isA R # # where R is the root, L is a leaf and A is a direct # child of both. Logically, since A is a child of the # leaf we want to skip A. But a strait forward imple- # mentation will see that A is a child of the root and # include it. Requireing that the R should be a strict # parent of A solves this. if root in cls . get_parents ( strict = True ): branch . update ( _branch ( cls , leafs )) else : branch = ( { root , } if include_leafs else set () ) return branch if isinstance ( root , str ): root = self . get_by_label ( root ) leafs = set ( self . get_by_label ( leaf ) if isinstance ( leaf , str ) else leaf for leaf in leafs ) leafs . discard ( root ) if exclude : exclude = set ( self . get_by_label ( e ) if isinstance ( e , str ) else e for e in exclude ) leafs . update ( exclude ) branch = _branch ( root , leafs ) # Exclude all descendants of any leaf if strict_leafs : descendants = root . descendants () for leaf in leafs : if leaf in descendants : branch . difference_update ( leaf . descendants ( include_self = False ) ) if exclude : branch . difference_update ( exclude ) # Sort according to depth, then by label if sort : branch = sorted ( sorted ( branch , key = asstring ), key = lambda x : len ( x . mro ()), ) return branch","title":"get_branch()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_by_label","text":"Returns entity with label annotation label . Parameters: Name Type Description Default label str label so serach for. May be written as 'label' or 'prefix:label'. get_by_label('prefix:label') == get_by_label('label', prefix='prefix'). required label_annotations str a sequence of label annotation names to look up. Defaults to the label_annotations property. None prefix str if provided, it should be the last component of the base iri of an ontology (with trailing slash (/) or hash (#) stripped off). The search for a matching label will be limited to this namespace. None If several entities have the same label, only the one which is found first is returned.Use get_by_label_all() to get all matches. A NoSuchLabelError is raised if label cannot be found.","title":"get_by_label()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_by_label--note","text":"The current implementation also supports \"*\" as a wildcard matching any number of characters. This may change in the future. Source code in ontopy/ontology.py def get_by_label ( self , label : str , label_annotations : str = None , prefix : str = None ): \"\"\"Returns entity with label annotation `label`. Args: label: label so serach for. May be written as 'label' or 'prefix:label'. get_by_label('prefix:label') == get_by_label('label', prefix='prefix'). label_annotations: a sequence of label annotation names to look up. Defaults to the `label_annotations` property. prefix: if provided, it should be the last component of the base iri of an ontology (with trailing slash (/) or hash (#) stripped off). The search for a matching label will be limited to this namespace. If several entities have the same label, only the one which is found first is returned.Use get_by_label_all() to get all matches. A NoSuchLabelError is raised if `label` cannot be found. Note ---- The current implementation also supports \"*\" as a wildcard matching any number of characters. This may change in the future. \"\"\" # pylint: disable=too-many-arguments,too-many-branches if not isinstance ( label , str ): raise TypeError ( f \"Invalid label definition, must be a string: { label !r} \" ) if \" \" in label : raise ValueError ( f \"Invalid label definition, { label !r} contains spaces.\" ) if self . _label_annotations is None : for iri in DEFAULT_LABEL_ANNOTATIONS : try : self . add_label_annotation ( iri ) except ValueError : pass splitlabel = label . split ( \":\" ) if len ( splitlabel ) > 2 : raise ValueError ( f \"Invalid label definition, { label !r} \" \" contains more than one ':' .\" \"The string before ':' indicates the prefix. \" \"The string after ':' indicates the label.\" ) if len ( splitlabel ) == 2 : label = splitlabel [ 1 ] if prefix and prefix != splitlabel [ 0 ]: warnings . warn ( f \"Prefix given both as argument ( { prefix } ) \" f \"and in label ( { splitlabel [ 0 ] } ). \" \"Prefix given in label takes presendence \" ) prefix = splitlabel [ 0 ] if prefix : entitylist = self . get_by_label_all ( label , label_annotations = label_annotations , prefix = prefix , ) if len ( entitylist ) > 0 : return entitylist [ 0 ] raise NoSuchLabelError ( f \"No label annotations matches { label !r} with prefix \" f \" { prefix !r} \" ) # if label in self._namespaces: # return self._namespaces[label] if label_annotations is None : annotations = ( a . name for a in self . label_annotations ) else : annotations = ( a . name if hasattr ( a , \"storid\" ) else a for a in label_annotations ) for key in annotations : entity = self . search_one ( ** { key : label }) if entity : return entity if self . _special_labels and label in self . _special_labels : return self . _special_labels [ label ] entity = self . world [ self . base_iri + label ] if entity : return entity raise NoSuchLabelError ( f \"No label annotations matches { label !r} \" )","title":"Note"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_by_label_all","text":"Like get_by_label(), but returns a list with all matching labels. Returns an empty list if no matches could be found. Source code in ontopy/ontology.py def get_by_label_all ( self , label , label_annotations = None , prefix = None ): \"\"\"Like get_by_label(), but returns a list with all matching labels. Returns an empty list if no matches could be found. \"\"\" if not isinstance ( label , str ): raise TypeError ( f \"Invalid label definition, \" f \"must be a string: { label !r} \" ) if \" \" in label : raise ValueError ( f \"Invalid label definition, { label !r} contains spaces.\" ) if label_annotations is None : annotations = ( _ . name for _ in self . label_annotations ) else : annotations = ( _ . name if hasattr ( _ , \"storid\" ) else _ for _ in label_annotations ) entity = self . world . search ( ** { next ( annotations ): label }) for key in annotations : entity . extend ( self . world . search ( ** { key : label })) if self . _special_labels and label in self . _special_labels : entity . append ( self . _special_labels [ label ]) if prefix : return [ _ for _ in entity if _ . namespace . ontology . prefix == prefix ] return entity","title":"get_by_label_all()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_descendants","text":"Return descendants/subclasses of all classes in classes . Parameters: Name Type Description Default classes Union[List, ThingClass] to be provided as list. required common bool whether to only return descendants common to all classes. False generations int Include this number of generations, default is all. None Returns: Type Description set A set of descendants for given number of generations. If 'common'=True, the common descendants are returned within the specified number of generations. 'generations' defaults to all. Source code in ontopy/ontology.py def get_descendants ( self , classes : \"Union[List, ThingClass]\" , common : bool = False , generations : int = None , ) -> set : \"\"\"Return descendants/subclasses of all classes in `classes`. Args: classes: to be provided as list. common: whether to only return descendants common to all classes. generations: Include this number of generations, default is all. Returns: A set of descendants for given number of generations. If 'common'=True, the common descendants are returned within the specified number of generations. 'generations' defaults to all. \"\"\" if not isinstance ( classes , Sequence ): classes = [ classes ] descendants = { name : [] for name in classes } def _children_recursively ( num , newentity , parent , descendants ): \"\"\"Helper function to get all children up to generation.\"\"\" for child in self . get_children_of ( newentity ): descendants [ parent ] . append ( child ) if num < generations : _children_recursively ( num + 1 , child , parent , descendants ) if generations == 0 : return set () if not generations : for entity in classes : descendants [ entity ] = entity . descendants () # only include proper descendants descendants [ entity ] . remove ( entity ) else : for entity in classes : _children_recursively ( 1 , entity , entity , descendants ) results = descendants . values () if common is True : return set . intersection ( * map ( set , results )) return set ( flatten ( results ))","title":"get_descendants()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_entities","text":"Return a generator over (optionally) all classes, individuals, object_properties, data_properties and annotation_properties. If imported is True , entities in imported ontologies will also be included. Source code in ontopy/ontology.py def get_entities ( # pylint: disable=too-many-arguments self , imported = True , classes = True , individuals = True , object_properties = True , data_properties = True , annotation_properties = True , ): \"\"\"Return a generator over (optionally) all classes, individuals, object_properties, data_properties and annotation_properties. If `imported` is `True`, entities in imported ontologies will also be included. \"\"\" generator = [] if classes : generator . append ( self . classes ( imported )) if individuals : generator . append ( self . individuals ( imported )) if object_properties : generator . append ( self . object_properties ( imported )) if data_properties : generator . append ( self . data_properties ( imported )) if annotation_properties : generator . append ( self . annotation_properties ( imported )) for entity in itertools . chain ( * generator ): yield entity","title":"get_entities()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_graph","text":"Returns a new graph object. See emmo.graph.OntoGraph. Note that this method requires the Python graphviz package. Source code in ontopy/ontology.py def get_graph ( self , ** kwargs ): \"\"\"Returns a new graph object. See emmo.graph.OntoGraph. Note that this method requires the Python graphviz package. \"\"\" # pylint: disable=import-outside-toplevel,cyclic-import from ontopy.graph import OntoGraph return OntoGraph ( self , ** kwargs )","title":"get_graph()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_imported_ontologies","text":"Return a list with imported ontologies. If recursive is True , ontologies imported by imported ontologies are also returned. Source code in ontopy/ontology.py def get_imported_ontologies ( self , recursive = False ): \"\"\"Return a list with imported ontologies. If `recursive` is `True`, ontologies imported by imported ontologies are also returned. \"\"\" def rec_imported ( onto ): for ontology in onto . imported_ontologies : if ontology not in imported : imported . add ( ontology ) rec_imported ( ontology ) if recursive : imported = set () rec_imported ( self ) return list ( imported ) return self . imported_ontologies","title":"get_imported_ontologies()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_relations","text":"Returns a generator for all relations. Source code in ontopy/ontology.py def get_relations ( self ): \"\"\"Returns a generator for all relations.\"\"\" warnings . warn ( \"Ontology.get_relations() is deprecated. Use \" \"onto.object_properties() instead.\" , DeprecationWarning , ) return self . object_properties ()","title":"get_relations()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_root_classes","text":"Returns a list or root classes. Source code in ontopy/ontology.py def get_root_classes ( self , imported = False ): \"\"\"Returns a list or root classes.\"\"\" return [ cls for cls in self . classes ( imported = imported ) if not cls . ancestors () . difference ( set ([ cls , owlready2 . Thing ])) ]","title":"get_root_classes()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_root_data_properties","text":"Returns a list of root object properties. Source code in ontopy/ontology.py def get_root_data_properties ( self , imported = False ): \"\"\"Returns a list of root object properties.\"\"\" props = set ( self . data_properties ( imported = imported )) return [ p for p in props if not props . intersection ( p . is_a )]","title":"get_root_data_properties()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_root_object_properties","text":"Returns a list of root object properties. Source code in ontopy/ontology.py def get_root_object_properties ( self , imported = False ): \"\"\"Returns a list of root object properties.\"\"\" props = set ( self . object_properties ( imported = imported )) return [ p for p in props if not props . intersection ( p . is_a )]","title":"get_root_object_properties()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_roots","text":"Returns all class, object_property and data_property roots. Source code in ontopy/ontology.py def get_roots ( self , imported = False ): \"\"\"Returns all class, object_property and data_property roots.\"\"\" roots = self . get_root_classes ( imported = imported ) roots . extend ( self . get_root_object_properties ( imported = imported )) roots . extend ( self . get_root_data_properties ( imported = imported )) return roots","title":"get_roots()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_unabbreviated_triples","text":"Returns all matching triples unabbreviated. If blank is given, it will be used to represent blank nodes. Source code in ontopy/ontology.py def get_unabbreviated_triples ( self , subject = None , predicate = None , obj = None , blank = None ): \"\"\"Returns all matching triples unabbreviated. If `blank` is given, it will be used to represent blank nodes. \"\"\" # pylint: disable=invalid-name return _get_unabbreviated_triples ( self , subject = subject , predicate = predicate , obj = obj , blank = blank )","title":"get_unabbreviated_triples()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_version","text":"Returns the version number of the ontology as inferred from the owl:versionIRI tag or, if owl:versionIRI is not found, from owl:versionINFO. If as_iri is True, the full versionIRI is returned. Source code in ontopy/ontology.py def get_version ( self , as_iri = False ) -> str : \"\"\"Returns the version number of the ontology as inferred from the owl:versionIRI tag or, if owl:versionIRI is not found, from owl:versionINFO. If `as_iri` is True, the full versionIRI is returned. \"\"\" version_iri_storid = self . world . _abbreviate ( \"http://www.w3.org/2002/07/owl#versionIRI\" ) tokens = self . get_triples ( s = self . storid , p = version_iri_storid ) if ( not tokens ) and ( as_iri is True ): raise TypeError ( \"No owl:versionIRI \" f \"in Ontology { self . base_iri !r} . \" \"Search for owl:versionInfo with as_iri=False\" ) if tokens : _ , _ , obj = tokens [ 0 ] version_iri = self . world . _unabbreviate ( obj ) if as_iri : return version_iri return infer_version ( self . base_iri , version_iri ) version_info_storid = self . world . _abbreviate ( \"http://www.w3.org/2002/07/owl#versionInfo\" ) tokens = self . get_triples ( s = self . storid , p = version_info_storid ) if not tokens : raise TypeError ( \"No versionIRI or versionInfo \" f \"in Ontology { self . base_iri !r} \" ) _ , _ , version_info = tokens [ 0 ] return version_info . strip ( '\"' ) . strip ( \"'\" )","title":"get_version()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.get_wu_palmer_measure","text":"Return Wu-Palmer measure for semantic similarity. Returns Wu-Palmer measure for semantic similarity between two concepts. Wu, Palmer; ACL 94: Proceedings of the 32nd annual meeting on Association for Computational Linguistics, June 1994. Source code in ontopy/ontology.py def get_wu_palmer_measure ( self , cls1 , cls2 ): \"\"\"Return Wu-Palmer measure for semantic similarity. Returns Wu-Palmer measure for semantic similarity between two concepts. Wu, Palmer; ACL 94: Proceedings of the 32nd annual meeting on Association for Computational Linguistics, June 1994. \"\"\" cca = self . closest_common_ancestor ( cls1 , cls2 ) ccadepth = self . number_of_generations ( cca , self . Thing ) generations1 = self . number_of_generations ( cls1 , cca ) generations2 = self . number_of_generations ( cls2 , cca ) return 2 * ccadepth / ( generations1 + generations2 + 2 * ccadepth )","title":"get_wu_palmer_measure()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.individuals","text":"Returns an generator over all individuals. If imported is True , will imported individuals are also returned. Source code in ontopy/ontology.py def individuals ( self , imported = False ): \"\"\"Returns an generator over all individuals. If `imported` is `True`, will imported individuals are also returned. \"\"\" if imported : return self . world . individuals () return super () . individuals ()","title":"individuals()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.is_defined","text":"Returns true if the entity is a defined class. Source code in ontopy/ontology.py def is_defined ( self , entity ): \"\"\"Returns true if the entity is a defined class.\"\"\" if isinstance ( entity , str ): entity = self . get_by_label ( entity ) return hasattr ( entity , \"equivalent_to\" ) and bool ( entity . equivalent_to )","title":"is_defined()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.is_individual","text":"Returns true if entity is an individual. Source code in ontopy/ontology.py def is_individual ( self , entity ): \"\"\"Returns true if entity is an individual.\"\"\" if isinstance ( entity , str ): entity = self . get_by_label ( entity ) return isinstance ( entity , owlready2 . Thing )","title":"is_individual()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.load","text":"Load the ontology.","title":"load()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.load--parameters","text":"bool Whether to only read local files. This requires that you have appended the path to the ontology to owlready2.onto_path. str Path to file to load the ontology from. Defaults to base_iri provided to get_ontology(). str Format of filename . Default is inferred from filename extension. bool Whether to reload the ontology if it is already loaded. bool Whether to reload the ontology if the source has changed since last time it was loaded. bool | None Whether to use catalog file to resolve the location of base_iri . If None, the catalog file is used if it exists in the same directory as filename . str Name of Prot\u00e8g\u00e8 catalog file in the same folder as the ontology. This option is used together with only_local and defaults to \"catalog-v001.xml\". bool Whether this is an EMMO-based ontology or not, default True . prefix: defaults to self.get_namespace.name if bool, default None. If emmo_based is True it defaults to True and sets the prefix of all imported ontologies with base_iri starting with 'http://emmo.info/emmo' to emmo Kwargs Additional keyword arguments are passed on to owlready2.Ontology.load(). Source code in ontopy/ontology.py def load ( # pylint: disable=too-many-arguments,arguments-renamed self , only_local = False , filename = None , format = None , # pylint: disable=redefined-builtin reload = None , reload_if_newer = False , url_from_catalog = None , catalog_file = \"catalog-v001.xml\" , emmo_based = True , prefix = None , prefix_emmo = None , ** kwargs , ): \"\"\"Load the ontology. Parameters ---------- only_local: bool Whether to only read local files. This requires that you have appended the path to the ontology to owlready2.onto_path. filename: str Path to file to load the ontology from. Defaults to `base_iri` provided to get_ontology(). format: str Format of `filename`. Default is inferred from `filename` extension. reload: bool Whether to reload the ontology if it is already loaded. reload_if_newer: bool Whether to reload the ontology if the source has changed since last time it was loaded. url_from_catalog: bool | None Whether to use catalog file to resolve the location of `base_iri`. If None, the catalog file is used if it exists in the same directory as `filename`. catalog_file: str Name of Prot\u00e8g\u00e8 catalog file in the same folder as the ontology. This option is used together with `only_local` and defaults to \"catalog-v001.xml\". emmo_based: bool Whether this is an EMMO-based ontology or not, default `True`. prefix: defaults to self.get_namespace.name if prefix_emmo: bool, default None. If emmo_based is True it defaults to True and sets the prefix of all imported ontologies with base_iri starting with 'http://emmo.info/emmo' to emmo kwargs: Additional keyword arguments are passed on to owlready2.Ontology.load(). \"\"\" # TODO: make sure that `only_local` argument is respected... if self . loaded : return self self . _load ( only_local = only_local , filename = filename , format = format , reload = reload , reload_if_newer = reload_if_newer , url_from_catalog = url_from_catalog , catalog_file = catalog_file , ** kwargs , ) # Enable optimised search by get_by_label() if self . _special_labels is None and emmo_based : for iri in DEFAULT_LABEL_ANNOTATIONS : self . add_label_annotation ( iri ) top = self . world [ \"http://www.w3.org/2002/07/owl#topObjectProperty\" ] self . _special_labels = { \"Thing\" : owlready2 . Thing , \"Nothing\" : owlready2 . Nothing , \"topObjectProperty\" : top , \"owl:Thing\" : owlready2 . Thing , \"owl:Nothing\" : owlready2 . Nothing , \"owl:topObjectProperty\" : top , } # set prefix if another prefix is desired # if we do this, shouldn't we make the name of all # entities of the given ontology to the same? if prefix : self . prefix = prefix else : self . prefix = self . name if emmo_based and prefix_emmo is None : prefix_emmo = True if prefix_emmo : self . set_common_prefix () return self","title":"Parameters"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.new_entity","text":"Create and return new entity Makes a new entity in the ontology with given parent(s). Return the new entity. Throws exception if name consists of more than one word. Source code in ontopy/ontology.py def new_entity ( self , name : str , parent : Union [ ThingClass , Iterable ] ) -> ThingClass : \"\"\"Create and return new entity Makes a new entity in the ontology with given parent(s). Return the new entity. Throws exception if name consists of more than one word. \"\"\" if len ( name . split ( \" \" )) > 1 : raise LabelDefinitionError ( f \"Error in label name definition ' { name } ': \" f \"Label consists of more than one word.\" ) parents = tuple ( parent ) if isinstance ( parent , Iterable ) else ( parent ,) for thing in parents : if not isinstance ( thing , owlready2 . ThingClass ): raise ThingClassDefinitionError ( f \"Error in parent definition: \" f \"' { thing } ' is not an owlready2.ThingClass.\" ) with self : entity = types . new_class ( name , parents ) return entity","title":"new_entity()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.number_of_generations","text":"Return shortest distance from ancestor to descendant Source code in ontopy/ontology.py def number_of_generations ( self , descendant , ancestor ): \"\"\"Return shortest distance from ancestor to descendant\"\"\" if ancestor not in descendant . ancestors (): raise ValueError ( \"Descendant is not a descendant of ancestor\" ) return self . _number_of_generations ( descendant , ancestor , 0 )","title":"number_of_generations()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.object_properties","text":"Returns an generator over all object properties. If imported is true, will imported object properties are also returned. Source code in ontopy/ontology.py def object_properties ( self , imported = False ): \"\"\"Returns an generator over all object properties. If `imported` is true, will imported object properties are also returned. \"\"\" if imported : return self . world . object_properties () return super () . object_properties ()","title":"object_properties()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.remove_label_annotation","text":"Removes label annotation used by get_by_label(). May be provided either as an IRI or as its owlready2 representation. Source code in ontopy/ontology.py def remove_label_annotation ( self , iri ): \"\"\"Removes label annotation used by get_by_label(). May be provided either as an IRI or as its owlready2 representation. \"\"\" label_annotation = iri if hasattr ( iri , \"storid\" ) else self . world [ iri ] if not label_annotation : raise ValueError ( f \"IRI not in ontology: { iri } \" ) self . _label_annotations . remove ( label_annotation )","title":"remove_label_annotation()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.rename_entities","text":"Set name of all entities to the first non-empty annotation in annotations . Warning, this method changes all IRIs in the ontology. However, it may be useful to make the ontology more readable and to work with it together with a triple store. Source code in ontopy/ontology.py def rename_entities ( self , annotations = ( \"prefLabel\" , \"label\" , \"altLabel\" ), ): \"\"\"Set `name` of all entities to the first non-empty annotation in `annotations`. Warning, this method changes all IRIs in the ontology. However, it may be useful to make the ontology more readable and to work with it together with a triple store. \"\"\" for entity in self . get_entities (): for annotation in annotations : if hasattr ( entity , annotation ): name = getattr ( entity , annotation ) . first () if name : entity . name = name break","title":"rename_entities()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.save","text":"Writes the ontology to file.","title":"save()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.save--parameters","text":"None | str | Path Name of file to write to. If None, it defaults to the name of the ontology with format as file extension. str Output format. The default is to infer it from filename . str | Path If filename is a relative path, it is a relative path to dir . bool Whether to create output directory if it does not exists. bool If true and filename exists, remove the existing file before saving. The default is to append to an existing ontology. bool Whether to save imported ontologies recursively. This is commonly combined with filename=None , dir and mkdir . bool If true, rdflib will be used to save the current ontology together with all its sub-ontologies into filename . It make no sense to combine this with recursive . bool Whether to also write a catalog file to disk. bool Whether to append to an existing catalog file. str | Path Name of catalog file. If not an absolute path, it is prepended to dir . Source code in ontopy/ontology.py def save ( self , filename = None , format = None , dir = \".\" , mkdir = False , overwrite = False , recursive = False , squash = False , write_catalog_file = False , append_catalog = False , catalog_file = \"catalog-v001.xml\" , ): \"\"\"Writes the ontology to file. Parameters ---------- filename: None | str | Path Name of file to write to. If None, it defaults to the name of the ontology with `format` as file extension. format: str Output format. The default is to infer it from `filename`. dir: str | Path If `filename` is a relative path, it is a relative path to `dir`. mkdir: bool Whether to create output directory if it does not exists. owerwrite: bool If true and `filename` exists, remove the existing file before saving. The default is to append to an existing ontology. recursive: bool Whether to save imported ontologies recursively. This is commonly combined with `filename=None`, `dir` and `mkdir`. squash: bool If true, rdflib will be used to save the current ontology together with all its sub-ontologies into `filename`. It make no sense to combine this with `recursive`. write_catalog_file: bool Whether to also write a catalog file to disk. append_catalog: bool Whether to append to an existing catalog file. catalog_file: str | Path Name of catalog file. If not an absolute path, it is prepended to `dir`. \"\"\" # pylint: disable=redefined-builtin,too-many-arguments # pylint: disable=too-many-statements,too-many-branches # pylint: disable=too-many-locals,arguments-renamed if not _validate_installed_version ( package = \"rdflib\" , min_version = \"6.0.0\" ) and format == FMAP . get ( \"ttl\" , \"\" ): from rdflib import ( # pylint: disable=import-outside-toplevel __version__ as __rdflib_version__ , ) warnings . warn ( IncompatibleVersion ( \"To correctly convert to Turtle format, rdflib must be \" \"version 6.0.0 or greater, however, the detected rdflib \" \"version used by your Python interpreter is \" f \" { __rdflib_version__ !r} . For more information see the \" \"'Known issues' section of the README.\" ) ) revmap = { value : key for key , value in FMAP . items ()} if filename is None : if format : fmt = revmap . get ( format , format ) filename = f \" { self . name } . { fmt } \" else : TypeError ( \"`filename` and `format` cannot both be None.\" ) filename = os . path . join ( dir , filename ) dir = Path ( filename ) . resolve () . parent if mkdir : outdir = Path ( filename ) . parent . resolve () if not outdir . exists (): outdir . mkdir ( parents = True ) if not format : format = guess_format ( filename , fmap = FMAP ) fmt = revmap . get ( format , format ) if overwrite and filename and os . path . exists ( filename ): os . remove ( filename ) EMMO = rdflib . Namespace ( # pylint:disable=invalid-name \"http://emmo.info/emmo#\" ) if recursive : if squash : raise ValueError ( \"`recursive` and `squash` should not both be true\" ) base = self . base_iri . rstrip ( \"#/\" ) for onto in self . imported_ontologies : obase = onto . base_iri . rstrip ( \"#/\" ) newdir = Path ( dir ) / os . path . relpath ( obase , base ) onto . save ( filename = None , format = format , dir = newdir . resolve (), mkdir = mkdir , overwrite = overwrite , recursive = recursive , squash = squash , write_catalog_file = write_catalog_file , append_catalog = append_catalog , catalog_file = catalog_file , ) if squash : from rdflib import ( # pylint:disable=import-outside-toplevel URIRef , RDF , OWL , ) graph = self . world . as_rdflib_graph () graph . namespace_manager . bind ( \"emmo\" , EMMO ) # Remove anonymous namespace and imports graph . remove (( URIRef ( \"http://anonymous\" ), RDF . type , OWL . Ontology )) imports = list ( graph . triples (( None , OWL . imports , None ))) for triple in imports : graph . remove ( triple ) graph . serialize ( destination = filename , format = format ) elif format in OWLREADY2_FORMATS : super () . save ( file = filename , format = fmt ) else : # The try-finally clause is needed for cleanup and because # we have to provide delete=False to NamedTemporaryFile # since Windows does not allow to reopen an already open # file. try : with tempfile . NamedTemporaryFile ( suffix = \".owl\" , delete = False ) as handle : tmpfile = handle . name super () . save ( tmpfile , format = \"rdfxml\" ) graph = rdflib . Graph () graph . parse ( tmpfile , format = \"xml\" ) graph . serialize ( destination = filename , format = format ) finally : os . remove ( tmpfile ) if write_catalog_file : mappings = {} base = self . base_iri . rstrip ( \"#/\" ) def append ( onto ): obase = onto . base_iri . rstrip ( \"#/\" ) newdir = Path ( dir ) / os . path . relpath ( obase , base ) newpath = newdir . resolve () / f \" { onto . name } . { fmt } \" relpath = os . path . relpath ( newpath , dir ) mappings [ onto . get_version ( as_iri = True )] = str ( relpath ) for imported in onto . imported_ontologies : append ( imported ) if recursive : append ( self ) write_catalog ( mappings , output = catalog_file , directory = dir , append = append_catalog , )","title":"Parameters"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.set_common_prefix","text":"Set a common prefix for all imported ontologies with the same first part of the base_iri. Parameters: Name Type Description Default iri_base str The start of the base_iri to look for. Defaults to the emmo base_iri http://emmo.info/emmo 'http://emmo.info/emmo' prefix str the desired prefix. Defaults to emmo. 'emmo' Source code in ontopy/ontology.py def set_common_prefix ( self , iri_base : str = \"http://emmo.info/emmo\" , prefix : str = \"emmo\" , ) -> None : \"\"\"Set a common prefix for all imported ontologies with the same first part of the base_iri. Args: iri_base: The start of the base_iri to look for. Defaults to the emmo base_iri http://emmo.info/emmo prefix: the desired prefix. Defaults to emmo. \"\"\" if self . base_iri . startswith ( iri_base ): self . prefix = prefix for onto in self . imported_ontologies : onto . set_common_prefix ( iri_base = iri_base , prefix = prefix )","title":"set_common_prefix()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.set_version","text":"Assign version to ontology by asigning owl:versionIRI. If version but not version_iri is provided, the version IRI will be the combination of base_iri and version . Source code in ontopy/ontology.py def set_version ( self , version = None , version_iri = None ): \"\"\"Assign version to ontology by asigning owl:versionIRI. If `version` but not `version_iri` is provided, the version IRI will be the combination of `base_iri` and `version`. \"\"\" _version_iri = \"http://www.w3.org/2002/07/owl#versionIRI\" version_iri_storid = self . world . _abbreviate ( _version_iri ) if self . _has_obj_triple_spo ( # pylint: disable=unexpected-keyword-arg # For some reason _has_obj_triples_spo exists in both # owlready2.namespace.Namespace (with arguments subject/predicate) # and in owlready2.triplelite._GraphManager (with arguments s/p) # owlready2.Ontology inherits from Namespace directly # and pylint checks that. # It actually accesses the one in triplelite. # subject=self.storid, predicate=version_iri_storid s = self . storid , p = version_iri_storid , ): self . _del_obj_triple_spo ( s = self . storid , p = version_iri_storid ) if not version_iri : if not version : raise TypeError ( \"Either `version` or `version_iri` must be provided\" ) head , tail = self . base_iri . rstrip ( \"#/\" ) . rsplit ( \"/\" , 1 ) version_iri = \"/\" . join ([ head , version , tail ]) self . _add_obj_triple_spo ( s = self . storid , p = self . world . _abbreviate ( _version_iri ), o = self . world . _abbreviate ( version_iri ), )","title":"set_version()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.sync_attributes","text":"This method is intended to be called after you have added new classes (typically via Python) to make sure that attributes like label and comments are defined. If a class, object property, data property or annotation property in the current ontology has no label, the name of the corresponding Python class will be assigned as label. If a class, object property, data property or annotation property has no comment, it will be assigned the docstring of the corresponding Python class. name_policy specify wether and how the names in the ontology should be updated. Valid values are: None not changed \"uuid\" name_prefix followed by a global unique id (UUID). \"sequential\" name_prefix followed a sequantial number. EMMO conventions imply name_policy=='uuid' . If sync_imported is true, all imported ontologies are also updated. The class_docstring argument specifies the annotation that class docstrings are mapped to. Defaults to \"comment\". Source code in ontopy/ontology.py def sync_attributes ( # pylint: disable=too-many-branches self , name_policy = None , name_prefix = \"\" , class_docstring = \"comment\" , sync_imported = False , ): \"\"\"This method is intended to be called after you have added new classes (typically via Python) to make sure that attributes like `label` and `comments` are defined. If a class, object property, data property or annotation property in the current ontology has no label, the name of the corresponding Python class will be assigned as label. If a class, object property, data property or annotation property has no comment, it will be assigned the docstring of the corresponding Python class. `name_policy` specify wether and how the names in the ontology should be updated. Valid values are: None not changed \"uuid\" `name_prefix` followed by a global unique id (UUID). \"sequential\" `name_prefix` followed a sequantial number. EMMO conventions imply ``name_policy=='uuid'``. If `sync_imported` is true, all imported ontologies are also updated. The `class_docstring` argument specifies the annotation that class docstrings are mapped to. Defaults to \"comment\". \"\"\" for cls in itertools . chain ( self . classes (), self . object_properties (), self . data_properties (), self . annotation_properties (), ): if not hasattr ( cls , \"prefLabel\" ): # no prefLabel - create new annotation property.. with self : # pylint: disable=invalid-name,missing-class-docstring # pylint: disable=unused-variable class prefLabel ( owlready2 . label ): pass cls . prefLabel = [ locstr ( cls . __name__ , lang = \"en\" )] elif not cls . prefLabel : cls . prefLabel . append ( locstr ( cls . __name__ , lang = \"en\" )) if class_docstring and hasattr ( cls , \"__doc__\" ) and cls . __doc__ : getattr ( cls , class_docstring ) . append ( locstr ( inspect . cleandoc ( cls . __doc__ ), lang = \"en\" ) ) for ind in self . individuals (): if not hasattr ( ind , \"prefLabel\" ): # no prefLabel - create new annotation property.. with self : # pylint: disable=invalid-name,missing-class-docstring # pylint: disable=function-redefined class prefLabel ( owlready2 . label ): iri = \"http://www.w3.org/2004/02/skos/core#prefLabel\" ind . prefLabel = [ locstr ( ind . name , lang = \"en\" )] elif not ind . prefLabel : ind . prefLabel . append ( locstr ( ind . name , lang = \"en\" )) chain = itertools . chain ( self . classes (), self . individuals (), self . object_properties (), self . data_properties (), self . annotation_properties (), ) if name_policy == \"uuid\" : for obj in chain : obj . name = name_prefix + str ( uuid . uuid5 ( uuid . NAMESPACE_DNS , obj . name ) ) elif name_policy == \"sequential\" : for obj in chain : counter = 0 while f \" { self . base_iri }{ name_prefix }{ counter } \" in self : counter += 1 obj . name = f \" { name_prefix }{ counter } \" elif name_policy is not None : raise TypeError ( f \"invalid name_policy: { name_policy !r} \" ) if sync_imported : for onto in self . imported_ontologies : onto . sync_attributes ()","title":"sync_attributes()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.sync_python_names","text":"Update the python_name attribute of all properties. The python_name attribute will be set to the first non-empty annotation in the sequence of annotations in annotations for the property. Source code in ontopy/ontology.py def sync_python_names ( self , annotations = ( \"prefLabel\" , \"label\" , \"altLabel\" )): \"\"\"Update the `python_name` attribute of all properties. The python_name attribute will be set to the first non-empty annotation in the sequence of annotations in `annotations` for the property. \"\"\" def update ( gen ): for prop in gen : for annotation in annotations : if hasattr ( prop , annotation ) and getattr ( prop , annotation ): prop . python_name = getattr ( prop , annotation ) . first () break update ( self . get_entities ( classes = False , individuals = False , object_properties = False , data_properties = False , ) ) update ( self . get_entities ( classes = False , individuals = False , annotation_properties = False ) )","title":"sync_python_names()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.Ontology.sync_reasoner","text":"Update current ontology by running the given reasoner. Supported values for reasoner are 'Pellet', 'HermiT' and 'FaCT++'. If include_imported is true, the reasoner will also reason over imported ontologies. Note that this may be very slow with Pellet and HermiT. Keyword arguments are passed to the underlying owlready2 function. Source code in ontopy/ontology.py def sync_reasoner ( self , reasoner = \"FaCT++\" , include_imported = False , ** kwargs ): \"\"\"Update current ontology by running the given reasoner. Supported values for `reasoner` are 'Pellet', 'HermiT' and 'FaCT++'. If `include_imported` is true, the reasoner will also reason over imported ontologies. Note that this may be **very** slow with Pellet and HermiT. Keyword arguments are passed to the underlying owlready2 function. \"\"\" if reasoner == \"FaCT++\" : sync = sync_reasoner_factpp elif reasoner == \"Pellet\" : sync = owlready2 . sync_reasoner_pellet elif reasoner == \"HermiT\" : sync = owlready2 . sync_reasoner_hermit else : raise ValueError ( f \"unknown reasoner { reasoner !r} . Supported reasoners \" 'are \"Pellet\", \"HermiT\" and \"FaCT++\".' ) # For some reason we must visit all entities once before running # the reasoner... list ( self . get_entities ()) with self : if include_imported : sync ( self . world , ** kwargs ) else : sync ( self , ** kwargs )","title":"sync_reasoner()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.World","text":"A subclass of owlready2.World. Source code in ontopy/ontology.py class World ( owlready2 . World ): \"\"\"A subclass of owlready2.World.\"\"\" def __init__ ( self , * args , ** kwargs ): # Caches stored in the world self . _cached_catalogs = {} # maps url to (mtime, iris, dirs) self . _iri_mappings = {} # all iri mappings loaded so far super () . __init__ ( * args , ** kwargs ) def get_ontology ( self , base_iri = \"emmo-inferred\" ): \"\"\"Returns a new Ontology from `base_iri`. The `base_iri` argument may be one of: - valid URL (possible excluding final .owl or .ttl) - file name (possible excluding final .owl or .ttl) - \"emmo\": load latest version of asserted EMMO - \"emmo-inferred\": load latest version of inferred EMMO (default) - \"emmo-development\": load latest inferred development version of EMMO. Until first stable release emmo-inferred and emmo-development will be the same. \"\"\" base_iri = base_iri . as_uri () if isinstance ( base_iri , Path ) else base_iri if base_iri == \"emmo\" : base_iri = ( \"http://emmo-repo.github.io/versions/1.0.0-beta4/emmo.ttl\" ) elif base_iri == \"emmo-inferred\" : base_iri = ( \"https://emmo-repo.github.io/versions/1.0.0-beta4/\" \"emmo-inferred.ttl\" ) elif base_iri == \"emmo-development\" : base_iri = ( \"https://emmo-repo.github.io/versions/1.0.0-beta4/\" \"emmo-inferred.ttl\" ) if base_iri in self . ontologies : onto = self . ontologies [ base_iri ] elif base_iri + \"#\" in self . ontologies : onto = self . ontologies [ base_iri + \"#\" ] elif base_iri + \"/\" in self . ontologies : onto = self . ontologies [ base_iri + \"/\" ] else : if os . path . exists ( base_iri ): iri = os . path . abspath ( base_iri ) elif os . path . exists ( base_iri + \".ttl\" ): iri = os . path . abspath ( base_iri + \".ttl\" ) elif os . path . exists ( base_iri + \".owl\" ): iri = os . path . abspath ( base_iri + \".owl\" ) else : iri = base_iri if iri [ - 1 ] not in \"/#\" : iri += \"#\" onto = Ontology ( self , iri ) return onto def get_unabbreviated_triples ( self , subject = None , predicate = None , obj = None , blank = None ): # pylint: disable=invalid-name \"\"\"Returns all triples unabbreviated. If any of the `subject`, `predicate` or `obj` arguments are given, only matching triples will be returned. If `blank` is given, it will be used to represent blank nodes. \"\"\" return _get_unabbreviated_triples ( self , subject = subject , predicate = predicate , obj = obj , blank = blank )","title":"World"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.World.get_ontology","text":"Returns a new Ontology from base_iri . The base_iri argument may be one of: - valid URL (possible excluding final .owl or .ttl) - file name (possible excluding final .owl or .ttl) - \"emmo\": load latest version of asserted EMMO - \"emmo-inferred\": load latest version of inferred EMMO (default) - \"emmo-development\": load latest inferred development version of EMMO. Until first stable release emmo-inferred and emmo-development will be the same. Source code in ontopy/ontology.py def get_ontology ( self , base_iri = \"emmo-inferred\" ): \"\"\"Returns a new Ontology from `base_iri`. The `base_iri` argument may be one of: - valid URL (possible excluding final .owl or .ttl) - file name (possible excluding final .owl or .ttl) - \"emmo\": load latest version of asserted EMMO - \"emmo-inferred\": load latest version of inferred EMMO (default) - \"emmo-development\": load latest inferred development version of EMMO. Until first stable release emmo-inferred and emmo-development will be the same. \"\"\" base_iri = base_iri . as_uri () if isinstance ( base_iri , Path ) else base_iri if base_iri == \"emmo\" : base_iri = ( \"http://emmo-repo.github.io/versions/1.0.0-beta4/emmo.ttl\" ) elif base_iri == \"emmo-inferred\" : base_iri = ( \"https://emmo-repo.github.io/versions/1.0.0-beta4/\" \"emmo-inferred.ttl\" ) elif base_iri == \"emmo-development\" : base_iri = ( \"https://emmo-repo.github.io/versions/1.0.0-beta4/\" \"emmo-inferred.ttl\" ) if base_iri in self . ontologies : onto = self . ontologies [ base_iri ] elif base_iri + \"#\" in self . ontologies : onto = self . ontologies [ base_iri + \"#\" ] elif base_iri + \"/\" in self . ontologies : onto = self . ontologies [ base_iri + \"/\" ] else : if os . path . exists ( base_iri ): iri = os . path . abspath ( base_iri ) elif os . path . exists ( base_iri + \".ttl\" ): iri = os . path . abspath ( base_iri + \".ttl\" ) elif os . path . exists ( base_iri + \".owl\" ): iri = os . path . abspath ( base_iri + \".owl\" ) else : iri = base_iri if iri [ - 1 ] not in \"/#\" : iri += \"#\" onto = Ontology ( self , iri ) return onto","title":"get_ontology()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.World.get_unabbreviated_triples","text":"Returns all triples unabbreviated. If any of the subject , predicate or obj arguments are given, only matching triples will be returned. If blank is given, it will be used to represent blank nodes. Source code in ontopy/ontology.py def get_unabbreviated_triples ( self , subject = None , predicate = None , obj = None , blank = None ): # pylint: disable=invalid-name \"\"\"Returns all triples unabbreviated. If any of the `subject`, `predicate` or `obj` arguments are given, only matching triples will be returned. If `blank` is given, it will be used to represent blank nodes. \"\"\" return _get_unabbreviated_triples ( self , subject = subject , predicate = predicate , obj = obj , blank = blank )","title":"get_unabbreviated_triples()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.flatten","text":"Yield items from any nested iterable. Source code in ontopy/ontology.py def flatten ( items ): \"\"\"Yield items from any nested iterable.\"\"\" for item in items : if isinstance ( item , Iterable ) and not isinstance ( item , ( str , bytes )): for sub_item in flatten ( item ): yield sub_item else : yield item","title":"flatten()"},{"location":"api_reference/ontopy/ontology/#ontopy.ontology.get_ontology","text":"Returns a new Ontology from base_iri . This is a convenient function for calling World.get_ontology(). Source code in ontopy/ontology.py def get_ontology ( * args , ** kwargs ): \"\"\"Returns a new Ontology from `base_iri`. This is a convenient function for calling World.get_ontology().\"\"\" return World () . get_ontology ( * args , ** kwargs )","title":"get_ontology()"},{"location":"api_reference/ontopy/patch/","text":"patch \u00b6 This module injects some additional methods into owlready2 classes. disjoint_with ( self , reduce = False ) \u00b6 Returns a generator with all classes that are disjoint with self . If reduce is True , all classes that are a descendant of another class will be excluded. Source code in ontopy/patch.py def disjoint_with ( self , reduce = False ): \"\"\"Returns a generator with all classes that are disjoint with `self`. If `reduce` is `True`, all classes that are a descendant of another class will be excluded. \"\"\" if reduce : disjoint_set = set ( self . disjoint_with ()) for entity in disjoint_set . copy (): disjoint_set . difference_update ( entity . descendants ( include_self = False ) ) for entity in disjoint_set : yield entity else : for disjoint in self . disjoints (): for entity in disjoint . entities : if entity is not self : yield entity get_annotations ( self , all = False , imported = True ) \u00b6 Returns a dict with non-empty annotations. If all is True , also annotations with no value are included. If imported is True , also include annotations defined in imported ontologies. Source code in ontopy/patch.py def get_annotations ( self , all = False , imported = True ): # pylint: disable=redefined-builtin \"\"\"Returns a dict with non-empty annotations. If `all` is `True`, also annotations with no value are included. If `imported` is `True`, also include annotations defined in imported ontologies. \"\"\" onto = self . namespace . ontology annotations = { get_preferred_label ( _ ): _ . _get_values_for_class ( self ) for _ in onto . annotation_properties ( imported = imported ) } if all : return annotations return { key : value for key , value in annotations . items () if value } get_indirect_is_a ( self , skip_classes = True ) \u00b6 Returns the set of all isSubclassOf relations of self and its ancestors. If skip_classes is True , indirect classes are not included in the returned set. Source code in ontopy/patch.py def get_indirect_is_a ( self , skip_classes = True ): \"\"\"Returns the set of all isSubclassOf relations of self and its ancestors. If `skip_classes` is `True`, indirect classes are not included in the returned set. \"\"\" subclass_relations = set () for entity in reversed ( self . mro ()): if hasattr ( entity , \"is_a\" ): if skip_classes : subclass_relations . update ( _ for _ in entity . is_a if not isinstance ( _ , owlready2 . ThingClass ) ) else : subclass_relations . update ( entity . is_a ) subclass_relations . update ( self . is_a ) return subclass_relations get_parents ( self , strict = False ) \u00b6 Returns a list of all parents. If strict is True , parents that are parents of other parents are excluded. Source code in ontopy/patch.py def get_parents ( self , strict = False ): \"\"\"Returns a list of all parents. If `strict` is `True`, parents that are parents of other parents are excluded. \"\"\" if strict : parents = self . get_parents () for entity in parents . copy (): parents . difference_update ( entity . ancestors ( include_self = False )) return parents if isinstance ( self , ThingClass ): return { cls for cls in self . is_a if isinstance ( cls , ThingClass )} if isinstance ( self , owlready2 . ObjectPropertyClass ): return { cls for cls in self . is_a if isinstance ( cls , owlready2 . ObjectPropertyClass ) } raise Exception ( \"self has no parents - this should not be possible!\" ) get_preferred_label ( self ) \u00b6 Returns the preferred label as a string (not list). The following heuristics is used: - if prefLabel annotation property exists, returns the first prefLabel - if label annotation property exists, returns the first label - otherwise return the name Source code in ontopy/patch.py def get_preferred_label ( self ): \"\"\"Returns the preferred label as a string (not list). The following heuristics is used: - if prefLabel annotation property exists, returns the first prefLabel - if label annotation property exists, returns the first label - otherwise return the name \"\"\" if hasattr ( self , \"prefLabel\" ) and self . prefLabel : return self . prefLabel [ 0 ] if hasattr ( self , \"label\" ) and self . label : return self . label . first () return self . name get_typename ( self ) \u00b6 Get restriction type label/name. Source code in ontopy/patch.py def get_typename ( self ): \"\"\"Get restriction type label/name.\"\"\" return owlready2 . class_construct . _restriction_type_2_label [ self . type ] has ( self , name ) \u00b6 Returns true if name Source code in ontopy/patch.py def has ( self , name ): \"\"\"Returns true if `name`\"\"\" return name in set ( self . keys ()) items ( self ) \u00b6 Return a generator over annotation property (name, value_list) pairs associates with this ontology. Source code in ontopy/patch.py def items ( self ): \"\"\"Return a generator over annotation property (name, value_list) pairs associates with this ontology.\"\"\" namespace = self . namespace for annotation in namespace . annotation_properties (): if namespace . _has_data_triple_spod ( s = namespace . storid , p = annotation . storid ): yield annotation , getattr ( self , annotation . name ) keys ( self ) \u00b6 Return a generator over annotation property names associates with this ontology. Source code in ontopy/patch.py def keys ( self ): \"\"\"Return a generator over annotation property names associates with this ontology.\"\"\" namespace = self . namespace for annotation in namespace . annotation_properties (): if namespace . _has_data_triple_spod ( s = namespace . storid , p = annotation . storid ): yield annotation namespace_init ( self , world_or_ontology , base_iri , name = None ) \u00b6 init function for the Namespace class. Source code in ontopy/patch.py def namespace_init ( self , world_or_ontology , base_iri , name = None ): \"\"\"__init__ function for the `Namespace` class.\"\"\" orig_namespace_init ( self , world_or_ontology , base_iri , name ) if self . name . endswith ( \".ttl\" ): self . name = self . name [: - 4 ] render_func ( entity ) \u00b6 Improve default rendering of entities. Source code in ontopy/patch.py def render_func ( entity ): \"\"\"Improve default rendering of entities.\"\"\" if hasattr ( entity , \"prefLabel\" ) and entity . prefLabel : name = entity . prefLabel [ 0 ] elif hasattr ( entity , \"label\" ) and entity . label : name = entity . label [ 0 ] elif hasattr ( entity , \"altLabel\" ) and entity . altLabel : name = entity . altLabel [ 0 ] else : name = entity . name return f \" { entity . namespace . name } . { name } \"","title":"patch"},{"location":"api_reference/ontopy/patch/#patch","text":"This module injects some additional methods into owlready2 classes.","title":"patch"},{"location":"api_reference/ontopy/patch/#ontopy.patch.disjoint_with","text":"Returns a generator with all classes that are disjoint with self . If reduce is True , all classes that are a descendant of another class will be excluded. Source code in ontopy/patch.py def disjoint_with ( self , reduce = False ): \"\"\"Returns a generator with all classes that are disjoint with `self`. If `reduce` is `True`, all classes that are a descendant of another class will be excluded. \"\"\" if reduce : disjoint_set = set ( self . disjoint_with ()) for entity in disjoint_set . copy (): disjoint_set . difference_update ( entity . descendants ( include_self = False ) ) for entity in disjoint_set : yield entity else : for disjoint in self . disjoints (): for entity in disjoint . entities : if entity is not self : yield entity","title":"disjoint_with()"},{"location":"api_reference/ontopy/patch/#ontopy.patch.get_annotations","text":"Returns a dict with non-empty annotations. If all is True , also annotations with no value are included. If imported is True , also include annotations defined in imported ontologies. Source code in ontopy/patch.py def get_annotations ( self , all = False , imported = True ): # pylint: disable=redefined-builtin \"\"\"Returns a dict with non-empty annotations. If `all` is `True`, also annotations with no value are included. If `imported` is `True`, also include annotations defined in imported ontologies. \"\"\" onto = self . namespace . ontology annotations = { get_preferred_label ( _ ): _ . _get_values_for_class ( self ) for _ in onto . annotation_properties ( imported = imported ) } if all : return annotations return { key : value for key , value in annotations . items () if value }","title":"get_annotations()"},{"location":"api_reference/ontopy/patch/#ontopy.patch.get_indirect_is_a","text":"Returns the set of all isSubclassOf relations of self and its ancestors. If skip_classes is True , indirect classes are not included in the returned set. Source code in ontopy/patch.py def get_indirect_is_a ( self , skip_classes = True ): \"\"\"Returns the set of all isSubclassOf relations of self and its ancestors. If `skip_classes` is `True`, indirect classes are not included in the returned set. \"\"\" subclass_relations = set () for entity in reversed ( self . mro ()): if hasattr ( entity , \"is_a\" ): if skip_classes : subclass_relations . update ( _ for _ in entity . is_a if not isinstance ( _ , owlready2 . ThingClass ) ) else : subclass_relations . update ( entity . is_a ) subclass_relations . update ( self . is_a ) return subclass_relations","title":"get_indirect_is_a()"},{"location":"api_reference/ontopy/patch/#ontopy.patch.get_parents","text":"Returns a list of all parents. If strict is True , parents that are parents of other parents are excluded. Source code in ontopy/patch.py def get_parents ( self , strict = False ): \"\"\"Returns a list of all parents. If `strict` is `True`, parents that are parents of other parents are excluded. \"\"\" if strict : parents = self . get_parents () for entity in parents . copy (): parents . difference_update ( entity . ancestors ( include_self = False )) return parents if isinstance ( self , ThingClass ): return { cls for cls in self . is_a if isinstance ( cls , ThingClass )} if isinstance ( self , owlready2 . ObjectPropertyClass ): return { cls for cls in self . is_a if isinstance ( cls , owlready2 . ObjectPropertyClass ) } raise Exception ( \"self has no parents - this should not be possible!\" )","title":"get_parents()"},{"location":"api_reference/ontopy/patch/#ontopy.patch.get_preferred_label","text":"Returns the preferred label as a string (not list). The following heuristics is used: - if prefLabel annotation property exists, returns the first prefLabel - if label annotation property exists, returns the first label - otherwise return the name Source code in ontopy/patch.py def get_preferred_label ( self ): \"\"\"Returns the preferred label as a string (not list). The following heuristics is used: - if prefLabel annotation property exists, returns the first prefLabel - if label annotation property exists, returns the first label - otherwise return the name \"\"\" if hasattr ( self , \"prefLabel\" ) and self . prefLabel : return self . prefLabel [ 0 ] if hasattr ( self , \"label\" ) and self . label : return self . label . first () return self . name","title":"get_preferred_label()"},{"location":"api_reference/ontopy/patch/#ontopy.patch.get_typename","text":"Get restriction type label/name. Source code in ontopy/patch.py def get_typename ( self ): \"\"\"Get restriction type label/name.\"\"\" return owlready2 . class_construct . _restriction_type_2_label [ self . type ]","title":"get_typename()"},{"location":"api_reference/ontopy/patch/#ontopy.patch.has","text":"Returns true if name Source code in ontopy/patch.py def has ( self , name ): \"\"\"Returns true if `name`\"\"\" return name in set ( self . keys ())","title":"has()"},{"location":"api_reference/ontopy/patch/#ontopy.patch.items","text":"Return a generator over annotation property (name, value_list) pairs associates with this ontology. Source code in ontopy/patch.py def items ( self ): \"\"\"Return a generator over annotation property (name, value_list) pairs associates with this ontology.\"\"\" namespace = self . namespace for annotation in namespace . annotation_properties (): if namespace . _has_data_triple_spod ( s = namespace . storid , p = annotation . storid ): yield annotation , getattr ( self , annotation . name )","title":"items()"},{"location":"api_reference/ontopy/patch/#ontopy.patch.keys","text":"Return a generator over annotation property names associates with this ontology. Source code in ontopy/patch.py def keys ( self ): \"\"\"Return a generator over annotation property names associates with this ontology.\"\"\" namespace = self . namespace for annotation in namespace . annotation_properties (): if namespace . _has_data_triple_spod ( s = namespace . storid , p = annotation . storid ): yield annotation","title":"keys()"},{"location":"api_reference/ontopy/patch/#ontopy.patch.namespace_init","text":"init function for the Namespace class. Source code in ontopy/patch.py def namespace_init ( self , world_or_ontology , base_iri , name = None ): \"\"\"__init__ function for the `Namespace` class.\"\"\" orig_namespace_init ( self , world_or_ontology , base_iri , name ) if self . name . endswith ( \".ttl\" ): self . name = self . name [: - 4 ]","title":"namespace_init()"},{"location":"api_reference/ontopy/patch/#ontopy.patch.render_func","text":"Improve default rendering of entities. Source code in ontopy/patch.py def render_func ( entity ): \"\"\"Improve default rendering of entities.\"\"\" if hasattr ( entity , \"prefLabel\" ) and entity . prefLabel : name = entity . prefLabel [ 0 ] elif hasattr ( entity , \"label\" ) and entity . label : name = entity . label [ 0 ] elif hasattr ( entity , \"altLabel\" ) and entity . altLabel : name = entity . altLabel [ 0 ] else : name = entity . name return f \" { entity . namespace . name } . { name } \"","title":"render_func()"},{"location":"api_reference/ontopy/utils/","text":"utils \u00b6 Some generic utility functions. EMMOntoPyException ( Exception ) \u00b6 A BaseException class for EMMOntoPy Source code in ontopy/utils.py class EMMOntoPyException ( Exception ): \"\"\"A BaseException class for EMMOntoPy\"\"\" EMMOntoPyWarning ( Warning ) \u00b6 A BaseWarning class for EMMOntoPy Source code in ontopy/utils.py class EMMOntoPyWarning ( Warning ): \"\"\"A BaseWarning class for EMMOntoPy\"\"\" IncompatibleVersion ( EMMOntoPyWarning ) \u00b6 An installed dependency version may be incompatible with a functionality of this package - or rather an outcome of a functionality. This is not critical, hence this is only a warning. Source code in ontopy/utils.py class IncompatibleVersion ( EMMOntoPyWarning ): \"\"\"An installed dependency version may be incompatible with a functionality of this package - or rather an outcome of a functionality. This is not critical, hence this is only a warning.\"\"\" LabelDefinitionError ( EMMOntoPyException ) \u00b6 Error in label definition. Source code in ontopy/utils.py class LabelDefinitionError ( EMMOntoPyException ): \"\"\"Error in label definition.\"\"\" NoSuchLabelError ( LookupError , AttributeError , EMMOntoPyException ) \u00b6 Error raised when a label cannot be found. Source code in ontopy/utils.py class NoSuchLabelError ( LookupError , AttributeError , EMMOntoPyException ): \"\"\"Error raised when a label cannot be found.\"\"\" ReadCatalogError ( OSError ) \u00b6 Error reading catalog file. Source code in ontopy/utils.py class ReadCatalogError ( IOError ): \"\"\"Error reading catalog file.\"\"\" ThingClassDefinitionError ( EMMOntoPyException ) \u00b6 Error in ThingClass definition. Source code in ontopy/utils.py class ThingClassDefinitionError ( EMMOntoPyException ): \"\"\"Error in ThingClass definition.\"\"\" UnknownVersion ( EMMOntoPyException ) \u00b6 Cannot retrieve version from a package. Source code in ontopy/utils.py class UnknownVersion ( EMMOntoPyException ): \"\"\"Cannot retrieve version from a package.\"\"\" annotate_source ( onto , imported = True ) \u00b6 Annotate all entities with the base IRI of the ontology using rdfs:isDefinedBy annotations. If imported is true, all entities in imported sub-ontologies will also be annotated. This is contextual information that is otherwise lost when the ontology is squashed and/or inferred. Source code in ontopy/utils.py def annotate_source ( onto , imported = True ): \"\"\"Annotate all entities with the base IRI of the ontology using `rdfs:isDefinedBy` annotations. If `imported` is true, all entities in imported sub-ontologies will also be annotated. This is contextual information that is otherwise lost when the ontology is squashed and/or inferred. \"\"\" source = onto . _abbreviate ( \"http://www.w3.org/2000/01/rdf-schema#isDefinedBy\" ) for entity in onto . get_entities ( imported = imported ): triple = ( entity . storid , source , onto . _abbreviate ( entity . namespace . ontology . base_iri ), ) if not onto . _has_obj_triple_spo ( * triple ): onto . _add_obj_triple_spo ( * triple ) asstring ( expr , link = ' {name} ' , recursion_depth = 0 , exclude_object = False ) \u00b6 Returns a string representation of expr , which may be an entity, restriction, or logical expression of these. link is a format string for formatting references to entities or relations. It may contain the keywords \"name\", \"url\" and \"lowerurl\". recursion_depth is the recursion depth and only intended for internal use. If exclude_object is true, the object will be excluded in restrictions. Source code in ontopy/utils.py def asstring ( # pylint: disable=too-many-return-statements,too-many-branches expr , link = \" {name} \" , recursion_depth = 0 , exclude_object = False ): \"\"\"Returns a string representation of `expr`, which may be an entity, restriction, or logical expression of these. `link` is a format string for formatting references to entities or relations. It may contain the keywords \"name\", \"url\" and \"lowerurl\". `recursion_depth` is the recursion depth and only intended for internal use. If `exclude_object` is true, the object will be excluded in restrictions. \"\"\" def fmt ( entity ): \"\"\"Returns the formatted label of an entity.\"\"\" name = None for attr in ( \"prefLabel\" , \"label\" , \"__name__\" , \"name\" ): if hasattr ( entity , attr ) and getattr ( entity , attr ): name = getattr ( entity , attr ) if not isinstance ( name , str ) and hasattr ( name , \"__getitem__\" ): name = name [ 0 ] break if not name : name = str ( entity ) . replace ( \".\" , \":\" ) url = name if re . match ( r \"^[a-z]+://\" , name ) else \"#\" + name return link . format ( name = name , url = url , lowerurl = url . lower ()) if isinstance ( expr , str ): # return link.format(name=expr) return fmt ( expr ) if isinstance ( expr , owlready2 . Restriction ): rlabel = owlready2 . class_construct . _restriction_type_2_label [ expr . type ] if isinstance ( expr . property , ( owlready2 . ObjectPropertyClass , owlready2 . DataPropertyClass ), ): res = fmt ( expr . property ) elif isinstance ( expr . property , owlready2 . Inverse ): res = f \"Inverse( { asstring ( expr . property . property , link , recursion_depth + 1 ) } )\" # pylint: disable=line-too-long else : print ( f \"*** WARNING: unknown restriction property: { expr . property !r} \" ) res = fmt ( expr . property ) if not rlabel : pass elif expr . type in ( owlready2 . MIN , owlready2 . MAX , owlready2 . EXACTLY ): res += f \" { rlabel } { expr . cardinality } \" elif expr . type in ( owlready2 . SOME , owlready2 . ONLY , owlready2 . VALUE , owlready2 . HAS_SELF , ): res += f \" { rlabel } \" else : print ( \"*** WARNING: unknown relation\" , expr , rlabel ) res += f \" { rlabel } \" if not exclude_object : if isinstance ( expr . value , str ): res += f \" { asstring ( expr . value , link , recursion_depth + 1 ) !r} \" else : res += f \" { asstring ( expr . value , link , recursion_depth + 1 ) } \" return res if isinstance ( expr , owlready2 . Or ): res = \" or \" . join ( [ asstring ( c , link , recursion_depth + 1 ) for c in expr . Classes ] ) return res if recursion_depth == 0 else f \"( { res } )\" if isinstance ( expr , owlready2 . And ): res = \" and \" . join ( [ asstring ( c , link , recursion_depth + 1 ) for c in expr . Classes ] ) return res if recursion_depth == 0 else f \"( { res } )\" if isinstance ( expr , owlready2 . Not ): return f \"not { asstring ( expr . Class , link , recursion_depth + 1 ) } \" if isinstance ( expr , owlready2 . ThingClass ): return fmt ( expr ) if isinstance ( expr , owlready2 . PropertyClass ): return fmt ( expr ) if isinstance ( expr , owlready2 . Thing ): # instance (individual) return fmt ( expr ) if isinstance ( expr , owlready2 . class_construct . Inverse ): return f \"inverse( { fmt ( expr . property ) } )\" if isinstance ( expr , owlready2 . disjoint . AllDisjoint ): return fmt ( expr ) if isinstance ( expr , ( bool , int , float )): return repr ( expr ) # Check for subclasses if issubclass ( expr , ( bool , int , float , str )): return fmt ( expr . __class__ . __name__ ) if issubclass ( expr , datetime . date ): return \"date\" if issubclass ( expr , datetime . time ): return \"datetime\" if issubclass ( expr , datetime . datetime ): return \"datetime\" raise RuntimeError ( f \"Unknown expression: { expr !r} (type: { type ( expr ) !r} )\" ) camelsplit ( string ) \u00b6 Splits CamelCase string before upper case letters (except if there is a sequence of upper case letters). Source code in ontopy/utils.py def camelsplit ( string ): \"\"\"Splits CamelCase string before upper case letters (except if there is a sequence of upper case letters).\"\"\" if len ( string ) < 2 : return string result = [] prev_lower = False prev_isspace = True char = string [ 0 ] for next_char in string [ 1 :]: if ( not prev_isspace and char . isupper () and next_char . islower ()) or ( prev_lower and char . isupper () ): result . append ( \" \" ) result . append ( char ) prev_lower = char . islower () prev_isspace = char . isspace () char = next_char result . append ( char ) return \"\" . join ( result ) convert_imported ( input_ontology , output_ontology , input_format = None , output_format = 'xml' , url_from_catalog = None , catalog_file = 'catalog-v001.xml' ) \u00b6 Convert imported ontologies. Store the output in a directory structure matching the source files. This require catalog file(s) to be present. Warning To convert to Turtle ( .ttl ) format, you must have installed rdflib>=6.0.0 . See Known issues for more information. Parameters: Name Type Description Default input_ontology Union[Path, str] input ontology file name required output_ontology Union[Path, str] output ontology file path. The directory part of output will be the root of the generated directory structure required input_format Optional[str] input format. The default is to infer from input_ontology None output_format str output format. The default is to infer from output_ontology 'xml' url_from_catalog Optional[bool] Whether to read urls form catalog file. If False, the catalog file will be used if it exists. None catalog_file str name of catalog file, that maps ontology IRIs to local file names 'catalog-v001.xml' Source code in ontopy/utils.py def convert_imported ( # pylint: disable=too-many-arguments,too-many-locals input_ontology : \"Union[Path, str]\" , output_ontology : \"Union[Path, str]\" , input_format : \"Optional[str]\" = None , output_format : str = \"xml\" , url_from_catalog : \"Optional[bool]\" = None , catalog_file : str = \"catalog-v001.xml\" , ): \"\"\"Convert imported ontologies. Store the output in a directory structure matching the source files. This require catalog file(s) to be present. Warning: To convert to Turtle (`.ttl`) format, you must have installed `rdflib>=6.0.0`. See [Known issues](../../../#known-issues) for more information. Args: input_ontology: input ontology file name output_ontology: output ontology file path. The directory part of `output` will be the root of the generated directory structure input_format: input format. The default is to infer from `input_ontology` output_format: output format. The default is to infer from `output_ontology` url_from_catalog: Whether to read urls form catalog file. If False, the catalog file will be used if it exists. catalog_file: name of catalog file, that maps ontology IRIs to local file names \"\"\" inroot = os . path . dirname ( os . path . abspath ( input_ontology )) outroot = os . path . dirname ( os . path . abspath ( output_ontology )) outext = os . path . splitext ( output_ontology )[ 1 ] if url_from_catalog is None : url_from_catalog = os . path . exists ( os . path . join ( inroot , catalog_file )) if url_from_catalog : iris , dirs = read_catalog ( inroot , catalog_file = catalog_file , recursive = True , return_paths = True ) # Create output dirs and copy catalog files for indir in dirs : outdir = os . path . normpath ( os . path . join ( outroot , os . path . relpath ( indir , inroot )) ) if not os . path . exists ( outdir ): os . makedirs ( outdir ) with open ( os . path . join ( indir , catalog_file ), mode = \"rt\" , encoding = \"utf8\" ) as handle : content = handle . read () for path in iris . values (): newpath = os . path . splitext ( path )[ 0 ] + outext content = content . replace ( os . path . basename ( path ), os . path . basename ( newpath ) ) with open ( os . path . join ( outdir , catalog_file ), mode = \"wt\" , encoding = \"utf8\" ) as handle : handle . write ( content ) else : iris = {} outpaths = set () def recur ( graph , outext ): for imported in graph . objects ( predicate = URIRef ( \"http://www.w3.org/2002/07/owl#imports\" ) ): inpath = iris . get ( str ( imported ), str ( imported )) if inpath . startswith (( \"http://\" , \"https://\" , \"ftp://\" )): outpath = os . path . join ( outroot , inpath . split ( \"/\" )[ - 1 ]) else : outpath = os . path . join ( outroot , os . path . relpath ( inpath , inroot )) outpath = os . path . splitext ( os . path . normpath ( outpath ))[ 0 ] + outext if outpath not in outpaths : outpaths . add ( outpath ) fmt = ( input_format if input_format else guess_format ( inpath , fmap = FMAP ) ) new_graph = Graph () new_graph . parse ( iris . get ( inpath , inpath ), format = fmt ) new_graph . serialize ( destination = outpath , format = output_format ) recur ( new_graph , outext ) # Write output files fmt = ( input_format if input_format else guess_format ( input_ontology , fmap = FMAP ) ) if not _validate_installed_version ( package = \"rdflib\" , min_version = \"6.0.0\" ) and ( output_format == FMAP . get ( \"ttl\" , \"\" ) or outext == \"ttl\" ): from rdflib import ( # pylint: disable=import-outside-toplevel __version__ as __rdflib_version__ , ) warnings . warn ( IncompatibleVersion ( \"To correctly convert to Turtle format, rdflib must be \" \"version 6.0.0 or greater, however, the detected rdflib \" \"version used by your Python interpreter is \" f \" { __rdflib_version__ !r} . For more information see the \" \"'Known issues' section of the README.\" ) ) graph = Graph () try : graph . parse ( input_ontology , format = fmt ) except PluginException as exc : # Add input_ontology to exception msg raise PluginException ( f 'Cannot load \" { input_ontology } \": { exc . msg } ' ) . with_traceback ( exc . __traceback__ ) graph . serialize ( destination = output_ontology , format = output_format ) recur ( graph , outext ) get_label ( entity ) \u00b6 Returns the label of an entity. Source code in ontopy/utils.py def get_label ( entity ): \"\"\"Returns the label of an entity.\"\"\" if hasattr ( entity , \"prefLabel\" ) and entity . prefLabel : return entity . prefLabel . first () if hasattr ( entity , \"label\" ) and entity . label : return entity . label . first () if hasattr ( entity , \"__name__\" ): return entity . __name__ if hasattr ( entity , \"name\" ): return str ( entity . name ) if isinstance ( entity , str ): return entity return repr ( entity ) infer_version ( iri , version_iri ) \u00b6 Infer version from IRI and versionIRI. Source code in ontopy/utils.py def infer_version ( iri , version_iri ): \"\"\"Infer version from IRI and versionIRI.\"\"\" if str ( version_iri [: len ( iri )]) == str ( iri ): version = version_iri [ len ( iri ) :] . lstrip ( \"/\" ) else : j = 0 version_parts = [] for i , char in enumerate ( iri ): while i + j < len ( version_iri ) and char != version_iri [ i + j ]: version_parts . append ( version_iri [ i + j ]) j += 1 version = \"\" . join ( version_parts ) . lstrip ( \"/\" ) . rstrip ( \"/#\" ) if \"/\" in version : raise ValueError ( f \"version IRI { version_iri !r} is not consistent with base IRI \" f \" { iri !r} \" ) return version isinteractive () \u00b6 Returns true if we are running from an interactive interpreater, false otherwise. Source code in ontopy/utils.py def isinteractive (): \"\"\"Returns true if we are running from an interactive interpreater, false otherwise.\"\"\" return bool ( hasattr ( __builtins__ , \"__IPYTHON__\" ) or sys . flags . interactive or hasattr ( sys , \"ps1\" ) ) normalise_url ( url ) \u00b6 Returns url in a normalised form. Source code in ontopy/utils.py def normalise_url ( url ): \"\"\"Returns `url` in a normalised form.\"\"\" splitted = urllib . parse . urlsplit ( url ) components = list ( splitted ) components [ 2 ] = os . path . normpath ( splitted . path ) return urllib . parse . urlunsplit ( components ) read_catalog ( uri , catalog_file = 'catalog-v001.xml' , baseuri = None , recursive = False , return_paths = False , visited_iris = None , visited_paths = None ) \u00b6 Reads a Prot\u00e8g\u00e8 catalog file and returns as a dict. The returned dict maps the ontology IRI (name) to its actual location (URI). The location can be either an absolute file path or a HTTP, HTTPS or FTP web location. uri is a string locating the catalog file. It may be a http or https web location or a file path. The catalog_file argument spesifies the catalog file name and is used if path is used when recursive is true or when path is a directory. If baseuri is not None, it will be used as the base URI for the mapped locations. Otherwise it defaults to uri with its final component omitted. If recursive is true, catalog files in sub-folders are also read. If return_paths is true, a set of directory paths to source files is returned in addition to the default dict. The visited_uris and visited_paths arguments are only intended for internal use to avoid infinite recursions. A ReadCatalogError is raised if the catalog file cannot be found. Source code in ontopy/utils.py def read_catalog ( # pylint: disable=too-many-locals,too-many-statements,too-many-arguments uri , catalog_file = \"catalog-v001.xml\" , baseuri = None , recursive = False , return_paths = False , visited_iris = None , visited_paths = None , ): \"\"\"Reads a Prot\u00e8g\u00e8 catalog file and returns as a dict. The returned dict maps the ontology IRI (name) to its actual location (URI). The location can be either an absolute file path or a HTTP, HTTPS or FTP web location. `uri` is a string locating the catalog file. It may be a http or https web location or a file path. The `catalog_file` argument spesifies the catalog file name and is used if `path` is used when `recursive` is true or when `path` is a directory. If `baseuri` is not None, it will be used as the base URI for the mapped locations. Otherwise it defaults to `uri` with its final component omitted. If `recursive` is true, catalog files in sub-folders are also read. If `return_paths` is true, a set of directory paths to source files is returned in addition to the default dict. The `visited_uris` and `visited_paths` arguments are only intended for internal use to avoid infinite recursions. A ReadCatalogError is raised if the catalog file cannot be found. \"\"\" # Protocols supported by urllib.request web_protocols = \"http://\" , \"https://\" , \"ftp://\" uri = str ( uri ) # in case uri is a pathlib.Path object iris = visited_iris if visited_iris else {} dirs = visited_paths if visited_paths else set () if uri in iris : return ( iris , dirs ) if return_paths else iris if uri . startswith ( web_protocols ): # Call read_catalog() recursively to ensure that the temporary # file is properly cleaned up with tempfile . TemporaryDirectory () as tmpdir : destfile = os . path . join ( tmpdir , catalog_file ) uris = { # maps uri to base uri : ( baseuri if baseuri else os . path . dirname ( uri )), f ' { uri . rstrip ( \"/\" ) } / { catalog_file } ' : ( baseuri if baseuri else uri . rstrip ( \"/\" ) ), f \" { os . path . dirname ( uri ) } / { catalog_file } \" : ( os . path . dirname ( uri ) ), } for url , base in uris . items (): try : # The URL can only contain the schemes from `web_protocols`. _ , msg = urllib . request . urlretrieve ( url , destfile ) # nosec except urllib . request . URLError : continue else : if \"Content-Length\" not in msg : continue return read_catalog ( destfile , catalog_file = catalog_file , baseuri = baseuri if baseuri else base , recursive = recursive , return_paths = return_paths , visited_iris = iris , visited_paths = dirs , ) raise ReadCatalogError ( \"Cannot download catalog from URLs: \" + \", \" . join ( uris ) ) elif uri . startswith ( \"file://\" ): path = uri [ 7 :] else : path = uri if os . path . isdir ( path ): dirname = os . path . abspath ( path ) filepath = os . path . join ( dirname , catalog_file ) else : catalog_file = os . path . basename ( path ) filepath = os . path . abspath ( path ) dirname = os . path . dirname ( filepath ) def gettag ( entity ): return entity . tag . rsplit ( \"}\" , 1 )[ - 1 ] def load_catalog ( filepath ): if not os . path . exists ( filepath ): raise ReadCatalogError ( \"No such catalog file: \" + filepath ) dirname = os . path . normpath ( os . path . dirname ( filepath )) dirs . add ( baseuri if baseuri else dirname ) xml = ET . parse ( filepath ) root = xml . getroot () if gettag ( root ) != \"catalog\" : raise ReadCatalogError ( f \"expected root tag of catalog file { filepath !r} to be \" '\"catalog\"' ) for child in root : if gettag ( child ) == \"uri\" : load_uri ( child , dirname ) elif gettag ( child ) == \"group\" : for uri in child : load_uri ( uri , dirname ) def load_uri ( uri , dirname ): if gettag ( uri ) != \"uri\" : raise ValueError ( f \" { gettag ( uri ) !r} should be 'uri'.\" ) uri_as_str = uri . attrib [ \"uri\" ] if uri_as_str . startswith ( web_protocols ): url = uri_as_str else : uri_as_str = os . path . normpath ( uri_as_str ) if baseuri and baseuri . startswith ( web_protocols ): url = f \" { baseuri } / { uri_as_str } \" else : url = os . path . join ( baseuri if baseuri else dirname , uri_as_str ) iris . setdefault ( uri . attrib [ \"name\" ], url ) if recursive : directory = os . path . dirname ( url ) if directory not in dirs : catalog = os . path . join ( directory , catalog_file ) if catalog . startswith ( web_protocols ): iris_ , dirs_ = read_catalog ( catalog , catalog_file = catalog_file , baseuri = None , recursive = recursive , return_paths = True , visited_iris = iris , visited_paths = dirs , ) iris . update ( iris_ ) dirs . update ( dirs_ ) else : load_catalog ( catalog ) load_catalog ( filepath ) if return_paths : return iris , dirs return iris rename_iris ( onto , annotation = 'prefLabel' ) \u00b6 For IRIs with the given annotation, change the name of the entity to the value of the annotation. Also add an skos:exactMatch annotation referring to the old IRI. Source code in ontopy/utils.py def rename_iris ( onto , annotation = \"prefLabel\" ): \"\"\"For IRIs with the given annotation, change the name of the entity to the value of the annotation. Also add an `skos:exactMatch` annotation referring to the old IRI. \"\"\" exactMatch = onto . _abbreviate ( # pylint:disable=invalid-name \"http://www.w3.org/2004/02/skos/core#exactMatch\" ) for entity in onto . get_entities (): if hasattr ( entity , annotation ) and getattr ( entity , annotation ): onto . _add_data_triple_spod ( entity . storid , exactMatch , entity . iri , \"\" ) entity . name = getattr ( entity , annotation ) . first () write_catalog ( mappings , output = 'catalog-v001.xml' , directory = '.' , relative_paths = True , append = False ) \u00b6 Write catalog file do disk. Parameters: Name Type Description Default mappings dict dict mapping ontology IRIs (name) to actual locations (URIs). It has the same format as the dict returned by read_catalog(). required output Union[str, Path] name of catalog file. 'catalog-v001.xml' directory Union[str, Path] directory path to the catalog file. Only used if output is a relative path. '.' relative_paths bool whether to write absolute or relative paths to for file paths inside the catalog file. True append bool whether to append to a possible existing catalog file. If false, an existing file will be overwritten. False Source code in ontopy/utils.py def write_catalog ( mappings : dict , output : \"Union[str, Path]\" = \"catalog-v001.xml\" , directory : \"Union[str, Path]\" = \".\" , relative_paths : bool = True , append : bool = False , ): # pylint: disable=redefined-builtin \"\"\"Write catalog file do disk. Args: mappings: dict mapping ontology IRIs (name) to actual locations (URIs). It has the same format as the dict returned by read_catalog(). output: name of catalog file. directory: directory path to the catalog file. Only used if `output` is a relative path. relative_paths: whether to write absolute or relative paths to for file paths inside the catalog file. append: whether to append to a possible existing catalog file. If false, an existing file will be overwritten. \"\"\" web_protocol = \"http://\" , \"https://\" , \"ftp://\" if relative_paths : for key , item in mappings . items (): if not item . startswith ( web_protocol ): mappings [ key ] = os . path . relpath ( item , Path ( directory ) . resolve ()) filename = ( Path ( directory ) / output ) . resolve () if filename . exists () and append : iris = read_catalog ( filename ) iris . update ( mappings ) mappings = iris res = [ '<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>' , '<catalog prefer=\"public\" ' 'xmlns=\"urn:oasis:names:tc:entity:xmlns:xml:catalog\">' , ' <group id=\"Folder Repository, directory=, recursive=true, ' 'Auto-Update=false, version=2\" prefer=\"public\" xml:base=\"\">' , ] for key , value in dict ( mappings ) . items (): res . append ( f ' <uri name=\" { key } \" uri=\" { value } \"/>' ) res . append ( \" </group>\" ) res . append ( \"</catalog>\" ) with open ( filename , \"wt\" ) as handle : handle . write ( \" \\n \" . join ( res ) + \" \\n \" )","title":"utils"},{"location":"api_reference/ontopy/utils/#utils","text":"Some generic utility functions.","title":"utils"},{"location":"api_reference/ontopy/utils/#ontopy.utils.EMMOntoPyException","text":"A BaseException class for EMMOntoPy Source code in ontopy/utils.py class EMMOntoPyException ( Exception ): \"\"\"A BaseException class for EMMOntoPy\"\"\"","title":"EMMOntoPyException"},{"location":"api_reference/ontopy/utils/#ontopy.utils.EMMOntoPyWarning","text":"A BaseWarning class for EMMOntoPy Source code in ontopy/utils.py class EMMOntoPyWarning ( Warning ): \"\"\"A BaseWarning class for EMMOntoPy\"\"\"","title":"EMMOntoPyWarning"},{"location":"api_reference/ontopy/utils/#ontopy.utils.IncompatibleVersion","text":"An installed dependency version may be incompatible with a functionality of this package - or rather an outcome of a functionality. This is not critical, hence this is only a warning. Source code in ontopy/utils.py class IncompatibleVersion ( EMMOntoPyWarning ): \"\"\"An installed dependency version may be incompatible with a functionality of this package - or rather an outcome of a functionality. This is not critical, hence this is only a warning.\"\"\"","title":"IncompatibleVersion"},{"location":"api_reference/ontopy/utils/#ontopy.utils.LabelDefinitionError","text":"Error in label definition. Source code in ontopy/utils.py class LabelDefinitionError ( EMMOntoPyException ): \"\"\"Error in label definition.\"\"\"","title":"LabelDefinitionError"},{"location":"api_reference/ontopy/utils/#ontopy.utils.NoSuchLabelError","text":"Error raised when a label cannot be found. Source code in ontopy/utils.py class NoSuchLabelError ( LookupError , AttributeError , EMMOntoPyException ): \"\"\"Error raised when a label cannot be found.\"\"\"","title":"NoSuchLabelError"},{"location":"api_reference/ontopy/utils/#ontopy.utils.ReadCatalogError","text":"Error reading catalog file. Source code in ontopy/utils.py class ReadCatalogError ( IOError ): \"\"\"Error reading catalog file.\"\"\"","title":"ReadCatalogError"},{"location":"api_reference/ontopy/utils/#ontopy.utils.ThingClassDefinitionError","text":"Error in ThingClass definition. Source code in ontopy/utils.py class ThingClassDefinitionError ( EMMOntoPyException ): \"\"\"Error in ThingClass definition.\"\"\"","title":"ThingClassDefinitionError"},{"location":"api_reference/ontopy/utils/#ontopy.utils.UnknownVersion","text":"Cannot retrieve version from a package. Source code in ontopy/utils.py class UnknownVersion ( EMMOntoPyException ): \"\"\"Cannot retrieve version from a package.\"\"\"","title":"UnknownVersion"},{"location":"api_reference/ontopy/utils/#ontopy.utils.annotate_source","text":"Annotate all entities with the base IRI of the ontology using rdfs:isDefinedBy annotations. If imported is true, all entities in imported sub-ontologies will also be annotated. This is contextual information that is otherwise lost when the ontology is squashed and/or inferred. Source code in ontopy/utils.py def annotate_source ( onto , imported = True ): \"\"\"Annotate all entities with the base IRI of the ontology using `rdfs:isDefinedBy` annotations. If `imported` is true, all entities in imported sub-ontologies will also be annotated. This is contextual information that is otherwise lost when the ontology is squashed and/or inferred. \"\"\" source = onto . _abbreviate ( \"http://www.w3.org/2000/01/rdf-schema#isDefinedBy\" ) for entity in onto . get_entities ( imported = imported ): triple = ( entity . storid , source , onto . _abbreviate ( entity . namespace . ontology . base_iri ), ) if not onto . _has_obj_triple_spo ( * triple ): onto . _add_obj_triple_spo ( * triple )","title":"annotate_source()"},{"location":"api_reference/ontopy/utils/#ontopy.utils.asstring","text":"Returns a string representation of expr , which may be an entity, restriction, or logical expression of these. link is a format string for formatting references to entities or relations. It may contain the keywords \"name\", \"url\" and \"lowerurl\". recursion_depth is the recursion depth and only intended for internal use. If exclude_object is true, the object will be excluded in restrictions. Source code in ontopy/utils.py def asstring ( # pylint: disable=too-many-return-statements,too-many-branches expr , link = \" {name} \" , recursion_depth = 0 , exclude_object = False ): \"\"\"Returns a string representation of `expr`, which may be an entity, restriction, or logical expression of these. `link` is a format string for formatting references to entities or relations. It may contain the keywords \"name\", \"url\" and \"lowerurl\". `recursion_depth` is the recursion depth and only intended for internal use. If `exclude_object` is true, the object will be excluded in restrictions. \"\"\" def fmt ( entity ): \"\"\"Returns the formatted label of an entity.\"\"\" name = None for attr in ( \"prefLabel\" , \"label\" , \"__name__\" , \"name\" ): if hasattr ( entity , attr ) and getattr ( entity , attr ): name = getattr ( entity , attr ) if not isinstance ( name , str ) and hasattr ( name , \"__getitem__\" ): name = name [ 0 ] break if not name : name = str ( entity ) . replace ( \".\" , \":\" ) url = name if re . match ( r \"^[a-z]+://\" , name ) else \"#\" + name return link . format ( name = name , url = url , lowerurl = url . lower ()) if isinstance ( expr , str ): # return link.format(name=expr) return fmt ( expr ) if isinstance ( expr , owlready2 . Restriction ): rlabel = owlready2 . class_construct . _restriction_type_2_label [ expr . type ] if isinstance ( expr . property , ( owlready2 . ObjectPropertyClass , owlready2 . DataPropertyClass ), ): res = fmt ( expr . property ) elif isinstance ( expr . property , owlready2 . Inverse ): res = f \"Inverse( { asstring ( expr . property . property , link , recursion_depth + 1 ) } )\" # pylint: disable=line-too-long else : print ( f \"*** WARNING: unknown restriction property: { expr . property !r} \" ) res = fmt ( expr . property ) if not rlabel : pass elif expr . type in ( owlready2 . MIN , owlready2 . MAX , owlready2 . EXACTLY ): res += f \" { rlabel } { expr . cardinality } \" elif expr . type in ( owlready2 . SOME , owlready2 . ONLY , owlready2 . VALUE , owlready2 . HAS_SELF , ): res += f \" { rlabel } \" else : print ( \"*** WARNING: unknown relation\" , expr , rlabel ) res += f \" { rlabel } \" if not exclude_object : if isinstance ( expr . value , str ): res += f \" { asstring ( expr . value , link , recursion_depth + 1 ) !r} \" else : res += f \" { asstring ( expr . value , link , recursion_depth + 1 ) } \" return res if isinstance ( expr , owlready2 . Or ): res = \" or \" . join ( [ asstring ( c , link , recursion_depth + 1 ) for c in expr . Classes ] ) return res if recursion_depth == 0 else f \"( { res } )\" if isinstance ( expr , owlready2 . And ): res = \" and \" . join ( [ asstring ( c , link , recursion_depth + 1 ) for c in expr . Classes ] ) return res if recursion_depth == 0 else f \"( { res } )\" if isinstance ( expr , owlready2 . Not ): return f \"not { asstring ( expr . Class , link , recursion_depth + 1 ) } \" if isinstance ( expr , owlready2 . ThingClass ): return fmt ( expr ) if isinstance ( expr , owlready2 . PropertyClass ): return fmt ( expr ) if isinstance ( expr , owlready2 . Thing ): # instance (individual) return fmt ( expr ) if isinstance ( expr , owlready2 . class_construct . Inverse ): return f \"inverse( { fmt ( expr . property ) } )\" if isinstance ( expr , owlready2 . disjoint . AllDisjoint ): return fmt ( expr ) if isinstance ( expr , ( bool , int , float )): return repr ( expr ) # Check for subclasses if issubclass ( expr , ( bool , int , float , str )): return fmt ( expr . __class__ . __name__ ) if issubclass ( expr , datetime . date ): return \"date\" if issubclass ( expr , datetime . time ): return \"datetime\" if issubclass ( expr , datetime . datetime ): return \"datetime\" raise RuntimeError ( f \"Unknown expression: { expr !r} (type: { type ( expr ) !r} )\" )","title":"asstring()"},{"location":"api_reference/ontopy/utils/#ontopy.utils.camelsplit","text":"Splits CamelCase string before upper case letters (except if there is a sequence of upper case letters). Source code in ontopy/utils.py def camelsplit ( string ): \"\"\"Splits CamelCase string before upper case letters (except if there is a sequence of upper case letters).\"\"\" if len ( string ) < 2 : return string result = [] prev_lower = False prev_isspace = True char = string [ 0 ] for next_char in string [ 1 :]: if ( not prev_isspace and char . isupper () and next_char . islower ()) or ( prev_lower and char . isupper () ): result . append ( \" \" ) result . append ( char ) prev_lower = char . islower () prev_isspace = char . isspace () char = next_char result . append ( char ) return \"\" . join ( result )","title":"camelsplit()"},{"location":"api_reference/ontopy/utils/#ontopy.utils.convert_imported","text":"Convert imported ontologies. Store the output in a directory structure matching the source files. This require catalog file(s) to be present. Warning To convert to Turtle ( .ttl ) format, you must have installed rdflib>=6.0.0 . See Known issues for more information. Parameters: Name Type Description Default input_ontology Union[Path, str] input ontology file name required output_ontology Union[Path, str] output ontology file path. The directory part of output will be the root of the generated directory structure required input_format Optional[str] input format. The default is to infer from input_ontology None output_format str output format. The default is to infer from output_ontology 'xml' url_from_catalog Optional[bool] Whether to read urls form catalog file. If False, the catalog file will be used if it exists. None catalog_file str name of catalog file, that maps ontology IRIs to local file names 'catalog-v001.xml' Source code in ontopy/utils.py def convert_imported ( # pylint: disable=too-many-arguments,too-many-locals input_ontology : \"Union[Path, str]\" , output_ontology : \"Union[Path, str]\" , input_format : \"Optional[str]\" = None , output_format : str = \"xml\" , url_from_catalog : \"Optional[bool]\" = None , catalog_file : str = \"catalog-v001.xml\" , ): \"\"\"Convert imported ontologies. Store the output in a directory structure matching the source files. This require catalog file(s) to be present. Warning: To convert to Turtle (`.ttl`) format, you must have installed `rdflib>=6.0.0`. See [Known issues](../../../#known-issues) for more information. Args: input_ontology: input ontology file name output_ontology: output ontology file path. The directory part of `output` will be the root of the generated directory structure input_format: input format. The default is to infer from `input_ontology` output_format: output format. The default is to infer from `output_ontology` url_from_catalog: Whether to read urls form catalog file. If False, the catalog file will be used if it exists. catalog_file: name of catalog file, that maps ontology IRIs to local file names \"\"\" inroot = os . path . dirname ( os . path . abspath ( input_ontology )) outroot = os . path . dirname ( os . path . abspath ( output_ontology )) outext = os . path . splitext ( output_ontology )[ 1 ] if url_from_catalog is None : url_from_catalog = os . path . exists ( os . path . join ( inroot , catalog_file )) if url_from_catalog : iris , dirs = read_catalog ( inroot , catalog_file = catalog_file , recursive = True , return_paths = True ) # Create output dirs and copy catalog files for indir in dirs : outdir = os . path . normpath ( os . path . join ( outroot , os . path . relpath ( indir , inroot )) ) if not os . path . exists ( outdir ): os . makedirs ( outdir ) with open ( os . path . join ( indir , catalog_file ), mode = \"rt\" , encoding = \"utf8\" ) as handle : content = handle . read () for path in iris . values (): newpath = os . path . splitext ( path )[ 0 ] + outext content = content . replace ( os . path . basename ( path ), os . path . basename ( newpath ) ) with open ( os . path . join ( outdir , catalog_file ), mode = \"wt\" , encoding = \"utf8\" ) as handle : handle . write ( content ) else : iris = {} outpaths = set () def recur ( graph , outext ): for imported in graph . objects ( predicate = URIRef ( \"http://www.w3.org/2002/07/owl#imports\" ) ): inpath = iris . get ( str ( imported ), str ( imported )) if inpath . startswith (( \"http://\" , \"https://\" , \"ftp://\" )): outpath = os . path . join ( outroot , inpath . split ( \"/\" )[ - 1 ]) else : outpath = os . path . join ( outroot , os . path . relpath ( inpath , inroot )) outpath = os . path . splitext ( os . path . normpath ( outpath ))[ 0 ] + outext if outpath not in outpaths : outpaths . add ( outpath ) fmt = ( input_format if input_format else guess_format ( inpath , fmap = FMAP ) ) new_graph = Graph () new_graph . parse ( iris . get ( inpath , inpath ), format = fmt ) new_graph . serialize ( destination = outpath , format = output_format ) recur ( new_graph , outext ) # Write output files fmt = ( input_format if input_format else guess_format ( input_ontology , fmap = FMAP ) ) if not _validate_installed_version ( package = \"rdflib\" , min_version = \"6.0.0\" ) and ( output_format == FMAP . get ( \"ttl\" , \"\" ) or outext == \"ttl\" ): from rdflib import ( # pylint: disable=import-outside-toplevel __version__ as __rdflib_version__ , ) warnings . warn ( IncompatibleVersion ( \"To correctly convert to Turtle format, rdflib must be \" \"version 6.0.0 or greater, however, the detected rdflib \" \"version used by your Python interpreter is \" f \" { __rdflib_version__ !r} . For more information see the \" \"'Known issues' section of the README.\" ) ) graph = Graph () try : graph . parse ( input_ontology , format = fmt ) except PluginException as exc : # Add input_ontology to exception msg raise PluginException ( f 'Cannot load \" { input_ontology } \": { exc . msg } ' ) . with_traceback ( exc . __traceback__ ) graph . serialize ( destination = output_ontology , format = output_format ) recur ( graph , outext )","title":"convert_imported()"},{"location":"api_reference/ontopy/utils/#ontopy.utils.get_label","text":"Returns the label of an entity. Source code in ontopy/utils.py def get_label ( entity ): \"\"\"Returns the label of an entity.\"\"\" if hasattr ( entity , \"prefLabel\" ) and entity . prefLabel : return entity . prefLabel . first () if hasattr ( entity , \"label\" ) and entity . label : return entity . label . first () if hasattr ( entity , \"__name__\" ): return entity . __name__ if hasattr ( entity , \"name\" ): return str ( entity . name ) if isinstance ( entity , str ): return entity return repr ( entity )","title":"get_label()"},{"location":"api_reference/ontopy/utils/#ontopy.utils.infer_version","text":"Infer version from IRI and versionIRI. Source code in ontopy/utils.py def infer_version ( iri , version_iri ): \"\"\"Infer version from IRI and versionIRI.\"\"\" if str ( version_iri [: len ( iri )]) == str ( iri ): version = version_iri [ len ( iri ) :] . lstrip ( \"/\" ) else : j = 0 version_parts = [] for i , char in enumerate ( iri ): while i + j < len ( version_iri ) and char != version_iri [ i + j ]: version_parts . append ( version_iri [ i + j ]) j += 1 version = \"\" . join ( version_parts ) . lstrip ( \"/\" ) . rstrip ( \"/#\" ) if \"/\" in version : raise ValueError ( f \"version IRI { version_iri !r} is not consistent with base IRI \" f \" { iri !r} \" ) return version","title":"infer_version()"},{"location":"api_reference/ontopy/utils/#ontopy.utils.isinteractive","text":"Returns true if we are running from an interactive interpreater, false otherwise. Source code in ontopy/utils.py def isinteractive (): \"\"\"Returns true if we are running from an interactive interpreater, false otherwise.\"\"\" return bool ( hasattr ( __builtins__ , \"__IPYTHON__\" ) or sys . flags . interactive or hasattr ( sys , \"ps1\" ) )","title":"isinteractive()"},{"location":"api_reference/ontopy/utils/#ontopy.utils.normalise_url","text":"Returns url in a normalised form. Source code in ontopy/utils.py def normalise_url ( url ): \"\"\"Returns `url` in a normalised form.\"\"\" splitted = urllib . parse . urlsplit ( url ) components = list ( splitted ) components [ 2 ] = os . path . normpath ( splitted . path ) return urllib . parse . urlunsplit ( components )","title":"normalise_url()"},{"location":"api_reference/ontopy/utils/#ontopy.utils.read_catalog","text":"Reads a Prot\u00e8g\u00e8 catalog file and returns as a dict. The returned dict maps the ontology IRI (name) to its actual location (URI). The location can be either an absolute file path or a HTTP, HTTPS or FTP web location. uri is a string locating the catalog file. It may be a http or https web location or a file path. The catalog_file argument spesifies the catalog file name and is used if path is used when recursive is true or when path is a directory. If baseuri is not None, it will be used as the base URI for the mapped locations. Otherwise it defaults to uri with its final component omitted. If recursive is true, catalog files in sub-folders are also read. If return_paths is true, a set of directory paths to source files is returned in addition to the default dict. The visited_uris and visited_paths arguments are only intended for internal use to avoid infinite recursions. A ReadCatalogError is raised if the catalog file cannot be found. Source code in ontopy/utils.py def read_catalog ( # pylint: disable=too-many-locals,too-many-statements,too-many-arguments uri , catalog_file = \"catalog-v001.xml\" , baseuri = None , recursive = False , return_paths = False , visited_iris = None , visited_paths = None , ): \"\"\"Reads a Prot\u00e8g\u00e8 catalog file and returns as a dict. The returned dict maps the ontology IRI (name) to its actual location (URI). The location can be either an absolute file path or a HTTP, HTTPS or FTP web location. `uri` is a string locating the catalog file. It may be a http or https web location or a file path. The `catalog_file` argument spesifies the catalog file name and is used if `path` is used when `recursive` is true or when `path` is a directory. If `baseuri` is not None, it will be used as the base URI for the mapped locations. Otherwise it defaults to `uri` with its final component omitted. If `recursive` is true, catalog files in sub-folders are also read. If `return_paths` is true, a set of directory paths to source files is returned in addition to the default dict. The `visited_uris` and `visited_paths` arguments are only intended for internal use to avoid infinite recursions. A ReadCatalogError is raised if the catalog file cannot be found. \"\"\" # Protocols supported by urllib.request web_protocols = \"http://\" , \"https://\" , \"ftp://\" uri = str ( uri ) # in case uri is a pathlib.Path object iris = visited_iris if visited_iris else {} dirs = visited_paths if visited_paths else set () if uri in iris : return ( iris , dirs ) if return_paths else iris if uri . startswith ( web_protocols ): # Call read_catalog() recursively to ensure that the temporary # file is properly cleaned up with tempfile . TemporaryDirectory () as tmpdir : destfile = os . path . join ( tmpdir , catalog_file ) uris = { # maps uri to base uri : ( baseuri if baseuri else os . path . dirname ( uri )), f ' { uri . rstrip ( \"/\" ) } / { catalog_file } ' : ( baseuri if baseuri else uri . rstrip ( \"/\" ) ), f \" { os . path . dirname ( uri ) } / { catalog_file } \" : ( os . path . dirname ( uri ) ), } for url , base in uris . items (): try : # The URL can only contain the schemes from `web_protocols`. _ , msg = urllib . request . urlretrieve ( url , destfile ) # nosec except urllib . request . URLError : continue else : if \"Content-Length\" not in msg : continue return read_catalog ( destfile , catalog_file = catalog_file , baseuri = baseuri if baseuri else base , recursive = recursive , return_paths = return_paths , visited_iris = iris , visited_paths = dirs , ) raise ReadCatalogError ( \"Cannot download catalog from URLs: \" + \", \" . join ( uris ) ) elif uri . startswith ( \"file://\" ): path = uri [ 7 :] else : path = uri if os . path . isdir ( path ): dirname = os . path . abspath ( path ) filepath = os . path . join ( dirname , catalog_file ) else : catalog_file = os . path . basename ( path ) filepath = os . path . abspath ( path ) dirname = os . path . dirname ( filepath ) def gettag ( entity ): return entity . tag . rsplit ( \"}\" , 1 )[ - 1 ] def load_catalog ( filepath ): if not os . path . exists ( filepath ): raise ReadCatalogError ( \"No such catalog file: \" + filepath ) dirname = os . path . normpath ( os . path . dirname ( filepath )) dirs . add ( baseuri if baseuri else dirname ) xml = ET . parse ( filepath ) root = xml . getroot () if gettag ( root ) != \"catalog\" : raise ReadCatalogError ( f \"expected root tag of catalog file { filepath !r} to be \" '\"catalog\"' ) for child in root : if gettag ( child ) == \"uri\" : load_uri ( child , dirname ) elif gettag ( child ) == \"group\" : for uri in child : load_uri ( uri , dirname ) def load_uri ( uri , dirname ): if gettag ( uri ) != \"uri\" : raise ValueError ( f \" { gettag ( uri ) !r} should be 'uri'.\" ) uri_as_str = uri . attrib [ \"uri\" ] if uri_as_str . startswith ( web_protocols ): url = uri_as_str else : uri_as_str = os . path . normpath ( uri_as_str ) if baseuri and baseuri . startswith ( web_protocols ): url = f \" { baseuri } / { uri_as_str } \" else : url = os . path . join ( baseuri if baseuri else dirname , uri_as_str ) iris . setdefault ( uri . attrib [ \"name\" ], url ) if recursive : directory = os . path . dirname ( url ) if directory not in dirs : catalog = os . path . join ( directory , catalog_file ) if catalog . startswith ( web_protocols ): iris_ , dirs_ = read_catalog ( catalog , catalog_file = catalog_file , baseuri = None , recursive = recursive , return_paths = True , visited_iris = iris , visited_paths = dirs , ) iris . update ( iris_ ) dirs . update ( dirs_ ) else : load_catalog ( catalog ) load_catalog ( filepath ) if return_paths : return iris , dirs return iris","title":"read_catalog()"},{"location":"api_reference/ontopy/utils/#ontopy.utils.rename_iris","text":"For IRIs with the given annotation, change the name of the entity to the value of the annotation. Also add an skos:exactMatch annotation referring to the old IRI. Source code in ontopy/utils.py def rename_iris ( onto , annotation = \"prefLabel\" ): \"\"\"For IRIs with the given annotation, change the name of the entity to the value of the annotation. Also add an `skos:exactMatch` annotation referring to the old IRI. \"\"\" exactMatch = onto . _abbreviate ( # pylint:disable=invalid-name \"http://www.w3.org/2004/02/skos/core#exactMatch\" ) for entity in onto . get_entities (): if hasattr ( entity , annotation ) and getattr ( entity , annotation ): onto . _add_data_triple_spod ( entity . storid , exactMatch , entity . iri , \"\" ) entity . name = getattr ( entity , annotation ) . first ()","title":"rename_iris()"},{"location":"api_reference/ontopy/utils/#ontopy.utils.write_catalog","text":"Write catalog file do disk. Parameters: Name Type Description Default mappings dict dict mapping ontology IRIs (name) to actual locations (URIs). It has the same format as the dict returned by read_catalog(). required output Union[str, Path] name of catalog file. 'catalog-v001.xml' directory Union[str, Path] directory path to the catalog file. Only used if output is a relative path. '.' relative_paths bool whether to write absolute or relative paths to for file paths inside the catalog file. True append bool whether to append to a possible existing catalog file. If false, an existing file will be overwritten. False Source code in ontopy/utils.py def write_catalog ( mappings : dict , output : \"Union[str, Path]\" = \"catalog-v001.xml\" , directory : \"Union[str, Path]\" = \".\" , relative_paths : bool = True , append : bool = False , ): # pylint: disable=redefined-builtin \"\"\"Write catalog file do disk. Args: mappings: dict mapping ontology IRIs (name) to actual locations (URIs). It has the same format as the dict returned by read_catalog(). output: name of catalog file. directory: directory path to the catalog file. Only used if `output` is a relative path. relative_paths: whether to write absolute or relative paths to for file paths inside the catalog file. append: whether to append to a possible existing catalog file. If false, an existing file will be overwritten. \"\"\" web_protocol = \"http://\" , \"https://\" , \"ftp://\" if relative_paths : for key , item in mappings . items (): if not item . startswith ( web_protocol ): mappings [ key ] = os . path . relpath ( item , Path ( directory ) . resolve ()) filename = ( Path ( directory ) / output ) . resolve () if filename . exists () and append : iris = read_catalog ( filename ) iris . update ( mappings ) mappings = iris res = [ '<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>' , '<catalog prefer=\"public\" ' 'xmlns=\"urn:oasis:names:tc:entity:xmlns:xml:catalog\">' , ' <group id=\"Folder Repository, directory=, recursive=true, ' 'Auto-Update=false, version=2\" prefer=\"public\" xml:base=\"\">' , ] for key , value in dict ( mappings ) . items (): res . append ( f ' <uri name=\" { key } \" uri=\" { value } \"/>' ) res . append ( \" </group>\" ) res . append ( \"</catalog>\" ) with open ( filename , \"wt\" ) as handle : handle . write ( \" \\n \" . join ( res ) + \" \\n \" )","title":"write_catalog()"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/","text":"factppgraph \u00b6 ontopy.factpluspluswrapper.factppgraph \u00b6 FaCTPPGraph \u00b6 Class for running the FaCT++ reasoner (using OwlApiInterface) and postprocessing the resulting inferred ontology. Parameters \u00b6 graph : owlapi.Graph instance The graph to be inferred. Source code in ontopy/factpluspluswrapper/factppgraph.py class FaCTPPGraph : \"\"\"Class for running the FaCT++ reasoner (using OwlApiInterface) and postprocessing the resulting inferred ontology. Parameters ---------- graph : owlapi.Graph instance The graph to be inferred. \"\"\" def __init__ ( self , graph ): self . graph = graph self . _inferred = None self . _namespaces = None self . _base_iri = None @property def inferred ( self ): \"\"\"The current inferred graph.\"\"\" if self . _inferred is None : self . _inferred = self . raw_inferred_graph () return self . _inferred @property def base_iri ( self ): \"\"\"Base iri of inferred ontology.\"\"\" if self . _base_iri is None : self . _base_iri = URIRef ( self . asserted_base_iri () + \"-inferred\" ) return self . _base_iri @base_iri . setter def base_iri ( self , value ): \"\"\"Assign inferred base iri.\"\"\" self . _base_iri = URIRef ( value ) @property def namespaces ( self ): \"\"\"Namespaces defined in the original graph.\"\"\" if self . _namespaces is None : self . _namespaces = dict ( self . graph . namespaces ()) . copy () self . _namespaces [ \"\" ] = self . base_iri return self . _namespaces def asserted_base_iri ( self ): \"\"\"Returns the base iri or the original graph.\"\"\" return URIRef ( dict ( self . graph . namespaces ()) . get ( \"\" , \"\" ) . rstrip ( \"#/\" )) def raw_inferred_graph ( self ): \"\"\"Returns the raw non-postprocessed inferred ontology as a rdflib graph.\"\"\" return OwlApiInterface () . reason ( self . graph ) def inferred_graph ( self ): \"\"\"Returns the postprocessed inferred graph.\"\"\" self . add_base_annotations () self . set_namespace () self . clean_base () self . remove_nothing_is_nothing () self . clean_ancestors () return self . inferred def add_base_annotations ( self ): \"\"\"Copy base annotations from original graph to the inferred graph.\"\"\" base = self . base_iri inferred = self . inferred for _ , predicate , obj in self . graph . triples ( ( self . asserted_base_iri (), None , None ) ): if predicate == OWL . versionIRI : version = obj . rsplit ( \"/\" , 1 )[ - 1 ] obj = URIRef ( f \" { base } / { version } \" ) inferred . add (( base , predicate , obj )) def set_namespace ( self ): \"\"\"Override namespace of inferred graph with the namespace of the original graph. \"\"\" inferred = self . inferred for key , value in self . namespaces . items (): inferred . namespace_manager . bind ( key , value , override = True , replace = True ) def clean_base ( self ): \"\"\"Remove all relations `s? a owl:Ontology` where `s?` is not `base_iri`. \"\"\" inferred = self . inferred for ( subject , predicate , obj , ) in inferred . triples ( # pylint: disable=not-an-iterable ( None , RDF . type , OWL . Ontology ) ): inferred . remove (( subject , predicate , obj )) inferred . add (( self . base_iri , RDF . type , OWL . Ontology )) def remove_nothing_is_nothing ( self ): \"\"\"Remove superfluid relation in inferred graph: owl:Nothing rdfs:subClassOf owl:Nothing \"\"\" triple = OWL . Nothing , RDFS . subClassOf , OWL . Nothing inferred = self . inferred if triple in inferred : inferred . remove ( triple ) def clean_ancestors ( self ): \"\"\"Remove redundant rdfs:subClassOf relations in inferred graph.\"\"\" inferred = self . inferred for ( # pylint: disable=too-many-nested-blocks subject ) in inferred . subjects ( RDF . type , OWL . Class ): if isinstance ( subject , URIRef ): parents = set ( parent for parent in inferred . objects ( subject , RDFS . subClassOf ) if isinstance ( parent , URIRef ) ) if len ( parents ) > 1 : for parent in parents : ancestors = set ( inferred . transitive_objects ( parent , RDFS . subClassOf ) ) for entity in parents : if entity != parent and entity in ancestors : triple = subject , RDFS . subClassOf , entity if triple in inferred : inferred . remove ( triple ) base_iri property writable \u00b6 Base iri of inferred ontology. inferred property readonly \u00b6 The current inferred graph. namespaces property readonly \u00b6 Namespaces defined in the original graph. add_base_annotations ( self ) \u00b6 Copy base annotations from original graph to the inferred graph. Source code in ontopy/factpluspluswrapper/factppgraph.py def add_base_annotations ( self ): \"\"\"Copy base annotations from original graph to the inferred graph.\"\"\" base = self . base_iri inferred = self . inferred for _ , predicate , obj in self . graph . triples ( ( self . asserted_base_iri (), None , None ) ): if predicate == OWL . versionIRI : version = obj . rsplit ( \"/\" , 1 )[ - 1 ] obj = URIRef ( f \" { base } / { version } \" ) inferred . add (( base , predicate , obj )) asserted_base_iri ( self ) \u00b6 Returns the base iri or the original graph. Source code in ontopy/factpluspluswrapper/factppgraph.py def asserted_base_iri ( self ): \"\"\"Returns the base iri or the original graph.\"\"\" return URIRef ( dict ( self . graph . namespaces ()) . get ( \"\" , \"\" ) . rstrip ( \"#/\" )) clean_ancestors ( self ) \u00b6 Remove redundant rdfs:subClassOf relations in inferred graph. Source code in ontopy/factpluspluswrapper/factppgraph.py def clean_ancestors ( self ): \"\"\"Remove redundant rdfs:subClassOf relations in inferred graph.\"\"\" inferred = self . inferred for ( # pylint: disable=too-many-nested-blocks subject ) in inferred . subjects ( RDF . type , OWL . Class ): if isinstance ( subject , URIRef ): parents = set ( parent for parent in inferred . objects ( subject , RDFS . subClassOf ) if isinstance ( parent , URIRef ) ) if len ( parents ) > 1 : for parent in parents : ancestors = set ( inferred . transitive_objects ( parent , RDFS . subClassOf ) ) for entity in parents : if entity != parent and entity in ancestors : triple = subject , RDFS . subClassOf , entity if triple in inferred : inferred . remove ( triple ) clean_base ( self ) \u00b6 Remove all relations s? a owl:Ontology where s? is not base_iri . Source code in ontopy/factpluspluswrapper/factppgraph.py def clean_base ( self ): \"\"\"Remove all relations `s? a owl:Ontology` where `s?` is not `base_iri`. \"\"\" inferred = self . inferred for ( subject , predicate , obj , ) in inferred . triples ( # pylint: disable=not-an-iterable ( None , RDF . type , OWL . Ontology ) ): inferred . remove (( subject , predicate , obj )) inferred . add (( self . base_iri , RDF . type , OWL . Ontology )) inferred_graph ( self ) \u00b6 Returns the postprocessed inferred graph. Source code in ontopy/factpluspluswrapper/factppgraph.py def inferred_graph ( self ): \"\"\"Returns the postprocessed inferred graph.\"\"\" self . add_base_annotations () self . set_namespace () self . clean_base () self . remove_nothing_is_nothing () self . clean_ancestors () return self . inferred raw_inferred_graph ( self ) \u00b6 Returns the raw non-postprocessed inferred ontology as a rdflib graph. Source code in ontopy/factpluspluswrapper/factppgraph.py def raw_inferred_graph ( self ): \"\"\"Returns the raw non-postprocessed inferred ontology as a rdflib graph.\"\"\" return OwlApiInterface () . reason ( self . graph ) remove_nothing_is_nothing ( self ) \u00b6 Remove superfluid relation in inferred graph: owl:Nothing rdfs:subClassOf owl:Nothing Source code in ontopy/factpluspluswrapper/factppgraph.py def remove_nothing_is_nothing ( self ): \"\"\"Remove superfluid relation in inferred graph: owl:Nothing rdfs:subClassOf owl:Nothing \"\"\" triple = OWL . Nothing , RDFS . subClassOf , OWL . Nothing inferred = self . inferred if triple in inferred : inferred . remove ( triple ) set_namespace ( self ) \u00b6 Override namespace of inferred graph with the namespace of the original graph. Source code in ontopy/factpluspluswrapper/factppgraph.py def set_namespace ( self ): \"\"\"Override namespace of inferred graph with the namespace of the original graph. \"\"\" inferred = self . inferred for key , value in self . namespaces . items (): inferred . namespace_manager . bind ( key , value , override = True , replace = True ) FactPPError \u00b6 Postprocessing error after reasoning with FaCT++. Source code in ontopy/factpluspluswrapper/factppgraph.py class FactPPError : \"\"\"Postprocessing error after reasoning with FaCT++.\"\"\"","title":"factppgraph"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#factppgraph","text":"","title":"factppgraph"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#ontopy.factpluspluswrapper.factppgraph--ontopyfactpluspluswrapperfactppgraph","text":"","title":"\n\n  \n\n\n    \n\n      ontopy.factpluspluswrapper.factppgraph&para;\n\n\n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\n        \nFaCTPPGraph        \n\n\n\n\u0002amp\u0003para;\n\n    \n\n      Class for running the FaCT++ reasoner (using OwlApiInterface) and\npostprocessing the resulting inferred ontology.\nParameters&para;\ngraph : owlapi.Graph instance\n    The graph to be inferred.\n\n        \n          Source code in ontopy/factpluspluswrapper/factppgraph.py\n          class FaCTPPGraph:\n    &quot;&quot;&quot;Class for running the FaCT++ reasoner (using OwlApiInterface) and\n    postprocessing the resulting inferred ontology.\n\n    Parameters\n    ----------\n    graph : owlapi.Graph instance\n        The graph to be inferred.\n    &quot;&quot;&quot;\n\n    def __init__(self, graph):\n        self.graph = graph\n        self._inferred = None\n        self._namespaces = None\n        self._base_iri = None\n\n    @property\n    def inferred(self):\n        &quot;&quot;&quot;The current inferred graph.&quot;&quot;&quot;\n        if self._inferred is None:\n            self._inferred = self.raw_inferred_graph()\n        return self._inferred\n\n    @property\n    def base_iri(self):\n        &quot;&quot;&quot;Base iri of inferred ontology.&quot;&quot;&quot;\n        if self._base_iri is None:\n            self._base_iri = URIRef(self.asserted_base_iri() + &quot;-inferred&quot;)\n        return self._base_iri\n\n    @base_iri.setter\n    def base_iri(self, value):\n        &quot;&quot;&quot;Assign inferred base iri.&quot;&quot;&quot;\n        self._base_iri = URIRef(value)\n\n    @property\n    def namespaces(self):\n        &quot;&quot;&quot;Namespaces defined in the original graph.&quot;&quot;&quot;\n        if self._namespaces is None:\n            self._namespaces = dict(self.graph.namespaces()).copy()\n            self._namespaces[&quot;&quot;] = self.base_iri\n        return self._namespaces\n\n    def asserted_base_iri(self):\n        &quot;&quot;&quot;Returns the base iri or the original graph.&quot;&quot;&quot;\n        return URIRef(dict(self.graph.namespaces()).get(&quot;&quot;, &quot;&quot;).rstrip(&quot;#/&quot;))\n\n    def raw_inferred_graph(self):\n        &quot;&quot;&quot;Returns the raw non-postprocessed inferred ontology as a rdflib\n        graph.&quot;&quot;&quot;\n        return OwlApiInterface().reason(self.graph)\n\n    def inferred_graph(self):\n        &quot;&quot;&quot;Returns the postprocessed inferred graph.&quot;&quot;&quot;\n        self.add_base_annotations()\n        self.set_namespace()\n        self.clean_base()\n        self.remove_nothing_is_nothing()\n        self.clean_ancestors()\n        return self.inferred\n\n    def add_base_annotations(self):\n        &quot;&quot;&quot;Copy base annotations from original graph to the inferred graph.&quot;&quot;&quot;\n        base = self.base_iri\n        inferred = self.inferred\n        for _, predicate, obj in self.graph.triples(\n            (self.asserted_base_iri(), None, None)\n        ):\n            if predicate == OWL.versionIRI:\n                version = obj.rsplit(&quot;/&quot;, 1)[-1]\n                obj = URIRef(f&quot;{base}/{version}&quot;)\n            inferred.add((base, predicate, obj))\n\n    def set_namespace(self):\n        &quot;&quot;&quot;Override namespace of inferred graph with the namespace of the\n        original graph.\n        &quot;&quot;&quot;\n        inferred = self.inferred\n        for key, value in self.namespaces.items():\n            inferred.namespace_manager.bind(\n                key, value, override=True, replace=True\n            )\n\n    def clean_base(self):\n        &quot;&quot;&quot;Remove all relations `s? a owl:Ontology` where `s?` is not\n        `base_iri`.\n        &quot;&quot;&quot;\n        inferred = self.inferred\n        for (\n            subject,\n            predicate,\n            obj,\n        ) in inferred.triples(  # pylint: disable=not-an-iterable\n            (None, RDF.type, OWL.Ontology)\n        ):\n            inferred.remove((subject, predicate, obj))\n        inferred.add((self.base_iri, RDF.type, OWL.Ontology))\n\n    def remove_nothing_is_nothing(self):\n        &quot;&quot;&quot;Remove superfluid relation in inferred graph:\n\n        owl:Nothing rdfs:subClassOf owl:Nothing\n        &quot;&quot;&quot;\n        triple = OWL.Nothing, RDFS.subClassOf, OWL.Nothing\n        inferred = self.inferred\n        if triple in inferred:\n            inferred.remove(triple)\n\n    def clean_ancestors(self):\n        &quot;&quot;&quot;Remove redundant rdfs:subClassOf relations in inferred graph.&quot;&quot;&quot;\n        inferred = self.inferred\n        for (  # pylint: disable=too-many-nested-blocks\n            subject\n        ) in inferred.subjects(RDF.type, OWL.Class):\n            if isinstance(subject, URIRef):\n                parents = set(\n                    parent\n                    for parent in inferred.objects(subject, RDFS.subClassOf)\n                    if isinstance(parent, URIRef)\n                )\n                if len(parents) &gt; 1:\n                    for parent in parents:\n                        ancestors = set(\n                            inferred.transitive_objects(parent, RDFS.subClassOf)\n                        )\n                        for entity in parents:\n                            if entity != parent and entity in ancestors:\n                                triple = subject, RDFS.subClassOf, entity\n                                if triple in inferred:\n                                    inferred.remove(triple)\n\n        \n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\nbase_iri\n\n  \n      property\n      writable\n  \n\n\u0002amp\u0003para;\n\n    \n\n      Base iri of inferred ontology.\n    \n\n  \n\n\n\n  \n\n\n\n\ninferred\n\n  \n      property\n      readonly\n  \n\n\u0002amp\u0003para;\n\n    \n\n      The current inferred graph.\n    \n\n  \n\n\n\n  \n\n\n\n\nnamespaces\n\n  \n      property\n      readonly\n  \n\n\u0002amp\u0003para;\n\n    \n\n      Namespaces defined in the original graph.\n    \n\n  \n\n\n\n\n\n\n\n  \n\n\n\n\nadd_base_annotations(self)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Copy base annotations from original graph to the inferred graph.\n\n        \n          Source code in ontopy/factpluspluswrapper/factppgraph.py\n          def add_base_annotations(self):\n    &quot;&quot;&quot;Copy base annotations from original graph to the inferred graph.&quot;&quot;&quot;\n    base = self.base_iri\n    inferred = self.inferred\n    for _, predicate, obj in self.graph.triples(\n        (self.asserted_base_iri(), None, None)\n    ):\n        if predicate == OWL.versionIRI:\n            version = obj.rsplit(&quot;/&quot;, 1)[-1]\n            obj = URIRef(f&quot;{base}/{version}&quot;)\n        inferred.add((base, predicate, obj))\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\nasserted_base_iri(self)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Returns the base iri or the original graph.\n\n        \n          Source code in ontopy/factpluspluswrapper/factppgraph.py\n          def asserted_base_iri(self):\n    &quot;&quot;&quot;Returns the base iri or the original graph.&quot;&quot;&quot;\n    return URIRef(dict(self.graph.namespaces()).get(&quot;&quot;, &quot;&quot;).rstrip(&quot;#/&quot;))\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\nclean_ancestors(self)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Remove redundant rdfs:subClassOf relations in inferred graph.\n\n        \n          Source code in ontopy/factpluspluswrapper/factppgraph.py\n          def clean_ancestors(self):\n    &quot;&quot;&quot;Remove redundant rdfs:subClassOf relations in inferred graph.&quot;&quot;&quot;\n    inferred = self.inferred\n    for (  # pylint: disable=too-many-nested-blocks\n        subject\n    ) in inferred.subjects(RDF.type, OWL.Class):\n        if isinstance(subject, URIRef):\n            parents = set(\n                parent\n                for parent in inferred.objects(subject, RDFS.subClassOf)\n                if isinstance(parent, URIRef)\n            )\n            if len(parents) &gt; 1:\n                for parent in parents:\n                    ancestors = set(\n                        inferred.transitive_objects(parent, RDFS.subClassOf)\n                    )\n                    for entity in parents:\n                        if entity != parent and entity in ancestors:\n                            triple = subject, RDFS.subClassOf, entity\n                            if triple in inferred:\n                                inferred.remove(triple)\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\nclean_base(self)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Remove all relations s? a owl:Ontology where s? is not\nbase_iri.\n\n        \n          Source code in ontopy/factpluspluswrapper/factppgraph.py\n          def clean_base(self):\n    &quot;&quot;&quot;Remove all relations `s? a owl:Ontology` where `s?` is not\n    `base_iri`.\n    &quot;&quot;&quot;\n    inferred = self.inferred\n    for (\n        subject,\n        predicate,\n        obj,\n    ) in inferred.triples(  # pylint: disable=not-an-iterable\n        (None, RDF.type, OWL.Ontology)\n    ):\n        inferred.remove((subject, predicate, obj))\n    inferred.add((self.base_iri, RDF.type, OWL.Ontology))\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\ninferred_graph(self)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Returns the postprocessed inferred graph.\n\n        \n          Source code in ontopy/factpluspluswrapper/factppgraph.py\n          def inferred_graph(self):\n    &quot;&quot;&quot;Returns the postprocessed inferred graph.&quot;&quot;&quot;\n    self.add_base_annotations()\n    self.set_namespace()\n    self.clean_base()\n    self.remove_nothing_is_nothing()\n    self.clean_ancestors()\n    return self.inferred\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\nraw_inferred_graph(self)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Returns the raw non-postprocessed inferred ontology as a rdflib\ngraph.\n\n        \n          Source code in ontopy/factpluspluswrapper/factppgraph.py\n          def raw_inferred_graph(self):\n    &quot;&quot;&quot;Returns the raw non-postprocessed inferred ontology as a rdflib\n    graph.&quot;&quot;&quot;\n    return OwlApiInterface().reason(self.graph)\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\nremove_nothing_is_nothing(self)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Remove superfluid relation in inferred graph:\nowl:Nothing rdfs:subClassOf owl:Nothing\n\n        \n          Source code in ontopy/factpluspluswrapper/factppgraph.py\n          def remove_nothing_is_nothing(self):\n    &quot;&quot;&quot;Remove superfluid relation in inferred graph:\n\n    owl:Nothing rdfs:subClassOf owl:Nothing\n    &quot;&quot;&quot;\n    triple = OWL.Nothing, RDFS.subClassOf, OWL.Nothing\n    inferred = self.inferred\n    if triple in inferred:\n        inferred.remove(triple)\n\n        \n    \n\n  \n\n\n\n  \n\n\n\n\nset_namespace(self)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Override namespace of inferred graph with the namespace of the\noriginal graph.\n\n        \n          Source code in ontopy/factpluspluswrapper/factppgraph.py\n          def set_namespace(self):\n    &quot;&quot;&quot;Override namespace of inferred graph with the namespace of the\n    original graph.\n    &quot;&quot;&quot;\n    inferred = self.inferred\n    for key, value in self.namespaces.items():\n        inferred.namespace_manager.bind(\n            key, value, override=True, replace=True\n        )\n\n        \n    \n\n  \n\n\n\n\n\n  \n\n    \n\n  \n\n\n\n  \n\n\n\n\n        \nFactPPError        \n\n\n\n\u0002amp\u0003para;\n\n    \n\n      Postprocessing error after reasoning with FaCT++.\n\n        \n          Source code in ontopy/factpluspluswrapper/factppgraph.py\n          class FactPPError:\n    &quot;&quot;&quot;Postprocessing error after reasoning with FaCT++.&quot;&quot;&quot;\n\n        \n\n\n    \n\n  \n\n\n\n\n\n\n\n  \n\n    \n\n  \n\n"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#ontopy.factpluspluswrapper.factppgraph.FaCTPPGraph","text":"Class for running the FaCT++ reasoner (using OwlApiInterface) and postprocessing the resulting inferred ontology.","title":"FaCTPPGraph"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#ontopy.factpluspluswrapper.factppgraph.FaCTPPGraph--parameters","text":"graph : owlapi.Graph instance The graph to be inferred. Source code in ontopy/factpluspluswrapper/factppgraph.py class FaCTPPGraph : \"\"\"Class for running the FaCT++ reasoner (using OwlApiInterface) and postprocessing the resulting inferred ontology. Parameters ---------- graph : owlapi.Graph instance The graph to be inferred. \"\"\" def __init__ ( self , graph ): self . graph = graph self . _inferred = None self . _namespaces = None self . _base_iri = None @property def inferred ( self ): \"\"\"The current inferred graph.\"\"\" if self . _inferred is None : self . _inferred = self . raw_inferred_graph () return self . _inferred @property def base_iri ( self ): \"\"\"Base iri of inferred ontology.\"\"\" if self . _base_iri is None : self . _base_iri = URIRef ( self . asserted_base_iri () + \"-inferred\" ) return self . _base_iri @base_iri . setter def base_iri ( self , value ): \"\"\"Assign inferred base iri.\"\"\" self . _base_iri = URIRef ( value ) @property def namespaces ( self ): \"\"\"Namespaces defined in the original graph.\"\"\" if self . _namespaces is None : self . _namespaces = dict ( self . graph . namespaces ()) . copy () self . _namespaces [ \"\" ] = self . base_iri return self . _namespaces def asserted_base_iri ( self ): \"\"\"Returns the base iri or the original graph.\"\"\" return URIRef ( dict ( self . graph . namespaces ()) . get ( \"\" , \"\" ) . rstrip ( \"#/\" )) def raw_inferred_graph ( self ): \"\"\"Returns the raw non-postprocessed inferred ontology as a rdflib graph.\"\"\" return OwlApiInterface () . reason ( self . graph ) def inferred_graph ( self ): \"\"\"Returns the postprocessed inferred graph.\"\"\" self . add_base_annotations () self . set_namespace () self . clean_base () self . remove_nothing_is_nothing () self . clean_ancestors () return self . inferred def add_base_annotations ( self ): \"\"\"Copy base annotations from original graph to the inferred graph.\"\"\" base = self . base_iri inferred = self . inferred for _ , predicate , obj in self . graph . triples ( ( self . asserted_base_iri (), None , None ) ): if predicate == OWL . versionIRI : version = obj . rsplit ( \"/\" , 1 )[ - 1 ] obj = URIRef ( f \" { base } / { version } \" ) inferred . add (( base , predicate , obj )) def set_namespace ( self ): \"\"\"Override namespace of inferred graph with the namespace of the original graph. \"\"\" inferred = self . inferred for key , value in self . namespaces . items (): inferred . namespace_manager . bind ( key , value , override = True , replace = True ) def clean_base ( self ): \"\"\"Remove all relations `s? a owl:Ontology` where `s?` is not `base_iri`. \"\"\" inferred = self . inferred for ( subject , predicate , obj , ) in inferred . triples ( # pylint: disable=not-an-iterable ( None , RDF . type , OWL . Ontology ) ): inferred . remove (( subject , predicate , obj )) inferred . add (( self . base_iri , RDF . type , OWL . Ontology )) def remove_nothing_is_nothing ( self ): \"\"\"Remove superfluid relation in inferred graph: owl:Nothing rdfs:subClassOf owl:Nothing \"\"\" triple = OWL . Nothing , RDFS . subClassOf , OWL . Nothing inferred = self . inferred if triple in inferred : inferred . remove ( triple ) def clean_ancestors ( self ): \"\"\"Remove redundant rdfs:subClassOf relations in inferred graph.\"\"\" inferred = self . inferred for ( # pylint: disable=too-many-nested-blocks subject ) in inferred . subjects ( RDF . type , OWL . Class ): if isinstance ( subject , URIRef ): parents = set ( parent for parent in inferred . objects ( subject , RDFS . subClassOf ) if isinstance ( parent , URIRef ) ) if len ( parents ) > 1 : for parent in parents : ancestors = set ( inferred . transitive_objects ( parent , RDFS . subClassOf ) ) for entity in parents : if entity != parent and entity in ancestors : triple = subject , RDFS . subClassOf , entity if triple in inferred : inferred . remove ( triple )","title":"Parameters"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#ontopy.factpluspluswrapper.factppgraph.FaCTPPGraph.base_iri","text":"Base iri of inferred ontology.","title":"base_iri"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#ontopy.factpluspluswrapper.factppgraph.FaCTPPGraph.inferred","text":"The current inferred graph.","title":"inferred"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#ontopy.factpluspluswrapper.factppgraph.FaCTPPGraph.namespaces","text":"Namespaces defined in the original graph.","title":"namespaces"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#ontopy.factpluspluswrapper.factppgraph.FaCTPPGraph.add_base_annotations","text":"Copy base annotations from original graph to the inferred graph. Source code in ontopy/factpluspluswrapper/factppgraph.py def add_base_annotations ( self ): \"\"\"Copy base annotations from original graph to the inferred graph.\"\"\" base = self . base_iri inferred = self . inferred for _ , predicate , obj in self . graph . triples ( ( self . asserted_base_iri (), None , None ) ): if predicate == OWL . versionIRI : version = obj . rsplit ( \"/\" , 1 )[ - 1 ] obj = URIRef ( f \" { base } / { version } \" ) inferred . add (( base , predicate , obj ))","title":"add_base_annotations()"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#ontopy.factpluspluswrapper.factppgraph.FaCTPPGraph.asserted_base_iri","text":"Returns the base iri or the original graph. Source code in ontopy/factpluspluswrapper/factppgraph.py def asserted_base_iri ( self ): \"\"\"Returns the base iri or the original graph.\"\"\" return URIRef ( dict ( self . graph . namespaces ()) . get ( \"\" , \"\" ) . rstrip ( \"#/\" ))","title":"asserted_base_iri()"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#ontopy.factpluspluswrapper.factppgraph.FaCTPPGraph.clean_ancestors","text":"Remove redundant rdfs:subClassOf relations in inferred graph. Source code in ontopy/factpluspluswrapper/factppgraph.py def clean_ancestors ( self ): \"\"\"Remove redundant rdfs:subClassOf relations in inferred graph.\"\"\" inferred = self . inferred for ( # pylint: disable=too-many-nested-blocks subject ) in inferred . subjects ( RDF . type , OWL . Class ): if isinstance ( subject , URIRef ): parents = set ( parent for parent in inferred . objects ( subject , RDFS . subClassOf ) if isinstance ( parent , URIRef ) ) if len ( parents ) > 1 : for parent in parents : ancestors = set ( inferred . transitive_objects ( parent , RDFS . subClassOf ) ) for entity in parents : if entity != parent and entity in ancestors : triple = subject , RDFS . subClassOf , entity if triple in inferred : inferred . remove ( triple )","title":"clean_ancestors()"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#ontopy.factpluspluswrapper.factppgraph.FaCTPPGraph.clean_base","text":"Remove all relations s? a owl:Ontology where s? is not base_iri . Source code in ontopy/factpluspluswrapper/factppgraph.py def clean_base ( self ): \"\"\"Remove all relations `s? a owl:Ontology` where `s?` is not `base_iri`. \"\"\" inferred = self . inferred for ( subject , predicate , obj , ) in inferred . triples ( # pylint: disable=not-an-iterable ( None , RDF . type , OWL . Ontology ) ): inferred . remove (( subject , predicate , obj )) inferred . add (( self . base_iri , RDF . type , OWL . Ontology ))","title":"clean_base()"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#ontopy.factpluspluswrapper.factppgraph.FaCTPPGraph.inferred_graph","text":"Returns the postprocessed inferred graph. Source code in ontopy/factpluspluswrapper/factppgraph.py def inferred_graph ( self ): \"\"\"Returns the postprocessed inferred graph.\"\"\" self . add_base_annotations () self . set_namespace () self . clean_base () self . remove_nothing_is_nothing () self . clean_ancestors () return self . inferred","title":"inferred_graph()"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#ontopy.factpluspluswrapper.factppgraph.FaCTPPGraph.raw_inferred_graph","text":"Returns the raw non-postprocessed inferred ontology as a rdflib graph. Source code in ontopy/factpluspluswrapper/factppgraph.py def raw_inferred_graph ( self ): \"\"\"Returns the raw non-postprocessed inferred ontology as a rdflib graph.\"\"\" return OwlApiInterface () . reason ( self . graph )","title":"raw_inferred_graph()"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#ontopy.factpluspluswrapper.factppgraph.FaCTPPGraph.remove_nothing_is_nothing","text":"Remove superfluid relation in inferred graph: owl:Nothing rdfs:subClassOf owl:Nothing Source code in ontopy/factpluspluswrapper/factppgraph.py def remove_nothing_is_nothing ( self ): \"\"\"Remove superfluid relation in inferred graph: owl:Nothing rdfs:subClassOf owl:Nothing \"\"\" triple = OWL . Nothing , RDFS . subClassOf , OWL . Nothing inferred = self . inferred if triple in inferred : inferred . remove ( triple )","title":"remove_nothing_is_nothing()"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#ontopy.factpluspluswrapper.factppgraph.FaCTPPGraph.set_namespace","text":"Override namespace of inferred graph with the namespace of the original graph. Source code in ontopy/factpluspluswrapper/factppgraph.py def set_namespace ( self ): \"\"\"Override namespace of inferred graph with the namespace of the original graph. \"\"\" inferred = self . inferred for key , value in self . namespaces . items (): inferred . namespace_manager . bind ( key , value , override = True , replace = True )","title":"set_namespace()"},{"location":"api_reference/ontopy/factpluspluswrapper/factppgraph/#ontopy.factpluspluswrapper.factppgraph.FactPPError","text":"Postprocessing error after reasoning with FaCT++. Source code in ontopy/factpluspluswrapper/factppgraph.py class FactPPError : \"\"\"Postprocessing error after reasoning with FaCT++.\"\"\"","title":"FactPPError"},{"location":"api_reference/ontopy/factpluspluswrapper/owlapi_interface/","text":"owlapi_interface \u00b6 Python interface to the FaCT++ Reasoner. This module is copied from the SimPhoNy project. Original author: Matthias Urban OwlApiInterface \u00b6 Interface to the FaCT++ reasoner via OWLAPI. Source code in ontopy/factpluspluswrapper/owlapi_interface.py class OwlApiInterface : \"\"\"Interface to the FaCT++ reasoner via OWLAPI.\"\"\" def __init__ ( self ): \"\"\"Initialize the interface.\"\"\" def reason ( self , graph ): \"\"\"Generate the inferred axioms for a given Graph. Args: graph (Graph): An rdflib graph to execute the reasoner on. \"\"\" with tempfile . NamedTemporaryFile ( \"wt\" ) as tmpdir : graph . serialize ( tmpdir . name , format = \"xml\" ) return self . _run ( tmpdir . name , command = \"--run-reasoner\" ) def reason_files ( self , * owl_files ): \"\"\"Merge the given owl and generate the inferred axioms. Args: *owl_files (os.path): The owl files two merge. \"\"\" return self . _run ( * owl_files , command = \"--run-reasoner\" ) def merge_files ( self , * owl_files ): \"\"\"Merge the given owl files and its import closure. Args: *owl_files (os.path): The owl files two merge. \"\"\" return self . _run ( * owl_files , command = \"--merge-only\" ) @staticmethod def _run ( * owl_files , command , output_file = None , return_graph = True ) -> rdflib . Graph : \"\"\"Run the FaCT++ reasoner using a java command. Args: *owl_files (str): Path to the owl files to load. command (str): Either --run-reasoner or --merge-only output_file (str, optional): Where the output should be stored. Defaults to None. return_graph (bool, optional): Whether the result should be parsed and returned. Defaults to True. Returns: The reasoned result. \"\"\" java_base = os . path . abspath ( os . path . join ( os . path . dirname ( __file__ ), \"java\" ) ) cmd = ( [ \"java\" , \"-cp\" , java_base + \"/lib/jars/*\" , \"-Djava.library.path=\" + java_base + \"/lib/so\" , \"org.simphony.OntologyLoader\" , ] + [ command ] + list ( owl_files ) ) logger . info ( \"Running Reasoner\" ) logger . debug ( \"Command %s \" , cmd ) subprocess . run ( cmd , check = True ) # nosec graph = None if return_graph : graph = rdflib . Graph () graph . parse ( RESULT_FILE ) if output_file : os . rename ( RESULT_FILE , output_file ) else : os . remove ( RESULT_FILE ) return graph __init__ ( self ) special \u00b6 Initialize the interface. Source code in ontopy/factpluspluswrapper/owlapi_interface.py def __init__ ( self ): \"\"\"Initialize the interface.\"\"\" merge_files ( self , * owl_files ) \u00b6 Merge the given owl files and its import closure. Parameters: Name Type Description Default *owl_files os.path The owl files two merge. () Source code in ontopy/factpluspluswrapper/owlapi_interface.py def merge_files ( self , * owl_files ): \"\"\"Merge the given owl files and its import closure. Args: *owl_files (os.path): The owl files two merge. \"\"\" return self . _run ( * owl_files , command = \"--merge-only\" ) reason ( self , graph ) \u00b6 Generate the inferred axioms for a given Graph. Parameters: Name Type Description Default graph Graph An rdflib graph to execute the reasoner on. required Source code in ontopy/factpluspluswrapper/owlapi_interface.py def reason ( self , graph ): \"\"\"Generate the inferred axioms for a given Graph. Args: graph (Graph): An rdflib graph to execute the reasoner on. \"\"\" with tempfile . NamedTemporaryFile ( \"wt\" ) as tmpdir : graph . serialize ( tmpdir . name , format = \"xml\" ) return self . _run ( tmpdir . name , command = \"--run-reasoner\" ) reason_files ( self , * owl_files ) \u00b6 Merge the given owl and generate the inferred axioms. Parameters: Name Type Description Default *owl_files os.path The owl files two merge. () Source code in ontopy/factpluspluswrapper/owlapi_interface.py def reason_files ( self , * owl_files ): \"\"\"Merge the given owl and generate the inferred axioms. Args: *owl_files (os.path): The owl files two merge. \"\"\" return self . _run ( * owl_files , command = \"--run-reasoner\" ) reason_from_terminal () \u00b6 Run the reasoner from terminal. Source code in ontopy/factpluspluswrapper/owlapi_interface.py def reason_from_terminal (): \"\"\"Run the reasoner from terminal.\"\"\" parser = argparse . ArgumentParser ( description = \"Run the FaCT++ reasoner on the given OWL file. \" \"Catalog files are used to load the import closure. \" \"Then the reasoner is executed and the inferred triples are merged \" \"with the asserted ones. If multiple OWL files are given, they are \" \"merged beforehand\" ) parser . add_argument ( \"owl_file\" , nargs = \"+\" , help = \"OWL file(s) to run the reasoner on.\" ) parser . add_argument ( \"output_file\" , help = \"Path to store inferred axioms to.\" ) args = parser . parse_args () OwlApiInterface () . _run ( # pylint: disable=protected-access * args . owl_file , command = \"--run-reasoner\" , return_graph = False , output_file = args . output_file , )","title":"owlapi_interface"},{"location":"api_reference/ontopy/factpluspluswrapper/owlapi_interface/#owlapi_interface","text":"Python interface to the FaCT++ Reasoner. This module is copied from the SimPhoNy project. Original author: Matthias Urban","title":"owlapi_interface"},{"location":"api_reference/ontopy/factpluspluswrapper/owlapi_interface/#ontopy.factpluspluswrapper.owlapi_interface.OwlApiInterface","text":"Interface to the FaCT++ reasoner via OWLAPI. Source code in ontopy/factpluspluswrapper/owlapi_interface.py class OwlApiInterface : \"\"\"Interface to the FaCT++ reasoner via OWLAPI.\"\"\" def __init__ ( self ): \"\"\"Initialize the interface.\"\"\" def reason ( self , graph ): \"\"\"Generate the inferred axioms for a given Graph. Args: graph (Graph): An rdflib graph to execute the reasoner on. \"\"\" with tempfile . NamedTemporaryFile ( \"wt\" ) as tmpdir : graph . serialize ( tmpdir . name , format = \"xml\" ) return self . _run ( tmpdir . name , command = \"--run-reasoner\" ) def reason_files ( self , * owl_files ): \"\"\"Merge the given owl and generate the inferred axioms. Args: *owl_files (os.path): The owl files two merge. \"\"\" return self . _run ( * owl_files , command = \"--run-reasoner\" ) def merge_files ( self , * owl_files ): \"\"\"Merge the given owl files and its import closure. Args: *owl_files (os.path): The owl files two merge. \"\"\" return self . _run ( * owl_files , command = \"--merge-only\" ) @staticmethod def _run ( * owl_files , command , output_file = None , return_graph = True ) -> rdflib . Graph : \"\"\"Run the FaCT++ reasoner using a java command. Args: *owl_files (str): Path to the owl files to load. command (str): Either --run-reasoner or --merge-only output_file (str, optional): Where the output should be stored. Defaults to None. return_graph (bool, optional): Whether the result should be parsed and returned. Defaults to True. Returns: The reasoned result. \"\"\" java_base = os . path . abspath ( os . path . join ( os . path . dirname ( __file__ ), \"java\" ) ) cmd = ( [ \"java\" , \"-cp\" , java_base + \"/lib/jars/*\" , \"-Djava.library.path=\" + java_base + \"/lib/so\" , \"org.simphony.OntologyLoader\" , ] + [ command ] + list ( owl_files ) ) logger . info ( \"Running Reasoner\" ) logger . debug ( \"Command %s \" , cmd ) subprocess . run ( cmd , check = True ) # nosec graph = None if return_graph : graph = rdflib . Graph () graph . parse ( RESULT_FILE ) if output_file : os . rename ( RESULT_FILE , output_file ) else : os . remove ( RESULT_FILE ) return graph","title":"OwlApiInterface"},{"location":"api_reference/ontopy/factpluspluswrapper/owlapi_interface/#ontopy.factpluspluswrapper.owlapi_interface.OwlApiInterface.__init__","text":"Initialize the interface. Source code in ontopy/factpluspluswrapper/owlapi_interface.py def __init__ ( self ): \"\"\"Initialize the interface.\"\"\"","title":"__init__()"},{"location":"api_reference/ontopy/factpluspluswrapper/owlapi_interface/#ontopy.factpluspluswrapper.owlapi_interface.OwlApiInterface.merge_files","text":"Merge the given owl files and its import closure. Parameters: Name Type Description Default *owl_files os.path The owl files two merge. () Source code in ontopy/factpluspluswrapper/owlapi_interface.py def merge_files ( self , * owl_files ): \"\"\"Merge the given owl files and its import closure. Args: *owl_files (os.path): The owl files two merge. \"\"\" return self . _run ( * owl_files , command = \"--merge-only\" )","title":"merge_files()"},{"location":"api_reference/ontopy/factpluspluswrapper/owlapi_interface/#ontopy.factpluspluswrapper.owlapi_interface.OwlApiInterface.reason","text":"Generate the inferred axioms for a given Graph. Parameters: Name Type Description Default graph Graph An rdflib graph to execute the reasoner on. required Source code in ontopy/factpluspluswrapper/owlapi_interface.py def reason ( self , graph ): \"\"\"Generate the inferred axioms for a given Graph. Args: graph (Graph): An rdflib graph to execute the reasoner on. \"\"\" with tempfile . NamedTemporaryFile ( \"wt\" ) as tmpdir : graph . serialize ( tmpdir . name , format = \"xml\" ) return self . _run ( tmpdir . name , command = \"--run-reasoner\" )","title":"reason()"},{"location":"api_reference/ontopy/factpluspluswrapper/owlapi_interface/#ontopy.factpluspluswrapper.owlapi_interface.OwlApiInterface.reason_files","text":"Merge the given owl and generate the inferred axioms. Parameters: Name Type Description Default *owl_files os.path The owl files two merge. () Source code in ontopy/factpluspluswrapper/owlapi_interface.py def reason_files ( self , * owl_files ): \"\"\"Merge the given owl and generate the inferred axioms. Args: *owl_files (os.path): The owl files two merge. \"\"\" return self . _run ( * owl_files , command = \"--run-reasoner\" )","title":"reason_files()"},{"location":"api_reference/ontopy/factpluspluswrapper/owlapi_interface/#ontopy.factpluspluswrapper.owlapi_interface.reason_from_terminal","text":"Run the reasoner from terminal. Source code in ontopy/factpluspluswrapper/owlapi_interface.py def reason_from_terminal (): \"\"\"Run the reasoner from terminal.\"\"\" parser = argparse . ArgumentParser ( description = \"Run the FaCT++ reasoner on the given OWL file. \" \"Catalog files are used to load the import closure. \" \"Then the reasoner is executed and the inferred triples are merged \" \"with the asserted ones. If multiple OWL files are given, they are \" \"merged beforehand\" ) parser . add_argument ( \"owl_file\" , nargs = \"+\" , help = \"OWL file(s) to run the reasoner on.\" ) parser . add_argument ( \"output_file\" , help = \"Path to store inferred axioms to.\" ) args = parser . parse_args () OwlApiInterface () . _run ( # pylint: disable=protected-access * args . owl_file , command = \"--run-reasoner\" , return_graph = False , output_file = args . output_file , )","title":"reason_from_terminal()"},{"location":"api_reference/ontopy/factpluspluswrapper/sync_factpp/","text":"sync_factpp \u00b6 ontopy.factpluspluswrapper.syncfatpp \u00b6 sync_reasoner_factpp ( ontology_or_world = None , infer_property_values = False , debug = 1 ) \u00b6 Run FaCT++ reasoner and load the inferred relations back into the owlready2 triplestore. Parameters \u00b6 ontology_or_world : None | Ontology instance | World instance | list Identifies the world to run the reasoner over. infer_property_values : bool Whether to also infer property values. debug : bool Whether to print debug info to standard output. Source code in ontopy/factpluspluswrapper/sync_factpp.py def sync_reasoner_factpp ( ontology_or_world = None , infer_property_values = False , debug = 1 ): \"\"\"Run FaCT++ reasoner and load the inferred relations back into the owlready2 triplestore. Parameters ---------- ontology_or_world : None | Ontology instance | World instance | list Identifies the world to run the reasoner over. infer_property_values : bool Whether to also infer property values. debug : bool Whether to print debug info to standard output. \"\"\" # pylint: disable=too-many-locals,too-many-branches,too-many-statements if isinstance ( ontology_or_world , World ): world = ontology_or_world elif isinstance ( ontology_or_world , Ontology ): world = ontology_or_world . world elif isinstance ( ontology_or_world , Sequence ): world = ontology_or_world [ 0 ] . world else : world = owlready2 . default_world if isinstance ( ontology_or_world , Ontology ): ontology = ontology_or_world elif CURRENT_NAMESPACES . get (): ontology = CURRENT_NAMESPACES . get ()[ - 1 ] . ontology else : ontology = world . get_ontology ( _INFERRENCES_ONTOLOGY ) locked = world . graph . has_write_lock () if locked : world . graph . release_write_lock () # Not needed during reasoning try : if debug : print ( \"*** Prepare graph\" ) # Exclude owl:imports because they are not needed and can # cause trouble when loading the inferred ontology graph1 = rdflib . Graph () for subject , predicate , obj in world . as_rdflib_graph () . triples ( ( None , None , None ) ): if predicate != OWL . imports : graph1 . add (( subject , predicate , obj )) if debug : print ( \"*** Run FaCT++ reasoner (and postprocess)\" ) graph2 = FaCTPPGraph ( graph1 ) . inferred_graph () if debug : print ( \"*** Load inferred ontology\" ) # Check all rdfs:subClassOf relations in the inferred graph and add # them to the world if they are missing new_parents = defaultdict ( list ) new_equivs = defaultdict ( list ) entity_2_type = {} for ( subject , predicate , obj , ) in graph2 . triples ( # pylint: disable=not-an-iterable ( None , None , None ) ): if ( isinstance ( subject , URIRef ) and predicate in OWL_2_TYPE and isinstance ( obj , URIRef ) ): s_storid = ontology . _abbreviate ( str ( subject ), False ) p_storid = ontology . _abbreviate ( str ( predicate ), False ) o_storid = ontology . _abbreviate ( str ( obj ), False ) if ( s_storid is not None and p_storid is not None and o_storid is not None ): if predicate in ( RDFS . subClassOf , RDFS . subPropertyOf , RDF . type , ): new_parents [ s_storid ] . append ( o_storid ) entity_2_type [ s_storid ] = OWL_2_TYPE [ predicate ] else : new_equivs [ s_storid ] . append ( o_storid ) entity_2_type [ s_storid ] = OWL_2_TYPE [ predicate ] if infer_property_values : inferred_obj_relations = [] # Hmm, does FaCT++ infer any property values? # If not, remove the `infer_property_values` keyword argument. raise NotImplementedError finally : if locked : world . graph . acquire_write_lock () # re-lock when applying results if debug : print ( \"*** Applying reasoning results\" ) _apply_reasoning_results ( world , ontology , debug , new_parents , new_equivs , entity_2_type ) if infer_property_values : _apply_inferred_obj_relations ( world , ontology , debug , inferred_obj_relations )","title":"sync_factpp"},{"location":"api_reference/ontopy/factpluspluswrapper/sync_factpp/#sync_factpp","text":"","title":"sync_factpp"},{"location":"api_reference/ontopy/factpluspluswrapper/sync_factpp/#ontopy.factpluspluswrapper.sync_factpp--ontopyfactpluspluswrappersyncfatpp","text":"","title":"\n\n  \n\n\n    \n\n      ontopy.factpluspluswrapper.syncfatpp&para;\n\n\n\n  \n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nsync_reasoner_factpp(ontology_or_world=None, infer_property_values=False, debug=1)\n\n\n\u0002amp\u0003para;\n\n    \n\n      Run FaCT++ reasoner and load the inferred relations back into\nthe owlready2 triplestore.\nParameters&para;\nontology_or_world : None | Ontology instance | World instance | list\n    Identifies the world to run the reasoner over.\ninfer_property_values : bool\n    Whether to also infer property values.\ndebug : bool\n    Whether to print debug info to standard output.\n\n        \n          Source code in ontopy/factpluspluswrapper/sync_factpp.py\n          def sync_reasoner_factpp(\n    ontology_or_world=None, infer_property_values=False, debug=1\n):\n    &quot;&quot;&quot;Run FaCT++ reasoner and load the inferred relations back into\n    the owlready2 triplestore.\n\n    Parameters\n    ----------\n    ontology_or_world : None | Ontology instance | World instance | list\n        Identifies the world to run the reasoner over.\n    infer_property_values : bool\n        Whether to also infer property values.\n    debug : bool\n        Whether to print debug info to standard output.\n    &quot;&quot;&quot;\n    # pylint: disable=too-many-locals,too-many-branches,too-many-statements\n    if isinstance(ontology_or_world, World):\n        world = ontology_or_world\n    elif isinstance(ontology_or_world, Ontology):\n        world = ontology_or_world.world\n    elif isinstance(ontology_or_world, Sequence):\n        world = ontology_or_world[0].world\n    else:\n        world = owlready2.default_world\n\n    if isinstance(ontology_or_world, Ontology):\n        ontology = ontology_or_world\n    elif CURRENT_NAMESPACES.get():\n        ontology = CURRENT_NAMESPACES.get()[-1].ontology\n    else:\n        ontology = world.get_ontology(_INFERRENCES_ONTOLOGY)\n\n    locked = world.graph.has_write_lock()\n    if locked:\n        world.graph.release_write_lock()  # Not needed during reasoning\n\n    try:\n        if debug:\n            print(&quot;*** Prepare graph&quot;)\n        # Exclude owl:imports because they are not needed and can\n        # cause trouble when loading the inferred ontology\n        graph1 = rdflib.Graph()\n        for subject, predicate, obj in world.as_rdflib_graph().triples(\n            (None, None, None)\n        ):\n            if predicate != OWL.imports:\n                graph1.add((subject, predicate, obj))\n\n        if debug:\n            print(&quot;*** Run FaCT++ reasoner (and postprocess)&quot;)\n        graph2 = FaCTPPGraph(graph1).inferred_graph()\n\n        if debug:\n            print(&quot;*** Load inferred ontology&quot;)\n        # Check all rdfs:subClassOf relations in the inferred graph and add\n        # them to the world if they are missing\n        new_parents = defaultdict(list)\n        new_equivs = defaultdict(list)\n        entity_2_type = {}\n\n        for (\n            subject,\n            predicate,\n            obj,\n        ) in graph2.triples(  # pylint: disable=not-an-iterable\n            (None, None, None)\n        ):\n            if (\n                isinstance(subject, URIRef)\n                and predicate in OWL_2_TYPE\n                and isinstance(obj, URIRef)\n            ):\n                s_storid = ontology._abbreviate(str(subject), False)\n                p_storid = ontology._abbreviate(str(predicate), False)\n                o_storid = ontology._abbreviate(str(obj), False)\n                if (\n                    s_storid is not None\n                    and p_storid is not None\n                    and o_storid is not None\n                ):\n                    if predicate in (\n                        RDFS.subClassOf,\n                        RDFS.subPropertyOf,\n                        RDF.type,\n                    ):\n                        new_parents[s_storid].append(o_storid)\n                        entity_2_type[s_storid] = OWL_2_TYPE[predicate]\n                    else:\n                        new_equivs[s_storid].append(o_storid)\n                        entity_2_type[s_storid] = OWL_2_TYPE[predicate]\n\n        if infer_property_values:\n            inferred_obj_relations = []\n            # Hmm, does FaCT++ infer any property values?\n            # If not, remove the `infer_property_values` keyword argument.\n            raise NotImplementedError\n\n    finally:\n        if locked:\n            world.graph.acquire_write_lock()  # re-lock when applying results\n\n    if debug:\n        print(&quot;*** Applying reasoning results&quot;)\n\n    _apply_reasoning_results(\n        world, ontology, debug, new_parents, new_equivs, entity_2_type\n    )\n    if infer_property_values:\n        _apply_inferred_obj_relations(\n            world, ontology, debug, inferred_obj_relations\n        )\n\n        \n    \n\n  \n\n\n\n\n\n\n  \n\n    \n\n  \n\n"},{"location":"api_reference/ontopy/factpluspluswrapper/sync_factpp/#ontopy.factpluspluswrapper.sync_factpp.sync_reasoner_factpp","text":"Run FaCT++ reasoner and load the inferred relations back into the owlready2 triplestore.","title":"sync_reasoner_factpp()"},{"location":"api_reference/ontopy/factpluspluswrapper/sync_factpp/#ontopy.factpluspluswrapper.sync_factpp.sync_reasoner_factpp--parameters","text":"ontology_or_world : None | Ontology instance | World instance | list Identifies the world to run the reasoner over. infer_property_values : bool Whether to also infer property values. debug : bool Whether to print debug info to standard output. Source code in ontopy/factpluspluswrapper/sync_factpp.py def sync_reasoner_factpp ( ontology_or_world = None , infer_property_values = False , debug = 1 ): \"\"\"Run FaCT++ reasoner and load the inferred relations back into the owlready2 triplestore. Parameters ---------- ontology_or_world : None | Ontology instance | World instance | list Identifies the world to run the reasoner over. infer_property_values : bool Whether to also infer property values. debug : bool Whether to print debug info to standard output. \"\"\" # pylint: disable=too-many-locals,too-many-branches,too-many-statements if isinstance ( ontology_or_world , World ): world = ontology_or_world elif isinstance ( ontology_or_world , Ontology ): world = ontology_or_world . world elif isinstance ( ontology_or_world , Sequence ): world = ontology_or_world [ 0 ] . world else : world = owlready2 . default_world if isinstance ( ontology_or_world , Ontology ): ontology = ontology_or_world elif CURRENT_NAMESPACES . get (): ontology = CURRENT_NAMESPACES . get ()[ - 1 ] . ontology else : ontology = world . get_ontology ( _INFERRENCES_ONTOLOGY ) locked = world . graph . has_write_lock () if locked : world . graph . release_write_lock () # Not needed during reasoning try : if debug : print ( \"*** Prepare graph\" ) # Exclude owl:imports because they are not needed and can # cause trouble when loading the inferred ontology graph1 = rdflib . Graph () for subject , predicate , obj in world . as_rdflib_graph () . triples ( ( None , None , None ) ): if predicate != OWL . imports : graph1 . add (( subject , predicate , obj )) if debug : print ( \"*** Run FaCT++ reasoner (and postprocess)\" ) graph2 = FaCTPPGraph ( graph1 ) . inferred_graph () if debug : print ( \"*** Load inferred ontology\" ) # Check all rdfs:subClassOf relations in the inferred graph and add # them to the world if they are missing new_parents = defaultdict ( list ) new_equivs = defaultdict ( list ) entity_2_type = {} for ( subject , predicate , obj , ) in graph2 . triples ( # pylint: disable=not-an-iterable ( None , None , None ) ): if ( isinstance ( subject , URIRef ) and predicate in OWL_2_TYPE and isinstance ( obj , URIRef ) ): s_storid = ontology . _abbreviate ( str ( subject ), False ) p_storid = ontology . _abbreviate ( str ( predicate ), False ) o_storid = ontology . _abbreviate ( str ( obj ), False ) if ( s_storid is not None and p_storid is not None and o_storid is not None ): if predicate in ( RDFS . subClassOf , RDFS . subPropertyOf , RDF . type , ): new_parents [ s_storid ] . append ( o_storid ) entity_2_type [ s_storid ] = OWL_2_TYPE [ predicate ] else : new_equivs [ s_storid ] . append ( o_storid ) entity_2_type [ s_storid ] = OWL_2_TYPE [ predicate ] if infer_property_values : inferred_obj_relations = [] # Hmm, does FaCT++ infer any property values? # If not, remove the `infer_property_values` keyword argument. raise NotImplementedError finally : if locked : world . graph . acquire_write_lock () # re-lock when applying results if debug : print ( \"*** Applying reasoning results\" ) _apply_reasoning_results ( world , ontology , debug , new_parents , new_equivs , entity_2_type ) if infer_property_values : _apply_inferred_obj_relations ( world , ontology , debug , inferred_obj_relations )","title":"Parameters"},{"location":"demo/","text":"EMMO use cases \u00b6 This demo contains two use cases on how EMMO can be used to achieve vertical and horizontal interpoerability, respectivily. Warning This demonstration is still work in progress. Especially documentation is lacking. Content \u00b6 Vertical interoperability . Horizontal interoperability . The user case - welding an aluminium plate to steel \u00b6","title":"EMMO use cases"},{"location":"demo/#emmo-use-cases","text":"This demo contains two use cases on how EMMO can be used to achieve vertical and horizontal interpoerability, respectivily. Warning This demonstration is still work in progress. Especially documentation is lacking.","title":"EMMO use cases"},{"location":"demo/#content","text":"Vertical interoperability . Horizontal interoperability .","title":"Content"},{"location":"demo/#the-user-case-welding-an-aluminium-plate-to-steel","text":"","title":"The user case - welding an aluminium plate to steel"},{"location":"demo/horizontal/","text":"EMMO use case for horizontal interoperability \u00b6 Horizontal interoperability is about interoperability between different types of models and codes for a single material (i.e., one use case, multiple models). The key here is to show how to map between EMMO (or an EMMO-based ontology) and another ontology (possible EMMO-based). In this example we use a data-driven approach based on a C-implementation of SOFT 1 , 2 . This is done in four steps: Generate metadata from the EMMO-based user case ontology. Implemented in the script step1_generate_metadata.py . Define metadata for an application developed independently of EMMO. In this case a metadata description of the ASE Atoms class 3 is created in atoms.json . Implemented in the script step2_define_metadata.py . Instantiate the metadata defined defined in step 2 with an atomistic structure interface structure. Implemented in the script step3_instantiate.py . Map the atomistic interface structure from the application representation to the common EMMO-based representation. Implemented in the script step4_map_instance.py . Essentially, this demonstration shows how EMMO can be extended and how external data can be mapped into our extended ontology (serving as a common representational system). Requirements for running the user case \u00b6 In addition to emmo, this demo also requires: DLite , a C-implementation of SOFT used for handling metadata ASE , for reading atom structure from cif and visualisation","title":"EMMO use case for horizontal interoperability"},{"location":"demo/horizontal/#emmo-use-case-for-horizontal-interoperability","text":"Horizontal interoperability is about interoperability between different types of models and codes for a single material (i.e., one use case, multiple models). The key here is to show how to map between EMMO (or an EMMO-based ontology) and another ontology (possible EMMO-based). In this example we use a data-driven approach based on a C-implementation of SOFT 1 , 2 . This is done in four steps: Generate metadata from the EMMO-based user case ontology. Implemented in the script step1_generate_metadata.py . Define metadata for an application developed independently of EMMO. In this case a metadata description of the ASE Atoms class 3 is created in atoms.json . Implemented in the script step2_define_metadata.py . Instantiate the metadata defined defined in step 2 with an atomistic structure interface structure. Implemented in the script step3_instantiate.py . Map the atomistic interface structure from the application representation to the common EMMO-based representation. Implemented in the script step4_map_instance.py . Essentially, this demonstration shows how EMMO can be extended and how external data can be mapped into our extended ontology (serving as a common representational system).","title":"EMMO use case for horizontal interoperability"},{"location":"demo/horizontal/#requirements-for-running-the-user-case","text":"In addition to emmo, this demo also requires: DLite , a C-implementation of SOFT used for handling metadata ASE , for reading atom structure from cif and visualisation","title":"Requirements for running the user case"},{"location":"demo/vertical/","text":"EMMO use case for vertical interoperability \u00b6 Vertical interoperability is about interoperability across two or more granulaty levels. In this use case we study the welded interface between an aluminium and a steel plate at three granularity levels. In this case, the granularity levels corresponds to three different length scales, that we here denote component , microstructure and atomistic scale. Creating an EMMO-based user case ontology \u00b6 The script define_ontology.py uses the Python API for EMMO to generate an application ontology extending EMMO with additional concepts needed to describe the data that is exchanged between scales. The user case ontology can then be visualised with the script plot_ontology.py . Defining the needed material entities \u00b6 Assigning properties to material entities \u00b6 Note that we here also assign properties to e-bonded_atom , even though e-bonded_atom is defined in EMMO. Assigning units to properties \u00b6 We choose here to consistently use SI units for all scales (even though at the atomistic scale units like \u00c5ngstr\u00f6m and electron volt are more commonly used). Assigning types to properties \u00b6 In order to be able to generate metadata and to describe the actual data transferred between scales, we also need to define types. The new application-ontology \u00b6 The final plot shows the user case ontology in context of EMMO.","title":"EMMO use case for vertical interoperability"},{"location":"demo/vertical/#emmo-use-case-for-vertical-interoperability","text":"Vertical interoperability is about interoperability across two or more granulaty levels. In this use case we study the welded interface between an aluminium and a steel plate at three granularity levels. In this case, the granularity levels corresponds to three different length scales, that we here denote component , microstructure and atomistic scale.","title":"EMMO use case for vertical interoperability"},{"location":"demo/vertical/#creating-an-emmo-based-user-case-ontology","text":"The script define_ontology.py uses the Python API for EMMO to generate an application ontology extending EMMO with additional concepts needed to describe the data that is exchanged between scales. The user case ontology can then be visualised with the script plot_ontology.py .","title":"Creating an EMMO-based user case ontology"},{"location":"demo/vertical/#defining-the-needed-material-entities","text":"","title":"Defining the needed material entities"},{"location":"demo/vertical/#assigning-properties-to-material-entities","text":"Note that we here also assign properties to e-bonded_atom , even though e-bonded_atom is defined in EMMO.","title":"Assigning properties to material entities"},{"location":"demo/vertical/#assigning-units-to-properties","text":"We choose here to consistently use SI units for all scales (even though at the atomistic scale units like \u00c5ngstr\u00f6m and electron volt are more commonly used).","title":"Assigning units to properties"},{"location":"demo/vertical/#assigning-types-to-properties","text":"In order to be able to generate metadata and to describe the actual data transferred between scales, we also need to define types.","title":"Assigning types to properties"},{"location":"demo/vertical/#the-new-application-ontology","text":"The final plot shows the user case ontology in context of EMMO.","title":"The new application-ontology"},{"location":"developers/release-instructions/","text":"Steps for creating a new release \u00b6 Create a release on GitHub with a short release description. Ensure you add a # <version number> title to the description. Set the tag to the version number prefixed with \"v\" and title to the version number as explained above. Ensure the GitHub Action CD workflows run as expected. The workflow failed If something is wrong and the workflow fails before publishing the package to PyPI, make sure to remove all traces of the release and tag, fix the bug, and try again. If something is wrong and the workflow fails after publishing the package to PyPI: DO NOT REMOVE THE RELEASE OR TAG ! Deployment of the documentation should (in theory) be the only thing that has failed. This can be deployed manually using similar steps as in the workflow.","title":"Steps for creating a new release"},{"location":"developers/release-instructions/#steps-for-creating-a-new-release","text":"Create a release on GitHub with a short release description. Ensure you add a # <version number> title to the description. Set the tag to the version number prefixed with \"v\" and title to the version number as explained above. Ensure the GitHub Action CD workflows run as expected. The workflow failed If something is wrong and the workflow fails before publishing the package to PyPI, make sure to remove all traces of the release and tag, fix the bug, and try again. If something is wrong and the workflow fails after publishing the package to PyPI: DO NOT REMOVE THE RELEASE OR TAG ! Deployment of the documentation should (in theory) be the only thing that has failed. This can be deployed manually using similar steps as in the workflow.","title":"Steps for creating a new release"},{"location":"developers/setup/","text":"Development environment \u00b6 This section outlines some suggestions as well as conventions used by the EMMOntoPy developers, which should be considered or followed if one wants to contribute to the package. Setup \u00b6 Requirements This section expects you to be running on a Unix-like system (e.g., Linux) with minimum Python 3.7. Virtual environment \u00b6 Since development can be messy, it is good to separate the development environment from the rest of your system's environment. To do this, you can use a virtual environment. There are a several different ways to create a virtual environment, but we recommend using either virtualenv or venv . Virtual environment considerations There are several different virtual environment setups, here we only address a very few. A great resource for an overview can be found in this StackOverflow answer . However, note that in the end, it is very subjective on the solution one uses and one is not necessarily \"better\" than another. virtualenv (recommended) venv To install virtualenv + virtualenvwrapper run: $ pip install virtualenvwrapper There is other setup, most of which only needs to be run once. For more information about this, see the virtualenvwrapper documentation . After successfully setting up virtualenv through virtualenvwrapper , you can create a new virtual environment: $ mkproject -p python3.7 emmo-python Note If you do not have Python 3.7 installed (or instead want to use your system's default Python version), you can leave out the extra -p python3.7 argument. Or you can choose to use another version of Python by changing this argument to another (valid) python interpreter. Then, if the virtual environment has not been activated automatically (you should see the name emmo-python in a parenthesis in your console), you can run: $ workon emmo-python Tip You can quickly see a list of all your virtual environments by writing workon and pressing Tab twice. To deactivate the virtual environment, returning to the system/global environment again, run: (emmo-python) $ deactivate venv is a built-in package in Python, which works similar to virtualenv , but with fewer capabilities. To create a new virtual environment with venv , first go to the directory, where you desire to keep your virtual environment. Then run the venv module using the Python interpreter you wish to use in the virtual environment. For Python 3.7 this would look like the following: $ python3.7 -m venv emmo-python A folder with the name emmo-python containing the environment is created. To activate the environment run: $ ./emmo-python/activate or $ /path/to/emmo-python/activate You should now see the name emmo-python in a parenthesis in your console, letting you know you have activated and are currently using the emmo-python virtual environment. To deactivate the virtual environment, returning to the system/global environment again, run: (emmo-python) $ deactivate Expectation From here on, all commands expect you to have activated your virtual environment, if you are using one, unless stated otherwise. Installation \u00b6 To install the package, please do not install from PyPI. Instead you should clone the repository from GitHub: $ git clone https://github.com/emmo-repo/EMMOntoPy.git or, if you are using an SSH connection to GitHub, you can instead clone via: $ git clone git@github.com:emmo-repo/EMMOntoPy.git Then enter into the newly cloned EMMOntoPy directory ( cd EMMOntoPy ) and run: $ pip install -U -e . [ dev ] $ pre-commit install This will install the EMMOntoPy Python package, including all dependencies and requirements for building and serving (locally) the documentation and running unit tests. The second line installs the pre-commit hooks defined in the .pre-commit-config.yaml file. pre-commit is a tool that runs immediately prior to you creating new commits ( git commit ), and checks all the changes, automatically updates the API reference in the documentation and much more. Mainly, it helps to ensure that the package stays nicely formattet, safe, and user-friendly for developers. Non-Python dependencies \u00b6 There are a few non-Python dependencies that EMMOntoPy relies on as well. These can be installed by running (on a Debian system): $ sudo apt-get update && sudo apt-get install -y graphviz openjdk-11-jre-headless If you are on a non-Debian system (Debian, Ubuntu, ...), please check which package manager you are using and find packages for graphviz and openjdk minimum version 11. Test the installation \u00b6 It is good practice to test the integrity of the installation and that all necessary dependencies are correctly installed. You can run unit tests, to check the integrity of the Python functionality, by running: $ pytest If all has installed and is running correctly, you should not have any failures, but perhaps some warnings (deprecation warnings) in the test summary.","title":"Development environment"},{"location":"developers/setup/#development-environment","text":"This section outlines some suggestions as well as conventions used by the EMMOntoPy developers, which should be considered or followed if one wants to contribute to the package.","title":"Development environment"},{"location":"developers/setup/#setup","text":"Requirements This section expects you to be running on a Unix-like system (e.g., Linux) with minimum Python 3.7.","title":"Setup"},{"location":"developers/setup/#virtual-environment","text":"Since development can be messy, it is good to separate the development environment from the rest of your system's environment. To do this, you can use a virtual environment. There are a several different ways to create a virtual environment, but we recommend using either virtualenv or venv . Virtual environment considerations There are several different virtual environment setups, here we only address a very few. A great resource for an overview can be found in this StackOverflow answer . However, note that in the end, it is very subjective on the solution one uses and one is not necessarily \"better\" than another. virtualenv (recommended) venv To install virtualenv + virtualenvwrapper run: $ pip install virtualenvwrapper There is other setup, most of which only needs to be run once. For more information about this, see the virtualenvwrapper documentation . After successfully setting up virtualenv through virtualenvwrapper , you can create a new virtual environment: $ mkproject -p python3.7 emmo-python Note If you do not have Python 3.7 installed (or instead want to use your system's default Python version), you can leave out the extra -p python3.7 argument. Or you can choose to use another version of Python by changing this argument to another (valid) python interpreter. Then, if the virtual environment has not been activated automatically (you should see the name emmo-python in a parenthesis in your console), you can run: $ workon emmo-python Tip You can quickly see a list of all your virtual environments by writing workon and pressing Tab twice. To deactivate the virtual environment, returning to the system/global environment again, run: (emmo-python) $ deactivate venv is a built-in package in Python, which works similar to virtualenv , but with fewer capabilities. To create a new virtual environment with venv , first go to the directory, where you desire to keep your virtual environment. Then run the venv module using the Python interpreter you wish to use in the virtual environment. For Python 3.7 this would look like the following: $ python3.7 -m venv emmo-python A folder with the name emmo-python containing the environment is created. To activate the environment run: $ ./emmo-python/activate or $ /path/to/emmo-python/activate You should now see the name emmo-python in a parenthesis in your console, letting you know you have activated and are currently using the emmo-python virtual environment. To deactivate the virtual environment, returning to the system/global environment again, run: (emmo-python) $ deactivate Expectation From here on, all commands expect you to have activated your virtual environment, if you are using one, unless stated otherwise.","title":"Virtual environment"},{"location":"developers/setup/#installation","text":"To install the package, please do not install from PyPI. Instead you should clone the repository from GitHub: $ git clone https://github.com/emmo-repo/EMMOntoPy.git or, if you are using an SSH connection to GitHub, you can instead clone via: $ git clone git@github.com:emmo-repo/EMMOntoPy.git Then enter into the newly cloned EMMOntoPy directory ( cd EMMOntoPy ) and run: $ pip install -U -e . [ dev ] $ pre-commit install This will install the EMMOntoPy Python package, including all dependencies and requirements for building and serving (locally) the documentation and running unit tests. The second line installs the pre-commit hooks defined in the .pre-commit-config.yaml file. pre-commit is a tool that runs immediately prior to you creating new commits ( git commit ), and checks all the changes, automatically updates the API reference in the documentation and much more. Mainly, it helps to ensure that the package stays nicely formattet, safe, and user-friendly for developers.","title":"Installation"},{"location":"developers/setup/#non-python-dependencies","text":"There are a few non-Python dependencies that EMMOntoPy relies on as well. These can be installed by running (on a Debian system): $ sudo apt-get update && sudo apt-get install -y graphviz openjdk-11-jre-headless If you are on a non-Debian system (Debian, Ubuntu, ...), please check which package manager you are using and find packages for graphviz and openjdk minimum version 11.","title":"Non-Python dependencies"},{"location":"developers/setup/#test-the-installation","text":"It is good practice to test the integrity of the installation and that all necessary dependencies are correctly installed. You can run unit tests, to check the integrity of the Python functionality, by running: $ pytest If all has installed and is running correctly, you should not have any failures, but perhaps some warnings (deprecation warnings) in the test summary.","title":"Test the installation"},{"location":"developers/testing/","text":"Testing and tooling \u00b6 Unit testing \u00b6 The PyTest framework is used for testing the EMMOntoPy package. It is a unit testing framework with a plugin system, sporting an extensive plugin library as well as a sound fixture injection system. To run the tests locally install the package with the dev extra (see the developer's setup guide ) and run: $ pytest === test session starts === ... To understand what options you have, run pytest --help . Tools \u00b6 Several tools are used to maintain the package, keeping it secure, readable, and easing maintenance. Mypy \u00b6 Mypy is a static type checker for Python. Documentation : mypy.readthedocs.io The signs of this tool will be found in the code especially through the typing.TYPE_CHECKING boolean variable, which will be used in the current way: from typing import TYPE_CHECKING if TYPE_CHECKING : from typing import List Since TYPE_CHECKING is False at runtime, the if -block will not be run as part of running the script or module or if importing the module. However, when Mypy runs to check the static typing, it forcefully runs these blocks, considering TYPE_CHECKING to be True (see the typing.TYPE_CHECKING section in the Mypy documentation). This means the imports in the if -block are meant to only be used for static typing, helping developers to understand the intention of the code as well as to check the invoked methods make sense (through Mypy).","title":"Testing and tooling"},{"location":"developers/testing/#testing-and-tooling","text":"","title":"Testing and tooling"},{"location":"developers/testing/#unit-testing","text":"The PyTest framework is used for testing the EMMOntoPy package. It is a unit testing framework with a plugin system, sporting an extensive plugin library as well as a sound fixture injection system. To run the tests locally install the package with the dev extra (see the developer's setup guide ) and run: $ pytest === test session starts === ... To understand what options you have, run pytest --help .","title":"Unit testing"},{"location":"developers/testing/#tools","text":"Several tools are used to maintain the package, keeping it secure, readable, and easing maintenance.","title":"Tools"},{"location":"developers/testing/#mypy","text":"Mypy is a static type checker for Python. Documentation : mypy.readthedocs.io The signs of this tool will be found in the code especially through the typing.TYPE_CHECKING boolean variable, which will be used in the current way: from typing import TYPE_CHECKING if TYPE_CHECKING : from typing import List Since TYPE_CHECKING is False at runtime, the if -block will not be run as part of running the script or module or if importing the module. However, when Mypy runs to check the static typing, it forcefully runs these blocks, considering TYPE_CHECKING to be True (see the typing.TYPE_CHECKING section in the Mypy documentation). This means the imports in the if -block are meant to only be used for static typing, helping developers to understand the intention of the code as well as to check the invoked methods make sense (through Mypy).","title":"Mypy"},{"location":"examples/emmodoc/","text":"Generate documentation for EMMO \u00b6 This directory contains the needed templates, introductory text and figures for generating the full EMMO documentation using ontodoc . Since the introduction is written in markdown, pandoc is required for both pdf and html generation. For a standalone html documentation including all inferred relations, enter this directory and run: ontodoc --template=emmo.md --format=html emmo-inferred emmo.html Pandoc options may be adjusted with the files pandoc-options.yaml and pandoc-html-options.yaml . Similarly, for generating pdf documentation, enter this directory and run: ontodoc --template=emmo.md emmo-inferred emmo.pdf By default, we have configured pandoc to use xelatex for better unicode support. It is possible to change these settings in pandoc-options.yaml and pandoc-pdf-options.yaml . Content of this directory \u00b6 ontodoc templates with introductory text and document layout \u00b6 emmo.md : Main template for EMMO. It includes the other templates. introduction.md : Introductory text. relations.md : Introduction and sections for Relations chapter. classes.md : Introduction and sections for Classes. figs : Figures used in the introduction. pandoc configuration files \u00b6 emmodoc-meta.yaml : Metadata for EMMO, like title, authers, abstract, etc. pandoc-options.yaml : General pandoc options. pandoc-html-options.yaml : Additional pandoc options for html generation. pandoc-pdf-options.yaml : Additional pandoc options for pdf generation. pandoc-html.css : css file used for html generation. pandoc-template.html : Modified copy of the standard pandoc html template with a small adjustment for the author list. pandoc-template.tex : Modified copy of the standard pandoc latex template with a small adjustment for the author list. Using this example as a starting point for documenting your own ontology \u00b6 For simple html documentation, you can skip all input files and simply run ontodoc as ontodoc --format=simple-html YOUR_ONTO.owl YOUR_ONTO.html It is also possible to include ontodoc templates using the --template option for adding additional information and structure the document. In this case the template may only contain ontodoc pre-processer directives and inline html, but not markdown. In order to produce output in pdf (or any other output format supported by pandoc), you can write your ontodoc template in markdown (with ontodoc pre-processer directives) and follow these steps to get started: Copy all the files starting with pandoc- to a new directory. Create a metadata YAML file for your ontology. You can use emmodoc-meta.yaml as a template. Update pandoc-options.yaml . Especially change: input-files to the name of your new yaml metadata file. logo to the path of your logo (or remove it). titlegraphic to the path of your title figure (or remove it). Optionally add ontodoc template files with additional information about your ontology and document layout. That should be it. Good luck!","title":"EMMOdoc"},{"location":"examples/emmodoc/#generate-documentation-for-emmo","text":"This directory contains the needed templates, introductory text and figures for generating the full EMMO documentation using ontodoc . Since the introduction is written in markdown, pandoc is required for both pdf and html generation. For a standalone html documentation including all inferred relations, enter this directory and run: ontodoc --template=emmo.md --format=html emmo-inferred emmo.html Pandoc options may be adjusted with the files pandoc-options.yaml and pandoc-html-options.yaml . Similarly, for generating pdf documentation, enter this directory and run: ontodoc --template=emmo.md emmo-inferred emmo.pdf By default, we have configured pandoc to use xelatex for better unicode support. It is possible to change these settings in pandoc-options.yaml and pandoc-pdf-options.yaml .","title":"Generate documentation for EMMO"},{"location":"examples/emmodoc/#content-of-this-directory","text":"","title":"Content of this directory"},{"location":"examples/emmodoc/#ontodoc-templates-with-introductory-text-and-document-layout","text":"emmo.md : Main template for EMMO. It includes the other templates. introduction.md : Introductory text. relations.md : Introduction and sections for Relations chapter. classes.md : Introduction and sections for Classes. figs : Figures used in the introduction.","title":"ontodoc templates with introductory text and document layout"},{"location":"examples/emmodoc/#pandoc-configuration-files","text":"emmodoc-meta.yaml : Metadata for EMMO, like title, authers, abstract, etc. pandoc-options.yaml : General pandoc options. pandoc-html-options.yaml : Additional pandoc options for html generation. pandoc-pdf-options.yaml : Additional pandoc options for pdf generation. pandoc-html.css : css file used for html generation. pandoc-template.html : Modified copy of the standard pandoc html template with a small adjustment for the author list. pandoc-template.tex : Modified copy of the standard pandoc latex template with a small adjustment for the author list.","title":"pandoc configuration files"},{"location":"examples/emmodoc/#using-this-example-as-a-starting-point-for-documenting-your-own-ontology","text":"For simple html documentation, you can skip all input files and simply run ontodoc as ontodoc --format=simple-html YOUR_ONTO.owl YOUR_ONTO.html It is also possible to include ontodoc templates using the --template option for adding additional information and structure the document. In this case the template may only contain ontodoc pre-processer directives and inline html, but not markdown. In order to produce output in pdf (or any other output format supported by pandoc), you can write your ontodoc template in markdown (with ontodoc pre-processer directives) and follow these steps to get started: Copy all the files starting with pandoc- to a new directory. Create a metadata YAML file for your ontology. You can use emmodoc-meta.yaml as a template. Update pandoc-options.yaml . Especially change: input-files to the name of your new yaml metadata file. logo to the path of your logo (or remove it). titlegraphic to the path of your title figure (or remove it). Optionally add ontodoc template files with additional information about your ontology and document layout. That should be it. Good luck!","title":"Using this example as a starting point for documenting your own ontology"},{"location":"examples/emmodoc/classes/","text":"%% %% This file %% This is Markdown file, except of lines starting with %% will %% be stripped off. %% %HEADER \"EMMO Classes\" level=1 emmo is a class representing the collection of all the individuals (signs) that are used in the ontology. Individuals are declared by the EMMO users when they want to apply the EMMO to represent the world. %BRANCHHEAD EMMO The root of all classes used to represent the world. It has two children; collection and item . collection is the class representing the collection of all the individuals (signs) that represents a collection of non-connected real world objects. item Is the class that collects all the individuals that are members of a set (it's the most comprehensive set individual). It is the branch of mereotopology. %% - based on has_part mereological relation that can be axiomatically defined %% - a fusion is the sum of its parts (e.g. a car is made of several %% mechanical parts, an molecule is made of nuclei and electrons) %% - a fusion is of the same entity type as its parts (e.g. a physical %% entity is made of physical entities parts) %% - a fusion can be partitioned in more than one way %BRANCH EMMO %BRANCHDOC Elementary %BRANCHDOC Perspective %BRANCHDOC Holistic %BRANCHDOC Semiotics %BRANCHDOC Sign %BRANCHDOC Interpreter %BRANCHDOC Object %BRANCHDOC Conventional %BRANCHDOC Property %BRANCHDOC Icon %BRANCHDOC Process %BRANCHDOC Perceptual %BRANCHDOC Graphical %BRANCHDOC Geometrical %BRANCHDOC Symbol %BRANCHDOC Mathematical %BRANCHDOC MathematicalSymbol %BRANCHDOC MathematicalModel %BRANCHDOC MathematicalOperator %BRANCHDOC Metrological %BRANCHDOC PhysicalDimension rankdir=RL %BRANCHDOC PhysicalQuantity %BRANCHDOC Number %BRANCHDOC MeasurementUnit %BRANCHDOC UTF8 %BRANCHDOC SIBaseUnit %BRANCHDOC SISpecialUnit rankdir=RL %BRANCHDOC PrefixedUnit %BRANCHDOC MetricPrefix rankdir=RL %BRANCHDOC Quantity %BRANCHDOC BaseQuantity %BRANCHDOC DerivedQuantity rankdir=RL %BRANCHDOC PhysicalConstant %BRANCHDOC Reductionistic %BRANCHDOC Expression %BRANCHDOC Physicalistic %BRANCHDOC ElementaryParticle %BRANCHDOC Subatomic \u00b6 %BRANCHDOC Matter %BRANCHDOC Fluid %BRANCHDOC Mixture %BRANCHDOC StateOfMatter","title":"Classes"},{"location":"examples/emmodoc/classes/#branchdoc-subatomic","text":"%BRANCHDOC Matter %BRANCHDOC Fluid %BRANCHDOC Mixture %BRANCHDOC StateOfMatter","title":"%BRANCHDOC Subatomic"},{"location":"examples/emmodoc/emmo/","text":"%% %% This is the main Markdown input file for the EMMO documentation. %% %% Lines starting with a % are pre-processor directives. %% %INCLUDE introduction.md %INCLUDE relations.md %INCLUDE classes.md %HEADER Individuals level=1 %ALL individuals %HEADER Appendix level=1 %HEADER \"The complete taxonomy of EMMO relations\" level=2 %BRANCHFIG EMMORelation caption='The complete taxonomy of EMMO relations.' terminated=0 relations=all edgelabels=0 %HEADER \"The taxonomy of EMMO classes\" level=2 %BRANCHFIG EMMO caption='The almost complete taxonomy of EMMO classes. Only physical quantities and constants are left out.' terminated=0 relations=isA edgelabels=0 leafs=PhysicalDimension,BaseQuantity,DerivedQuantity,ExactConstant,MeasuredConstant,SIBaseUnit,SISpecialUnit,MetricPrefix,UTF8","title":"Emmo"},{"location":"examples/emmodoc/important_concepts/","text":"Important concepts \u00b6 Mereotopological composition \u00b6 Substrate \u00b6 A substrate represents the place (in general sense) in which every real world item exists. It provides the dimensions of existence for real world entities. This follows from the fact that everything that exists is placed somewhere in space and time. Hence, its space and time coordinates can be used to identify it. Substrates are always topologically connected spaces . A topological space, X, is said to be disconnected if it is the union of two disjoint non-empty open sets. Otherwise, X is said to be connected. substrate is the superclass of space , time and their combinations, like spacetime . Following Kant, space and time are a priori forms of intuition, i.e. they are the substrate upon which we place our intuitions, assigning space and time coordinates to them. Hybrid \u00b6 A hybrid is the combination of space and time . It has the subclasses world_line (0D space + 1D time), world_sheet (1D space + 1D time), world_volume (2D space + 1D time) and spacetime (3D space + 1D time). Spacetime \u00b6 EMMO represents real world entities as subclasses of spacetime . A spacetime is valid for all reference systems (as required by the theory of relativity). Matter \u00b6 matter is used to represent a group of elementary in an enclosing spacetime . As illustrated in the figure, a matter is an elementary or a composition of other matter and vacuum . In EMMO matter is always a 4D spacetime. This is a fundamental difference between EMMO and most other ontologies. In order to describe the real world, we must also take into account the vacuum between the elementaries that composes higher granularity level entity (e.g. an atom). In EMMO vacuum is defined as a spacetime that has no elementary parts. Existent \u00b6 An existent is defined as a matter that unfolds in time as a succession of states. It is used to represent the whole life of a complex but structured state-changing matter entity, like e.g. an atom that becomes ionised and then recombines with an electron. On the contrary, a matter and not existent entity is something \"amorphous\", randomly collected and not classifiable by common terms or definitions. That is a heterogeneous heap of elementary , appearing and disappearing in time. State \u00b6 A state is matter in a particular configurational state. It is defined as having spatial direct parts that persist (do not change) throughout the lifetime of the state . Hence, a state is like a snapshot of a physical in a finite time interval. The use of spatial direct parthood in the definition of state means that a state cannot overlap in space with another state . An important feature of states, that follows from the fact that they are spacetime , is that they constitute a finite time interval. Elementary \u00b6 The basic assumption of decomposition in EMMO, is that the most basic manifestation of matter is represented by a subclass of spacetime called elementary . The elementary class defines the \"atomic\" (undividable) level in EMMO. A generic matter can always be decomposed in proper parts down to the elementary level using proper parthood. An elementary can still be decomposed in temporal parts, that are themselves elementary . Example of elementaries are electrons, photons and quarks. Granularity - direct parthood \u00b6 Granularity is a central concept of EMMO, which allows the user to percieve the world at different levels of detail (granularity) that follow physics and materials science perspectives. Every material in EMMO is placed on a granularity level and the ontology gives information about the direct upper and direct lower level classes. This is done with the non-transitive is_direct_part_of relation. Granularity is a defined class and is useful sine a reasoner automatically can put the individuals defined by the user under a generic class that clearly expresses the types of its compositional parts. Mathematical entities \u00b6 The class mathematical_entity represents fundamental elements of mathematical expressions, like numbers, variables, unknowns and equations. Mathematical entities are pure mathematical and have no physical unit. Natural law \u00b6 A natural_law is an abstraction for a series of experiments that tries to define a common cause and effect of the time evolution of a set of interacting participants. It is (by definition) a pre-mathematical entity. The natural_law class is defined as is_abstraction_for some experiment It can be represented e.g. as a thought in the mind of the experimentalist, a sketch and textual description in a book of science. physical_law and material_law are, according to the RoMM and CWA , the laws behind physical equations and material relations, respectively. Properties \u00b6 Properties are abstracts that are related to a specific material entity with the relation has_property , but that depend on a specific observation process , participated by a specific observer , who catch the physical entity behaviour that is abstracted as a property. Properties enable us to connect a measured property to the measurement process and the measurement instrument.","title":"Important concepts"},{"location":"examples/emmodoc/important_concepts/#important-concepts","text":"","title":"Important concepts"},{"location":"examples/emmodoc/important_concepts/#mereotopological-composition","text":"","title":"Mereotopological composition"},{"location":"examples/emmodoc/important_concepts/#substrate","text":"A substrate represents the place (in general sense) in which every real world item exists. It provides the dimensions of existence for real world entities. This follows from the fact that everything that exists is placed somewhere in space and time. Hence, its space and time coordinates can be used to identify it. Substrates are always topologically connected spaces . A topological space, X, is said to be disconnected if it is the union of two disjoint non-empty open sets. Otherwise, X is said to be connected. substrate is the superclass of space , time and their combinations, like spacetime . Following Kant, space and time are a priori forms of intuition, i.e. they are the substrate upon which we place our intuitions, assigning space and time coordinates to them.","title":"Substrate"},{"location":"examples/emmodoc/important_concepts/#hybrid","text":"A hybrid is the combination of space and time . It has the subclasses world_line (0D space + 1D time), world_sheet (1D space + 1D time), world_volume (2D space + 1D time) and spacetime (3D space + 1D time).","title":"Hybrid"},{"location":"examples/emmodoc/important_concepts/#spacetime","text":"EMMO represents real world entities as subclasses of spacetime . A spacetime is valid for all reference systems (as required by the theory of relativity).","title":"Spacetime"},{"location":"examples/emmodoc/important_concepts/#matter","text":"matter is used to represent a group of elementary in an enclosing spacetime . As illustrated in the figure, a matter is an elementary or a composition of other matter and vacuum . In EMMO matter is always a 4D spacetime. This is a fundamental difference between EMMO and most other ontologies. In order to describe the real world, we must also take into account the vacuum between the elementaries that composes higher granularity level entity (e.g. an atom). In EMMO vacuum is defined as a spacetime that has no elementary parts.","title":"Matter"},{"location":"examples/emmodoc/important_concepts/#existent","text":"An existent is defined as a matter that unfolds in time as a succession of states. It is used to represent the whole life of a complex but structured state-changing matter entity, like e.g. an atom that becomes ionised and then recombines with an electron. On the contrary, a matter and not existent entity is something \"amorphous\", randomly collected and not classifiable by common terms or definitions. That is a heterogeneous heap of elementary , appearing and disappearing in time.","title":"Existent"},{"location":"examples/emmodoc/important_concepts/#state","text":"A state is matter in a particular configurational state. It is defined as having spatial direct parts that persist (do not change) throughout the lifetime of the state . Hence, a state is like a snapshot of a physical in a finite time interval. The use of spatial direct parthood in the definition of state means that a state cannot overlap in space with another state . An important feature of states, that follows from the fact that they are spacetime , is that they constitute a finite time interval.","title":"State"},{"location":"examples/emmodoc/important_concepts/#elementary","text":"The basic assumption of decomposition in EMMO, is that the most basic manifestation of matter is represented by a subclass of spacetime called elementary . The elementary class defines the \"atomic\" (undividable) level in EMMO. A generic matter can always be decomposed in proper parts down to the elementary level using proper parthood. An elementary can still be decomposed in temporal parts, that are themselves elementary . Example of elementaries are electrons, photons and quarks.","title":"Elementary"},{"location":"examples/emmodoc/important_concepts/#granularity-direct-parthood","text":"Granularity is a central concept of EMMO, which allows the user to percieve the world at different levels of detail (granularity) that follow physics and materials science perspectives. Every material in EMMO is placed on a granularity level and the ontology gives information about the direct upper and direct lower level classes. This is done with the non-transitive is_direct_part_of relation. Granularity is a defined class and is useful sine a reasoner automatically can put the individuals defined by the user under a generic class that clearly expresses the types of its compositional parts.","title":"Granularity - direct parthood"},{"location":"examples/emmodoc/important_concepts/#mathematical-entities","text":"The class mathematical_entity represents fundamental elements of mathematical expressions, like numbers, variables, unknowns and equations. Mathematical entities are pure mathematical and have no physical unit.","title":"Mathematical entities"},{"location":"examples/emmodoc/important_concepts/#natural-law","text":"A natural_law is an abstraction for a series of experiments that tries to define a common cause and effect of the time evolution of a set of interacting participants. It is (by definition) a pre-mathematical entity. The natural_law class is defined as is_abstraction_for some experiment It can be represented e.g. as a thought in the mind of the experimentalist, a sketch and textual description in a book of science. physical_law and material_law are, according to the RoMM and CWA , the laws behind physical equations and material relations, respectively.","title":"Natural law"},{"location":"examples/emmodoc/important_concepts/#properties","text":"Properties are abstracts that are related to a specific material entity with the relation has_property , but that depend on a specific observation process , participated by a specific observer , who catch the physical entity behaviour that is abstracted as a property. Properties enable us to connect a measured property to the measurement process and the measurement instrument.","title":"Properties"},{"location":"examples/emmodoc/introduction/","text":"Introduction \u00b6 EMMO is a multidisciplinary effort to develop a standard representational framework (the ontology) based on current materials modelling knowledge, including physical sciences, analytical philosophy and information and communication technologies. This multidisciplinarity is illustrated by the figure on the title page. It provides the connection between the physical world, materials characterisation world and materials modelling world. EMMO is based on and is consistent with the Review of Materials Modelling , CEN Workshop Agreement and MODA template . However, while these efforts are written for humans, EMMO is defined using the Web Ontology Language (OWL) , which is machine readable and allows for machine reasoning. In terms of semantic representation, EMMO brings everything to a much higher level than these foundations. As illustrated in the figure below, EMMO covers all aspects of materials modelling and characterisation, including: the material itself, which must be described in a rigorous way; the observation process involving an observer that percieves the real world (characterisation); the properties that are measured or modelled; the physics laws that describe the material behaviour; the physical models that approximate the physics laws; the solver including the numerical discretisation method that leads to a solvable mathematical representation under certain simplifying assumptions; the numerical solver that performs the calculations; and the post processing of experimental or simulated data. EMMO is released under the Creative Commons license and is available at emmo.info/ . The OWL2-DL sources are available in RDF/XML format. What is an ontology \u00b6 In short, an ontology is a specification of a conceptualization. The word ontology has a long history in philosophy, in which it refers to the subject of existence. The so-called ontological argument for the existence of God was proposed by Anselm of Canterbury in 1078. He defined God as \"that than which nothing greater can be thought\" , and argued that \"if the greatest possible being exists in the mind, it must also exist in reality. If it only exists in the mind, then an even greater being must be possible -- one which exists both in the mind and in reality\" . Even though this example has little to do with todays use of ontologies in e.g. computer science, it illustrates the basic idea; the ontology defines some basic premises (concepts and relations between them) from which it is possible reason to gain new knowledge. For a more elaborated and modern definition of the ontology we refer the reader to the one provided by Tom Gruber (2009) . Another useful introduction to ontologies is the paper Ontology Development 101: A Guide to Creating Your First Ontology by Noy and McGuinness (2001), which is based on the Protege sortware, with which EMMO has been developed. A taxonomy is a hierarchical representation of classes and subclasses connected via is_a relations. Hence, it is a subset of the ontology excluding all but the is_a relations. The main use of taxonomies is for the organisation of classifications. The figure shows a simple example of a taxonomy illustrating a categorisation of four classes into a hierarchy of more higher of levels of generality. In EMMO, the taxonomy is a rooted directed acyclic graph (DAG). This is important since many classification methods relies on this property, see e.g. Valentini (2014) and Robison et al (2015) . Note, that EMMO is a DAG does not prevent some classes from having more than one parent. A Variable is for instance both a Mathematical and a Symbol . See appendix for the full EMMO taxonomy. Primitive elements in EMMO \u00b6 Individuals \u00b6 Individuals are the basic, \"ground level\" components of EMMO. They may include concrete objects such as cars, flowers, stars, persons and molecules, as well as abstract individuals such as a measured height, a specific equation and software programs. Individuals possess attributes in form of axioms that are defined by the user (interpreter) upon declaration. Classes \u00b6 Classes represent concepts. They are the building blocks that we use to create an ontology as a representation of knowledge. We distinguish between defined and non-defined classes. Defined classes are defined by the requirements for being a member of the class. In the graphical representations of EMMO, defined classes are orange. For instance, in the graph of the top-level entity branch below, The root EMMO and a defined class (defined to be the disjoint union of Item and Collection ). Non-defined classes are defined as an abstract group of objects, whose members are defined as belonging to the class. They are yellow in the graphical representations. %BRANCHFIG EMMO leafs=Perspective,Elementary caption='Example of the top-level branch of EMMO showing some classes and relationships between them.' width=460 Axioms \u00b6 Axioms are propositions in a logical framework that define the relations between the individuals and classes. They are used to categorise individuals in classes and to define the defined classes. The simplest form of a class axiom is a class description that just states the existence of the class and gives it an unique identifier. In order to provide more knowledge about the class, class axioms typically contain additional components that state necessary and/or sufficient characteristics of the class. OWL contains three language constructs for combining class descriptions into class axioms: Subclass ( rdfs:subClassOf ) allows one to say that the class extension of a class description is a subset of the class extension of another class description. Equivalence ( owl:equivalentClass ) allows one to say that a class description has exactly the same class extension (i.e. the individuals associated with the class) as another class description. Distjointness ( owl:disjointWith ) allows one to say that the class extension of a class description has no members in common with the class extension of another class description. See the section about Description logic for more information about these language constructs. Axioms are also used to define relations between relations. These are further detailed in the chapter on Relations . Theoretical foundations \u00b6 EMMO build upon several theoretical frameworks. Semiotics \u00b6 Semiotics is the study of meaning-making. It is the dicipline of formulating something that possibly can exist in a defined space and time in the real world. %%It is introdused in EMMO via the %% semion class and used as a way to reduce the complexity of a %%physical to a simple sign (symbol). A Sign is a physical %%entity that can represent another object. %% %%### Set theory %%Set theory is the theory of membership. This is introduced via %%the set class, representing the collection of all individuals %%(signs) that represent a collection of items. Sets are defined %%via the hasMember relations. Mereotopology \u00b6 Mereotopology is the combination of mereology (science of parthood) and topology (mathematical study of the geometrical properties and conservation through deformations). It is introdused via the Item class and based on the mereotopological relations. Items in EMMO are always topologically connected in space and time. EMMO makes a strong distinction between membership and parthood relations. In contrast to collections, items can only have parts that are themselves items. For further information, see Casati and Varzi \"Parts and Places\" (1999) . Physics \u00b6 EMMO is strongly based on physics, with the aim of being able to describe all aspects and all domains of physics, from quantum mechanics to continuum, engeneering, chemistry, etc. EMMO is compatible with both the De Broglie - Bohm and the Copenhagen interpretation of quantum mecanics (see Physical for more comments). EMMO defines a physics-based parthood hierachy under Physical by introducing the following concepts (illustrated in the figure below): Elementary is the fundamental, non-divisible constituent of entities. In EMMO, elementaries are based on the standard model of physics. State is a Physical whose parts does not change during its life time (at the chosen level of granularity). This is consistent with a state within e.g. thermodynamics. Existent is a succession of states. Metrology \u00b6 Metrology is the science of measurements. It introduces units and links them to properties. The description of metrology in EMMO is based on the standards of International System of Quantities (ISQ) and International System of Units (SI) . Description logic \u00b6 Description logic (DL) is a formal knowledge representation language in which the axioms are expressed. It is less expressive than first-order logic (FOL) , but commonly used for providing the logical formalism for ontologies and semantic web. EMMO is expressed in the Web Ontology Language (OWL) , which in turn is based on DL. This brings along features like reasoning. Since it is essential to have a basic notion of OWL and DL, we include here a very brief overview. For a proper introduction to OWL and DL, we refer the reader to sources like Grau et.al. (2008) , OWL2 Primer and OWL Reference . OWL distinguishes between six types of class descriptions: a class identifier (a IRI reference); an exhaustive enumeration of individuals that together form the instances of a class ( owl:oneOf ); a property restriction ( owl:someValuesFrom , owl:allValuesFrom , owl:hasValue , owl:cardinality , owl:minCardinality , owl:maxCardinality ); the intersection of two or more class descriptions ( owl:intersectionOf ); the union of two or more class descriptions ( owl:unionOf ); and the complement of a class description ( owl:complementOf ). Except for the first, all of these refer to defined classes . The table below shows the notation in OWL, DL and the Manchester OWL syntax , all commonly used for the definitions. The Manchester syntax is used by Protege and is designed to not use DL symbols and to be easy and quick to read and write. Several other syntaxes exist for DL. An interesting example is the pure Python syntax proposed by Lamy (2017) , which is used in the open source Owlready2 Python package. The Python API for EMMO is also based on Owlready2. DL Manchester Python + Owlready2 Read Meaning --------------- ----------------- ------------------- ------------------- -------------------- Constants $\\top$ Thing top A special class with every individual as an instance $\\bot$ Nothing bottom The empty class Axioms $A\\doteq B$ A is defined to be Class definition equal to B $A\\sqsubseteq B$ A subclass_of B class A(B): ... all A are B Class inclusion issubclass(A, B) Test for *inclusion* $A\\equiv B$ A equivalent_to B A.equivalent_to.append(B) A is equivalent to B Class equivalence B in A.equivalent_to Test for equivalence $a:A$ a is_a A a = A() a is a A Class assertion ( instantiation ) isinstance(a, A) Test for instance of $(a,b):R$ a object property a.R.append(b) a is R-related to b Property assertion assertion b $(a,n):R$ a data property a.R.append(n) a is R-related to n Data assertion assertion n Constructions $A\\sqcap B$ A and B A & B A and B Class intersection ( conjunction ) $A\\sqcup B$ A or B A | B A or B Class union ( disjunction ) $\\lnot A$ not A Not(A) not A Class complement ( negation ) ${a, b, ...}$ {a, b, ...} OneOf([a, b, ...]) one of a, b, ... Class enumeration $S\\equiv R^-$ S inverse_of R Inverse(R) S is inverse of R Property inverse S.inverse == R Test for *inverse* $\\forall R.A$ R only A R.only(A) all A with R Universal restriction $\\exists R.A$ R some A R.some(A) some A with R Existential restriction $=n R.A$ R exactly n A R.exactly(n, A) Cardinality restriction $\\leq n R.A$ R min n A R.min(n, A) Minimum cardinality restriction $\\geq n R.A$ R max n A R.max(n, A) Minimum cardinality restriction $\\exists R{a}$ R value a R.value(a) Value restriction Decompositions $A\\sqcup B A disjoint with B AllDisjoint([A, B]) A disjoint with B Disjoint \\sqsubseteq\\bot$ B in A.disjoints() Test for disjointness $\\exists R.\\top R domain A R.domain = [A] Classes that the restriction applies to \\sqsubseteq A$ $\\top\\sqsubseteq R range B R.range = [B] All classes that can be the value of the restriction \\forall R.B$ Table: Notation for DL and Protege. A and B are classes, R is an active relation, S is an passive relation, a and b are individuals and n is a literal. Inspired by the Great table of Description Logics . Examples \u00b6 Here are some examples of different class descriptions using both the DL and Manchester notation. Equivalence ( owl:equivalentTo ) \u00b6 Equivalence ($\\equiv$) defines necessary and sufficient conditions. Parent is equivalent to mother or father DL: parent $\\equiv$ mother $\\lor$ father Manchester: parent equivalent_to mother or father Inclusion ( rdf:subclassOf ) \u00b6 Inclusion ($\\sqsubseteq$) defines necessary conditions. An employee is a person. DL: employee $\\sqsubseteq$ person Manchester: employee is_a person Enumeration ( owl:oneOf ) \u00b6 The color of a wine is either white, rose or red: DL: wine_color $\\equiv$ { white , rose , red } Manchester: wine_color equivalent_to {white, rose, red} Existential restriction ( owl:someValuesFrom ) \u00b6 A mother is a woman that has a child (some person): DL: mother $\\equiv$ woman $\\sqcap$ $\\exists$ has_child . person Manchester: mother equivalent_to woman and has_child some person Universal restriction ( owl:allValuesFrom ) \u00b6 All parents that only have daughters: DL: parents_with_only_daughters $\\equiv$ person $\\sqcap$ $\\forall$ has_child . woman Manchester: parents_with_only_daughters equivalent_to person and has_child only woman Value restriction ( owl:hasValue ) \u00b6 The owl:hasValue restriction allows to define classes based on the existence of particular property values. There must be at least one matching property value. All children of Mary: DL: Marys_children $\\equiv$ person $\\sqcap$ $\\exists$ has_parent .{ Mary } Manchester: Marys_children equivalent_to person and has_parent value Mary Property cardinality ( owl:cardinality ) \u00b6 The owl:cardinality restrictions ($\\geq$, $\\leq$ or $\\equiv$) allow to define classes based on the maximum (owl:maxCardinality), minimum (owl:minCardinality) or exact (owl:cardinality) number of occurences. A person with one parent: DL: half_orphant $\\equiv$ person and =1 has_parent . person Manchester: half_orphant equivalent_to person and has_parent exactly 1 person Intersection ( owl:intersectionOf ) \u00b6 Individuals of the intersection ($\\sqcap$) of two classes, are simultaneously instances of both classes. A man is a person that is male: DL: man $\\equiv$ person $\\sqcap$ male Manchester: man equivalent_to person and male Union ( owl:unionOf ) \u00b6 Individuals of the union ($\\sqcup$) of two classes, are either instances of one or both classes. A person is a man or woman: DL: person $\\equiv$ man $\\sqcup$ woman Manchester: person equivalent_to man or woman Complement ( owl:complementOf ) \u00b6 Individuals of the complement ($\\lnot$) of a class, are all individuals that are not member of the class. Not a man: DL: female $\\equiv$ $\\lnot$ male Manchester: female equivalent_to not male The structure of EMMO \u00b6 The EMMO ontology is structured in shells, expressed by specific ontology fragments, that extends from fundamental concepts to the application domains, following the dependency flow. Top Level \u00b6 The EMMO top level is the group of fundamental axioms that constitute the philosophical foundation of the EMMO. Adopting a physicalistic/nominalistic perspective, the EMMO defines real world objects as 4D objects that are always extended in space and time (i.e. real world objects cannot be spaceless nor timeless). For this reason abstract objects, i.e. objects that does not extend in space and time, are forbidden in the EMMO. EMMO is strongly based on the analytical philosophy dicipline semiotic. The role of abstract objects are in EMMO fulfilled by semiotic objects, i.e. real world objects (e.g. symbol or sign) that stand for other real world objects that are to be interpreted by an agent. These symbols appear in actions (semiotic processes) meant to communicate meaning by establishing relationships between symbols (signs). Another important building block of from analytical philosophy is atomistic mereology applied to 4D objects. The EMMO calls it 'quantum mereology', since the there is a epistemological limit to how fine we can resolve space and time due to the uncertanity principles. The mereotopology module introduces the fundamental mereotopological concepts and their relations with the real world objects that they represent. The EMMO uses mereotopology as the ground for all the subsequent ontology modules. The concept of topological connection is used to define the first distinction between ontology entities namely the Item and Collection classes. Items are causally self-connected objects, while collections are causally disconnected. Quantum mereology is represented by the Quantum class. This module introduces also the fundamental mereotopological relations used to distinguish between space and time dimensions. The physical module, defines the Physical objects and the concept of Void that plays a fundamental role in the description of multiscale objects and quantum systems. It also define the Elementary class, that restricts mereological atomism in space. In EMMO, the only univocally defined real world object is the Item individual called Universe that stands for the universe. Every other real world object is a composition of elementaries up to the most comprehensive object; the Universe . Intermediate objects are not univocally defined, but their definition is provided according to some specific philosophical perspectives. This is an expression of reductionism (i.e. objects are made of sub-objects) and epistemological pluralism (i.e. objects are always defined according to the perspective of an interpreter, or a class of interpreters). The Perspective class collects the different ways to represent the objects that populate the conceptual region between the elementary and universe levels. Middle Level \u00b6 The middle level ontologies act as roots for extending the EMMO towards specific application domains. The Reductionistic perspective class uses the fundamental non-transitive parthood relation, called direct parthood, to provide a powerful granularity description of multiscale real world objects. The EMMO can in principle represents the Universe with direct parthood relations as a direct rooted tree up to its elementary constituents. The Phenomenic perspective class introduces the concept of real world objects that express of a recognisable pattern in space or time that impress the user. Under this class the EMMO categorises e.g. formal languages, pictures, geometry, mathematics and sounds. Phenomenic objects can be used in a semiotic process as signs. The Physicalistic perspective class introduces the concept of real world objects that have a meaning for the under applied physics perspective. The Holistic perspective class introduces the concept of real world objects that unfold in time in a way that has a meaning for the EMMO user, through the definition of the classes Process and Participant . The semiotics module introduces the concepts of semiotics and the Semiosis process that has a Sign , an Object and an Interpreter as participants. This forms the basis in EMMO to represent e.g. models, formal languages, theories, information and properties. EMMO relations \u00b6 All EMMO relations are subrelations of the relations found in the two roots: mereotopological and semiotical . The relation hierarchy extends more vertically (i.e. more subrelations) than horizontally (i.e. less sibling relations), facilitating the categorisation and inferencing of individuals. See also the chapter EMMO Relations . Imposing all relations to fall under mereotopology or semiotics is how the EMMO force the developers to respect its perspectives. Two entities are related only by contact or parthood (mereotopology) or by standing one for another (semiosis): no other types of relation are possible within the EMMO. A unique feature in EMMO, is the introduction of direct parthood . As illustrated in the figure below, it is a mereological relation that lacks transitivity. This makes it possible to entities made of parts at different levels of granularity and to go between granularity levels in a well-defined manner. This is paramount for cross scale interoperability. Every material in EMMO is placed on a granularity level and the ontology gives information about the direct upper and direct lower level classes using the non-transitive direct parthood relations. Annotations \u00b6 All entities and relations in EMMO have some attributes, called annotations . In some cases, only the required International Resource Identifier (IRI) and relations are provided. However, descriptive annotations, like elucidation and comment , are planned to be added for all classes and relations. Possible annotations are: Elucidation is a human readable explanation and clearification of the documented class or relation. Example clearifies the elucidation through an example. A class may have several examples, each addressing different aspects. Comment is a clearifying note complementing the definition and elucidation. A class may have several comments, each clearifying different aspects. IRI stands for international resource identifier . It is an identifier that uniquely identifies the class or relation. IRIs are similar to URIs, but are not restricted to the ASCII character set. In EMMO, the IRIs are now valid URLs pointing to the stable version of EMMO. Relations is a list of relations applying to the current class or relation. The relations for relations are special and will be elaborated on in the introduction to chapter [Relations]. Some of the listed relations are defined in the OWL sources, while other are inferred by the reasoner. The relations are expressed using the Manchester OWL syntax introduced in section Description logic . %%### Graphs %%The generated graphs borrow some syntax from the Unified Modelling %%Language (UML) , which is a general purpose language for software %%design and modelling. The table below shows the style used for the %%different types of relations and the concept they correspond to in %%UML. %% %%Relation UML arrow UML concept %%------------- ----------- ----------- %%is-a ![img][isa] inheritance %%disjoint_with ![img][djw] association %%equivalent_to ![img][eqt] association %%encloses ![img][rel] aggregation %%has_abstract_part ![img][rel] aggregation %%has_abstraction ![img][rel] aggregation %%has_representation ![img][rel] aggregation %%has_member ![img][rel] aggregation %%has_property ![img][rel] aggregation %% %%Table: Notation for arrow styles used in the graphs. Only active %%relations are listed. Corresponding passive relations use the same %%style. %% %%[isa]: figs/arrow-is_a.png \"inheritance\" %%[djw]: figs/arrow-disjoint_with.png \"association\" %%[eqt]: figs/arrow-equivalent_to.png \"association\" %%[rel]: figs/arrow-relation.png \"aggregation\" %%All relationships have a direction. In the graphical visualisations, %%the relationships are represented with an arrow pointing from the %%subject to the object. In order to reduce clutter and limit the size %%of the graphs, the relations are abbreviated according to the %%following table: %% %%Relation Abbreviation %%-------- ------------ %%has_part only hp-o %%is_part_of only ipo-o %%has_member some hm-s %%is_member_of some imo-s %%has_abstraction some ha-s %%is_abstraction_of some iao-s %%has_abstract_part only pap-o %%is_abstract_part_of only iapo-o %%has_space_slice some hss-s %%is_space_slice_of some isso-s %%has_time_slice some hts-s %%is_time_slice_of some itso-s %%has_projection some hp-s %%is_projection_of some ipo-s %%has_proper_part some hpp-s %%is_proper_part_of some ippo-s %%has_proper_part_of some hppo-s %%has_spatial_direct_part min hsdp-m %%has_spatial_direct_part some hsdp-s %%has_spatial_direct_part exactly hsdp-e %% %%Table: Abbriviations of relations used in the graphical representation %%of the different subbranches. %% %% %%UML represents classes as a box with three compartments; names, attributes %%and operators. However, since the classes in EMMO have no operators and %%since it gives little meaning to include the OWL annotations as attributes, %%we simply represent the classes as boxes by a name. %% %%As already mentioned, defined classes are colored orange, while %%undefined classes are yellow. %% %% %%","title":"Introduction"},{"location":"examples/emmodoc/introduction/#introduction","text":"EMMO is a multidisciplinary effort to develop a standard representational framework (the ontology) based on current materials modelling knowledge, including physical sciences, analytical philosophy and information and communication technologies. This multidisciplinarity is illustrated by the figure on the title page. It provides the connection between the physical world, materials characterisation world and materials modelling world. EMMO is based on and is consistent with the Review of Materials Modelling , CEN Workshop Agreement and MODA template . However, while these efforts are written for humans, EMMO is defined using the Web Ontology Language (OWL) , which is machine readable and allows for machine reasoning. In terms of semantic representation, EMMO brings everything to a much higher level than these foundations. As illustrated in the figure below, EMMO covers all aspects of materials modelling and characterisation, including: the material itself, which must be described in a rigorous way; the observation process involving an observer that percieves the real world (characterisation); the properties that are measured or modelled; the physics laws that describe the material behaviour; the physical models that approximate the physics laws; the solver including the numerical discretisation method that leads to a solvable mathematical representation under certain simplifying assumptions; the numerical solver that performs the calculations; and the post processing of experimental or simulated data. EMMO is released under the Creative Commons license and is available at emmo.info/ . The OWL2-DL sources are available in RDF/XML format.","title":"Introduction"},{"location":"examples/emmodoc/introduction/#what-is-an-ontology","text":"In short, an ontology is a specification of a conceptualization. The word ontology has a long history in philosophy, in which it refers to the subject of existence. The so-called ontological argument for the existence of God was proposed by Anselm of Canterbury in 1078. He defined God as \"that than which nothing greater can be thought\" , and argued that \"if the greatest possible being exists in the mind, it must also exist in reality. If it only exists in the mind, then an even greater being must be possible -- one which exists both in the mind and in reality\" . Even though this example has little to do with todays use of ontologies in e.g. computer science, it illustrates the basic idea; the ontology defines some basic premises (concepts and relations between them) from which it is possible reason to gain new knowledge. For a more elaborated and modern definition of the ontology we refer the reader to the one provided by Tom Gruber (2009) . Another useful introduction to ontologies is the paper Ontology Development 101: A Guide to Creating Your First Ontology by Noy and McGuinness (2001), which is based on the Protege sortware, with which EMMO has been developed. A taxonomy is a hierarchical representation of classes and subclasses connected via is_a relations. Hence, it is a subset of the ontology excluding all but the is_a relations. The main use of taxonomies is for the organisation of classifications. The figure shows a simple example of a taxonomy illustrating a categorisation of four classes into a hierarchy of more higher of levels of generality. In EMMO, the taxonomy is a rooted directed acyclic graph (DAG). This is important since many classification methods relies on this property, see e.g. Valentini (2014) and Robison et al (2015) . Note, that EMMO is a DAG does not prevent some classes from having more than one parent. A Variable is for instance both a Mathematical and a Symbol . See appendix for the full EMMO taxonomy.","title":"What is an ontology"},{"location":"examples/emmodoc/introduction/#primitive-elements-in-emmo","text":"","title":"Primitive elements in EMMO"},{"location":"examples/emmodoc/introduction/#individuals","text":"Individuals are the basic, \"ground level\" components of EMMO. They may include concrete objects such as cars, flowers, stars, persons and molecules, as well as abstract individuals such as a measured height, a specific equation and software programs. Individuals possess attributes in form of axioms that are defined by the user (interpreter) upon declaration.","title":"Individuals"},{"location":"examples/emmodoc/introduction/#classes","text":"Classes represent concepts. They are the building blocks that we use to create an ontology as a representation of knowledge. We distinguish between defined and non-defined classes. Defined classes are defined by the requirements for being a member of the class. In the graphical representations of EMMO, defined classes are orange. For instance, in the graph of the top-level entity branch below, The root EMMO and a defined class (defined to be the disjoint union of Item and Collection ). Non-defined classes are defined as an abstract group of objects, whose members are defined as belonging to the class. They are yellow in the graphical representations. %BRANCHFIG EMMO leafs=Perspective,Elementary caption='Example of the top-level branch of EMMO showing some classes and relationships between them.' width=460","title":"Classes"},{"location":"examples/emmodoc/introduction/#axioms","text":"Axioms are propositions in a logical framework that define the relations between the individuals and classes. They are used to categorise individuals in classes and to define the defined classes. The simplest form of a class axiom is a class description that just states the existence of the class and gives it an unique identifier. In order to provide more knowledge about the class, class axioms typically contain additional components that state necessary and/or sufficient characteristics of the class. OWL contains three language constructs for combining class descriptions into class axioms: Subclass ( rdfs:subClassOf ) allows one to say that the class extension of a class description is a subset of the class extension of another class description. Equivalence ( owl:equivalentClass ) allows one to say that a class description has exactly the same class extension (i.e. the individuals associated with the class) as another class description. Distjointness ( owl:disjointWith ) allows one to say that the class extension of a class description has no members in common with the class extension of another class description. See the section about Description logic for more information about these language constructs. Axioms are also used to define relations between relations. These are further detailed in the chapter on Relations .","title":"Axioms"},{"location":"examples/emmodoc/introduction/#theoretical-foundations","text":"EMMO build upon several theoretical frameworks.","title":"Theoretical foundations"},{"location":"examples/emmodoc/introduction/#semiotics","text":"Semiotics is the study of meaning-making. It is the dicipline of formulating something that possibly can exist in a defined space and time in the real world. %%It is introdused in EMMO via the %% semion class and used as a way to reduce the complexity of a %%physical to a simple sign (symbol). A Sign is a physical %%entity that can represent another object. %% %%### Set theory %%Set theory is the theory of membership. This is introduced via %%the set class, representing the collection of all individuals %%(signs) that represent a collection of items. Sets are defined %%via the hasMember relations.","title":"Semiotics"},{"location":"examples/emmodoc/introduction/#mereotopology","text":"Mereotopology is the combination of mereology (science of parthood) and topology (mathematical study of the geometrical properties and conservation through deformations). It is introdused via the Item class and based on the mereotopological relations. Items in EMMO are always topologically connected in space and time. EMMO makes a strong distinction between membership and parthood relations. In contrast to collections, items can only have parts that are themselves items. For further information, see Casati and Varzi \"Parts and Places\" (1999) .","title":"Mereotopology"},{"location":"examples/emmodoc/introduction/#physics","text":"EMMO is strongly based on physics, with the aim of being able to describe all aspects and all domains of physics, from quantum mechanics to continuum, engeneering, chemistry, etc. EMMO is compatible with both the De Broglie - Bohm and the Copenhagen interpretation of quantum mecanics (see Physical for more comments). EMMO defines a physics-based parthood hierachy under Physical by introducing the following concepts (illustrated in the figure below): Elementary is the fundamental, non-divisible constituent of entities. In EMMO, elementaries are based on the standard model of physics. State is a Physical whose parts does not change during its life time (at the chosen level of granularity). This is consistent with a state within e.g. thermodynamics. Existent is a succession of states.","title":"Physics"},{"location":"examples/emmodoc/introduction/#metrology","text":"Metrology is the science of measurements. It introduces units and links them to properties. The description of metrology in EMMO is based on the standards of International System of Quantities (ISQ) and International System of Units (SI) .","title":"Metrology"},{"location":"examples/emmodoc/introduction/#description-logic","text":"Description logic (DL) is a formal knowledge representation language in which the axioms are expressed. It is less expressive than first-order logic (FOL) , but commonly used for providing the logical formalism for ontologies and semantic web. EMMO is expressed in the Web Ontology Language (OWL) , which in turn is based on DL. This brings along features like reasoning. Since it is essential to have a basic notion of OWL and DL, we include here a very brief overview. For a proper introduction to OWL and DL, we refer the reader to sources like Grau et.al. (2008) , OWL2 Primer and OWL Reference . OWL distinguishes between six types of class descriptions: a class identifier (a IRI reference); an exhaustive enumeration of individuals that together form the instances of a class ( owl:oneOf ); a property restriction ( owl:someValuesFrom , owl:allValuesFrom , owl:hasValue , owl:cardinality , owl:minCardinality , owl:maxCardinality ); the intersection of two or more class descriptions ( owl:intersectionOf ); the union of two or more class descriptions ( owl:unionOf ); and the complement of a class description ( owl:complementOf ). Except for the first, all of these refer to defined classes . The table below shows the notation in OWL, DL and the Manchester OWL syntax , all commonly used for the definitions. The Manchester syntax is used by Protege and is designed to not use DL symbols and to be easy and quick to read and write. Several other syntaxes exist for DL. An interesting example is the pure Python syntax proposed by Lamy (2017) , which is used in the open source Owlready2 Python package. The Python API for EMMO is also based on Owlready2. DL Manchester Python + Owlready2 Read Meaning --------------- ----------------- ------------------- ------------------- -------------------- Constants $\\top$ Thing top A special class with every individual as an instance $\\bot$ Nothing bottom The empty class Axioms $A\\doteq B$ A is defined to be Class definition equal to B $A\\sqsubseteq B$ A subclass_of B class A(B): ... all A are B Class inclusion issubclass(A, B) Test for *inclusion* $A\\equiv B$ A equivalent_to B A.equivalent_to.append(B) A is equivalent to B Class equivalence B in A.equivalent_to Test for equivalence $a:A$ a is_a A a = A() a is a A Class assertion ( instantiation ) isinstance(a, A) Test for instance of $(a,b):R$ a object property a.R.append(b) a is R-related to b Property assertion assertion b $(a,n):R$ a data property a.R.append(n) a is R-related to n Data assertion assertion n Constructions $A\\sqcap B$ A and B A & B A and B Class intersection ( conjunction ) $A\\sqcup B$ A or B A | B A or B Class union ( disjunction ) $\\lnot A$ not A Not(A) not A Class complement ( negation ) ${a, b, ...}$ {a, b, ...} OneOf([a, b, ...]) one of a, b, ... Class enumeration $S\\equiv R^-$ S inverse_of R Inverse(R) S is inverse of R Property inverse S.inverse == R Test for *inverse* $\\forall R.A$ R only A R.only(A) all A with R Universal restriction $\\exists R.A$ R some A R.some(A) some A with R Existential restriction $=n R.A$ R exactly n A R.exactly(n, A) Cardinality restriction $\\leq n R.A$ R min n A R.min(n, A) Minimum cardinality restriction $\\geq n R.A$ R max n A R.max(n, A) Minimum cardinality restriction $\\exists R{a}$ R value a R.value(a) Value restriction Decompositions $A\\sqcup B A disjoint with B AllDisjoint([A, B]) A disjoint with B Disjoint \\sqsubseteq\\bot$ B in A.disjoints() Test for disjointness $\\exists R.\\top R domain A R.domain = [A] Classes that the restriction applies to \\sqsubseteq A$ $\\top\\sqsubseteq R range B R.range = [B] All classes that can be the value of the restriction \\forall R.B$ Table: Notation for DL and Protege. A and B are classes, R is an active relation, S is an passive relation, a and b are individuals and n is a literal. Inspired by the Great table of Description Logics .","title":"Description logic"},{"location":"examples/emmodoc/introduction/#examples","text":"Here are some examples of different class descriptions using both the DL and Manchester notation.","title":"Examples"},{"location":"examples/emmodoc/introduction/#equivalence-owlequivalentto","text":"Equivalence ($\\equiv$) defines necessary and sufficient conditions. Parent is equivalent to mother or father DL: parent $\\equiv$ mother $\\lor$ father Manchester: parent equivalent_to mother or father","title":"Equivalence (owl:equivalentTo)"},{"location":"examples/emmodoc/introduction/#inclusion-rdfsubclassof","text":"Inclusion ($\\sqsubseteq$) defines necessary conditions. An employee is a person. DL: employee $\\sqsubseteq$ person Manchester: employee is_a person","title":"Inclusion (rdf:subclassOf)"},{"location":"examples/emmodoc/introduction/#enumeration-owloneof","text":"The color of a wine is either white, rose or red: DL: wine_color $\\equiv$ { white , rose , red } Manchester: wine_color equivalent_to {white, rose, red}","title":"Enumeration (owl:oneOf)"},{"location":"examples/emmodoc/introduction/#existential-restriction-owlsomevaluesfrom","text":"A mother is a woman that has a child (some person): DL: mother $\\equiv$ woman $\\sqcap$ $\\exists$ has_child . person Manchester: mother equivalent_to woman and has_child some person","title":"Existential restriction (owl:someValuesFrom)"},{"location":"examples/emmodoc/introduction/#universal-restriction-owlallvaluesfrom","text":"All parents that only have daughters: DL: parents_with_only_daughters $\\equiv$ person $\\sqcap$ $\\forall$ has_child . woman Manchester: parents_with_only_daughters equivalent_to person and has_child only woman","title":"Universal restriction (owl:allValuesFrom)"},{"location":"examples/emmodoc/introduction/#value-restriction-owlhasvalue","text":"The owl:hasValue restriction allows to define classes based on the existence of particular property values. There must be at least one matching property value. All children of Mary: DL: Marys_children $\\equiv$ person $\\sqcap$ $\\exists$ has_parent .{ Mary } Manchester: Marys_children equivalent_to person and has_parent value Mary","title":"Value restriction (owl:hasValue)"},{"location":"examples/emmodoc/introduction/#property-cardinality-owlcardinality","text":"The owl:cardinality restrictions ($\\geq$, $\\leq$ or $\\equiv$) allow to define classes based on the maximum (owl:maxCardinality), minimum (owl:minCardinality) or exact (owl:cardinality) number of occurences. A person with one parent: DL: half_orphant $\\equiv$ person and =1 has_parent . person Manchester: half_orphant equivalent_to person and has_parent exactly 1 person","title":"Property cardinality (owl:cardinality)"},{"location":"examples/emmodoc/introduction/#intersection-owlintersectionof","text":"Individuals of the intersection ($\\sqcap$) of two classes, are simultaneously instances of both classes. A man is a person that is male: DL: man $\\equiv$ person $\\sqcap$ male Manchester: man equivalent_to person and male","title":"Intersection (owl:intersectionOf)"},{"location":"examples/emmodoc/introduction/#union-owlunionof","text":"Individuals of the union ($\\sqcup$) of two classes, are either instances of one or both classes. A person is a man or woman: DL: person $\\equiv$ man $\\sqcup$ woman Manchester: person equivalent_to man or woman","title":"Union (owl:unionOf)"},{"location":"examples/emmodoc/introduction/#complement-owlcomplementof","text":"Individuals of the complement ($\\lnot$) of a class, are all individuals that are not member of the class. Not a man: DL: female $\\equiv$ $\\lnot$ male Manchester: female equivalent_to not male","title":"Complement (owl:complementOf)"},{"location":"examples/emmodoc/introduction/#the-structure-of-emmo","text":"The EMMO ontology is structured in shells, expressed by specific ontology fragments, that extends from fundamental concepts to the application domains, following the dependency flow.","title":"The structure of EMMO"},{"location":"examples/emmodoc/introduction/#top-level","text":"The EMMO top level is the group of fundamental axioms that constitute the philosophical foundation of the EMMO. Adopting a physicalistic/nominalistic perspective, the EMMO defines real world objects as 4D objects that are always extended in space and time (i.e. real world objects cannot be spaceless nor timeless). For this reason abstract objects, i.e. objects that does not extend in space and time, are forbidden in the EMMO. EMMO is strongly based on the analytical philosophy dicipline semiotic. The role of abstract objects are in EMMO fulfilled by semiotic objects, i.e. real world objects (e.g. symbol or sign) that stand for other real world objects that are to be interpreted by an agent. These symbols appear in actions (semiotic processes) meant to communicate meaning by establishing relationships between symbols (signs). Another important building block of from analytical philosophy is atomistic mereology applied to 4D objects. The EMMO calls it 'quantum mereology', since the there is a epistemological limit to how fine we can resolve space and time due to the uncertanity principles. The mereotopology module introduces the fundamental mereotopological concepts and their relations with the real world objects that they represent. The EMMO uses mereotopology as the ground for all the subsequent ontology modules. The concept of topological connection is used to define the first distinction between ontology entities namely the Item and Collection classes. Items are causally self-connected objects, while collections are causally disconnected. Quantum mereology is represented by the Quantum class. This module introduces also the fundamental mereotopological relations used to distinguish between space and time dimensions. The physical module, defines the Physical objects and the concept of Void that plays a fundamental role in the description of multiscale objects and quantum systems. It also define the Elementary class, that restricts mereological atomism in space. In EMMO, the only univocally defined real world object is the Item individual called Universe that stands for the universe. Every other real world object is a composition of elementaries up to the most comprehensive object; the Universe . Intermediate objects are not univocally defined, but their definition is provided according to some specific philosophical perspectives. This is an expression of reductionism (i.e. objects are made of sub-objects) and epistemological pluralism (i.e. objects are always defined according to the perspective of an interpreter, or a class of interpreters). The Perspective class collects the different ways to represent the objects that populate the conceptual region between the elementary and universe levels.","title":"Top Level"},{"location":"examples/emmodoc/introduction/#middle-level","text":"The middle level ontologies act as roots for extending the EMMO towards specific application domains. The Reductionistic perspective class uses the fundamental non-transitive parthood relation, called direct parthood, to provide a powerful granularity description of multiscale real world objects. The EMMO can in principle represents the Universe with direct parthood relations as a direct rooted tree up to its elementary constituents. The Phenomenic perspective class introduces the concept of real world objects that express of a recognisable pattern in space or time that impress the user. Under this class the EMMO categorises e.g. formal languages, pictures, geometry, mathematics and sounds. Phenomenic objects can be used in a semiotic process as signs. The Physicalistic perspective class introduces the concept of real world objects that have a meaning for the under applied physics perspective. The Holistic perspective class introduces the concept of real world objects that unfold in time in a way that has a meaning for the EMMO user, through the definition of the classes Process and Participant . The semiotics module introduces the concepts of semiotics and the Semiosis process that has a Sign , an Object and an Interpreter as participants. This forms the basis in EMMO to represent e.g. models, formal languages, theories, information and properties.","title":"Middle Level"},{"location":"examples/emmodoc/introduction/#emmo-relations","text":"All EMMO relations are subrelations of the relations found in the two roots: mereotopological and semiotical . The relation hierarchy extends more vertically (i.e. more subrelations) than horizontally (i.e. less sibling relations), facilitating the categorisation and inferencing of individuals. See also the chapter EMMO Relations . Imposing all relations to fall under mereotopology or semiotics is how the EMMO force the developers to respect its perspectives. Two entities are related only by contact or parthood (mereotopology) or by standing one for another (semiosis): no other types of relation are possible within the EMMO. A unique feature in EMMO, is the introduction of direct parthood . As illustrated in the figure below, it is a mereological relation that lacks transitivity. This makes it possible to entities made of parts at different levels of granularity and to go between granularity levels in a well-defined manner. This is paramount for cross scale interoperability. Every material in EMMO is placed on a granularity level and the ontology gives information about the direct upper and direct lower level classes using the non-transitive direct parthood relations.","title":"EMMO relations"},{"location":"examples/emmodoc/introduction/#annotations","text":"All entities and relations in EMMO have some attributes, called annotations . In some cases, only the required International Resource Identifier (IRI) and relations are provided. However, descriptive annotations, like elucidation and comment , are planned to be added for all classes and relations. Possible annotations are: Elucidation is a human readable explanation and clearification of the documented class or relation. Example clearifies the elucidation through an example. A class may have several examples, each addressing different aspects. Comment is a clearifying note complementing the definition and elucidation. A class may have several comments, each clearifying different aspects. IRI stands for international resource identifier . It is an identifier that uniquely identifies the class or relation. IRIs are similar to URIs, but are not restricted to the ASCII character set. In EMMO, the IRIs are now valid URLs pointing to the stable version of EMMO. Relations is a list of relations applying to the current class or relation. The relations for relations are special and will be elaborated on in the introduction to chapter [Relations]. Some of the listed relations are defined in the OWL sources, while other are inferred by the reasoner. The relations are expressed using the Manchester OWL syntax introduced in section Description logic . %%### Graphs %%The generated graphs borrow some syntax from the Unified Modelling %%Language (UML) , which is a general purpose language for software %%design and modelling. The table below shows the style used for the %%different types of relations and the concept they correspond to in %%UML. %% %%Relation UML arrow UML concept %%------------- ----------- ----------- %%is-a ![img][isa] inheritance %%disjoint_with ![img][djw] association %%equivalent_to ![img][eqt] association %%encloses ![img][rel] aggregation %%has_abstract_part ![img][rel] aggregation %%has_abstraction ![img][rel] aggregation %%has_representation ![img][rel] aggregation %%has_member ![img][rel] aggregation %%has_property ![img][rel] aggregation %% %%Table: Notation for arrow styles used in the graphs. Only active %%relations are listed. Corresponding passive relations use the same %%style. %% %%[isa]: figs/arrow-is_a.png \"inheritance\" %%[djw]: figs/arrow-disjoint_with.png \"association\" %%[eqt]: figs/arrow-equivalent_to.png \"association\" %%[rel]: figs/arrow-relation.png \"aggregation\" %%All relationships have a direction. In the graphical visualisations, %%the relationships are represented with an arrow pointing from the %%subject to the object. In order to reduce clutter and limit the size %%of the graphs, the relations are abbreviated according to the %%following table: %% %%Relation Abbreviation %%-------- ------------ %%has_part only hp-o %%is_part_of only ipo-o %%has_member some hm-s %%is_member_of some imo-s %%has_abstraction some ha-s %%is_abstraction_of some iao-s %%has_abstract_part only pap-o %%is_abstract_part_of only iapo-o %%has_space_slice some hss-s %%is_space_slice_of some isso-s %%has_time_slice some hts-s %%is_time_slice_of some itso-s %%has_projection some hp-s %%is_projection_of some ipo-s %%has_proper_part some hpp-s %%is_proper_part_of some ippo-s %%has_proper_part_of some hppo-s %%has_spatial_direct_part min hsdp-m %%has_spatial_direct_part some hsdp-s %%has_spatial_direct_part exactly hsdp-e %% %%Table: Abbriviations of relations used in the graphical representation %%of the different subbranches. %% %% %%UML represents classes as a box with three compartments; names, attributes %%and operators. However, since the classes in EMMO have no operators and %%since it gives little meaning to include the OWL annotations as attributes, %%we simply represent the classes as boxes by a name. %% %%As already mentioned, defined classes are colored orange, while %%undefined classes are yellow. %% %% %%","title":"Annotations"},{"location":"examples/emmodoc/relations/","text":"%% %% This file %% This is Markdown file, except of lines starting with %% will %% be stripped off. %% %HEADER \"EMMO Relations\" level=1 In the language of OWL, relations are called properties . However, since relations describe relations between classes and individuals and since properties has an other meaning in EMMO, we only call them relations . Resource Description Framework (RDF) is a W3C standard that is widely used for describing informations on the web and is one of the standards that OWL builds on. RDF expresses information in form of subject-predicate-object triplets. The subject and object are resources (aka items to describe) and the predicate expresses a relationship between the subject and the object. In OWL are the subject and object classes or individuals (or data) while the predicate is a relation. An example of an relationship is the statement dog is_a animal . Here dog is the subject, is_a the predicate and animal the object. %%We distinguish between %% active relations where the subject is acting on the object and %% passive relations where the subject is acted on by the object. OWL distingues between object properties , that link classes or individuals to classes or individuals, and data properties that link individuals to data values. Since EMMO only deals with classes, we will only be discussing object properties. However, in actual simulation or characterisation applications build on EMMO, datatype propertyes will be important. The characteristics of the different properties are described by the following property axioms : rdf:subPropertyOf is used to define that a property is a subproperty of some other property. For instance, in the figure below showing the relation branch, we see that active_relation is a subproperty or relation . The rdf:subPropertyOf axioms forms a taxonomy-like tree for relations. owl:equivalentProperty states that two properties have the same property extension. owl:inverseOf axioms relate active relations to their corresponding passive relations, and vice versa. The root relation relation is its own inverse. owl:FunctionalProperty is a property that can have only one (unique) value y for each instance x, i.e. there cannot be two distinct values y1 and y2 such that the pairs (x,y1) and (x,y2) are both instances of this property. Both object properties and datatype properties can be declared as \"functional\". owl:InverseFunctionalProperty . owl:TransitiveProperty states that if a pair (x,y) is an instance of P, and the pair (y,z) is instance of P, then we can infer that the pair (x,z) is also an instance of P. owl:SymmetricProperty states that if the pair (x,y) is an instance of P, then the pair (y,x) is also an instance of P. A popular example of a symmetric property is the siblingOf relation. rdfs:domain specifies which classes the property applies to. Or said differently, the valid values of the subject in a subject-predicate-object triplet. rdfs:range specifies the property extension, i.e. the valid values of the object in a subject-predicate-object triplet. %HEADER \"Root of EMMO relations\" level=2 %BRANCHFIG EMMORelation caption=\"Top-level of the EMMO relation hierarchy.\" %ENTITY EMMORelation %%BRANCHDOC mereotopological \u00b6 %BRANCHHEAD mereotopological \u00b6 %BRANCH mereotopological \u00b6 %BRANCHDOC connected \u00b6 %BRANCHDOC hasPart %BRANCHDOC semiotical","title":"Relations"},{"location":"examples/emmodoc/relations/#branchdoc-mereotopological","text":"","title":"%%BRANCHDOC mereotopological"},{"location":"examples/emmodoc/relations/#branchhead-mereotopological","text":"","title":"%BRANCHHEAD mereotopological"},{"location":"examples/emmodoc/relations/#branch-mereotopological","text":"","title":"%BRANCH mereotopological"},{"location":"examples/emmodoc/relations/#branchdoc-connected","text":"%BRANCHDOC hasPart %BRANCHDOC semiotical","title":"%BRANCHDOC connected"},{"location":"examples/jupyter-visualization/","text":"Visualise an ontology using pyctoscape in Jupyter Notebook \u00b6 Installation instructions \u00b6 In a terminal, run: cd /path/to/env/dirs python -m venv cytopy # cytopy is my name, you can choose what ouy want source cytopy/bin/activate cd /dir/to/EMMOntoPy/ pip install -e . pip install jupyterlab python -m ipykernel install --user --name = cytopy pip install ipywidgets pip install nodejs # Note requires that node.js and npm has already been isntalled! pip install ipycytoscape pydotplus networkx pip install --upgrade setuptools jupyter labextension install @jupyter-widgets/jupyterlab-manager Test the notebook \u00b6 In a terminal, run: jupyter-lab That should start jupyter kernel and open a new tab in your browser. In the side pane, select team40.ipynb and run the notebook.","title":"Jupyter visualization"},{"location":"examples/jupyter-visualization/#visualise-an-ontology-using-pyctoscape-in-jupyter-notebook","text":"","title":"Visualise an ontology using pyctoscape in Jupyter Notebook"},{"location":"examples/jupyter-visualization/#installation-instructions","text":"In a terminal, run: cd /path/to/env/dirs python -m venv cytopy # cytopy is my name, you can choose what ouy want source cytopy/bin/activate cd /dir/to/EMMOntoPy/ pip install -e . pip install jupyterlab python -m ipykernel install --user --name = cytopy pip install ipywidgets pip install nodejs # Note requires that node.js and npm has already been isntalled! pip install ipycytoscape pydotplus networkx pip install --upgrade setuptools jupyter labextension install @jupyter-widgets/jupyterlab-manager","title":"Installation instructions"},{"location":"examples/jupyter-visualization/#test-the-notebook","text":"In a terminal, run: jupyter-lab That should start jupyter kernel and open a new tab in your browser. In the side pane, select team40.ipynb and run the notebook.","title":"Test the notebook"}]}